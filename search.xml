<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>Hugging Face预训练GPT微调ChatGPT（微调入门！新手友好！）</h1><p>在实战中，⼤多数情况下都不需要从0开始训练模型，⽽是使⽤“⼤⼚”或者其他研究者开源的已经训练好的⼤模型。</p><p>在各种⼤模型开源库中，最具代表性的就是<code>Hugging Face</code>。<code>Hugging Face</code>是⼀家专注于NLP领域的AI公司，开发了⼀个名为<code>Transformers</code>的开源库，该开源库拥有许多预训练后的深度学习模型，如BERT、GPT-2、T5等。<code>Hugging Face</code>的<code>Transformers</code>开源库使研究⼈员和开发⼈员能够更轻松地使⽤这些模型进⾏各种NLP任务，例如⽂本分类、问答、⽂本⽣成等。这个库也提供了简洁、⾼效的API，有助于快速实现⾃然语⾔处理应⽤。</p><p>从Hugging Face下载⼀个GPT-2并微调成ChatGPT，需要遵循的步骤如下。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503191444425.png" alt="image-20250319144401279" style="zoom:67%;"><h2 id="1-安装Hugging-Face-Transformers库">1.安装Hugging Face Transformers库</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers</span><br></pre></td></tr></table></figure><h2 id="2-载入预训练GPT-2模型和分词器">2.载入预训练GPT-2模型和分词器</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导⼊torch</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2Tokenizer <span class="comment"># 导⼊GPT-2分词器</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2LMHeadModel <span class="comment"># 导⼊GPT-2语⾔模型</span></span><br><span class="line">model_name = <span class="string">&quot;gpt2&quot;</span> <span class="comment"># 也可以选择其他模型，如&quot;gpt2-medium&quot; &quot;gpt2-large&quot;等</span></span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(model_name) <span class="comment"># 加载分词器</span></span><br><span class="line">tokenizer.pad_token = <span class="string">&#x27;&#x27;</span> <span class="comment"># 为分词器添加pad token</span></span><br><span class="line">tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span> <span class="comment"># 判断是否有可⽤的GPU</span></span><br><span class="line">model = GPT2LMHeadModel.from_pretrained(model_name).to(device) <span class="comment"># 将模型加载到设备上（CPU或GPU）</span></span><br><span class="line">vocab = tokenizer.get_vocab() <span class="comment"># 获取词汇表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;模型信息：&quot;</span>, model)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分词器信息：&quot;</span>,tokenizer)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;词汇表⼤⼩：&quot;</span>, <span class="built_in">len</span>(vocab))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;部分词汇示例：&quot;</span>, (<span class="built_in">list</span>(vocab.keys())[<span class="number">8000</span>:<span class="number">8005</span>]))</span><br></pre></td></tr></table></figure><h2 id="3-准备微调数据集">3.准备微调数据集</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset  <span class="comment"># 导入PyTorch的Dataset</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义ChatDataset类，继承自PyTorch的Dataset类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, file_path, tokenizer, vocab</span>):</span><br><span class="line">        self.tokenizer = tokenizer  <span class="comment"># 分词器</span></span><br><span class="line">        self.vocab = vocab  <span class="comment"># 词汇表</span></span><br><span class="line">        <span class="comment"># 加载数据并处理，将处理后的输入数据和目标数据赋值给input_data和target_data</span></span><br><span class="line">        self.input_data, self.target_data = self.load_and_process_data(file_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义加载和处理数据的方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_and_process_data</span>(<span class="params">self, file_path</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:  <span class="comment"># 读取文件内容</span></span><br><span class="line">            lines = f.readlines()</span><br><span class="line">        input_data, target_data = [], []</span><br><span class="line">        <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines):  <span class="comment"># 遍历文件的每一行</span></span><br><span class="line">            <span class="keyword">if</span> line.startswith(<span class="string">&quot;User:&quot;</span>):  <span class="comment"># 如以&quot;User:&quot;开头，移除&quot;User: &quot;前缀，并将张量转换为列表</span></span><br><span class="line">                tokens = self.tokenizer(line.strip()[<span class="number">6</span>:], return_tensors=<span class="string">&quot;pt&quot;</span>)[<span class="string">&quot;input_ids&quot;</span>].tolist()[<span class="number">0</span>]</span><br><span class="line">                tokens = tokens + [self.tokenizer.eos_token_id]  <span class="comment"># 添加结束符</span></span><br><span class="line">                input_data.append(torch.tensor(tokens, dtype=torch.long))  <span class="comment"># 添加到input_data</span></span><br><span class="line">            <span class="keyword">elif</span> line.startswith(<span class="string">&quot;AI:&quot;</span>):  <span class="comment"># 如以&quot;AI:&quot;开头，移除&quot;AI: &quot;前缀，并将张量转换为列表</span></span><br><span class="line">                tokens = self.tokenizer(line.strip()[<span class="number">4</span>:], return_tensors=<span class="string">&quot;pt&quot;</span>)[<span class="string">&quot;input_ids&quot;</span>].tolist()[<span class="number">0</span>]</span><br><span class="line">                tokens = tokens + [self.tokenizer.eos_token_id]  <span class="comment"># 添加结束符</span></span><br><span class="line">                target_data.append(torch.tensor(tokens, dtype=torch.long))  <span class="comment"># 添加到target_data</span></span><br><span class="line">        <span class="keyword">return</span> input_data, target_data</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义数据集的长度，即input_data的长度</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.input_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义获取数据集中指定索引的数据的方法</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">return</span> self.input_data[idx], self.target_data[idx]</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&quot;/kaggle/input/hugging-face-chatgpt-chat-data/chat.txt&quot;</span>  <span class="comment"># 加载chat.txt数据集</span></span><br><span class="line">chat_dataset = ChatDataset(file_path, tokenizer, vocab)  <span class="comment"># 创建ChatDataset对象，传入文件、分词器和词汇表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印数据集中前2个数据示例</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    input_example, target_example = chat_dataset[i]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;示例 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入：&quot;</span>, tokenizer.decode(input_example))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输出：&quot;</span>, tokenizer.decode(target_example))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="4-准备微调数据加载器">4.准备微调数据加载器</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader  <span class="comment"># 导入DataLoader</span></span><br><span class="line"></span><br><span class="line">tokenizer.pad_token = <span class="string">&#x27;&#x27;</span>  <span class="comment"># 为分词器添加pad token</span></span><br><span class="line">tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义pad_sequence函数，用于将一批序列补齐到相同长度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pad_sequence</span>(<span class="params">sequences, padding_value=<span class="number">0</span>, length=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 计算最大序列长度，如果length参数未提供，则使用输入序列中的最大长度</span></span><br><span class="line">    max_length = <span class="built_in">max</span>(<span class="built_in">len</span>(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences) <span class="keyword">if</span> length <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> length</span><br><span class="line">    <span class="comment"># 创建一个具有适当形状的全零张量，用于存储补齐后的序列</span></span><br><span class="line">    result = torch.full((<span class="built_in">len</span>(sequences), max_length), padding_value, dtype=torch.long)</span><br><span class="line">    <span class="comment"># 遍历序列，将每个序列的内容复制到张量result中</span></span><br><span class="line">    <span class="keyword">for</span> i, seq <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        end = <span class="built_in">len</span>(seq)</span><br><span class="line">        result[i, :end] = seq[:end]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义collate_fn函数，用于将一个批次的数据整理成适当的形状</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">    <span class="comment"># 从批次中分离源序列和目标序列</span></span><br><span class="line">    sources, targets = <span class="built_in">zip</span>(*batch)</span><br><span class="line">    <span class="comment"># 计算批次中的最大序列长度</span></span><br><span class="line">    max_length = <span class="built_in">max</span>(<span class="built_in">max</span>(<span class="built_in">len</span>(s) <span class="keyword">for</span> s <span class="keyword">in</span> sources), <span class="built_in">max</span>(<span class="built_in">len</span>(t) <span class="keyword">for</span> t <span class="keyword">in</span> targets))</span><br><span class="line">    <span class="comment"># 使用pad_sequence函数补齐源序列和目标序列</span></span><br><span class="line">    sources = pad_sequence(sources, padding_value=tokenizer.pad_token_id, length=max_length)</span><br><span class="line">    targets = pad_sequence(targets, padding_value=tokenizer.pad_token_id, length=max_length)</span><br><span class="line">    <span class="comment"># 返回补齐后的源序列和目标序列</span></span><br><span class="line">    <span class="keyword">return</span> sources, targets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DataLoader</span></span><br><span class="line">chat_dataloader = DataLoader(chat_dataset, batch_size=<span class="number">2</span>, shuffle=<span class="literal">True</span>, collate_fn=collate_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查Dataloader输出</span></span><br><span class="line"><span class="keyword">for</span> input_batch, target_batch <span class="keyword">in</span> chat_dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Input batch tensor size:&quot;</span>, input_batch.size())</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Target batch tensor size:&quot;</span>, target_batch.size())</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> input_batch, target_batch <span class="keyword">in</span> chat_dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Input batch tensor:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(input_batch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Target batch tensor:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(target_batch)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="5-对GPT-2进行微调">5.对GPT-2进行微调</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数，忽略pad_token_id对应的损失值</span></span><br><span class="line">criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行500个epoch的训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (input_batch, target_batch) <span class="keyword">in</span> <span class="built_in">enumerate</span>(chat_dataloader):  <span class="comment"># 遍历数据加载器中的批次</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">        input_batch, target_batch = input_batch.to(device), target_batch.to(device)  <span class="comment"># 输入和目标批次移至设备</span></span><br><span class="line">        </span><br><span class="line">        outputs = model(input_batch)  <span class="comment"># 前向传播</span></span><br><span class="line">        logits = outputs.logits  <span class="comment"># 获取logits</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = criterion(logits.view(-<span class="number">1</span>, <span class="built_in">len</span>(vocab)), target_batch.view(-<span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:  <span class="comment"># 每100个epoch打印一次损失值</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:04d&#125;</span>, cost = <span class="subst">&#123;loss:<span class="number">.6</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="6-用约束解码函数生成回答">6.用约束解码函数生成回答</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义集束解码函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_text_beam_search</span>(<span class="params">model, input_str, max_len=<span class="number">50</span>, beam_width=<span class="number">5</span></span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估模式（不计算梯度）</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 对输入字符串进行编码，并将其转换为张量，然后将其移动到相应的设备上</span></span><br><span class="line">    input_tokens = tokenizer.encode(input_str, return_tensors=<span class="string">&quot;pt&quot;</span>).to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 初始化候选序列列表，包含当前输入序列和其对数概率得分（我们从0开始）</span></span><br><span class="line">    candidates = [(input_tokens, <span class="number">0.0</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 禁用梯度计算，以加速预测过程</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># 迭代生成最大长度的序列</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_len):</span><br><span class="line">            new_candidates = []</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对于每个候选序列</span></span><br><span class="line">            <span class="keyword">for</span> candidate, candidate_score <span class="keyword">in</span> candidates:</span><br><span class="line">                <span class="comment"># 使用模型进行预测</span></span><br><span class="line">                outputs = model(candidate)</span><br><span class="line">                <span class="comment"># 获取输出logits</span></span><br><span class="line">                logits = outputs.logits[:, -<span class="number">1</span>, :]</span><br><span class="line">                <span class="comment"># 获取对数概率得分的top-k值（即beam_width）及其对应的token</span></span><br><span class="line">                scores, next_tokens = torch.topk(logits, beam_width, dim=-<span class="number">1</span>)</span><br><span class="line">                </span><br><span class="line">                final_results = []</span><br><span class="line">                <span class="comment"># 遍历top-k token及其对应的得分</span></span><br><span class="line">                <span class="keyword">for</span> score, next_token <span class="keyword">in</span> <span class="built_in">zip</span>(scores.squeeze(), next_tokens.squeeze()):</span><br><span class="line">                    <span class="comment"># 在当前候选序列中添加新的token</span></span><br><span class="line">                    new_candidate = torch.cat((candidate, next_token.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)), dim=-<span class="number">1</span>)</span><br><span class="line">                    <span class="comment"># 更新候选序列的得分</span></span><br><span class="line">                    new_score = candidate_score - score.item()</span><br><span class="line">                    <span class="comment"># 如果新的token是结束符（eos_token），则将该候选序列添加到最终结果中</span></span><br><span class="line">                    <span class="keyword">if</span> next_token.item() == tokenizer.eos_token_id:</span><br><span class="line">                        final_results.append((new_candidate, new_score))</span><br><span class="line">                    <span class="comment"># 否则，将新的候选序列添加到新候选序列列表中</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        new_candidates.append((new_candidate, new_score))</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 从新候选序列列表中选择得分最⾼的top-k个序列</span></span><br><span class="line">            candidates = <span class="built_in">sorted</span>(new_candidates, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])[:beam_width]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 选择得分最⾼的候选序列</span></span><br><span class="line">        best_candidate, _ = <span class="built_in">sorted</span>(candidates, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 将输出token转换回文本字符串</span></span><br><span class="line">        output_str = tokenizer.decode(best_candidate[<span class="number">0</span>])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 移除输入字符串并修复空格问题</span></span><br><span class="line">        input_len = <span class="built_in">len</span>(tokenizer.encode(input_str))</span><br><span class="line">        output_str = tokenizer.decode(best_candidate.squeeze()[input_len:])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> output_str</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">test_inputs = [</span><br><span class="line">    <span class="string">&quot;what is the weather like today?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;can you recommend a good book?&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出测试结果</span></span><br><span class="line"><span class="keyword">for</span> i, input_str <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_inputs, start=<span class="number">1</span>):</span><br><span class="line">    generated_text = generate_text_beam_search(model, input_str)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;测试 <span class="subst">&#123;i&#125;</span>:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;User: <span class="subst">&#123;input_str&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;AI: <span class="subst">&#123;generated_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">测试1:</span><br><span class="line">User: what is the weather like today?&lt;|endoftext|&gt;</span><br><span class="line">AI: you need an current time for now app with app app app app</span><br><span class="line">测试2:</span><br><span class="line">User: Can you recommend a good book?&lt;|endoftext|&gt;</span><br><span class="line">AI: ockingbird Lee Harper Harper Taylor</span><br></pre></td></tr></table></figure><p>模型的回答虽然称不上完美，但是，我们⾄少能够看出，微调数据集中的信息起到了⼀定的作⽤。第⼀个问题问及天⽓，模型敏锐地指向“app”（应⽤）这个存在于训练语料库中的信息，⽽查看“应⽤”确实是我们希望模型给出的答案。回答第⼆个问题时，模型给出了语料库中所推荐图书的作者的名字“Lee Harper”，⽽书名“To kill a Mockingbird”中的mockingbird是⼀个未知token，模型把它拆解成了三个token。具体信息如下。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tokenizer.encode(<span class="string">&#x27;Mockingbird&#x27;</span>)：[<span class="number">44</span>/<span class="number">76</span>, <span class="number">8629</span>, <span class="number">16944</span>]</span><br><span class="line">tokenizer.decode(<span class="number">44</span>)：<span class="string">&#x27;M&#x27;</span></span><br><span class="line">tokenizer.decode(<span class="number">8629</span>)：<span class="string">&#x27;ocking&#x27;</span></span><br><span class="line">tokenizer.decode(<span class="number">16944</span>)：<span class="string">&#x27;bird&#x27;</span></span><br></pre></td></tr></table></figure><p>因此，在解码时，出现了ockingbird这样的不完整信息，但是其中也的确包含了⼀定的语料库内部的知识。</p><p>⽽微调则针对特定任务进⾏优化。这⼀模式的优势在于，微调过程通常需要较少的训练数据和计算资源，同时仍能获得良好的性能。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>从零到一：如何训练简版生成式GPT模型，快速实现创意写作</h1><h2 id="一、从零到一：你的第一个GPT诞生记">一、从零到一：你的第一个GPT诞生记</h2><p><strong>震撼对比</strong>：使用相同训练数据（全唐诗30万首）</p><ul><li>传统RNN生成：“春风吹又生，花落知多少”（模板化）</li><li>简版GPT生成：“墨染江南烟雨楼，一蓑孤舟任水流。青山不语斜阳暮，白鹭惊飞入画轴”（创意性）</li></ul><p> </p><h2 id="二、自回归机制">二、自回归机制</h2><p>⾃回归模型（Autoregressive Model）是⽣成式模型的⼀种特例，它预测的新⽬标值是基于前⾯若⼲个已⽣成值的。⾃回归模型在时间序列分析、语⾳信号处理、⾃然语⾔处理等领域有⼴泛应⽤。在序列⽣成问题中，⾃回归模型特别重要，⽐如在机器翻译、⽂本⽣成、语⾳合成等任务中，Transformer的解码器、GPT等模型就是基于⾃回归原理的。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503172107844.png" alt="image-20250317210639269" style="zoom:50%;"><p>⽤⾃回归机制来逐词⽣成翻译结果。</p><p>还是使⽤同样的中英翻译数据集，还是使⽤Transformer模型，这⾥我们只是加⼀个⽤贪婪搜索进⾏⽣成式解码的函数，然后在测试过程中调⽤这个函数重新测试。</p><p>之前的数据见：<a href="https://blog.csdn.net/u011146203/article/details/146324014?spm=1001.2014.3001.5502">Transformer：GPT背后的造脑工程全解析（含手搓过程）-CSDN博客</a></p><h3 id="2-1定义贪婪解码器函数">2.1定义贪婪解码器函数</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义贪婪解码器函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">greedy_decoder</span>(<span class="params">model, enc_input, start_symbol</span>):</span><br><span class="line">    <span class="comment"># 对输入数据进行编码，并获得编码器输出以及自注意力权重</span></span><br><span class="line">    enc_outputs, enc_self_attns = model.encoder(enc_input)    </span><br><span class="line">    <span class="comment"># 初始化解码器输入为全零张量，大小为 (1, 5)，数据类型与 enc_input 一致</span></span><br><span class="line">    dec_input = torch.zeros(<span class="number">1</span>, <span class="number">5</span>).type_as(enc_input.data)    </span><br><span class="line">    <span class="comment"># 设置下一个要解码的符号为开始符号</span></span><br><span class="line">    next_symbol = start_symbol    </span><br><span class="line">    <span class="comment"># 循环 5 次，为解码器输入中的每一个位置填充一个符号</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">5</span>):</span><br><span class="line">        <span class="comment"># 将下一个符号放入解码器输入的当前位置</span></span><br><span class="line">        dec_input[<span class="number">0</span>][i] = next_symbol        </span><br><span class="line">        <span class="comment"># 运行解码器，获得解码器输出、解码器自注意力权重和编码器 - 解码器注意力权重</span></span><br><span class="line">        dec_output, _, _ = model.decoder(dec_input, enc_input, enc_outputs)        </span><br><span class="line">        <span class="comment"># 将解码器输出投影到目标词汇空间</span></span><br><span class="line">        projected = model.projection(dec_output)        </span><br><span class="line">        <span class="comment"># 找到具有最高概率的下一个单词</span></span><br><span class="line">        prob = projected.squeeze(<span class="number">0</span>).<span class="built_in">max</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">False</span>)[<span class="number">1</span>]</span><br><span class="line">        next_word = prob.data[i]        </span><br><span class="line">        <span class="comment"># 将找到的下一个单词作为新的符号</span></span><br><span class="line">        next_symbol = next_word.item()        </span><br><span class="line">    <span class="comment"># 返回解码器输入，它包含了生成的符号序列</span></span><br><span class="line">    dec_outputs = dec_input</span><br><span class="line">    <span class="keyword">return</span> dec_outputs</span><br></pre></td></tr></table></figure><p><code>greedy_decoder</code> 实现了贪婪解码算法的过程，其中：</p><ul><li>每次解码时，模型选择概率最大的单词作为下一个符号。</li><li>这个过程在目标序列的每个位置进行，直到生成一个完整的目标序列（此处假设目标序列长度为 5）。</li></ul><p><strong>贪婪解码</strong>是一种简单的解码策略，它总是选择当前时刻最可能的单词，而不考虑全局最优解。虽然这种方法快速，但可能会陷入局部最优解，导致生成的序列不尽如人意。在更复杂的情况下，可能需要使用如 <strong>束搜索</strong>（Beam Search）等策略来改进生成的质量。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用贪婪解码器生成翻译文本</span></span><br><span class="line">enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size=<span class="number">1</span>, test_batch=<span class="literal">True</span>) </span><br><span class="line"><span class="comment"># 使用贪婪解码器生成解码器输入</span></span><br><span class="line">greedy_dec_input = greedy_decoder(model, enc_inputs, start_symbol=corpus.tgt_vocab[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>])</span><br><span class="line"><span class="comment"># 将解码器输入转换为单词序列</span></span><br><span class="line">greedy_dec_output_words = [corpus.tgt_idx2word[n.item()] <span class="keyword">for</span> n <span class="keyword">in</span> greedy_dec_input.squeeze()]</span><br><span class="line"><span class="comment"># 打印编码器输入和贪婪解码器生成的文本</span></span><br><span class="line">enc_inputs_words = [corpus.src_idx2word[code.item()] <span class="keyword">for</span> code <span class="keyword">in</span> enc_inputs[<span class="number">0</span>]]</span><br><span class="line"><span class="built_in">print</span>(enc_inputs_words, <span class="string">&#x27;-&gt;&#x27;</span>, greedy_dec_output_words)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;我&#x27;, &#x27;爱&#x27;, &#x27;学习&#x27;, &#x27;人工智能&#x27;, &#x27;<span class="language-xml"><span class="tag">&lt;<span class="name">pad</span>&gt;</span></span>&#x27;] -&gt; [&#x27;<span class="language-xml"><span class="tag">&lt;<span class="name">sos</span>&gt;</span></span>&#x27;, &#x27;I&#x27;, &#x27;love&#x27;, &#x27;studying&#x27;, &#x27;AI&#x27;]</span><br></pre></td></tr></table></figure><p> </p><h2 id="三、构建GPT模型">三、<strong>构建</strong>GPT模型</h2><h3 id="3-1-搭建GPT模型（解码器）">3.1 搭建GPT模型（解码器）</h3><p>GPT只使⽤了Transformer的解码器部分，其关键组件如下图所示。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503172121029.png" alt="image-20250317212154916" style="zoom:67%;"><p>搭建GPT模型的代码的关键组件如下。</p><p>组件1 多头⾃注意⼒：通过<code>ScaledDotProductAttention</code>类实现缩放点积注意⼒机制，然后通过<code>MultiHeadAttention</code>类实现多头⾃注意⼒机制。</p><p>组件2 逐位置前馈⽹络：通过<code>PoswiseFeedForwardNet</code>类实现逐位置前馈⽹络。</p><p>组件3 正弦位置编码表：通过<code>get_sin_code_table</code>函数⽣成正弦位置编码表。</p><p>组件4 填充掩码：通过<code>get_attn_pad_mask</code>函数为填充<code>token</code>⽣成注意⼒掩码，避免注意⼒机制关注⽆⽤的信息。</p><p>组件5 后续掩码：通过<code>get_attn_subsequent_mask</code>函数为后续<code>token</code>（当前位置后⾯的信息）⽣成注意⼒掩码，避免解码器中的注意⼒机制“偷窥”未来的⽬标数据。</p><p>组件6 解码器层：通过<code>DecoderLayer</code>类定义解码器的单层。</p><p>组件7 解码器：通过<code>Decoder</code>类定义<code>Transformer</code>模型的完整解码器部分。</p><p>组件8 GPT：在解码器的基础上添加⼀个投影层，将解码器输出的特征向量转换为预测结果，实现⽂本⽣成。</p><p>之前在手搓transfomer中已经讲过前五个组件，这次从第六个组件开始讲解。</p><p> </p><h3 id="3-2-解码器层类">3.2 解码器层类</h3><p>因为GPT模型没有编码器组件，也不需要来⾃编码器的输出，因此GPT解码器的实现更简洁。GPT模型也省略了编码器-解码器注意⼒机制，因此模型的训练速度更快。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503172125290.png" alt="image-20250317212502224"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义解码器层类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">        self.self_attn = MultiHeadAttention()  <span class="comment"># 多头自注意力层</span></span><br><span class="line">        self.feed_forward = PoswiseFeedForwardNet()  <span class="comment"># 逐位置前馈网络层</span></span><br><span class="line">        self.norm1 = nn.LayerNorm(d_embedding)  <span class="comment"># 第一个层归一化</span></span><br><span class="line">        self.norm2 = nn.LayerNorm(d_embedding)  <span class="comment"># 第二个层归一化</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs, attn_mask=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 使用多头自注意力处理输入</span></span><br><span class="line">        attn_output, _ = self.self_attn(dec_inputs, dec_inputs, dec_inputs, attn_mask)</span><br><span class="line">        <span class="comment"># 将注意力输出与输入相加并进行第一个层归一化</span></span><br><span class="line">        norm1_outputs = self.norm1(dec_inputs + attn_output)</span><br><span class="line">        <span class="comment"># 将归一化后的输出输入到位置前馈神经网络</span></span><br><span class="line">        ff_outputs = self.feed_forward(norm1_outputs)</span><br><span class="line">        <span class="comment"># 将前馈神经网络输出与第一次归一化后的输出相加并进行第二个层归一化</span></span><br><span class="line">        dec_outputs = self.norm2(norm1_outputs + ff_outputs)</span><br><span class="line">        <span class="keyword">return</span> dec_outputs <span class="comment"># 返回解码器层输出</span></span><br></pre></td></tr></table></figure><p>GPT解码器层的构造⽐<code>Transformer</code>的解码器层简单，仅包含⼀个多头⾃注意⼒层<code>MultiHeadAttention</code>和⼀个逐位置前馈⽹络层<code>PosFeedForwardNet</code>，后⾯接了两个层归⼀化<code>nn.LayerNorm</code>。</p><p>主要是两个归一化层</p><p>解码器层中，两个层归⼀化的作⽤如下。</p><p>■ 第⼀个层归⼀化norm1：在多头⾃注意⼒<code>self_attn</code>处理后，将注意⼒输出<code>attn_output</code>与原始输⼊<code>dec_inputs</code>相加。这种加和操作实现了残差连接，可以加速梯度反向传播，有助于训练深层⽹络。将相加后的结果进⾏层归⼀化。层归⼀化对输⼊进⾏标准化处理，使其具有相同的均值和⽅差。这有助于减少梯度消失或梯度爆炸问题，从⽽提⾼模型训练的稳定性。</p><p>■ 第⼆个层归⼀化norm2：在逐位置前馈⽹络<code>feed_forward</code>处理后，将前馈神经⽹络输出<code>ff_outputs</code>与第⼀个层归⼀化输出<code>norm1_outputs</code>相加。这⾥同样实现了残差连接。将相加后的结果进⾏层归⼀化。这⼀步骤的⽬的与第⼀个层归⼀化相同，即标准化输⼊数据，以提⾼训练稳定性。</p><p> </p><h3 id="3-3-解码器类">3.3 解码器类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  定义解码器类</span></span><br><span class="line">n_layers = <span class="number">6</span>  <span class="comment"># 设置 Decoder 的层数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size, max_seq_len</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        <span class="comment"># 词嵌入层（参数为词典维度）</span></span><br><span class="line">        self.src_emb = nn.Embedding(vocab_size, d_embedding)  </span><br><span class="line">        <span class="comment"># 位置编码层（参数为序列长度）</span></span><br><span class="line">        self.pos_emb = nn.Embedding(max_seq_len, d_embedding)</span><br><span class="line">        <span class="comment"># 初始化 N 个解码器层       </span></span><br><span class="line">        self.layers = nn.ModuleList([DecoderLayer() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)]) </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs</span>):        </span><br><span class="line">        <span class="comment"># 创建位置信息</span></span><br><span class="line">        positions = torch.arange(<span class="built_in">len</span>(dec_inputs), device=dec_inputs.device).unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将词嵌入与位置编码相加</span></span><br><span class="line">        inputs_embedding = self.src_emb(dec_inputs) + self.pos_emb(positions)</span><br><span class="line">        <span class="comment"># 生成自注意力掩码</span></span><br><span class="line">        attn_mask = get_attn_subsequent_mask(inputs_embedding).to(device)</span><br><span class="line">        <span class="comment"># 初始化解码器输入，这是第一层解码器层的输入 </span></span><br><span class="line">        dec_outputs =  inputs_embedding </span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            <span class="comment"># 将输入数据传递给解码器层，并返回解码器层的输出，作为下一层的输入</span></span><br><span class="line">            dec_outputs = layer(dec_outputs, attn_mask) </span><br><span class="line">        <span class="keyword">return</span> dec_outputs <span class="comment"># 返回解码器输出</span></span><br></pre></td></tr></table></figure><p>GPT解码器的结构⽐Transformer解码器的结构简单，因为GPT是⼀个单向⽣成式模型，只关注⽣成⽂本⽽不关注源⽂本。GPT不需要实现编码器-解码器注意⼒的部分，仅接收解码器的输⼊，然后进⾏词嵌⼊和位置编码，并将⼆者相加，继⽽⽣成后续⾃注意⼒掩码，来保证每个位置只能看到当前位置之前的信息，以保持⽣成⽂本的⾃回归特性。最后把嵌⼊向量和掩码信息传递给解码器层，并⾏处理，并接收结果向量==dec_outputs==，然后把它返回给GPT模型。</p><p>一句话说的话就是，解码器只管生成文本。</p><p> </p><h3 id="3-4-GPT组件">3.4 GPT组件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 定义 GPT 模型</span><br><span class="line">class GPT(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, max_seq_len):</span><br><span class="line">        super(GPT, self).__init__()</span><br><span class="line">        self.decoder = Decoder(vocab_size, max_seq_len) # 解码器，用于学习文本生成能力</span><br><span class="line">        self.projection = nn.Linear(d_embedding, vocab_size)  # 全连接层，输出预测结果</span><br><span class="line">    def forward(self, dec_inputs):        </span><br><span class="line">        dec_outputs = self.decoder(dec_inputs) # 将输入数据传递给解码器</span><br><span class="line">        logits = self.projection(dec_outputs) # 传递给全连接层以生成预测</span><br><span class="line">        return logits # 返回预测结py</span><br><span class="line">        果</span><br></pre></td></tr></table></figure><p>在这个简化版的GPT模型中：解码器类负责学习⽂本⽣成能⼒；⼀个全连接层将解码器输出的特征向量映射到⼀个概率分布，表示⽣成每个单词的概率logits，⽤于将解码器的输出转换为与词汇表⼤⼩相匹配的预测结果。</p><p>GPT模型仅包含解码器部分，没有编码器部分。因此，它更适⽤于==⽆条件⽂本⽣成==任务，⽽不是类似机器翻译或问答等需要编码器-解码器结构的任务。</p><p> </p><h2 id="四、完成文本生成任务">四、完成文本生成任务</h2><h3 id="4-1-构建文本生成任务的数据集">4.1 构建文本生成任务的数据集</h3><p>我们要给GPT准备⼀个训练语料库。这个语料库是由现实中存在的⽂字组成的。当然，⽐起维基百科等⼤型语料库，我们的语料库中的数据⽐较少，你可以把它看成⼈类语料库的⼀个缩影。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503181410753.png" alt="image-20250318141004609" style="zoom:67%;"><p>把这个语料库存储在⽂件lang.txt中，等待程序读取。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建语料库</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LanguageCorpus</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentences</span>):</span><br><span class="line">        self.sentences = sentences</span><br><span class="line">        <span class="comment"># 计算语言的最大句子长度，并加 2 以容纳特殊符号 &lt;sos&gt; 和 &lt;eos&gt;</span></span><br><span class="line">        self.seq_len = <span class="built_in">max</span>([<span class="built_in">len</span>(sentence.split()) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences]) + <span class="number">2</span></span><br><span class="line">        self.vocab = self.create_vocabulary() <span class="comment"># 创建源语言和目标语言的词汇表</span></span><br><span class="line">        self.idx2word = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.vocab.items()&#125; <span class="comment"># 创建索引到单词的映射</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_vocabulary</span>(<span class="params">self</span>):</span><br><span class="line">        vocab = &#123;<span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;&lt;sos&gt;&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line">        counter = Counter()</span><br><span class="line">        <span class="comment"># 统计语料库的单词频率</span></span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> self.sentences:</span><br><span class="line">            words = sentence.split()</span><br><span class="line">            counter.update(words)</span><br><span class="line">        <span class="comment"># 创建词汇表，并为每个单词分配一个唯一的索引</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> counter:</span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> vocab:</span><br><span class="line">                vocab[word] = <span class="built_in">len</span>(vocab)</span><br><span class="line">        <span class="keyword">return</span> vocab</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_batch</span>(<span class="params">self, batch_size, test_batch=<span class="literal">False</span></span>):</span><br><span class="line">        input_batch, output_batch = [], [] <span class="comment"># 初始化批数据</span></span><br><span class="line">        sentence_indices = torch.randperm(<span class="built_in">len</span>(self.sentences))[:batch_size] <span class="comment"># 随机选择句子索引</span></span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> sentence_indices:</span><br><span class="line">            sentence = self.sentences[index]</span><br><span class="line">            <span class="comment"># 将句子转换为索引序列</span></span><br><span class="line">            seq = [self.vocab[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>]] + [self.vocab[word] <span class="keyword">for</span> word <span class="keyword">in</span> sentence.split()] + [self.vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]]</span><br><span class="line">            seq += [self.vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (self.seq_len - <span class="built_in">len</span>(seq)) <span class="comment"># 对序列进行填充</span></span><br><span class="line">            <span class="comment"># 将处理好的序列添加到批次中</span></span><br><span class="line">            input_batch.append(seq[:-<span class="number">1</span>])</span><br><span class="line">            output_batch.append(seq[<span class="number">1</span>:])</span><br><span class="line">        <span class="keyword">return</span> torch.LongTensor(input_batch), torch.LongTensor(output_batch)</span><br></pre></td></tr></table></figure><p>这个类的主要功能是创建词汇表、将句⼦转换为索引序列、⽣成批次数据等，其中最重要的是<code>make_batch</code>⽅法中⽣成批次数据时的“向右位移”操作，这是训练⽣成式语⾔模型的关键所在。</p><p>查看一些语料库的数据：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;lang.txt&quot;</span>, <span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> file: <span class="comment"># 从文件中读入语料</span></span><br><span class="line">    sentences = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> file.readlines()]</span><br><span class="line">corpus = LanguageCorpus(sentences) <span class="comment"># 创建语料库</span></span><br><span class="line">vocab_size = <span class="built_in">len</span>(corpus.vocab) <span class="comment"># 词汇表大小</span></span><br><span class="line">max_seq_len = corpus.seq_len <span class="comment"># 最大句子长度（用于设置位置编码）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; 语料库词汇表大小 : <span class="subst">&#123;vocab_size&#125;</span>&quot;</span>) <span class="comment"># 打印词汇表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot; 最长句子长度 : <span class="subst">&#123;max_seq_len&#125;</span>&quot;</span>) <span class="comment"># 打印最大序列长</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语料库词汇表大小 : 133</span><br><span class="line"></span><br><span class="line">最长句子长度 : 17</span><br></pre></td></tr></table></figure><p> </p><h3 id="4-2-训练过程中的自回归">4.2 训练过程中的自回归</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim <span class="comment"># 导入优化器</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span> <span class="comment"># 设置设备</span></span><br><span class="line">model = GPT(vocab_size, max_seq_len).to(device) <span class="comment"># 创建 GPT 模型实例</span></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment"># 损失函数</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.0001</span>) <span class="comment"># 优化器</span></span><br><span class="line">epochs = <span class="number">500</span> <span class="comment"># 训练轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):  <span class="comment"># 训练 epochs 轮</span></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    inputs, targets = corpus.make_batch(batch_size) <span class="comment"># 创建训练数据</span></span><br><span class="line">    inputs, targets = inputs.to(device), targets.to(device)</span><br><span class="line">    outputs = model(inputs) <span class="comment"># 获取模型输出 </span></span><br><span class="line">    loss = criterion(outputs.view(-<span class="number">1</span>, vocab_size), targets.view(-<span class="number">1</span>)) <span class="comment"># 计算损失</span></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 打印损失</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:04d&#125;</span> cost = <span class="subst">&#123;loss:<span class="number">.6</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step() <span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure><p> </p><p>4.3 文本生成的自回归(贪婪搜索)</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试文本生成</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_text</span>(<span class="params">model, input_str, max_len=<span class="number">50</span></span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估（测试）模式，关闭 dropout 和 batch normalization 等训练相关的层</span></span><br><span class="line">    <span class="comment"># 将输入字符串中的每个 token 转换为其在词汇表中的索引</span></span><br><span class="line">    input_tokens = [corpus.vocab[token] <span class="keyword">for</span> token <span class="keyword">in</span> input_str]</span><br><span class="line">    <span class="comment"># 创建一个新列表，将输入的 tokens 复制到输出 tokens 中 , 目前只有输入的词</span></span><br><span class="line">    output_tokens = input_tokens.copy()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁用梯度计算，以节省内存并加速测试过程</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_len):  <span class="comment"># 生成最多 max_len 个 tokens</span></span><br><span class="line">            <span class="comment"># 将输出的 token 转换为 PyTorch 张量，并增加一个代表批次的维度 [1, len(output_tokens)]</span></span><br><span class="line">            inputs = torch.LongTensor(output_tokens).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">            outputs = model(inputs) <span class="comment"># 输出 logits 形状为 [1, len(output_tokens), vocab_size]</span></span><br><span class="line">            <span class="comment"># 在最后一个维度上获取 logits 中的最大值，并返回其索引（即下一个 token）</span></span><br><span class="line">            _, next_token = torch.<span class="built_in">max</span>(outputs[:, -<span class="number">1</span>, :], dim=-<span class="number">1</span>)            </span><br><span class="line">            next_token = next_token.item() <span class="comment"># 将张量转换为 Python 整数            </span></span><br><span class="line">            <span class="keyword">if</span> next_token == corpus.vocab[<span class="string">&quot;&lt;eos&gt;&quot;</span>]:</span><br><span class="line">                <span class="keyword">break</span> <span class="comment"># 如果生成的 token 是 EOS（结束符），则停止生成过程           </span></span><br><span class="line">            output_tokens.append(next_token) <span class="comment"># 将生成的 tokens 添加到 output_tokens 列表</span></span><br><span class="line">    <span class="comment"># 将输出 tokens 转换回文本字符串</span></span><br><span class="line">    output_str = <span class="string">&quot; &quot;</span>.join([corpus.idx2word[token] <span class="keyword">for</span> token <span class="keyword">in</span> output_tokens])</span><br><span class="line">    <span class="keyword">return</span> output_str</span><br><span class="line">input_str = [<span class="string">&quot;Python&quot;</span>] <span class="comment"># 输入一个词：Python</span></span><br><span class="line">generated_text = generate_text(model, input_str) <span class="comment"># 模型跟着这个词生成后续文本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 生成的文本 :&quot;</span>, generated_text) <span class="comment"># 打印预测文本</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">生成的文本 : Python is a popular programming language.</span><br></pre></td></tr></table></figure><p> </p><h2 id="五、使用WikiText2数据集训练Wiki-GPT模型">五、使用WikiText2数据集训练Wiki-GPT模型</h2><p>使⽤⼀个从互联⽹中收集真实语料的数据集WikiText 。</p><p>WikiText数据集是从维基百科上经过验证的精选⽂章集中提取的超过1亿个标记的数据集合。让我们⽤这个更真实的语料数据集，来看⼀看现实世界的模型是如何训练出来的。</p><p>■ ⽬前NLP领域中常⽤数据集的导⼊（通过Torchtext库）、设计（创建PyTorch Dataset）、加载（使⽤PyTorch Data Loader），以及如何将数据集中的数据转换为</p><p>我们的GPT模型可以读取的格式（通过Torchtext的分词⼯具Tokenizer）。</p><p>■ 如何对模型的效能进⾏测试。</p><p>之前的数据集都很⼩，没有拆分成训练数据集和测试数据集的必要，⽽现在，⽤这个真实的、包含上万条语料的数据集，就可以⽤其中的⼀部分数据来测试模型的效能。这样，在多轮训练的过程中，我们就可以选择测试集上得分最⾼的模型。</p><p> </p><h3 id="5-1-用WikiText2构建Dataset和DataLoader">5.1 用WikiText2构建Dataset和DataLoader</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchtext.datasets <span class="keyword">import</span> WikiText2 <span class="comment"># 导入WikiText2</span></span><br><span class="line"><span class="keyword">from</span> torchtext.data.utils <span class="keyword">import</span> get_tokenizer <span class="comment"># 导入Tokenizer分词工具</span></span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> build_vocab_from_iterator <span class="comment"># 导入Vocabulary工具</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset <span class="comment"># 导入Pytorch的DataLoader和Dataset</span></span><br><span class="line"></span><br><span class="line">tokenizer = get_tokenizer(<span class="string">&quot;basic_english&quot;</span>) <span class="comment"># 定义数据预处理所需的tokenizer</span></span><br><span class="line"></span><br><span class="line">train_iter = WikiText2(split=<span class="string">&#x27;train&#x27;</span>) <span class="comment"># 加载WikiText2数据集的训练部分</span></span><br><span class="line">valid_iter = WikiText2(split=<span class="string">&#x27;valid&#x27;</span>) <span class="comment"># 加载WikiText2数据集的验证部分</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个生成器函数，用于将数据集中的文本转换为tokens</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yield_tokens</span>(<span class="params">data_iter</span>):</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data_iter:</span><br><span class="line">        <span class="keyword">yield</span> tokenizer(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建词汇表，包括特殊tokens：&quot;&lt;pad&gt;&quot;, &quot;&lt;sos&gt;&quot;, &quot;&lt;eos&gt;&quot;</span></span><br><span class="line">vocab = build_vocab_from_iterator(yield_tokens(train_iter), </span><br><span class="line">                                  specials=[<span class="string">&quot;&lt;pad&gt;&quot;</span>, <span class="string">&quot;&lt;sos&gt;&quot;</span>, <span class="string">&quot;&lt;eos&gt;&quot;</span>])</span><br><span class="line">vocab.set_default_index(vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印词汇表信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;词汇表大小:&quot;</span>, <span class="built_in">len</span>(vocab))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;词汇示例(word to index):&quot;</span>, </span><br><span class="line">      &#123;word: vocab[word] <span class="keyword">for</span> word <span class="keyword">in</span> [<span class="string">&quot;&lt;pad&gt;&quot;</span>, <span class="string">&quot;&lt;sos&gt;&quot;</span>, <span class="string">&quot;&lt;eos&gt;&quot;</span>, <span class="string">&quot;the&quot;</span>, <span class="string">&quot;apple&quot;</span>]&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset <span class="comment"># 导入Dataset</span></span><br><span class="line">max_seq_len = <span class="number">256</span> <span class="comment"># 设置序列的最大长度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个处理WikiText2数据集的自定义数据集类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WikiDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data_iter, vocab, max_len=max_seq_len</span>):</span><br><span class="line">        self.data = []        </span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> data_iter: <span class="comment"># 遍历数据集，将文本转换为tokens</span></span><br><span class="line">            <span class="comment"># 对每个句子进行tokenization，并截取长度为max_len-2，为&lt;sos&gt;和&lt;eos&gt;留出空间</span></span><br><span class="line">            tokens = tokenizer(sentence)[:max_len - <span class="number">2</span>]</span><br><span class="line">            tokens = [vocab[<span class="string">&quot;&lt;sos&gt;&quot;</span>]] + vocab(tokens) + [vocab[<span class="string">&quot;&lt;eos&gt;&quot;</span>]] <span class="comment"># 添加&lt;sos&gt;和&lt;eos&gt;            </span></span><br><span class="line">            self.data.append(tokens) <span class="comment"># 将处理好的tokens添加到数据集中</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="comment"># 定义数据集的长度</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>): <span class="comment"># 定义数据集的索引方法 (即抽取数据条目)        </span></span><br><span class="line">        source = self.data[idx][:-<span class="number">1</span>] <span class="comment"># 获取当前数据，并将&lt;eos&gt;移除，作为source        </span></span><br><span class="line">        target = self.data[idx][<span class="number">1</span>:] <span class="comment"># 获取当前数据，并将&lt;sos&gt;移除，作为target（右移1位）       </span></span><br><span class="line">        <span class="keyword">return</span> torch.tensor(source), torch.tensor(target) <span class="comment"># 转换为tensor并返回</span></span><br><span class="line"></span><br><span class="line">train_dataset = WikiDataset(train_iter, vocab) <span class="comment"># 创建训练数据集</span></span><br><span class="line">valid_dataset = WikiDataset(valid_iter, vocab) <span class="comment"># 创建验证数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Dataset数据条目: <span class="subst">&#123;<span class="built_in">len</span>(train_dataset)&#125;</span>&quot;</span>)</span><br><span class="line">sample_source, sample_target = train_dataset[<span class="number">100</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;输入序列张量样例: <span class="subst">&#123;sample_source&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目标序列张量样例: <span class="subst">&#123;sample_target&#125;</span>&quot;</span>)</span><br><span class="line">decoded_source = <span class="string">&#x27; &#x27;</span>.join(vocab.lookup_tokens(sample_source.tolist()))</span><br><span class="line">decoded_target = <span class="string">&#x27; &#x27;</span>.join(vocab.lookup_tokens(sample_target.tolist()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;输入序列样例文本: <span class="subst">&#123;decoded_source&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;目标序列样例文本: <span class="subst">&#123;decoded_target&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader <span class="comment"># 导入Dataloader</span></span><br><span class="line"><span class="comment"># 定义pad_sequence函数，用于将一批序列补齐到相同长度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pad_sequence</span>(<span class="params">sequences, padding_value=<span class="number">0</span>, length=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 计算最大序列长度，如果length参数未提供，则使用输入序列中的最大长度</span></span><br><span class="line">    max_length = <span class="built_in">max</span>(<span class="built_in">len</span>(seq) <span class="keyword">for</span> seq <span class="keyword">in</span> sequences) <span class="keyword">if</span> length <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> length    </span><br><span class="line">    <span class="comment"># 创建一个具有适当形状的全零张量，用于存储补齐后的序列</span></span><br><span class="line">    result = torch.full((<span class="built_in">len</span>(sequences), max_length), padding_value, dtype=torch.long)    </span><br><span class="line">    <span class="comment"># 遍历序列，将每个序列的内容复制到结果张量中</span></span><br><span class="line">    <span class="keyword">for</span> i, seq <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        end = <span class="built_in">len</span>(seq)</span><br><span class="line">        result[i, :end] = seq[:end]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义collate_fn函数，用于将一个批次的数据整理成适当的形状</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">collate_fn</span>(<span class="params">batch</span>):</span><br><span class="line">    <span class="comment"># 从批次中分离源序列和目标序列</span></span><br><span class="line">    sources, targets = <span class="built_in">zip</span>(*batch)    </span><br><span class="line">    <span class="comment"># 计算批次中的最大序列长度</span></span><br><span class="line">    max_length = <span class="built_in">max</span>(<span class="built_in">max</span>(<span class="built_in">len</span>(s) <span class="keyword">for</span> s <span class="keyword">in</span> sources), <span class="built_in">max</span>(<span class="built_in">len</span>(t) <span class="keyword">for</span> t <span class="keyword">in</span> targets))    </span><br><span class="line">    <span class="comment"># 使用pad_sequence函数补齐源序列和目标序列</span></span><br><span class="line">    sources = pad_sequence(sources, padding_value=vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>], length=max_length)</span><br><span class="line">    targets = pad_sequence(targets, padding_value=vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>], length=max_length)    </span><br><span class="line">    <span class="comment"># 返回补齐后的源序列和目标序列</span></span><br><span class="line">    <span class="keyword">return</span> sources, targets</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个训练数据加载器，使用自定义的collate_fn函数</span></span><br><span class="line">train_dataloader = DataLoader(train_dataset, batch_size=batch_size, </span><br><span class="line">                              shuffle=<span class="literal">True</span>, collate_fn=collate_fn)</span><br><span class="line"><span class="comment"># 创建一个验证数据加载器，使用自定义的collate_fn函数</span></span><br><span class="line">valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size,</span><br><span class="line">                              shuffle=<span class="literal">False</span>, collate_fn=collate_fn)</span><br></pre></td></tr></table></figure><h3 id="5-2-微调Wik-GPT">5.2 微调Wik-GPT</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim  <span class="comment"># 导入优化器</span></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>  <span class="comment"># 设置设备</span></span><br><span class="line">model = GPT(<span class="built_in">len</span>(vocab), max_seq_len).to(device)  <span class="comment"># 创建GPT模型实例</span></span><br><span class="line">criterion = nn.CrossEntropyLoss(ignore_index=vocab[<span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.0001</span>)  <span class="comment"># 优化器</span></span><br><span class="line">epochs = <span class="number">2</span>  <span class="comment"># 训练轮次</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    epoch_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (source, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_dataloader): <span class="comment"># 用Dataloader加载数据</span></span><br><span class="line">        inputs, targets = source.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 梯度清零</span></span><br><span class="line">        outputs = model(inputs)  <span class="comment"># 获取模型输出</span></span><br><span class="line">        loss = criterion(outputs.view(-<span class="number">1</span>, <span class="built_in">len</span>(vocab)), targets.view(-<span class="number">1</span>))  <span class="comment"># 计算损失</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">        epoch_loss += loss.item()        </span><br><span class="line">        <span class="keyword">if</span> (batch_idx + <span class="number">1</span>) % <span class="number">500</span> == <span class="number">0</span>: <span class="comment"># 每500个批次打印一次损失</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Batch <span class="subst">&#123;batch_idx + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;<span class="built_in">len</span>(train_dataloader)&#125;</span>, Loss: <span class="subst">&#123;loss.item()&#125;</span>&quot;</span>)    </span><br><span class="line">    epoch_loss /= <span class="built_in">len</span>(train_dataloader) <span class="comment"># 每轮打印一次损失</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;epochs&#125;</span>, Average Loss: <span class="subst">&#123;epoch_loss&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="5-3-生成文本">5.3 生成文本</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replace &#x27;model_timestamp.pt&#x27; with your saved model&#x27;s filename</span></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;trained_model_2023-05-05_14-08-24.pt&#x27;</span>))</span><br><span class="line"><span class="comment"># 测试文本生成</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_text_greedy_search</span>(<span class="params">model, input_str, max_len=<span class="number">50</span></span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估（测试）模式，关闭dropout和batch normalization等训练相关的层</span></span><br><span class="line">    <span class="comment"># 将输入字符串中的每个Token 转换为其在词汇表中的索引</span></span><br><span class="line">    input_tokens = [vocab[token] <span class="keyword">for</span> token <span class="keyword">in</span> input_str.split()]</span><br><span class="line">    <span class="comment"># 创建一个新列表，将输入的Token复制到输出Token中,目前只有输入的词</span></span><br><span class="line">    output_tokens = input_tokens.copy()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁用梯度计算，以节省内存并加速测试过程</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_len):  <span class="comment"># 生成最多max_len个Token</span></span><br><span class="line">            <span class="comment"># 将输出token转换为 PyTorch张量，并增加一个代表批次的维度[1, len(output_tokens)]</span></span><br><span class="line">            inputs = torch.LongTensor(output_tokens).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">            outputs = model(inputs) <span class="comment"># 输出 logits形状为[1, len(output_tokens), vocab_size]</span></span><br><span class="line">            logits = outputs[:, -<span class="number">1</span>, :] <span class="comment"># 只关心最后一个时间步（即最新生成的token）的logits</span></span><br><span class="line">            <span class="comment"># 在最后一个维度上获取logits中的最大值，并返回其索引（即下一个Token）</span></span><br><span class="line">            _, next_token = torch.<span class="built_in">max</span>(logits, dim=-<span class="number">1</span>)            </span><br><span class="line">            next_token = next_token.item() <span class="comment"># 将张量转换为Python整数            </span></span><br><span class="line">            <span class="keyword">if</span> next_token == vocab[<span class="string">&quot;&lt;eos&gt;&quot;</span>]:</span><br><span class="line">                <span class="keyword">break</span> <span class="comment"># 如果生成的Token是 EOS（结束符），则停止生成过程           </span></span><br><span class="line">            output_tokens.append(next_token) <span class="comment"># 将生成的Token添加到output_tokens列表</span></span><br><span class="line">    <span class="comment"># 将输出Token转换回文本字符串</span></span><br><span class="line">    output_str = <span class="string">&quot; &quot;</span>.join([vocab.get_itos()[token] <span class="keyword">for</span> token <span class="keyword">in</span> output_tokens</span><br><span class="line">                           <span class="keyword">if</span> vocab.get_itos()[token] != <span class="string">&quot;&lt;pad&gt;&quot;</span> <span class="keyword">and</span> vocab.get_itos()[token] != <span class="string">&quot;&lt;unk&gt;&quot;</span> ])</span><br><span class="line">    <span class="keyword">return</span> output_str</span><br><span class="line"></span><br><span class="line">input_str = <span class="string">&quot;how are you&quot;</span> <span class="comment"># 输入一个词：Python</span></span><br><span class="line">generated_text = generate_text_greedy_search(model, input_str) <span class="comment"># 模型跟着这个字生成后续文本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的文本:&quot;</span>, generated_text) <span class="comment"># 打印预测文本</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义集束搜索的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_text_beam_search</span>(<span class="params">model, input_str, max_len=<span class="number">50</span>, beam_width=<span class="number">5</span></span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 将模型设置为评估（测试）模式，关闭dropout和batch normalization等训练相关的层</span></span><br><span class="line">    <span class="comment"># 将输入字符串中的每个token 转换为其在词汇表中的索引</span></span><br><span class="line">    input_tokens = [vocab[token] <span class="keyword">for</span> token <span class="keyword">in</span> input_str.split()]</span><br><span class="line">    <span class="comment"># 创建一个列表，用于存储候选序列</span></span><br><span class="line">    candidates = [(input_tokens, <span class="number">0.0</span>)]</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  <span class="comment"># 禁用梯度计算，以节省内存并加速测试过程</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_len):  <span class="comment"># 生成最多max_len个tokens</span></span><br><span class="line">            new_candidates = []</span><br><span class="line">            <span class="keyword">for</span> candidate, candidate_score <span class="keyword">in</span> candidates:</span><br><span class="line">                inputs = torch.LongTensor(candidate).unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line">                outputs = model(inputs) <span class="comment"># 输出 logits形状为[1, len(output_tokens), vocab_size]</span></span><br><span class="line">                logits = outputs[:, -<span class="number">1</span>, :] <span class="comment"># 只关心最后一个时间步（即最新生成的token）的logits</span></span><br><span class="line">                <span class="comment"># 找到具有最高分数的前beam_width个tokens</span></span><br><span class="line">                scores, next_tokens = torch.topk(logits, beam_width, dim=-<span class="number">1</span>)</span><br><span class="line">                final_results = [] <span class="comment"># 初始化输出序列</span></span><br><span class="line">                <span class="keyword">for</span> score, next_token <span class="keyword">in</span> <span class="built_in">zip</span>(scores.squeeze(), next_tokens.squeeze()):</span><br><span class="line">                    new_candidate = candidate + [next_token.item()]</span><br><span class="line">                    new_score = candidate_score - score.item()  <span class="comment"># 使用负数，因为我们需要降序排列</span></span><br><span class="line">                    <span class="keyword">if</span> next_token.item() == vocab[<span class="string">&quot;&lt;eos&gt;&quot;</span>]:</span><br><span class="line">                        <span class="comment"># 如果生成的token是EOS（结束符），将其添加到最终结果中</span></span><br><span class="line">                        final_results.append((new_candidate, new_score))</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="comment"># 将新生成的候选序列添加到新候选列表中</span></span><br><span class="line">                        new_candidates.append((new_candidate, new_score))</span><br><span class="line">            <span class="comment"># 从新候选列表中选择得分最高的beam_width个序列</span></span><br><span class="line">            candidates = <span class="built_in">sorted</span>(new_candidates, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])[:beam_width]</span><br><span class="line">    <span class="comment"># 选择得分最高的候选序列</span></span><br><span class="line">    best_candidate, _ = <span class="built_in">sorted</span>(candidates, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 将输出 token 转换回文本字符串</span></span><br><span class="line">    output_str = <span class="string">&quot; &quot;</span>.join([vocab.get_itos()[token] <span class="keyword">for</span> token <span class="keyword">in</span> best_candidate <span class="keyword">if</span> vocab.get_itos()[token] != <span class="string">&quot;&lt;pad&gt;&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> output_str</span><br><span class="line"></span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;trained_model_2023-05-05_14-08-24.pt&#x27;</span>)) <span class="comment"># 加载模型</span></span><br><span class="line">input_str = <span class="string">&quot;my name&quot;</span>  <span class="comment"># 输入几个词</span></span><br><span class="line">generated_text = generate_text_beam_search(model, input_str)  <span class="comment"># 模型跟着这些词生成后续文本</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;生成的文本:&quot;</span>, generated_text)  <span class="comment"># 打印生成的文本</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">生成的文本: my name was also used in 1897 by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games in the common by lucasfilm games</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>Transformer：GPT背后的&quot;造脑工程&quot;全解析（含手搓过程）</h1><p><strong>Transformer</strong> 是人工智能领域的革命性架构，通过<strong>自注意力机制</strong>让模型像人类一样&quot;全局理解&quot;上下文关系。它摒弃传统循环结构，采用<strong>并行计算</strong>实现高效训练，配合<strong>位置编码</strong>破解序列的时空密码，在机器翻译、文本生成等任务中实现质的飞跃。GPT、BERT等顶尖模型均基于Transformer，其<strong>多头注意力</strong>设计如同给AI装上&quot;多核大脑&quot;，可同时捕捉词语间的语法、语义、指代等多维关系，成为通向通用人工智能的重要基石。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503161949640.png" alt="image-20250316194945482"></p><h2 id="一、从-人工智障-到-智能涌现-：Transformer的降维打击">一、从&quot;人工智障&quot;到&quot;智能涌现&quot;：Transformer的降维打击</h2><p><strong>震撼对比实验</strong>：<br>使用相同训练数据（维基百科+图书语料）</p><ul><li>RNN模型：“巴黎是法国的首都，位于__” → “塞纳河畔”（正确率68%）</li><li>Transformer：“巴黎是法国的首都，位于__” → “北部法兰西岛大区”（正确率92%）</li></ul><p><strong>传统模型三大痛点</strong>：</p><ol><li>梯度消失：长距离依赖难以捕捉（如&quot;虽然…但是…&quot;结构）</li><li>计算低效：无法并行处理序列数据</li><li>记忆瓶颈：固定长度上下文窗口</li></ol><p> </p><h2 id="二、位置编码">二、位置编码</h2><p>transfomer的其他结构均在之前文章有过涉及，这里着重讲一下位置编码。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503161952174.png" alt="image-20250316195236095"></p><p>由于Transformer模型不使⽤循环神经⽹络，因此⽆法从序列中学习到位置信息。为了解决这个问题，需要为输⼊序列添加位置编码，将每个词的位置信息加⼊词向量中。</p><p>==通过位置编码加入每一个token的位置信息==</p><p>图中的类似于太极图的那个符号其实是“正弦”符号。正弦位置编码使⽤不同频率的正弦和余弦函数对每个位置进⾏编码。编码后，每个位置都会得到⼀个固定的位置编码，与词向量拼接或相加后，可以作为模型的输⼊。</p><p>正弦位置编码具有平滑性和保留相对位置信息等优点，因此在原始的Transformer论⽂中被采⽤。当然，也有其他位置编码⽅法，如可学习的位置编码，它将位置信息作为模型参数进⾏学习。</p><h2 id="三、分部手搓Transformer核心组件">三、分部手搓Transformer核心组件</h2><p>这个逐步拆解的过程是从中⼼到两边、从左到右进⾏的。也就是从中⼼组件到外围延展，从编码器到解码器延展，然后把它们组合成Transformer类。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503161955544.png" alt="image-20250316195524344">以下是代码的关键组件。</p><p>（1）多头⾃注意⼒：通过<code>ScaledDotProductAttention</code>类实现缩放点积注意⼒机制，然后通过<code>MultiHeadAttention</code>类实现多头⾃注意⼒机制。</p><p>（2）逐位置前馈⽹络：通过<code>PoswiseFeedForwardNet</code>类实现逐位置前馈⽹络。</p><p>（3）正弦位置编码表：通过<code>get_sin_code_table</code>函数⽣成正弦位置编码表。</p><p>（4）填充掩码：通过<code>get_attn_pad_mask</code>函数为填充令牌⽣成注意⼒掩码，避免注意⼒机制关注⽆⽤的信息。</p><p>（5）编码器层：通过<code>EncoderLayer</code>类定义编码器的单层。</p><p>（6）编码器：通过<code>Encoder</code>类定义<code>Transformer</code>完整的编码器部分。</p><p>（7）后续掩码：通过<code>get_attn_subsequent_mask</code>函数为后续令牌（当前位置后⾯的信息）⽣成注意⼒掩码，避免解码器中的注意⼒机制“偷窥”未来的⽬标数据。</p><p>（8）解码器层：通过<code>DecoderLayer</code>类定义解码器的单层。</p><p>（9）解码器：通过<code>Decoder</code>类定义<code>Transformer</code>完整的解码器部分。</p><p>（10）<code>Transformer</code>类：此类将编码器和解码器整合为完整的<code>Transformer</code>模型。</p><h3 id="3-1-多头自注意力（包含残差连接和归一化）">3.1 多头自注意力（包含残差连接和归一化）</h3><p>多头自注意力的结构如下：</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503161958988.png" alt="image-20250316195800877"></p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503161958133.png" alt="image-20250316195813913" style="zoom: 50%;"><p>这⾥我们有两个⼦组件：<code>ScaledDotProductAttention</code>（缩放点积注意⼒）类和<code>MultiHeadAttention</code>（多头⾃注意⼒）类。它们在Transformer架构中负责实现⾃注意⼒机制。</p><p>其中，<code>ScaledDotProductAttention</code>类是构成<code>MultiHeadAttention</code>类的组件元素，也就是说，在多头⾃注意⼒中的每⼀个头，都使⽤缩放点积注意⼒来实现。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入 numpy 库</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch 库</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 torch.nn 库</span></span><br><span class="line">d_k = <span class="number">64</span> <span class="comment"># K(=Q) 维度</span></span><br><span class="line">d_v = <span class="number">64</span> <span class="comment"># V 维度</span></span><br><span class="line"><span class="comment"># 定义缩放点积注意力类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ScaledDotProductAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ScaledDotProductAttention, self).__init__()        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, attn_mask</span>):</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------        </span></span><br><span class="line">        <span class="comment"># Q K V [batch_size, n_heads, len_q/k/v, dim_q=k/v] (dim_q=dim_k)</span></span><br><span class="line">        <span class="comment"># attn_mask [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 计算注意力分数（原始权重）[batch_size，n_heads，len_q，len_k]</span></span><br><span class="line">        scores = torch.matmul(Q, K.transpose(-<span class="number">1</span>, -<span class="number">2</span>)) / np.sqrt(d_k) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------        </span></span><br><span class="line">        <span class="comment"># scores [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 使用注意力掩码，将 attn_mask 中值为 1 的位置的权重替换为极小值</span></span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># attn_mask [batch_size, n_heads, len_q, len_k], 形状和 scores 相同</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------    </span></span><br><span class="line">        scores.masked_fill_(attn_mask, -<span class="number">1e9</span>) </span><br><span class="line">        <span class="comment"># 对注意力分数进行 softmax 归一化</span></span><br><span class="line">        weights = nn.Softmax(dim=-<span class="number">1</span>)(scores) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># weights [batch_size, n_heads, len_q, len_k], 形状和 scores 相同</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------         </span></span><br><span class="line">        <span class="comment"># 计算上下文向量（也就是注意力的输出）, 是上下文信息的紧凑表示</span></span><br><span class="line">        context = torch.matmul(weights, V) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># context [batch_size, n_heads, len_q, dim_v]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------    </span></span><br><span class="line">        <span class="keyword">return</span> context, weights <span class="comment"># 返回上下文向量和注意力分数</span></span><br></pre></td></tr></table></figure><p>整个过程配合代码如下图所示：</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503162011238.png" alt="image-20250316201105122" style="zoom:50%;"><p>前向传播（forward）：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, attn_mask</span>):</span><br></pre></td></tr></table></figure><ul><li><strong><code>Q</code></strong>: 查询向量 (query)，形状是 <code>[batch_size, n_heads, len_q, dim_q]</code>。</li><li><strong><code>K</code></strong>: 键向量 (key)，形状是 <code>[batch_size, n_heads, len_k, dim_k]</code>。</li><li><strong><code>V</code></strong>: 值向量 (value)，形状是 <code>[batch_size, n_heads, len_v, dim_v]</code>。</li><li><strong><code>attn_mask</code></strong>: 注意力掩码 (mask)，形状是 <code>[batch_size, n_heads, len_q, len_k]</code>。用于==在计算注意力时屏蔽某些位置==（例如在解码器中，避免未来位置被看到）。</li></ul><p> </p><p>应用掩码:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scores.masked_fill_(attn_mask, -<span class="number">1e9</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>掩码应用</strong>：<code>attn_mask</code> 具有和 <code>scores</code> 相同的形状（<code>[batch_size, n_heads, len_q, len_k]</code>）。将 <code>attn_mask</code> 中为 <code>1</code> 的位置替换为一个非常小的值 <code>-1e9</code>，这些小值在后续的 <code>softmax</code> 操作中会被“屏蔽”，即变为 0，避免这些位置的注意力权重被关注。</li></ul><p>即1是需要忽略的部分，0是不需要忽略的部分。</p><p>attn_mask生成方式通常取决于以下几个因素：</p><ol><li><strong>解码器中的未来掩码（用于防止信息泄漏）</strong></li></ol><p>在 Transformer 的解码器中，我们需要确保模型只能看到当前时刻及之前的词，而不能看到未来时刻的词。例如，当前时刻的第 <code>t</code> 个位置的查询 <code>Q[t]</code> 应该只依赖于前 <code>t</code> 个位置的键 <code>K</code> 和对应的值 <code>V</code>。这样做的目的是防止在训练时未来信息泄漏。</p><p>例如，如果序列长度是 <code>4</code>，<code>attn_mask</code> 应该是一个上三角矩阵，表示模型不能看到未来时刻的内容。具体来说，<code>attn_mask</code> 会是一个形状为 <code>[batch_size, n_heads, len_q, len_k]</code> 的矩阵，其中 <code>attn_mask[i, j, p, q] = 1</code> 表示第 <code>i</code> 个样本、第 <code>j</code> 个头、第 <code>p</code> 个查询位置和第 <code>q</code> 个键位置之间的注意力需要被屏蔽。</p><p>举个例子，假设 <code>attn_mask</code> 为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]   <span class="comment"># 第 0 个位置只能看到自己</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>]   <span class="comment"># 第 1 个位置可以看到自己和第 0 个位置</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>]   <span class="comment"># 第 2 个位置可以看到自己和前两个位置</span></span><br><span class="line">[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]   <span class="comment"># 第 3 个位置可以看到自己和前三个位置</span></span><br></pre></td></tr></table></figure><p>这样，对于 <code>attn_mask</code> 中的每个位置为 <code>1</code> 的部分，<code>scores</code> 中对应的位置会被屏蔽（设为极小的值 <code>-1e9</code>），从而避免模型在生成时刻 <code>t</code> 的预测时“看到”未来的信息。</p><ol start="2"><li><strong>填充（Padding）掩码（用于忽略填充位置）</strong></li></ol><p>在处理变长输入序列时，序列中的某些位置可能是填充符（<code>&lt;PAD&gt;</code>），这些填充符并不包含实际的信息，因此我们希望忽略它们对注意力计算的影响。为了避免填充符影响模型的注意力计算，我们会将填充符对应的位置的 <code>attn_mask</code> 设置为 <code>1</code>（表示屏蔽这些位置）。</p><p>假设输入序列是：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>]  <span class="comment"># 1, 2, 3 是实际内容，0 是填充符</span></span><br></pre></td></tr></table></figure><p>对应的 <code>attn_mask</code> 可以是：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]  <span class="comment"># 填充符位置被标记为 1，表示要屏蔽</span></span><br></pre></td></tr></table></figure><p>这样，<code>attn_mask</code> 中为 <code>1</code> 的位置就会在计算注意力时被屏蔽，确保填充符不会影响计算。</p><ol start="3"><li><strong>其他任务相关掩码</strong></li></ol><p>有时，<code>attn_mask</code> 也可以根据特定任务的需求自定义。例如，某些任务可能要求在计算注意力时忽略特定的区域，或者仅在特定的部分计算注意力。这种情况通常是通过任务外部的逻辑生成掩码。</p><p> </p><p>下⾯定义多头⾃注意⼒另⼀个⼦组件，多头⾃注意⼒类（这⾥同时包含残差连接和层归⼀化操作）</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义多头自注意力类</span></span><br><span class="line">d_embedding = <span class="number">512</span>  <span class="comment"># Embedding 的维度</span></span><br><span class="line">n_heads = <span class="number">8</span>  <span class="comment"># Multi-Head Attention 中头的个数</span></span><br><span class="line">batch_size = <span class="number">3</span> <span class="comment"># 每一批的数据大小</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MultiHeadAttention, self).__init__()</span><br><span class="line">        self.W_Q = nn.Linear(d_embedding, d_k * n_heads) <span class="comment"># Q的线性变换层</span></span><br><span class="line">        self.W_K = nn.Linear(d_embedding, d_k * n_heads) <span class="comment"># K的线性变换层</span></span><br><span class="line">        self.W_V = nn.Linear(d_embedding, d_v * n_heads) <span class="comment"># V的线性变换层</span></span><br><span class="line">        self.linear = nn.Linear(n_heads * d_v, d_embedding)</span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_embedding)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, Q, K, V, attn_mask</span>): </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># Q K V [batch_size, len_q/k/v, embedding_dim] </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        residual, batch_size = Q, Q.size(<span class="number">0</span>) <span class="comment"># 保留残差连接</span></span><br><span class="line">        <span class="comment"># 将输入进行线性变换和重塑，以便后续处理</span></span><br><span class="line">        q_s = self.W_Q(Q).view(batch_size, -<span class="number">1</span>, n_heads, d_k).transpose(<span class="number">1</span>,<span class="number">2</span>)        </span><br><span class="line">        k_s = self.W_K(K).view(batch_size, -<span class="number">1</span>, n_heads, d_k).transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">        v_s = self.W_V(V).view(batch_size, -<span class="number">1</span>, n_heads, d_v).transpose(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># q_s k_s v_s: [batch_size, n_heads, len_q/k/v, d_q=k/v]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------- </span></span><br><span class="line">        <span class="comment"># 将注意力掩码复制到多头 attn_mask: [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        attn_mask = attn_mask.unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># attn_mask [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------- </span></span><br><span class="line">        <span class="comment"># 使用缩放点积注意力计算上下文和注意力权重</span></span><br><span class="line">        context, weights = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># context [batch_size, n_heads, len_q, dim_v]</span></span><br><span class="line">        <span class="comment"># weights [batch_size, n_heads, len_q, len_k]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------- </span></span><br><span class="line">        <span class="comment"># 通过调整维度将多个头的上下文向量连接在一起</span></span><br><span class="line">        context = context.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, -<span class="number">1</span>, n_heads * d_v) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># context [batch_size, len_q, n_heads * dim_v]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 用一个线性层把连接后的多头自注意力结果转换，原始地嵌入维度</span></span><br><span class="line">        output = self.linear(context) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># output [batch_size, len_q, embedding_dim]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 与输入 (Q) 进行残差链接，并进行层归一化后输出</span></span><br><span class="line">        output = self.layer_norm(output + residual)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># output [batch_size, len_q, embedding_dim]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="keyword">return</span> output, weights <span class="comment"># 返回层归一化的输出和注意力权重</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503162025160.png" alt="image-20250316202555045"></p><p>==将输⼊进⾏线性变换和重塑，就是为了形成多个头==</p><p> </p><h3 id="3-2-逐位置前馈网络（包含残差连接和层归一化）">3.2 逐位置前馈网络（包含残差连接和层归一化）</h3><p>前馈神经⽹络（Feed-Forward Network）我们都了解，是⼀个包含全连接层的神经络。这种⽹络在计算过程中是按照从输⼊到输出的⽅向进⾏前馈传播的。</p><p>但是这个“Position- wise”如何理解？</p><p>在这⾥，“Poswise”或“Position-wise”是指这个前馈神经⽹络独⽴地作⽤在输⼊序列的每个位置（即token）上，也就是对⾃注意⼒机制处理后的结果上的各个位置进⾏独⽴处理，⽽不是把⾃注意⼒结果展平之后，以⼀个⼤的⼀维张量的形式整体输⼊前馈⽹络。这意味着对于序列中的每个位置，我们都在该位置应⽤相同的神经⽹络，做相同的处理，并且不会受到其他位置的影响。因此，逐位置操作保持了输⼊序列的原始顺序</p><p>所以⽆论是多头⾃注意⼒组件，还是前馈神经⽹络组件，都严格地保证“队形”，不打乱、不整合、不循环，⽽这种对序列位置信息的完整保持和并⾏处理，正是Transformer的核⼼思路。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义逐位置前馈网络类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PoswiseFeedForwardNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_ff=<span class="number">2048</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PoswiseFeedForwardNet, self).__init__()</span><br><span class="line">        <span class="comment"># 定义一维卷积层 1，用于将输入映射到更高维度</span></span><br><span class="line">        self.conv1 = nn.Conv1d(in_channels=d_embedding, out_channels=d_ff, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 定义一维卷积层 2，用于将输入映射回原始维度</span></span><br><span class="line">        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_embedding, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 定义层归一化</span></span><br><span class="line">        self.layer_norm = nn.LayerNorm(d_embedding)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs</span>): </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># inputs [batch_size, len_q, embedding_dim]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------                       </span></span><br><span class="line">        residual = inputs  <span class="comment"># 保留残差连接 </span></span><br><span class="line">        <span class="comment"># 在卷积层 1 后使用 ReLU 激活函数 </span></span><br><span class="line">        output = nn.ReLU()(self.conv1(inputs.transpose(<span class="number">1</span>, <span class="number">2</span>))) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># output [batch_size, d_ff, len_q]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 使用卷积层 2 进行降维 </span></span><br><span class="line">        output = self.conv2(output).transpose(<span class="number">1</span>, <span class="number">2</span>) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># output [batch_size, len_q, embedding_dim]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 与输入进行残差链接，并进行层归一化</span></span><br><span class="line">        output = self.layer_norm(output + residual) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 -------------------------------- </span></span><br><span class="line">        <span class="comment"># output [batch_size, len_q, embedding_dim]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------</span></span><br><span class="line">        <span class="keyword">return</span> output <span class="comment"># 返回加入残差连接后层归一化的结果</span></span><br></pre></td></tr></table></figure><p>PoswiseFeedForwardNet类实现了逐位置前馈⽹络，⽤于处理Transformer中⾃注意⼒机制的输出。其中包含两个⼀维卷积层，它们⼀个负责将输⼊映射到更⾼维度，⼀个再把它映射回原始维度。在两个卷积层之间，使⽤了<code>ReLU</code>函数。</p><p>在这⾥，⽤⼀维卷积层代替了论⽂中的全连接层（线性层）来实现前馈神经⽹络。其原因是全连接层不共享权重，⽽⼀维卷积层在各个位置上共享权重，所以能够减少⽹络参数的数量。</p><p>⼀维卷积层的⼯作原理是将卷积核（也称为过滤器或特征映射）沿输⼊序列的⼀个维度滑动（如下图所示），并在每个位置进⾏点积操作。在这种情况下，我们使⽤⼤⼩为1的卷积核。这样，卷积操作实际上只会在输⼊序列的⼀个位置进⾏计算，因此它能够独⽴地处理输⼊序列中的每个位置。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503162049287.png" alt="image-20250316204907198" style="zoom:50%;"><p>在PoswiseFeedForwardNet类中，⾸先通过使⽤conv1的多个卷积核将输⼊序列映射到更⾼的维度（程序中是2048维，这是⼀个可调节的超参数），并应⽤ReLU函数。</p><p>接着，conv2将映射后的序列降维到原始维度。这个过程在输⼊序列的每个位置上都是独⽴完成的，因为⼀维卷积层会在每个位置进⾏逐点操作。所以，逐位置前馈神经⽹络能够在每个位置上分别应⽤相同的运算，从⽽捕捉输⼊序列中各个位置的信息。</p><p>逐位置前馈神经网络有下⾯⼏个作⽤。</p><p>（1）增强模型的表达能⼒。FFN为模型提供了更强⼤的表达能⼒，==使其能够捕捉输⼊序列中更复杂的模式==。通过逐位置前馈神经⽹络和⾃注意⼒机制的组合，Transformer可以==学习到不同位置之间的⻓距离依赖关系==。</p><p>（2）信息融合。==FFN可以将⾃注意⼒机制输出的信息进⾏融合。==每个位置上的信息在经过FFN后，都会得到⼀个新表示。这个新表示可以看作原始信息在经过⼀定程度的⾮线性变换之后的结果。</p><p>（3）层间传递。在Transformer中，逐位置前馈神经⽹络将在每个编码器和解码器层中使⽤。</p><p>这样可以确保每⼀层的输出都经过了FFN的处理，从⽽在多层次上捕捉到序列中的特征。多头⾃注意⼒层和逐位置前馈神经⽹络层是编码器层结构中的两个主要组件，不过，在开始构建编码器层之前，还要再定义两个辅助性的组件。第⼀个是位置编码表，第⼆个是⽣成填充注意⼒掩码的函数。</p><p> </p><h3 id="3-3-正弦编码表">3.3 正弦编码表</h3><p>Transformer模型的并⾏结构导致它不是按位置顺序来处理序列的，但是在处理序列尤其是注意⼒计算的过程中，仍需要位置信息来帮助捕捉序列中的顺序关系。为了解决这个问题，需要向输⼊序列中添加位置编码。</p><p>Tansformer的原始论⽂中使⽤的是正弦位置编码。它的计算公式如下：<br>$$<br>PE(\mathrm{pos},2i)=\sin\left(\frac{\mathrm{pos}}{10000^{2i/d}}\right)<br>$$</p><p>$$<br>PE(\mathrm{pos},2i+1)=\cos\left(\frac{\mathrm{pos}}{10000^{2ild}}\right)<br>$$</p><p>这种位置编码⽅式具有周期性和连续性的特点，可以让模型学会捕捉位置之间的相对关系和全</p><p>局关系。这个公式可以⽤于计算位置嵌⼊向量中每个维度的⻆度值。</p><p>■ pos：单词/标记在句⼦中的位置，从0到seq_len-1。</p><p>■ <em>d</em>：单词/标记嵌⼊向量的维度embedding_dim。</p><p>■ <em>i</em>：嵌⼊向量中的每个维度，从0到 $\frac{d}{2}-1$</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成正弦位置编码表的函数，用于在 Transformer 中引入位置信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_sin_enc_table</span>(<span class="params">n_position, embedding_dim</span>):</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># n_position: 输入序列的最大长度</span></span><br><span class="line">    <span class="comment"># embedding_dim: 词嵌入向量的维度</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------    </span></span><br><span class="line">    <span class="comment"># 根据位置和维度信息，初始化正弦位置编码表</span></span><br><span class="line">    sinusoid_table = np.zeros((n_position, embedding_dim))    </span><br><span class="line">    <span class="comment"># 遍历所有位置和维度，计算角度值</span></span><br><span class="line">    <span class="keyword">for</span> pos_i <span class="keyword">in</span> <span class="built_in">range</span>(n_position):</span><br><span class="line">        <span class="keyword">for</span> hid_j <span class="keyword">in</span> <span class="built_in">range</span>(embedding_dim):</span><br><span class="line">            angle = pos_i / np.power(<span class="number">10000</span>, <span class="number">2</span> * (hid_j // <span class="number">2</span>) / embedding_dim)</span><br><span class="line">            sinusoid_table[pos_i, hid_j] = angle    </span><br><span class="line">    <span class="comment"># 计算正弦和余弦值</span></span><br><span class="line">    sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>] = np.sin(sinusoid_table[:, <span class="number">0</span>::<span class="number">2</span>])  <span class="comment"># dim 2i 偶数维</span></span><br><span class="line">    sinusoid_table[:, <span class="number">1</span>::<span class="number">2</span>] = np.cos(sinusoid_table[:, <span class="number">1</span>::<span class="number">2</span>])  <span class="comment"># dim 2i+1 奇数维    </span></span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># sinusoid_table 的维度是 [n_position, embedding_dim]</span></span><br><span class="line">    <span class="comment">#----------------------------------------------------------------   </span></span><br><span class="line">    <span class="keyword">return</span> torch.FloatTensor(sinusoid_table)  <span class="comment"># 返回正弦位置编码表</span></span><br></pre></td></tr></table></figure><p>事实上，使⽤1、2、3、4等⾃然数序列作为位置编码确实可以为序列中的不同位置提供区分性。然⽽，这种⽅法可能在某些⽅⾯不如正弦和余弦函数⽣成的位置嵌⼊向量有效。</p><p>当我们使⽤⾃然数序列作为位置编码时，这些==编码是线性的==。这意味着相邻位置之间的差异在整个序列中保持恒定。然⽽，在许多任务中，==不同位置之间的关系可能更复杂==，可能需要⼀种能够捕捉到这种复杂关系的编码⽅法。</p><p>正弦和余弦函数⽣成的位置嵌⼊向量具有周期性和正交性，因此可以产⽣在各个尺度上都有区分性的位置嵌⼊。这使得模型可以==更容易地学习到序列中不同位置之间的关系==，特别是在捕捉⻓距离依赖关系时可能表现得更好。</p><p>所以，虽然使⽤⾃然数序列（1、2、3、4等）作为位置编码可以做⼀定的区分，但正弦和余弦函数⽣成的位置嵌⼊向量在捕捉序列中更复杂的位置关系⽅⾯更具优势。</p><p> </p><h3 id="3-4-填充掩码">3.4 填充掩码</h3><p>在NLP任务中，输⼊序列的⻓度通常是不固定的。为了能够同时处理多个序列，我们需要将这些序列填充到相同的⻓度，将不等⻓的序列补充到等⻓，这样才能将它们整合成同⼀个批次进⾏训练。</p><p>通常使⽤⼀个特殊的标记（如，编码后这个token的值通常是0）来表示填充部分。</p><p>然⽽，这些填充符号并没有实际的含义，所以我们希望模型在计算注意⼒时忽略它们。因此，在编码器的输⼊部分，我们使⽤了填充位的注意⼒掩码机制（如下⻚图所示）。这个掩码机制的作⽤是在注意⼒计算的时候把⽆⽤的信息屏蔽，防⽌模型在计算注意⼒权重时关注到填充位。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503171820336.png" alt="image-20250317181955015" style="zoom:67%;"><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义填充注意力掩码函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_pad_mask</span>(<span class="params">seq_q, seq_k</span>):</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># seq_q 的维度是 [batch_size, len_q]</span></span><br><span class="line">    <span class="comment"># seq_k 的维度是 [batch_size, len_k]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    batch_size, len_q = seq_q.size()</span><br><span class="line">    batch_size, len_k = seq_k.size()</span><br><span class="line">    <span class="comment"># 生成布尔类型张量</span></span><br><span class="line">    pad_attn_mask = seq_k.data.eq(<span class="number">0</span>).unsqueeze(<span class="number">1</span>)  <span class="comment"># &lt;PAD&gt;token 的编码值为 0</span></span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># pad_attn_mask 的维度是 [batch_size，1，len_k]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="comment"># 变形为与注意力分数相同形状的张量 </span></span><br><span class="line">    pad_attn_mask = pad_attn_mask.expand(batch_size, len_q, len_k)</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># pad_attn_mask 的维度是 [batch_size，len_q，len_k]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="keyword">return</span> pad_attn_mask</span><br></pre></td></tr></table></figure><p>我们为填充的⽂本序列创建⼀个与其形状相同的⼆维矩阵，称为填充掩码矩阵。填充掩码矩阵的⽬的是在注意⼒计算中屏蔽填充位置的影响。屏蔽流程如下。</p><p>（1）根据输⼊⽂本序列创建⼀个与其形状相同的⼆维矩阵。对于原始⽂本中的每个单词，矩阵中对应位置填充0；对于填充的符号，矩阵中对应位置填充1。</p><p>（2）为了将填充部分的权重降⾄接近负⽆穷，我们可以先将填充掩码矩阵中的1替换为⼀个⾮常⼤的负数（例如-1e9），再将处理后的填充掩码矩阵与注意⼒分数矩阵进⾏元素相加。这样，==有意义的token加了0，值保持不变，⽽填充部分加了⽆穷⼩值==，在注意⼒分数矩阵中的权重就会变得⾮常⼩。</p><p>（3）对注意⼒分数矩阵应⽤softmax函数进⾏归⼀化。==由于填充部分的权重接近负⽆穷，softmax函数会使其归⼀化后的权重接近于0==。这样，模型在计算注意⼒时就能够忽略填充部分的信息，专注于序列中实际包含的有效内容。</p><p> </p><h3 id="3-5-编码器层">3.5 编码器层</h3><p>有了多头⾃注意⼒和逐位置前馈⽹络这两个主要组件，以及正弦位置编码表和填充掩码这两个辅助函数后，现在我们终于可以搭建编码器层这个核⼼组件了。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义编码器层类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">EncoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(EncoderLayer, self).__init__()        </span><br><span class="line">        self.enc_self_attn = MultiHeadAttention() <span class="comment"># 多头自注意力层        </span></span><br><span class="line">        self.pos_ffn = PoswiseFeedForwardNet() <span class="comment"># 位置前馈神经网络层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs, enc_self_attn_mask</span>):</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_inputs 的维度是 [batch_size, seq_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># enc_self_attn_mask 的维度是 [batch_size, seq_len, seq_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 将相同的 Q，K，V 输入多头自注意力层 , 返回的 attn_weights 增加了头数  </span></span><br><span class="line">        enc_outputs, attn_weights = self.enc_self_attn(enc_inputs, enc_inputs,</span><br><span class="line">                                               enc_inputs, enc_self_attn_mask)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, seq_len, embedding_dim] </span></span><br><span class="line">        <span class="comment"># attn_weights 的维度是 [batch_size, n_heads, seq_len, seq_len]      </span></span><br><span class="line">        <span class="comment"># 将多头自注意力 outputs 输入位置前馈神经网络层</span></span><br><span class="line">        enc_outputs = self.pos_ffn(enc_outputs) <span class="comment"># 维度与 enc_inputs 相同</span></span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, seq_len, embedding_dim] </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="keyword">return</span> enc_outputs, attn_weights <span class="comment"># 返回编码器输出和每层编码器注意力权重</span></span><br></pre></td></tr></table></figure><p>这个类将多头自注意力层和位置前馈神经网络层组合在一起，并完成前向传播的计算。</p><p><code>EncoderLayer</code> 类将 <strong>多头自注意力机制</strong> 和 <strong>位置前馈神经网络</strong> 结合，完成了 Transformer 编码器层的基本结构。具体过程是：</p><ol><li>输入经过多头自注意力层，计算查询与键的注意力权重，并生成上下文向量。</li><li>将上下文向量输入到位置前馈神经网络中，得到最终的编码器输出。</li><li>返回编码器输出和每层的注意力权重。</li></ol><p>这种结构是 Transformer 编码器的核心部分，支持在输入序列中捕捉远距离依赖并进行非线性变换。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503171850255.png" alt="image-20250317185048109" style="zoom:50%;"><p> </p><h3 id="3-6-编码器">3.6 编码器</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义编码器类</span></span><br><span class="line">n_layers = <span class="number">6</span>  <span class="comment"># 设置 Encoder 的层数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()        </span><br><span class="line">        self.src_emb = nn.Embedding(<span class="built_in">len</span>(corpus.src_vocab), d_embedding) <span class="comment"># 词嵌入层</span></span><br><span class="line">        self.pos_emb = nn.Embedding.from_pretrained( \</span><br><span class="line">          get_sin_enc_table(corpus.src_len+<span class="number">1</span>, d_embedding), freeze=<span class="literal">True</span>) <span class="comment"># 位置嵌入层</span></span><br><span class="line">        self.layers = nn.ModuleList(EncoderLayer() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers))<span class="comment"># 编码器层数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs</span>):  </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_inputs 的维度是 [batch_size, source_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 创建一个从 1 到 source_len 的位置索引序列</span></span><br><span class="line">        pos_indices = torch.arange(<span class="number">1</span>, enc_inputs.size(<span class="number">1</span>) + <span class="number">1</span>).unsqueeze(<span class="number">0</span>).to(enc_inputs)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># pos_indices 的维度是 [1, source_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------             </span></span><br><span class="line">        <span class="comment"># 对输入进行词嵌入和位置嵌入相加 [batch_size, source_len，embedding_dim]</span></span><br><span class="line">        enc_outputs = self.src_emb(enc_inputs) + self.pos_emb(pos_indices)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, seq_len, embedding_dim]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 生成自注意力掩码</span></span><br><span class="line">        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_self_attn_mask 的维度是 [batch_size, len_q, len_k]        </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------         </span></span><br><span class="line">        enc_self_attn_weights = [] <span class="comment"># 初始化 enc_self_attn_weights</span></span><br><span class="line">        <span class="comment"># 通过编码器层 [batch_size, seq_len, embedding_dim]</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers: </span><br><span class="line">            enc_outputs, enc_self_attn_weight = layer(enc_outputs, enc_self_attn_mask)</span><br><span class="line">            enc_self_attn_weights.append(enc_self_attn_weight)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, seq_len, embedding_dim] 维度与 enc_inputs 相同</span></span><br><span class="line">        <span class="comment"># enc_self_attn_weights 是一个列表，每个元素的维度是 [batch_size, n_heads, seq_len, seq_len]          </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="keyword">return</span> enc_outputs, enc_self_attn_weights <span class="comment"># 返回编码器输出和编码器注意力权重</span></span><br></pre></td></tr></table></figure><p>这个编码器类实现了Transformer模型中的编码器部分，包括词嵌⼊、位置嵌⼊和多个编码器层。通过这个编码器，可以处理输⼊序列，并从中提取深层次的特征表示。这些特征表示可以直接应⽤于后续的任务，如序列到序列的⽣成任务（如机器翻译）或者分类任务（如情感分析）等。</p><p>BERT模型就只包含Transformer模型中的编码器部分，因此它很适合为各种NLP下游任务提供有⽤的特征表示。</p><p>编码器的定义⾄此结束，下⾯我们进⼊解码器组件。不过，在开始构建解码器层之前，也有⼀个⼩组件需要说明，它就是==⽣成后续注意⼒掩码的函数==。</p><p> </p><h3 id="3-7-后续掩码">3.7 后续掩码</h3><p>在⾃然语⾔处理中，尤其是Seq2Seq任务中，我们需要为解码器提供正确的输⼊，对于已经⽣成的部分，我们要让解码器看到序列是否正确，然后⽤正确的信息（Ground Truth）来预测下⼀个词。但是与此同时，为了确保模型不会提前获取未来的信息，我们⼜需要在注意⼒计算中遮住当前位置后⾯的信息（Subsequent Positions）。</p><p>所以，对序列中的第⼀个位置，我们需要遮住后⾯所有的词；⽽对后⾯的词，需要遮住的词会逐渐减少（如下图所示）。⽐如把“咖哥 喜欢 ⼩冰”这句话输⼊解码器，当对“咖哥”计算注意⼒时，解码器不可以看到“喜欢”“⼩冰”这两个词。当对“喜欢”计算注意⼒时，解码器可以看到“咖哥”，不能看到“⼩冰”，因为它正是需要根据“咖哥”和“喜欢”这个上下⽂，来猜测咖哥喜欢谁。当对最后⼀个词&quot;⼩冰&quot;计算注意⼒的时候，前两个词就不是秘密了。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503171905263.png" alt="image-20250317190524034" style="zoom:80%;"><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成后续注意力掩码的函数，用于在多头自注意力计算中忽略未来信息</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_attn_subsequent_mask</span>(<span class="params">seq</span>):</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># seq 的维度是 [batch_size, seq_len(Q)=seq_len(K)]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="comment"># 获取输入序列的形状</span></span><br><span class="line">    attn_shape = [seq.size(<span class="number">0</span>), seq.size(<span class="number">1</span>), seq.size(<span class="number">1</span>)]  </span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># attn_shape 是一个一维张量 [batch_size, seq_len(Q), seq_len(K)]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="comment"># 使用 numpy 创建一个上三角矩阵（triu = triangle upper）</span></span><br><span class="line">    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># subsequent_mask 的维度是 [batch_size, seq_len(Q), seq_len(K)]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="comment"># 将 numpy 数组转换为 PyTorch 张量，并将数据类型设置为 byte（布尔值）</span></span><br><span class="line">    subsequent_mask = torch.from_numpy(subsequent_mask).byte()</span><br><span class="line">    <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">    <span class="comment"># 返回的 subsequent_mask 的维度是 [batch_size, seq_len(Q), seq_len(K)]</span></span><br><span class="line">    <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">    <span class="keyword">return</span> subsequent_mask <span class="comment"># 返回后续位置的注意力掩码</span></span><br></pre></td></tr></table></figure><p>此段代码最终生成的是注意力掩码，根据上图第一行为例，因为咖哥只能看到自己来推测下面的词，所以先写出咖哥对整个句子的权重，在人为将看不到的地方取消关注（也就是替换成Zero weight），从上到下一行是一个时间的步长。</p><p> </p><h3 id="3-8-解码器层">3.8 解码器层</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义解码器层类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()        </span><br><span class="line">        self.dec_self_attn = MultiHeadAttention() <span class="comment"># 多头自注意力层       </span></span><br><span class="line">        self.dec_enc_attn = MultiHeadAttention()  <span class="comment"># 多头自注意力层，连接编码器和解码器        </span></span><br><span class="line">        self.pos_ffn = PoswiseFeedForwardNet() <span class="comment"># 位置前馈神经网络层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask</span>):</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_inputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, source_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_self_attn_mask 的维度是 [batch_size, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_enc_attn_mask 的维度是 [batch_size, target_len, source_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------      </span></span><br><span class="line">        <span class="comment"># 将相同的 Q，K，V 输入多头自注意力层</span></span><br><span class="line">        dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, </span><br><span class="line">                                                        dec_inputs, dec_self_attn_mask)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_self_attn 的维度是 [batch_size, n_heads, target_len, target_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 将解码器输出和编码器输出输入多头自注意力层</span></span><br><span class="line">        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, </span><br><span class="line">                                                      enc_outputs, dec_enc_attn_mask)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_enc_attn 的维度是 [batch_size, n_heads, target_len, source_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------          </span></span><br><span class="line">        <span class="comment"># 输入位置前馈神经网络层</span></span><br><span class="line">        dec_outputs = self.pos_ffn(dec_outputs)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_self_attn 的维度是 [batch_size, n_heads, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_enc_attn 的维度是 [batch_size, n_heads, target_len, source_len]   </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 返回解码器层输出，每层的自注意力和解 - 编码器注意力权重</span></span><br><span class="line">        <span class="keyword">return</span> dec_outputs, dec_self_attn, dec_enc_attn</span><br></pre></td></tr></table></figure><p>定义了一个标准的解码器层，通过三个主要步骤处理输入：</p><ol><li><strong>自注意力</strong>：通过多头自注意力机制理解目标语言的上下文。</li><li><strong>编码器-解码器注意力</strong>：通过与编码器的输出进行交互，理解目标语言与源语言的关系。</li><li><strong>前馈神经网络</strong>：对解码器输出进行进一步的转换和处理。</li></ol><p>这些步骤共同作用，使得解码器能够生成目标语言的翻译或输出。</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503171930172.png" alt="image-20250317193028046" style="zoom: 80%;"><p> </p><h3 id="3-9-解码器">3.9 解码器</h3><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503171930351.png" alt="image-20250317193057213" style="zoom: 50%;"><p>解码器类的实现代码如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  定义解码器类</span></span><br><span class="line">n_layers = <span class="number">6</span>  <span class="comment"># 设置 Decoder 的层数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        self.tgt_emb = nn.Embedding(<span class="built_in">len</span>(corpus.tgt_vocab), d_embedding) <span class="comment"># 词嵌入层</span></span><br><span class="line">        self.pos_emb = nn.Embedding.from_pretrained( \</span><br><span class="line">           get_sin_enc_table(corpus.tgt_len+<span class="number">1</span>, d_embedding), freeze=<span class="literal">True</span>) <span class="comment"># 位置嵌入层        </span></span><br><span class="line">        self.layers = nn.ModuleList([DecoderLayer() <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)]) <span class="comment"># 叠加多层</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_inputs, enc_inputs, enc_outputs</span>): </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_inputs 的维度是 [batch_size, target_len]</span></span><br><span class="line">        <span class="comment"># enc_inputs 的维度是 [batch_size, source_len]</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, source_len, embedding_dim]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------   </span></span><br><span class="line">        <span class="comment"># 创建一个从 1 到 source_len 的位置索引序列</span></span><br><span class="line">        pos_indices = torch.arange(<span class="number">1</span>, dec_inputs.size(<span class="number">1</span>) + <span class="number">1</span>).unsqueeze(<span class="number">0</span>).to(dec_inputs)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># pos_indices 的维度是 [1, target_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------              </span></span><br><span class="line">        <span class="comment"># 对输入进行词嵌入和位置嵌入相加</span></span><br><span class="line">        dec_outputs = self.tgt_emb(dec_inputs) + self.pos_emb(pos_indices)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">         <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 生成解码器自注意力掩码和解码器 - 编码器注意力掩码</span></span><br><span class="line">        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs) <span class="comment"># 填充位掩码</span></span><br><span class="line">        dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_inputs) <span class="comment"># 后续位掩码</span></span><br><span class="line">        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask \</span><br><span class="line">                                       + dec_self_attn_subsequent_mask), <span class="number">0</span>) </span><br><span class="line">        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs) <span class="comment"># 解码器 - 编码器掩码</span></span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------        </span></span><br><span class="line">        <span class="comment"># dec_self_attn_pad_mask 的维度是 [batch_size, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_self_attn_subsequent_mask 的维度是 [batch_size, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_self_attn_mask 的维度是 [batch_size, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_enc_attn_mask 的维度是 [batch_size, target_len, source_len]</span></span><br><span class="line">         <span class="comment">#-----------------------------------------------------------------       </span></span><br><span class="line">        dec_self_attns, dec_enc_attns = [], [] <span class="comment"># 初始化 dec_self_attns, dec_enc_attns</span></span><br><span class="line">        <span class="comment"># 通过解码器层 [batch_size, seq_len, embedding_dim]</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, </span><br><span class="line">                                               dec_self_attn_mask, dec_enc_attn_mask)</span><br><span class="line">            dec_self_attns.append(dec_self_attn)</span><br><span class="line">            dec_enc_attns.append(dec_enc_attn)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_self_attns 是一个列表，每个元素的维度是 [batch_size, n_heads, target_len, target_len]</span></span><br><span class="line">        <span class="comment"># dec_enc_attns 是一个列表，每个元素的维度是 [batch_size, n_heads, target_len, source_len]</span></span><br><span class="line">        <span class="comment">#----------------------------------------------------------------- </span></span><br><span class="line">        <span class="comment"># 返回解码器输出，解码器自注意力和解码器 - 编码器注意力权重       </span></span><br><span class="line">        <span class="keyword">return</span> dec_outputs, dec_self_attns, dec_enc_attns</span><br></pre></td></tr></table></figure><p>1.<strong>词嵌入</strong>：输入目标语言的词索引，并结合位置编码来生成解码器的输入。</p><p>2.<strong>掩码计算</strong>：生成自注意力掩码和解码器-编码器掩码，确保模型不会使用未来信息或填充位置的信息。</p><p>3.<strong>多层解码器</strong>：通过多层解码器来处理输入，生成目标语言的最终表示。</p><p>4.<strong>返回结果</strong>：解码器的输出和每一层的注意力权重。</p><p> </p><h3 id="3-10-transfomer类">3.10 transfomer类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 Transformer 模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, corpus</span>):</span><br><span class="line">        <span class="built_in">super</span>(Transformer, self).__init__()        </span><br><span class="line">        self.encoder = Encoder(corpus) <span class="comment"># 初始化编码器实例        </span></span><br><span class="line">        self.decoder = Decoder(corpus) <span class="comment"># 初始化解码器实例</span></span><br><span class="line">        <span class="comment"># 定义线性投影层，将解码器输出转换为目标词汇表大小的概率分布</span></span><br><span class="line">        self.projection = nn.Linear(d_embedding, <span class="built_in">len</span>(corpus.tgt_vocab), bias=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_inputs, dec_inputs</span>):</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_inputs 的维度是 [batch_size, source_seq_len]</span></span><br><span class="line">        <span class="comment"># dec_inputs 的维度是 [batch_size, target_seq_len]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------        </span></span><br><span class="line">        <span class="comment"># 将输入传递给编码器，并获取编码器输出和自注意力权重        </span></span><br><span class="line">        enc_outputs, enc_self_attns = self.encoder(enc_inputs)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># enc_outputs 的维度是 [batch_size, source_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># enc_self_attns 是一个列表，每个元素的维度是 [batch_size, n_heads, src_seq_len, src_seq_len]        </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------          </span></span><br><span class="line">        <span class="comment"># 将编码器输出、解码器输入和编码器输入传递给解码器</span></span><br><span class="line">        <span class="comment"># 获取解码器输出、解码器自注意力权重和编码器 - 解码器注意力权重     </span></span><br><span class="line">        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)</span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_outputs 的维度是 [batch_size, target_len, embedding_dim]</span></span><br><span class="line">        <span class="comment"># dec_self_attns 是一个列表，每个元素的维度是 [batch_size, n_heads, tgt_seq_len, src_seq_len]</span></span><br><span class="line">        <span class="comment"># dec_enc_attns 是一个列表，每个元素的维度是 [batch_size, n_heads, tgt_seq_len, src_seq_len]   </span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------                </span></span><br><span class="line">        <span class="comment"># 将解码器输出传递给投影层，生成目标词汇表大小的概率分布</span></span><br><span class="line">        dec_logits = self.projection(dec_outputs)  </span><br><span class="line">        <span class="comment">#------------------------- 维度信息 --------------------------------</span></span><br><span class="line">        <span class="comment"># dec_logits 的维度是 [batch_size, tgt_seq_len, tgt_vocab_size]</span></span><br><span class="line">        <span class="comment">#-----------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># 返回逻辑值 ( 原始预测结果 ), 编码器自注意力权重，解码器自注意力权重，解 - 编码器注意力权重</span></span><br><span class="line">        <span class="keyword">return</span> dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns</span><br></pre></td></tr></table></figure><p>⾸先初始化编码器、解码器和投影层。在forward⽅法中，将源序列输⼊传递给编码器，获取编码器输出和⾃注意⼒权重。然后将编码器输出、解码器输⼊和编码器输⼊传递给解码器，获取解码器输出、解码器⾃注意⼒权重和编码器-解码器注意⼒权重。最后，将解码器输出传递给投影层，⽣成⽬标词汇表⼤⼩的概率分布。</p><p>这个概率分布将被⽤于计算损失和评估模型的性能。</p><p> </p><h2 id="四、举一个栗子跑跑">四、举一个栗子跑跑</h2><h3 id="4-1-数据准备">4.1 数据准备</h3><p>先准备几个中英翻译例句</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentences = [</span><br><span class="line">    [<span class="string">&#x27;咖哥 喜欢 小冰&#x27;</span>, <span class="string">&#x27;KaGe likes XiaoBing&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;我 爱 学习 人工智能&#x27;</span>, <span class="string">&#x27;I love studying AI&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;深度学习 改变 世界&#x27;</span>, <span class="string">&#x27; DL changed the world&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;自然语言处理 很 强大&#x27;</span>, <span class="string">&#x27;NLP is powerful&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;神经网络 非常 复杂&#x27;</span>, <span class="string">&#x27;Neural-networks are complex&#x27;</span>] ]</span><br></pre></td></tr></table></figure><p>然后，创建TranslationCorpus类，⽤于读⼊中英翻译语料，并⽣成字典和模型可以读取的数据批次。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter <span class="comment"># 导入 Counter 类</span></span><br><span class="line"><span class="comment"># 定义 TranslationCorpus 类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TranslationCorpus</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentences</span>):</span><br><span class="line">        self.sentences = sentences</span><br><span class="line">        <span class="comment"># 计算源语言和目标语言的最大句子长度，并分别加 1 和 2 以容纳填充符和特殊符号</span></span><br><span class="line">        self.src_len = <span class="built_in">max</span>(<span class="built_in">len</span>(sentence[<span class="number">0</span>].split()) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences) + <span class="number">1</span></span><br><span class="line">        self.tgt_len = <span class="built_in">max</span>(<span class="built_in">len</span>(sentence[<span class="number">1</span>].split()) <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences) + <span class="number">2</span></span><br><span class="line">        <span class="comment"># 创建源语言和目标语言的词汇表</span></span><br><span class="line">        self.src_vocab, self.tgt_vocab = self.create_vocabularies()</span><br><span class="line">        <span class="comment"># 创建索引到单词的映射</span></span><br><span class="line">        self.src_idx2word = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.src_vocab.items()&#125;</span><br><span class="line">        self.tgt_idx2word = &#123;v: k <span class="keyword">for</span> k, v <span class="keyword">in</span> self.tgt_vocab.items()&#125;</span><br><span class="line">    <span class="comment"># 定义创建词汇表的函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create_vocabularies</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 统计源语言和目标语言的单词频率</span></span><br><span class="line">        src_counter = Counter(word <span class="keyword">for</span> sentence <span class="keyword">in</span> self.sentences <span class="keyword">for</span> word <span class="keyword">in</span> sentence[<span class="number">0</span>].split())</span><br><span class="line">        tgt_counter = Counter(word <span class="keyword">for</span> sentence <span class="keyword">in</span> self.sentences <span class="keyword">for</span> word <span class="keyword">in</span> sentence[<span class="number">1</span>].split())        </span><br><span class="line">        <span class="comment"># 创建源语言和目标语言的词汇表，并为每个单词分配一个唯一的索引</span></span><br><span class="line">        src_vocab = &#123;<span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">0</span>, **&#123;word: i+<span class="number">1</span> <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(src_counter)&#125;&#125;</span><br><span class="line">        tgt_vocab = &#123;<span class="string">&#x27;&lt;pad&gt;&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;&lt;sos&gt;&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>: <span class="number">2</span>, </span><br><span class="line">                     **&#123;word: i+<span class="number">3</span> <span class="keyword">for</span> i, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(tgt_counter)&#125;&#125;        </span><br><span class="line">        <span class="keyword">return</span> src_vocab, tgt_vocab</span><br><span class="line">    <span class="comment"># 定义创建批次数据的函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_batch</span>(<span class="params">self, batch_size, test_batch=<span class="literal">False</span></span>):</span><br><span class="line">        input_batch, output_batch, target_batch = [], [], []</span><br><span class="line">        <span class="comment"># 随机选择句子索引</span></span><br><span class="line">        sentence_indices = torch.randperm(<span class="built_in">len</span>(self.sentences))[:batch_size]</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> sentence_indices:</span><br><span class="line">            src_sentence, tgt_sentence = self.sentences[index]</span><br><span class="line">            <span class="comment"># 将源语言和目标语言的句子转换为索引序列</span></span><br><span class="line">            src_seq = [self.src_vocab[word] <span class="keyword">for</span> word <span class="keyword">in</span> src_sentence.split()]</span><br><span class="line">            tgt_seq = [self.tgt_vocab[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>]] + [self.tgt_vocab[word] \</span><br><span class="line">                         <span class="keyword">for</span> word <span class="keyword">in</span> tgt_sentence.split()] + [self.tgt_vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]]            </span><br><span class="line">            <span class="comment"># 对源语言和目标语言的序列进行填充</span></span><br><span class="line">            src_seq += [self.src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (self.src_len - <span class="built_in">len</span>(src_seq))</span><br><span class="line">            tgt_seq += [self.tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * (self.tgt_len - <span class="built_in">len</span>(tgt_seq))            </span><br><span class="line">            <span class="comment"># 将处理好的序列添加到批次中</span></span><br><span class="line">            input_batch.append(src_seq)</span><br><span class="line">            output_batch.append([self.tgt_vocab[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>]] + ([self.tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]] * \</span><br><span class="line">                                    (self.tgt_len - <span class="number">2</span>)) <span class="keyword">if</span> test_batch <span class="keyword">else</span> tgt_seq[:-<span class="number">1</span>])</span><br><span class="line">            target_batch.append(tgt_seq[<span class="number">1</span>:])        </span><br><span class="line">          <span class="comment"># 将批次转换为 LongTensor 类型</span></span><br><span class="line">        input_batch = torch.LongTensor(input_batch)</span><br><span class="line">        output_batch = torch.LongTensor(output_batch)</span><br><span class="line">        target_batch = torch.LongTensor(target_batch)            </span><br><span class="line">        <span class="keyword">return</span> input_batch, output_batch, target_batch</span><br><span class="line"><span class="comment"># 创建语料库类实例</span></span><br><span class="line">corpus = TranslationCorpus(sentences)</span><br></pre></td></tr></table></figure><h3 id="4-2-训练Transfomer模型">4.2 训练Transfomer模型</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim <span class="comment"># 导入优化器</span></span><br><span class="line">model = Transformer(corpus) <span class="comment"># 创建模型实例</span></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment"># 损失函数</span></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.0001</span>) <span class="comment"># 优化器</span></span><br><span class="line">epochs = <span class="number">5</span> <span class="comment"># 训练轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs): <span class="comment"># 训练 100 轮</span></span><br><span class="line">    optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line">    enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size) <span class="comment"># 创建训练数据        </span></span><br><span class="line">    outputs, _, _, _ = model(enc_inputs, dec_inputs) <span class="comment"># 获取模型输出 </span></span><br><span class="line">    loss = criterion(outputs.view(-<span class="number">1</span>, <span class="built_in">len</span>(corpus.tgt_vocab)), target_batch.view(-<span class="number">1</span>)) <span class="comment"># 计算损失</span></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">1</span> == <span class="number">0</span>: <span class="comment"># 打印损失</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:04d&#125;</span> cost = <span class="subst">&#123;loss:<span class="number">.6</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    loss.backward()<span class="comment"># 反向传播        </span></span><br><span class="line">    optimizer.step()<span class="comment"># 更新参数</span></span><br></pre></td></tr></table></figure><p>训练100轮之后，损失会减⼩到⼀个较⼩的值。</p><p> </p><h3 id="4-3-测试Transfomer模型">4.3 测试Transfomer模型</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个大小为 1 的批次，目标语言序列 dec_inputs 在测试阶段，仅包含句子开始符号 &lt;sos&gt;</span></span><br><span class="line">enc_inputs, dec_inputs, target_batch = corpus.make_batch(batch_size=<span class="number">1</span>,test_batch=<span class="literal">True</span>) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;编码器输入 :&quot;</span>, enc_inputs) <span class="comment"># 打印编码器输入</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;解码器输入 :&quot;</span>, dec_inputs) <span class="comment"># 打印解码器输入</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;目标数据 :&quot;</span>, target_batch) <span class="comment"># 打印目标数据</span></span><br><span class="line">predict, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs) <span class="comment"># 用模型进行翻译</span></span><br><span class="line">predict = predict.view(-<span class="number">1</span>, <span class="built_in">len</span>(corpus.tgt_vocab)) <span class="comment"># 将预测结果维度重塑</span></span><br><span class="line">predict = predict.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] <span class="comment"># 找到每个位置概率最大的词汇的索引</span></span><br><span class="line"><span class="comment"># 解码预测的输出，将所预测的目标句子中的索引转换为单词</span></span><br><span class="line">translated_sentence = [corpus.tgt_idx2word[idx.item()] <span class="keyword">for</span> idx <span class="keyword">in</span> predict.squeeze()]</span><br><span class="line"><span class="comment"># 将输入的源语言句子中的索引转换为单词</span></span><br><span class="line">input_sentence = <span class="string">&#x27; &#x27;</span>.join([corpus.src_idx2word[idx.item()] <span class="keyword">for</span> idx <span class="keyword">in</span> enc_inputs[<span class="number">0</span>]])</span><br><span class="line"><span class="built_in">print</span>(input_sentence, <span class="string">&#x27;-&gt;&#x27;</span>, translated_sentence) <span class="comment"># 打印原始句子和翻译后的句子</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">编码器输入 : tensor([[11, 12, 13,  0,  0]])</span><br><span class="line"></span><br><span class="line">解码器输入 : tensor([[1, 0, 0, 0, 0]])</span><br><span class="line"></span><br><span class="line">目标数据 : tensor([[14, 15, 16,  2,  0]])</span><br><span class="line"></span><br><span class="line">自然语言处理 很 强大 <span class="language-xml"><span class="tag">&lt;<span class="name">pad</span>&gt;</span></span> <span class="language-xml"><span class="tag">&lt;<span class="name">pad</span>&gt;</span></span> -&gt; [&#x27;NLP&#x27;, &#x27;NLP&#x27;, &#x27;NLP&#x27;, &#x27;NLP&#x27;, &#x27;NLP&#x27;]</span><br></pre></td></tr></table></figure><p>这个Transformer能训练，能⽤。不过，其输出结果并不理想，模型只成功翻译了⼀个单词“NLP”，之后就不断重复这个词。</p><p>对于这样简单的数据集，在设计和选择模型时，应该优先考虑简单的模型，像Transformer这样⽐较复杂的模型并不⼀定效果更好。</p><p>这次测试效果不理想的真正原因和模型的简单或者复杂⽆关，主要是因为此处我们并没有利⽤解码器的⾃回归机制进⾏逐位置（即逐词、逐令牌、逐元素或逐时间步）的⽣成式输出。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>注意力机制：让AI拥有&quot;黄金七秒记忆&quot;的魔法–（自注意力）</h1><p>⾃注意⼒就是⾃⼰对⾃⼰的注意，它允许模型在同⼀序列中的不同位置之间建⽴依赖关系。⽤我们刚才讲过的最简单的注意⼒来理解，如果我们把x2替换为x1⾃身，那么我们其实就实现了x1每⼀个位置对⾃身其他序列的所有位置的加权和。</p><p>如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 一个形状为 (batch_size, seq_len, feature_dim) 的张量 x</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 计算原始权重，形状为 (batch_size, seq_len, seq_len)</span></span><br><span class="line">raw_weights = torch.bmm(x, x.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 对原始权重进行 softmax 归一化，形状为 (batch_size, seq_len, seq_len)</span></span><br><span class="line">attn_weights = F.softmax(raw_weights, dim=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 计算加权和，形状为 (batch_size, seq_len, feature_dim) </span></span><br><span class="line">attn_outputs = torch.bmm(attn_weights, x)</span><br></pre></td></tr></table></figure><p>知道了这个，那么下面继续展示一下如何对输入序列进行不同的线性变换，得到Q，K和V向量，然后应用放缩点积注意力即可：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个形状为 (batch_size, seq_len, feature_dim) 的张量 x</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len, feature_dim)</span></span><br><span class="line"><span class="comment"># 定义线性层用于将 x 转换为 Q, K, V 向量</span></span><br><span class="line">linear_q = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">linear_k = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">linear_v = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 通过线性层计算 Q, K, V</span></span><br><span class="line">Q = linear_q(x) <span class="comment"># 形状 (batch_size, seq_len, feature_dim)</span></span><br><span class="line">K = linear_k(x) <span class="comment"># 形状 (batch_size, seq_len, feature_dim)</span></span><br><span class="line">V = linear_v(x) <span class="comment"># 形状 (batch_size, seq_len, feature_dim)</span></span><br><span class="line"><span class="comment"># 计算 Q 和 K 的点积，作为相似度分数 , 也就是自注意力原始权重</span></span><br><span class="line">raw_weights = torch.bmm(Q, K.transpose(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># 形状 (batch_size, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 将自注意力原始权重进行缩放</span></span><br><span class="line">scale_factor = K.size(-<span class="number">1</span>) ** <span class="number">0.5</span>  <span class="comment"># 这里是 4 ** 0.5</span></span><br><span class="line">scaled_weights = raw_weights / scale_factor <span class="comment"># 形状 (batch_size, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 对缩放后的权重进行 softmax 归一化，得到注意力权重</span></span><br><span class="line">attn_weights = F.softmax(scaled_weights, dim=<span class="number">2</span>) <span class="comment"># 形状 (batch_size, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 将注意力权重应用于 V 向量，计算加权和，得到加权信息</span></span><br><span class="line">attn_outputs = torch.bmm(attn_weights, V) <span class="comment"># 形状 (batch_size, seq_len, feature_dim)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 加权信息 :&quot;</span>, attn_outputs)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">加权信息 : tensor([[[ 0.5676, -0.0132, -0.8214, -0.0548],</span><br><span class="line"></span><br><span class="line"><span class="code">        [ 0.5352, -0.1170, -0.5392, -0.0256],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [ 0.6141, -0.1343, -0.5587, -0.0331]],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="code">       [[ 0.5973, -0.2426, -0.3217, -0.0335],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [ 0.5996, -0.1914, -0.2840,  0.0152],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [ 0.6117, -0.2507, -0.3363, -0.0404]]], grad_fn=&lt;BmmBackward0&gt;)</span></span><br></pre></td></tr></table></figure><h2 id="1-多头自注意力">1.多头自注意力</h2><p>多头⾃注意⼒（Multi-head Attention）机制是注意⼒机制的⼀种扩展，它可以帮助模型从不同的表示⼦空间捕获输⼊数据的多种特征。具体⽽⾔，多头⾃注意⼒在计算注意⼒权重和输出时，会对<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量分别进⾏多次线性变换，从⽽获得不同的头（Head），并进⾏并⾏计算</p><p>如下图所示：</p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503152226156.png" alt="image-20250315222533884" style="zoom:50%;"><p>以下是多头⾃注意⼒的计算过程。</p><p>（1）初始化：设定多头⾃注意⼒的头数。每个头将处理输⼊数据的⼀个⼦空间。</p><p>（2）线性变换：对<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量进⾏数次线性变换，每次变换使⽤不同的权重矩阵。这样，我们可以获得多组不同的<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量。</p><p>（3）缩放点积注意⼒：将每组<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量输⼊缩放点积注意⼒中进⾏计算，每个头将⽣成⼀个加权输出。</p><p>（4）合并：将所有头的加权输出拼接起来，并进⾏⼀次线性变换，得到多头⾃注意⼒的最终输出。</p><ul><li>假设我们有一个输入序列的表示矩阵 X（例如编码器的输出或者词嵌入），</li><li>我们通过三个不同的线性层（也就是不同的权重矩阵）分别计算 Query、Key 和 Value：<ul><li>$q=XW_q$</li><li>$k=XW_k$</li><li>$v= XW_v$</li></ul></li><li>这里，$W_q$、$W_k$ 和 $W_v$ 是模型在训练过程中学习到的参数矩阵。</li></ul><p>多头⾃注意⼒机制的优势在于，==通过同时学习多个⼦空间的特征==，可以==提⾼模型捕捉⻓距离依赖和不同语义层次的能⼒==。</p><p>如下列代码：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment"># 一个形状为 (batch_size, seq_len, feature_dim) 的张量 x</span></span><br><span class="line">x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line"><span class="comment"># 定义头数和每个头的维度</span></span><br><span class="line">num_heads = <span class="number">2</span></span><br><span class="line">head_dim = <span class="number">2</span></span><br><span class="line"><span class="comment"># feature_dim 必须是 num_heads * head_dim 的整数倍</span></span><br><span class="line"><span class="keyword">assert</span> x.size(-<span class="number">1</span>) == num_heads * head_dim</span><br><span class="line"><span class="comment"># 定义线性层用于将 x 转换为 Q, K, V 向量</span></span><br><span class="line">linear_q = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">linear_k = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">linear_v = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"><span class="comment"># 通过线性层计算 Q, K, V</span></span><br><span class="line">Q = linear_q(x)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line">K = linear_k(x)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line">V = linear_v(x)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line"><span class="comment"># 将 Q, K, V 分割成 num_heads 个头</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_heads</span>(<span class="params">tensor, num_heads</span>):</span><br><span class="line">    batch_size, seq_len, feature_dim = tensor.size()</span><br><span class="line">    head_dim = feature_dim // num_heads</span><br><span class="line">    output = tensor.view(batch_size, seq_len, num_heads, head_dim).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span>  output <span class="comment"># 形状 (batch_size, num_heads, seq_len, feature_dim)</span></span><br><span class="line">Q = split_heads(Q, num_heads)  <span class="comment"># 形状 (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">K = split_heads(K, num_heads)  <span class="comment"># 形状 (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line">V = split_heads(V, num_heads)  <span class="comment"># 形状 (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line"><span class="comment"># 计算 Q 和 K 的点积，作为相似度分数 , 也就是自注意力原始权重</span></span><br><span class="line">raw_weights = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>))  <span class="comment"># 形状 (batch_size, num_heads, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 对自注意力原始权重进行缩放</span></span><br><span class="line">scale_factor = K.size(-<span class="number">1</span>) ** <span class="number">0.5</span></span><br><span class="line">scaled_weights = raw_weights / scale_factor  <span class="comment"># 形状 (batch_size, num_heads, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 对缩放后的权重进行 softmax 归一化，得到注意力权重</span></span><br><span class="line">attn_weights = F.softmax(scaled_weights, dim=-<span class="number">1</span>)  <span class="comment"># 形状 (batch_size, num_heads, seq_len, seq_len)</span></span><br><span class="line"><span class="comment"># 将注意力权重应用于 V 向量，计算加权和，得到加权信息</span></span><br><span class="line">attn_outputs = torch.matmul(attn_weights, V)  <span class="comment"># 形状 (batch_size, num_heads, seq_len, head_dim)</span></span><br><span class="line"><span class="comment"># 将所有头的结果拼接起来</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_heads</span>(<span class="params">tensor, num_heads</span>):</span><br><span class="line">    batch_size, num_heads, seq_len, head_dim = tensor.size()</span><br><span class="line">    feature_dim = num_heads * head_dim</span><br><span class="line">    output = tensor.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, seq_len, feature_dim)</span><br><span class="line">    <span class="keyword">return</span> output<span class="comment"># 形状 : (batch_size, seq_len, feature_dim)</span></span><br><span class="line">attn_outputs = combine_heads(attn_outputs, num_heads)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line"><span class="comment"># 对拼接后的结果进行线性变换</span></span><br><span class="line">linear_out = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">attn_outputs = linear_out(attn_outputs)  <span class="comment"># 形状 (batch_size, seq_len, feature_dim) </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 加权信息 :&quot;</span>, attn_outputs)</span><br></pre></td></tr></table></figure><p>多头自注意力机制就是将输⼊向量投影到多个向量空间，在每个向量空间中执⾏点积注意⼒计算，然后连接各头的结果。</p><p>在实际应⽤中，多头⾃注意⼒通常作为更复杂模型（如Transformer）的⼀个组成部分。这些复杂的模型通常包含其他组件，例如前馈神经⽹络（Feed-Forward Neural Network）和层归⼀化（Layer Normalization），以提⾼模型的表达能⼒和稳定性。</p><p> </p><h2 id="2-注意力掩码">2.注意力掩码</h2><p>注意⼒中的掩码机制，不同于BERT训练过程中的那种对训练⽂本的“掩码”。注意⼒掩码的作⽤是避免模型在计算注意⼒分数时，将不相关的单词考虑进来。掩码操作可以防⽌模型学习到不必要的信息。</p><p>要直观地解释掩码，我们先回忆⼀下填充（Padding）的概念。在NLP任务中，我们经常需要将不同⻓度的⽂本输⼊模型。为了能够批量处理这些⽂本，我们需要将它们填充⾄相同的⻓度。</p><p>以这段有关损失函数的代码为例。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss(ignore_index=word2idx_en[<span class="string">&#x27;&#x27;</span>]) <span class="comment"># 损失函数</span></span><br></pre></td></tr></table></figure><p>这段代码中的ignore_index=word2idx_en[‘’]，就是为了告诉模型，是附加的冗余信息，模型在反向传播更新参数的时候没有必要关注它，因此也没有什么单词会被翻译成。</p><p> </p><p>填充掩码（Padding Mask）的作⽤和上⾯损失函数中的ignore_index参数有点类似，都是避免在计算注意⼒分数时，将填充位置的单词考虑进来（⻅右图）。因为填充位置的单词对于实际任务来说是⽆意义的，⽽且可能会引⼊噪声，影响模型的性能。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503152239578.png" alt="image-20250315223900477"></p><p>加⼊了掩码机制之后的注意⼒如下图所示，我们会把==将注意⼒权重矩阵与⼀个注意⼒掩码矩阵相加==，使得不需要的信息所对应的权重变得⾮常⼩（接近负⽆穷）。然后，通过应⽤softmax函数，将不需要的信息对应的权重变得接近于0，从⽽实现忽略它们的⽬的。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503152239187.png" alt="image-20250315223935095"></p><p>在Transformer中，使⽤了⾃注意⼒机制、多头⾃注意⼒机制和掩码，不仅有前⾯介绍的填充掩码，还有⼀种解码器专⽤的==后续注意⼒掩码==（Subsequent Attention Mask），简称后续掩码，也叫前瞻掩码（Look-ahead Masking），这是为了在训练时为解码器遮蔽未来的信息。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>注意力机制：让AI拥有&quot;黄金七秒记忆&quot;的魔法–（注意力机制中的Q、K、V）</h1><p>在注意⼒机制中，查询（Query）、键（Key）和值（Value）是三个关键部分。</p><p>■ 查询（Query）：是指当前需要处理的信息。模型根据查询向量在输⼊序列中查找相关信息。</p><p>■ 键（Key）：是指来⾃输⼊序列的⼀组表示。它们⽤于根据查询向量计算注意⼒权重。注意⼒权重反映了不同位置的输⼊数据与查询的相关性。</p><p>■ 值（Value）：是指来⾃输⼊序列的⼀组表示。它们⽤于根据注意⼒权重计算加权和，得到最终的注意⼒输出向量，其包含了与查询最相关的输⼊信息。</p><p>用下面栗子打一个比方：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment"># 导入 nn.functional</span></span><br><span class="line"><span class="comment"># 1. 创建两个张量 x1 和 x2</span></span><br><span class="line">x1 = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">x2 = torch.randn(<span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line"><span class="comment"># 2. 计算原始权重</span></span><br><span class="line">raw_weights = torch.bmm(x1, x2.transpose(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 3. 用 softmax 函数对原始权重进行归一化</span></span><br><span class="line">attn_weights = F.softmax(raw_weights, dim=<span class="number">2</span>) <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 4. 将注意力权重与 x2 相乘，计算加权和</span></span><br><span class="line">attn_output = torch.bmm(attn_weights, x2)  <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br></pre></td></tr></table></figure><p>我们可以将x1视为查询（Query，<strong>Q</strong>）向量，将x2视为键（Key，<strong>K</strong>）和值（Value，<strong>V</strong>）向量。这是因为我们直接使⽤x1和x2的点积作为相似度得分，并将权重应⽤于x2本身来计算加权信息。所以，在这个简化示例中，<strong>Q</strong>对应于x1，<strong>K</strong>和<strong>V</strong>都对应于x2。</p><p>然⽽，在Transformer中，<strong>Q</strong>、<strong>K</strong>和<strong>V</strong>通常是从相同的输⼊序列经过不同的线性变换得到的不同向量。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="comment">#1. 创建 Query、Key 和 Value 张量</span></span><br><span class="line">q = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">k = torch.randn(<span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line">v = torch.randn(<span class="number">2</span>, <span class="number">4</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line"><span class="comment"># 2. 计算点积，得到原始权重，形状为 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line">raw_weights = torch.bmm(q, k.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 3. 将原始权重进行缩放（可选），形状仍为 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line">scaling_factor = q.size(-<span class="number">1</span>) ** <span class="number">0.5</span></span><br><span class="line">scaled_weights = raw_weights / scaling_factor</span><br><span class="line"><span class="comment"># 4. 应用 softmax 函数，使结果的值在 0 和 1 之间，且每一行的和为 1</span></span><br><span class="line">attn_weights = F.softmax(scaled_weights, dim=-<span class="number">1</span>) <span class="comment"># 形状仍为 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 5. 与 Value 相乘，得到注意力分布的加权和 , 形状为 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">attn_output = torch.bmm(attn_weights, v)</span><br></pre></td></tr></table></figure><p><strong>K</strong>和<strong>V</strong>的维度是否需完全相同呢？</p><p>在缩放点积注意⼒中，<strong>K</strong>和<strong>V</strong>向量的维度不⼀定需要完全相同。在这种注意⼒机制中，<strong>K</strong>和<strong>V</strong>的序列⻓度维度（在这⾥是第2维）应该相同，因为它们描述了同⼀个序列的不同部分。然⽽，它们的特征（或隐藏层）维度（在这⾥是第3维）可以不同。<strong>V</strong>向量的第⼆个维度则决定了最终输出张量的特征维度，这个维度可以根据具体任务和模型设计进⾏调整。</p><p>⽽<strong>K</strong>向量的序列⻓度维度（在这⾥是第2维）和<strong>Q</strong>向量的序列⻓度维度可以不同，因为它们可以来⾃不同的输⼊序列，但是，<strong>K</strong>向量的特征维度（在这⾥是第3维）需要与<strong>Q</strong>向量的特征维度相同，因为它们之间要计算点积。</p><p>在实践中，<strong>K</strong>和<strong>V</strong>的各个维度通常是相同的，因为它们通常来⾃同⼀个输⼊序列并经过不同的线性变换。</p><p>在注意力机制中，<strong>k</strong>（Key）和 <strong>v</strong>（Value）的初始值并不是随机产生的，而是由输入数据经过各自的线性变换得到的。具体来说：</p><p>来源相同但变换不同：</p><ul><li><p>假设我们有一个输入序列的表示矩阵 X（例如编码器的输出或者词嵌入），</p></li><li><p>我们通过三个不同的线性层（也就是不同的权重矩阵）分别计算 Query、Key 和 Value：</p><ul><li>$q=XW_q$</li><li>$k=XW_k$</li><li>$v= XW_v$</li></ul></li><li><p>这里，$W_q$、$W_k$ 和 $W_v$ 是模型在训练过程中学习到的参数矩阵。</p></li><li><p><strong>确定方式</strong>：<br>这些矩阵 $W_k$ 和 $W_v$ 在模型设计时就被定义好，并在训练过程中通过反向传播进行更新。</p></li><li><p>作用不同</p><ul><li><strong>Key (k)</strong>：通过 $W_k$ 得到，用来与 Query 进行匹配，计算注意力分数，决定输入中哪些部分对当前 Query 最重要。</li><li><strong>Value (v)</strong>：通过 $W_v$得到，它携带的是具体的信息内容，最终会根据注意力分数被加权求和，形成输出的上下文向量。</li></ul></li><li><p>k 与 v 的初始值都源自相同的输入 X，但它们经过了各自独立的线性变换，参数 $W_k$ 和 $W_v$ 决定了它们具体的数值和表示。</p></li><li><p>这两个过程是在训练过程中自动学习并调整的，确保模型能够有效地捕捉和利用输入信息。</p></li></ul><p>这样，通过学习到的权重矩阵，模型可以从输入中抽取出适合进行匹配（Key）和传递信息（Value）的表示。</p><p>现在，重写缩放点积注意⼒的计算过程，如下所述。</p><p>（1）计算<strong>Q</strong>向量和<strong>K</strong>向量的点积。</p><p>（2）将点积结果除以缩放因⼦（<strong>Q</strong>向量特征维度的平⽅根）。</p><p>（3）应⽤softmax函数得到注意⼒权重。</p><p>（4）使⽤注意⼒权重对<strong>V</strong>向量进⾏加权求和。</p><p>这个过程的图示如下⻚图所示:</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503152205095.png" alt="image-20250315220205401"></p><p>具体到编码器-解码器注意⼒来说，可以这样理解<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量。</p><p>■ <strong>Q</strong>向量代表了解码器在当前时间步的表示，⽤于和<strong>K</strong>向量进⾏匹配，以==计算注意⼒权重==。<strong>Q</strong>向量通常是==解码器隐藏状态的线性变换==。</p><p>■ <strong>K</strong>向量是编码器输出的⼀种表示，⽤于和<strong>Q</strong>向量进⾏匹配，以确定哪些编码器输出对于当前解码器时间步来说==最相关==。<strong>K</strong>向量通常是==编码器隐藏状态的线性变换==。</p><p>■ <strong>V</strong>向量是编码器输出的另⼀种表示，⽤于计算加权求和，⽣成注意⼒上下⽂向量。注意⼒权重会作⽤在<strong>V</strong>向量上，以便在解码过程中关注输⼊序列中的特定部分。<strong>V</strong>向量通常也是==编码器隐藏状态的线性变换==。</p><p>在刚才的编码器-解码器注意⼒示例中，直接使⽤了编码器隐藏状态和解码器隐藏状态来计算注意⼒。这⾥的<strong>Q</strong>、<strong>K</strong>和<strong>V</strong>向量并没有显式地表示出来（⽽且，此处<strong>K</strong>和<strong>V</strong>是同⼀个向量），但它们的概念仍然隐含在实现中：</p><p>■ 编码器隐藏状态（encoder_hidden_states）充当了<strong>K</strong>和<strong>V</strong>向量的⻆⾊。</p><p>■ 解码器隐藏状态（decoder_hidden_states）充当了<strong>Q</strong>向量的⻆⾊。</p><p>我们计算<strong>Q</strong>向量（解码器隐藏状态）与<strong>K</strong>向量（编码器隐藏状态）之间的点积来得到注意⼒权重，然后⽤这些权重对<strong>V</strong>向量（编码器隐藏状态）进⾏加权求和，得到上下⽂向量。</p><p>当然了，在⼀些更复杂的注意⼒机制（如Transformer中的多头⾃注意⼒机制）中，<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量通常会更明确地表示出来，因为我们需要通过使⽤不同的线性层将相同的输⼊序列显式地映射到不同的<strong>Q</strong>、<strong>K</strong>、<strong>V</strong>向量空间。</p><p><strong>V</strong>向量表示值，⽤于计算加权信息。通过将注意⼒权重应⽤于<strong>V</strong>向量，我们可以获取输⼊序列中与<strong>Q</strong>向量相关的信息。它们（<strong>Q</strong>、<strong>K</strong>和<strong>V</strong>）其实都是输⼊序列，有时是编码器输⼊序列，有时是解码器输⼊序列，有时是神经⽹络中的隐藏状态（也来⾃输⼊序列）的线性表示，也都是序列的“嵌⼊向量”。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>注意力机制：让AI拥有&quot;黄金七秒记忆&quot;的魔法–（缩放点积注意力）</h1><h2 id="一、-缩放点积注意力">一、 缩放点积注意力</h2><p>缩放点积注意⼒（<code>Scaled Dot-Product Attention</code>）和点积注意⼒（<code>Dot-Product Attention</code>）之间的主要区别在于：缩放点积注意⼒在计算注意⼒权重之前，会将点积结果也就是原始权重除以⼀个缩放因⼦，得到缩放后的原始权重。通常，这个缩放因⼦是输⼊特征维度的平⽅根。</p><p>为什么要使⽤缩放因⼦呢？在深度学习模型中，点积的值可能会变得⾮常⼤，尤其是当特征维度较⼤时。当点积值特别⼤时，<code>softmax</code>函数可能会在⼀个⾮常陡峭的区域内运⾏，导致梯度变得⾮常⼩，也可能会导致训练过程中梯度消失。通过使⽤缩放因⼦，可以确保<code>softmax</code>函数在⼀个较为平缓的区域内⼯作，从⽽减轻梯度消失问题，提⾼模型的稳定性。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503151721031.png" alt="image-20250315172146857"></p><p>如上图，相比于点积注意力，多了第三步：将原始权重（得分）除以缩放因子。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment"># 导入 nn.functional</span></span><br><span class="line"><span class="comment"># 1. 创建两个张量 x1 和 x2</span></span><br><span class="line">x1 = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">x2 = torch.randn(<span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line"><span class="comment"># 2. 计算张量点积，得到原始权重</span></span><br><span class="line">raw_weights = torch.bmm(x1, x2.transpose(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 3. 将原始权重除以缩放因子</span></span><br><span class="line">scaling_factor = x1.size(-<span class="number">1</span>) ** <span class="number">0.5</span></span><br><span class="line">scaled_weights = raw_weights  / scaling_factor <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 4. 对原始权重进行归一化</span></span><br><span class="line">attn_weights  =  F.softmax(raw_weights, dim=<span class="number">2</span>) <span class="comment">#  形 状 (batch_size,  seq_len1,  seq_len2)</span></span><br><span class="line"><span class="comment"># 5. 使用注意力权重对 x2 加权求和</span></span><br><span class="line">attn_output = torch.bmm(attn_weights, x2)  <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br></pre></td></tr></table></figure><h2 id="二、编码器-解码器注意力">二、编码器-解码器注意力</h2><p>刚才，为了简化讲解的难度，也为了让你把全部注意⼒放在注意⼒机制本身上⾯。我们并没有说明，x1、x2在实际应⽤中分别代表着什么。</p><p>当我们应⽤点积注意⼒时，解码器的每个时间步都会根据编码器的隐藏状态计算⼀个注意⼒权重，然后将这些权重应⽤于编码器隐藏状态，以⽣成⼀个上下⽂向量（编码器-解码器注意⼒的输出）。这个上下⽂向量将包含关于编码器输⼊序列的有⽤信息，解码器可以利⽤这个信息⽣成更准确的输出序列，如下图所示。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503151731186.png" alt="image-20250315173111077"></p><p>要在这个程序中加⼊编码器-解码器注意⼒机制，我们可以按照以下步骤进⾏修改。</p><p>（1）定义Attention类。⽤于计算注意⼒权重和注意⼒上下⽂向量。</p><p>（2）重构Decoder类。更新Decoder类的初始化部分和前向传播⽅法，使其包含注意⼒层并在解码过程中利⽤注意⼒权重。</p><p>（3）重构Seq2Seq类。更新Seq2Seq类的前向传播⽅法，以便将编码器的输出传递给解码器。</p><p>（4）可视化注意⼒权重。</p><h3 id="2-1-构建语料库">2.1 构建语料库</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建语料库，每行包含中文、英文（解码器输入）和翻译成英文后的目标输出 3 个句子</span></span><br><span class="line">sentences = [</span><br><span class="line">    [<span class="string">&#x27;咖哥 喜欢 小冰&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; KaGe likes XiaoBing&#x27;</span>, <span class="string">&#x27;KaGe likes XiaoBing &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;我 爱 学习 人工智能&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; I love studying AI&#x27;</span>, <span class="string">&#x27;I love studying AI &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;深度学习 改变 世界&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; DL changed the world&#x27;</span>, <span class="string">&#x27;DL changed the world &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;自然 语言 处理 很 强大&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; NLP is so powerful&#x27;</span>, <span class="string">&#x27;NLP is so powerful &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;神经网络 非常 复杂&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; Neural-Nets are complex&#x27;</span>, <span class="string">&#x27;Neural-Nets are complex &lt;eos&gt;&#x27;</span>]]</span><br><span class="line">word_list_cn, word_list_en = [], []  <span class="comment"># 初始化中英文词汇表</span></span><br><span class="line"><span class="comment"># 遍历每一个句子并将单词添加到词汇表中</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> sentences:</span><br><span class="line">    word_list_cn.extend(s[<span class="number">0</span>].split())</span><br><span class="line">    word_list_en.extend(s[<span class="number">1</span>].split())</span><br><span class="line">    word_list_en.extend(s[<span class="number">2</span>].split())</span><br><span class="line"><span class="comment"># 去重，得到没有重复单词的词汇表</span></span><br><span class="line">word_list_cn = <span class="built_in">list</span>(<span class="built_in">set</span>(word_list_cn))</span><br><span class="line">word_list_en = <span class="built_in">list</span>(<span class="built_in">set</span>(word_list_en))</span><br><span class="line"><span class="comment"># 构建单词到索引的映射</span></span><br><span class="line">word2idx_cn = &#123;w: i <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_cn)&#125;</span><br><span class="line">word2idx_en = &#123;w: i <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_en)&#125;</span><br><span class="line"><span class="comment"># 构建索引到单词的映射</span></span><br><span class="line">idx2word_cn = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_cn)&#125;</span><br><span class="line">idx2word_en = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_en)&#125;</span><br><span class="line"><span class="comment"># 计算词汇表的大小</span></span><br><span class="line">voc_size_cn = <span class="built_in">len</span>(word_list_cn)</span><br><span class="line">voc_size_en = <span class="built_in">len</span>(word_list_en)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 句子数量：&quot;</span>, <span class="built_in">len</span>(sentences)) <span class="comment"># 打印句子数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 中文词汇表大小：&quot;</span>, voc_size_cn) <span class="comment"># 打印中文词汇表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 英文词汇表大小：&quot;</span>, voc_size_en) <span class="comment"># 打印英文词汇表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 中文词汇到索引的字典：&quot;</span>, word2idx_cn) <span class="comment"># 打印中文词汇到索引的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 英文词汇到索引的字典：&quot;</span>, word2idx_en) <span class="comment"># 打印英文词汇到索引的字典</span></span><br></pre></td></tr></table></figure><h3 id="2-2-设定编码器和解码器设定的张量">2.2 设定编码器和解码器设定的张量</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入 numpy</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> random <span class="comment"># 导入 random 库</span></span><br><span class="line"><span class="comment"># 定义一个函数，随机选择一个句子和词汇表生成输入、输出和目标数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_data</span>(<span class="params">sentences</span>):</span><br><span class="line">    <span class="comment"># 随机选择一个句子进行训练</span></span><br><span class="line">    random_sentence = random.choice(sentences)</span><br><span class="line">    <span class="comment"># 将输入句子中的单词转换为对应的索引</span></span><br><span class="line">    encoder_input = np.array([[word2idx_cn[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">0</span>].split()]])</span><br><span class="line">    <span class="comment"># 将输出句子中的单词转换为对应的索引</span></span><br><span class="line">    decoder_input = np.array([[word2idx_en[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">1</span>].split()]])</span><br><span class="line">    <span class="comment"># 将目标句子中的单词转换为对应的索引</span></span><br><span class="line">    target = np.array([[word2idx_en[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">2</span>].split()]])</span><br><span class="line">    <span class="comment"># 将输入、输出和目标批次转换为 LongTensor</span></span><br><span class="line">    encoder_input = torch.LongTensor(encoder_input)</span><br><span class="line">    decoder_input = torch.LongTensor(decoder_input)</span><br><span class="line">    target = torch.LongTensor(target)</span><br><span class="line">    <span class="keyword">return</span> encoder_input, decoder_input, target </span><br><span class="line"><span class="comment"># 使用 make_data 函数生成输入、输出和目标张量</span></span><br><span class="line">encoder_input, decoder_input, target = make_data(sentences)</span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> sentences: <span class="comment"># 获取原始句子</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">all</span>([word2idx_cn[w] <span class="keyword">in</span> encoder_input[<span class="number">0</span>] <span class="keyword">for</span> w <span class="keyword">in</span> s[<span class="number">0</span>].split()]):</span><br><span class="line">        original_sentence = s</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 原始句子：&quot;</span>, original_sentence) <span class="comment"># 打印原始句子</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 编码器输入张量的形状：&quot;</span>, encoder_input.shape)  <span class="comment"># 打印输入张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 解码器输入张量的形状：&quot;</span>, decoder_input.shape) <span class="comment"># 打印输出张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 目标张量的形状：&quot;</span>, target.shape) <span class="comment"># 打印目标张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 编码器输入张量：&quot;</span>, encoder_input) <span class="comment"># 打印输入张量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 解码器输入张量：&quot;</span>, decoder_input) <span class="comment"># 打印输出张量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 目标张量：&quot;</span>, target) <span class="comment"># 打印目标张量</span></span><br></pre></td></tr></table></figure><h3 id="2-3-定义attention类">2.3 定义attention类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 Attention 类</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 torch.nn 库</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, decoder_context, encoder_context</span>):</span><br><span class="line">        <span class="comment"># 计算 decoder_context 和 encoder_context 的点积，得到注意力分数</span></span><br><span class="line">        scores = torch.matmul(decoder_context, encoder_context.transpose(-<span class="number">2</span>, -<span class="number">1</span>))</span><br><span class="line">        <span class="comment"># 归一化分数</span></span><br><span class="line">        attn_weights = nn.functional.softmax(scores, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 将注意力权重乘以 encoder_context，得到加权的上下文向量</span></span><br><span class="line">        context = torch.matmul(attn_weights, encoder_context)</span><br><span class="line">        <span class="keyword">return</span> context, attn_weights</span><br></pre></td></tr></table></figure><p>点积解码器和译码器内容得到注意力分数后进行归一化得到权重，之后将权重乘解码器的内容以得到加权上下文的向量</p><h3 id="2-4-重构Decoder类">2.4 重构Decoder类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 torch.nn 库</span></span><br><span class="line"><span class="comment"># 定义编码器类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()       </span><br><span class="line">        self.hidden_size = hidden_size <span class="comment"># 设置隐藏层大小       </span></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size) <span class="comment"># 创建词嵌入层       </span></span><br><span class="line">        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=<span class="literal">True</span>) <span class="comment"># 创建 RNN 层    </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, hidden</span>): <span class="comment"># 前向传播函数</span></span><br><span class="line">        embedded = self.embedding(inputs) <span class="comment"># 将输入转换为嵌入向量       </span></span><br><span class="line">        output, hidden = self.rnn(embedded, hidden) <span class="comment"># 将嵌入向量输入 RNN 层并获取输出</span></span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"><span class="comment"># 定义解码器类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderWithAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderWithAttention, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size <span class="comment"># 设置隐藏层大小</span></span><br><span class="line">        self.embedding = nn.Embedding(output_size, hidden_size) <span class="comment"># 创建词嵌入层</span></span><br><span class="line">        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=<span class="literal">True</span>) <span class="comment"># 创建 RNN 层</span></span><br><span class="line">        self.attention = Attention()  <span class="comment"># 创建注意力层</span></span><br><span class="line">        self.out = nn.Linear(<span class="number">2</span> * hidden_size, output_size)  <span class="comment"># 修改线性输出层，考虑隐藏状态和上下文向量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec_input, hidden, enc_output</span>):</span><br><span class="line">        embedded = self.embedding(dec_input)  <span class="comment"># 将输入转换为嵌入向量</span></span><br><span class="line">        rnn_output, hidden = self.rnn(embedded, hidden)  <span class="comment"># 将嵌入向量输入 RNN 层并获取输出 </span></span><br><span class="line">        context, attn_weights = self.attention(rnn_output, enc_output)  <span class="comment"># 计算注意力上下文向量</span></span><br><span class="line">        dec_output = torch.cat((rnn_output, context), dim=-<span class="number">1</span>)  <span class="comment"># 将上下文向量与解码器的输出拼接</span></span><br><span class="line">        dec_output = self.out(dec_output)  <span class="comment"># 使用线性层生成最终输出</span></span><br><span class="line">        <span class="keyword">return</span> dec_output, hidden, attn_weights</span><br><span class="line">n_hidden = <span class="number">128</span> <span class="comment"># 设置隐藏层数量</span></span><br><span class="line"><span class="comment"># 创建编码器和解码器</span></span><br><span class="line">encoder = Encoder(voc_size_cn, n_hidden)</span><br><span class="line">decoder = DecoderWithAttention(n_hidden, voc_size_en)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; 编码器结构：&#x27;</span>, encoder)  <span class="comment"># 打印编码器的结构</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; 解码器结构：&#x27;</span>, decoder)  <span class="comment"># 打印解码器的结构</span></span><br></pre></td></tr></table></figure><p><strong>嵌入层</strong>：</p><ul><li>将解码器的输入（目标句子单词的索引）转成向量。</li></ul><p><strong>RNN 层</strong>：</p><ul><li>处理嵌入后的向量，得到当前时间步的输出以及更新后的隐藏状态，就像大厨根据配料进行预处理。</li></ul><p><strong>注意力机制</strong>：</p><ul><li>利用 Attention 层，根据当前解码器的输出（<code>rnn_output</code>）和编码器的输出（<code>enc_output</code>）计算注意力分数，并生成加权的上下文向量 <code>context</code>。</li></ul><p><strong>拼接与输出</strong>：</p><ul><li>将 RNN 输出和上下文向量在最后一维进行拼接，然后通过一个全连接层（线性层）得到最终的预测输出。</li></ul><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">编码器结构： Encoder(</span><br><span class="line"></span><br><span class="line">  (embedding): Embedding(18, 128)</span><br><span class="line"></span><br><span class="line">  (rnn): RNN(128, 128, batch<span class="emphasis">_first=True)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis"> 解码器结构： DecoderWithAttention(</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  (embedding): Embedding(20, 128)</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">  (rnn): RNN(128, 128, batch_</span>first=True)</span><br><span class="line"></span><br><span class="line">  (attention): Attention()</span><br><span class="line"></span><br><span class="line">  (out): Linear(in<span class="emphasis">_features=256, out_</span>features=20, bias=True)</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="2-5-重构Seq2Seq类">2.5 重构Seq2Seq类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 Seq2Seq 类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2Seq</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2Seq, self).__init__()</span><br><span class="line">        <span class="comment"># 初始化编码器和解码器</span></span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, encoder_input, hidden, decoder_input</span>): </span><br><span class="line">        <span class="comment"># 将输入序列通过编码器并获取输出和隐藏状态</span></span><br><span class="line">        encoder_output, encoder_hidden = self.encoder(encoder_input, hidden)</span><br><span class="line">        <span class="comment"># 将编码器的隐藏状态传递给解码器作为初始隐藏状态</span></span><br><span class="line">        decoder_hidden = encoder_hidden</span><br><span class="line">        <span class="comment"># 将目标序列通过解码器并获取输出 -  此处更新解码器调用</span></span><br><span class="line">        decoder_output, _, attn_weights = self.decoder(decoder_input, decoder_hidden, encoder_output) </span><br><span class="line">        <span class="keyword">return</span> decoder_output, attn_weights</span><br><span class="line"><span class="comment"># 创建 Seq2Seq 模型</span></span><br><span class="line">model = Seq2Seq(encoder, decoder)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;S2S 模型结构：&#x27;</span>, model)  <span class="comment"># 打印模型的结构</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">S2S 模型结构： Seq2Seq(</span><br><span class="line"></span><br><span class="line">  (encoder): Encoder(</span><br><span class="line"></span><br><span class="line"><span class="code">    (embedding): Embedding(18, 128)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    (rnn): RNN(128, 128, batch_first=True)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  (decoder): DecoderWithAttention(</span><br><span class="line"></span><br><span class="line"><span class="code">    (embedding): Embedding(20, 128)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    (rnn): RNN(128, 128, batch_first=True)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    (attention): Attention()</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">    (out): Linear(in_features=256, out_features=20, bias=True)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>步骤解析:</p><p><strong>编码器部分</strong>：</p><p>使用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">encoder_input</span><br></pre></td></tr></table></figure><p>和初始隐藏状态</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hidden</span><br></pre></td></tr></table></figure><p>作为输入，通过编码器处理后得到两个结果：</p><ul><li><code>encoder_output</code>：编码器在每个时间步的输出信息。</li><li><code>encoder_hidden</code>：编码器处理完所有输入后的最终隐藏状态。</li></ul><ol><li><strong>传递隐藏状态</strong>：<ul><li>将编码器的隐藏状态 <code>encoder_hidden</code> 直接作为解码器的初始隐藏状态，这样解码器便能“接续”编码器的记忆，保证信息的连续性。</li></ul></li><li><strong>解码器部分</strong>：<ul><li>将 <code>decoder_input</code>（目标序列的输入）、初始隐藏状态 <code>decoder_hidden</code> 以及编码器的输出 <code>encoder_output</code> 一同输入解码器。</li><li>==解码器内部会通过注意力机制计算当前解码状态与编码器输出之间的相关性，生成加权的上下文向量，并与解码器的 RNN 输出结合后产生最终预测==。</li><li>注意解码器返回了三个值，这里我们只需要 <code>decoder_output</code> 和 <code>attn_weights</code>（注意力权重），中间那个被忽略了，用 <code>_</code> 表示。</li></ul></li><li><strong>返回结果</strong>：<ul><li>函数最后返回解码器的输出 <code>decoder_output</code> 和注意力权重 <code>attn_weights</code>，这两个信息分别代表生成的目标序列和翻译过程中各个时间步关注的原始输入信息。</li></ul></li></ol><p>想象整个流程就像是编码器（大侦探）首先搜集所有线索，然后把搜集到的重要信息传给解码器（翻译大师），翻译大师通过“放大镜”（注意力机制）仔细核对细节，最终生成精准的译文。</p><h3 id="2-6可视化权重">2.6可视化权重</h3><p>训练函数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_seq2seq</span>(<span class="params">model, criterion, optimizer, epochs</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">       encoder_input, decoder_input, target = make_data(sentences) <span class="comment"># 训练数据的创建</span></span><br><span class="line">       hidden = torch.zeros(<span class="number">1</span>, encoder_input.size(<span class="number">0</span>), n_hidden) <span class="comment"># 初始化隐藏状态      </span></span><br><span class="line">       optimizer.zero_grad()<span class="comment"># 梯度清零        </span></span><br><span class="line">       output, _ = model(encoder_input, hidden, decoder_input) <span class="comment"># 获取模型输出         </span></span><br><span class="line">       loss = criterion(output.view(-<span class="number">1</span>, voc_size_en), target.view(-<span class="number">1</span>)) <span class="comment"># 计算损失        </span></span><br><span class="line">       <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">40</span> == <span class="number">0</span>: <span class="comment"># 打印损失</span></span><br><span class="line">          <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:04d&#125;</span> cost = <span class="subst">&#123;loss:<span class="number">.6</span>f&#125;</span>&quot;</span>)         </span><br><span class="line">       loss.backward()<span class="comment"># 反向传播        </span></span><br><span class="line">       optimizer.step()<span class="comment"># 更新参数      </span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">epochs = <span class="number">400</span> <span class="comment"># 训练轮次</span></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment"># 损失函数</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>) <span class="comment"># 优化器</span></span><br><span class="line">train_seq2seq(model, criterion, optimizer, epochs) <span class="comment"># 调用函数训练模型</span></span><br></pre></td></tr></table></figure><p>定义一个可用于可视化注意力的函数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入 matplotlib</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment"># 导入 seaborn</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定无衬线字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> <span class="comment">#  用 来 正 常 显 示 负 号 </span></span><br><span class="line"><span class="keyword">def</span>  <span class="title function_">visualize_attention</span>(<span class="params">source_sentence, predicted_sentence, attn_weights</span>):    </span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>)) <span class="comment"># 画布</span></span><br><span class="line">    ax = sns.heatmap(attn_weights, annot=<span class="literal">True</span>, cbar=<span class="literal">False</span>, </span><br><span class="line">                     xticklabels=source_sentence.split(), </span><br><span class="line">                     yticklabels=predicted_sentence, cmap=<span class="string">&quot;Greens&quot;</span>) <span class="comment"># 热力图</span></span><br><span class="line">    plt.xlabel(<span class="string">&quot; 源序列 &quot;</span>) </span><br><span class="line">    plt.ylabel(<span class="string">&quot; 目标序列 &quot;</span>)</span><br><span class="line">    plt.show() <span class="comment"># 显示图片</span></span><br></pre></td></tr></table></figure><p>在测试模型的过程中，可视化注意力权重：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_seq2seq</span>(<span class="params">model, source_sentence</span>):</span><br><span class="line">    <span class="comment"># 将输入的句子转换为索引</span></span><br><span class="line">    encoder_input = np.array([[word2idx_cn[n] <span class="keyword">for</span> n <span class="keyword">in</span> source_sentence.split()]])</span><br><span class="line">    <span class="comment"># 构建输出的句子的索引，以 &#x27;&lt;sos&gt;&#x27; 开始，后面跟 &#x27;&lt;eos&gt;&#x27;，长度与输入句子相同</span></span><br><span class="line">    decoder_input = np.array([word2idx_en[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>]] + [word2idx_en[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]]*(<span class="built_in">len</span>(encoder_input[<span class="number">0</span>])-<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 转换为 LongTensor 类型</span></span><br><span class="line">    encoder_input = torch.LongTensor(encoder_input)</span><br><span class="line">    decoder_input = torch.LongTensor(decoder_input).unsqueeze(<span class="number">0</span>) <span class="comment"># 增加一维    </span></span><br><span class="line">    hidden = torch.zeros(<span class="number">1</span>, encoder_input.size(<span class="number">0</span>), n_hidden) <span class="comment"># 初始化隐藏状态    </span></span><br><span class="line">    <span class="comment"># 获取模型输出和注意力权重</span></span><br><span class="line">    predict, attn_weights = model(encoder_input, hidden, decoder_input)    </span><br><span class="line">    predict = predict.data.<span class="built_in">max</span>(<span class="number">2</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] <span class="comment"># 获取概率最大的索引</span></span><br><span class="line">    <span class="comment"># 打印输入的句子和预测的句子</span></span><br><span class="line">    <span class="built_in">print</span>(source_sentence, <span class="string">&#x27;-&gt;&#x27;</span>, [idx2word_en[n.item()] <span class="keyword">for</span> n <span class="keyword">in</span> predict.squeeze()])</span><br><span class="line">    <span class="comment"># 可视化注意力权重</span></span><br><span class="line">    attn_weights = attn_weights.squeeze(<span class="number">0</span>).cpu().detach().numpy()</span><br><span class="line">    visualize_attention(source_sentence, [idx2word_en[n.item()] <span class="keyword">for</span> n <span class="keyword">in</span> predict.squeeze()], attn_weights)    </span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line"></span><br><span class="line">test_seq2seq(model, <span class="string">&#x27;自然 语言 处理 很 强大&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503151831691.png" alt="image-20250315183151508"></p><p>在这个注意⼒权重矩阵中，NLP对“⾃然”产⽣了很强的关注，权重值为1。</p><p>当然了，我们的训练数据过少，模型可能没有⾜够的数据来学习有效的注意⼒权重。在实际应⽤中，我们当然需要更⼤规模的数据来训练Seq2Seq模型，以便模型捕捉到更丰富的语⾔模式，这样模型才能够学习到更为复杂的注意⼒权重分布模式。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>注意力机制：让AI拥有&quot;黄金七秒记忆&quot;的魔法–（点积注意力）</h1><p>注意⼒机制对于初学者来说有点难理解，我们⼀点⼀点地讲。现在先暂时忘记编码器、解码器、隐藏层和序列到序列这些概念。想象我们有两个张量x1和x2，我们希望⽤注意⼒机制把它俩给衔接起来，让x1看⼀看，x2有哪些特别值得关注的地⽅。</p><p>具体来说，要得到x1对x2的点积注意⼒，我们可以按照以下步骤进⾏操作。</p><p>（1）创建两个形状分别为(<code>batch_size</code>, <code>seq_len1</code>, <code>feature_dim</code>)和(<code>batch_size</code>, <code>seq_len2</code>, <code>feature_dim</code>)的张量x1和x2。</p><p>（2）将x1中的每个元素和x2中的每个元素进⾏点积，得到形状为 (<code>batch_size</code>, <code>seq_len1</code>, <code>seq_len2</code>)的原始权重<code>raw_weights</code>。</p><p>（3）⽤<code>softmax</code>函数对原始权重进⾏归⼀化，得到归⼀化后的注意⼒权重<code>attn_weights</code>（注意⼒权重的值在0和1之间，且每⼀⾏的和为1），形状仍为 (<code>batch_size</code>, <code>seq_len1</code>, <code>seq_len2</code>)。</p><p>（4）⽤注意⼒权重<code>attn_weights</code>对x2中的元素进⾏加权求和（与x2相乘），得到输出张量y，形状为 (<code>batch_size</code>, <code>seq_len1</code>, <code>feature_dim</code>)。这就是x1对x2的点积注意⼒。</p><p>程序结构如下：</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503142012518.png" alt="image-20250314201213369"></p><h2 id="一、点积注意机制">一、点积注意机制</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment"># 导入 nn.functional</span></span><br><span class="line"><span class="comment"># 1. 创建两个张量 x1 和 x2</span></span><br><span class="line">x1 = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">x2 = torch.randn(<span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line"><span class="comment"># 2. 计算原始权重</span></span><br><span class="line">raw_weights = torch.bmm(x1, x2.transpose(<span class="number">1</span>, <span class="number">2</span>)) <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 3. 用 softmax 函数对原始权重进行归一化</span></span><br><span class="line">attn_weights = F.softmax(raw_weights, dim=<span class="number">2</span>) <span class="comment"># 形状 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line"><span class="comment"># 4. 将注意力权重与 x2 相乘，计算加权和</span></span><br><span class="line">attn_output = torch.bmm(attn_weights, x2)  <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br></pre></td></tr></table></figure><h3 id="1-1-创建两个张量x1和x2">1.1 创建两个张量x1和x2</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建两个张量 x1 和 x2</span></span><br><span class="line">x1 = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">x2 = torch.randn(<span class="number">2</span>, <span class="number">5</span>, <span class="number">4</span>) <span class="comment"># 形状 (batch_size, seq_len2, feature_dim)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x1:&quot;</span>, x1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x2:&quot;</span>, x2)</span><br></pre></td></tr></table></figure><h3 id="1-2-计算张量点积，得到原始权重">1.2 计算张量点积，得到原始权重</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算点积，得到原始权重，形状为 (batch_size, seq_len1, seq_len2)</span></span><br><span class="line">raw_weights = torch.bmm(x1, x2.transpose(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 原始权重：&quot;</span>, raw_weights) </span><br></pre></td></tr></table></figure><p>因为是对x1和x2的两个特征维度进行点积后归一化，所以要对x2数组进行转置。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503142215836.png" alt="image-20250314221502682"></p><p>⽐如，输出结果的第⼀⾏[ 1.2474, -0.6254, 1.4849, 2.9333, -0.1787]就代表着本批次第⼀个x1序列中第⼀个元素（每个x1序列有3个元素，所以第⼀批次共3⾏）与x2中第⼀批次5个元素的每⼀个元素的相似度得分（不难看出，x1中第⼀个元素与x2中第4个元素最相似，原始注意⼒分值为2.9333）。</p><p>==相似度的计算是注意⼒机制最核⼼的思想==。</p><p>因为点积其实可以一定程度上反应向量方向的相关性，所以通过将x1的元素与x2的各个元素进行点积就可以求出权重（原始得分）其中在x2中权重较大的（得分高的）对应的词即为与x1中相关度最高的，故x2可以根据这个原始的分来判断应该输出那些对应x1相关性最高的内容。</p><p>x1起到编译器，x2起到译码器的作用</p><p>在某些⽂献或代码中，有时会将相似度得分称为原始权重。这是因为它们实际上是在计算注意⼒权重之前的中间结果。严格来说，相似度得分表示输⼊序列中不同元素之间的关联性或相似度，⽽权重则是在应⽤某些操作（如缩放、掩码和归⼀化）后得到的归⼀化值。为了避免混淆，可以将这两个术语彻底区分开。</p><p>通常，将未处理的值称为得分，并在经过处理后将它们称为权重。这有助于更清晰地理解注意⼒机制的⼯作原理及其不同组件。</p><p>举一个栗子：</p><p>让我们⽤下⾯的图示来对向量点积和相似度得分进⾏相对直观的理解。在下图的例⼦中，有两个向量——电影的特征（<strong>M</strong>）和⽤户的兴趣（<strong>U</strong>）</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503142227713.png" alt="image-20250314222742613"></p><p>向量<strong>U</strong>中可能蕴含⽤户是否喜欢爱情⽚、喜欢动作⽚等信息；⽽向量<strong>M</strong>中则包含电影含有动作、浪漫等特征的程度。</p><p>通过计算<strong>U</strong>和<strong>M</strong>的点积或相似度得分，我们可以得到⼀个衡量<strong>U</strong>对<strong>M</strong>兴趣程度的分数。例如，如果向量<strong>U</strong>中喜欢爱情⽚、喜欢动作⽚的权重较⾼，⽽向量<strong>M</strong>中的动作和浪漫特征的权重也较⾼，那么计算得到的点积或相似度得分就会⽐较⾼，表示<strong>U</strong>对<strong>M</strong>的兴趣较⼤，系统有可能推荐这部电影给⽤户。</p><h3 id="1-3-对原始权重进行归一化">1.3 对原始权重进行归一化</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment"># 导入 torch.nn.functional</span></span><br><span class="line"><span class="comment"># 应用 softmax 函数，使权重的值在 0 和 1 之间，且每一行的和为 1</span></span><br><span class="line">attn_weights = F.softmax(raw_weights, dim=-<span class="number">1</span>) <span class="comment"># 归一化</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 归一化后的注意力权重：&quot;</span>, attn_weights)</span><br></pre></td></tr></table></figure><p>所谓的归⼀化，其实理解起来很简单。得到每⼀个x1序列中的元素与其所对应的5个x2序列元素的相似度得分后，使⽤softmax函数进⾏缩放，让这5个数加起来等于1。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503142231623.png" alt="image-20250314223142527"></p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">归一化后的注意力权重： tensor([[[0.3154, 0.2383, 0.2145, 0.1589, 0.0729],</span><br><span class="line"></span><br><span class="line"><span class="code">        [0.0015, 0.9234, 0.0090, 0.0015, 0.0645],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [0.0533, 0.0576, 0.5788, 0.0858, 0.2245]],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="code">       [[0.4959, 0.0374, 0.1558, 0.0349, 0.2760],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [0.0034, 0.0470, 0.0424, 0.8826, 0.0246],</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">        [0.2597, 0.0678, 0.0840, 0.1356, 0.4530]]])</span></span><br><span class="line"><span class="code"></span></span><br></pre></td></tr></table></figure><p>归⼀化后，<code>attn_weights</code>(权重)和<code>raw_weights</code>（得分）形状相同，但是值变了，第⼀⾏的5个数字加起来刚好是1。第4个数字是0.6697，这就表明：在本批次的第⼀⾏数据中，x2序列中的第4个元素和x1序列的第1个元素特别相关，应该加以注意。</p><h3 id="1-4-求出注意力机制的加权和">1.4 求出注意力机制的加权和</h3><p>注意⼒权重与x2相乘，就得到==注意⼒分布的加权和==。</p><p>换句话说，我们将x2中的每个位置向量乘以它们在x1中对应位置的注意⼒权重，然后将这些加权向量求和——这是点积注意⼒计算的最后⼀个环节。这⼀步的⽬的是根据注意⼒权重计算x2的加权和。这个==加权和才是x1对x2的注意⼒输出==。</p><p>加权只是对应着一个关系表，并不代表输出。</p><p>相当于在一个函数中，已经求得了对应关系，现在需要给一个输入，才能得出一个输出值。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 与 x2 相乘，得到注意力分布的加权和，形状为 (batch_size, seq_len1, feature_dim)</span></span><br><span class="line">attn_output = torch.bmm(attn_weights, x2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 注意力输出 :&quot;</span>, attn_output)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503142242634.png" alt="image-20250314224208498"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>循环神经网络：给AI装上&quot;记忆芯片&quot;</h1><p>RNN的核⼼思想是利⽤“循环”的机制，将⽹络的输出反馈到输⼊，这使得它能够==在处理数据时保留前⾯的信息==，从⽽捕获序列中的⻓距离依赖关系，在处理序列数据，如⽂本、语⾳和时间序列时具有明显的优势。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112136064.png" alt="image-20250311213635894"></p><p>在每一次的输入处理中都会把之前已经提问过的问题通过与权重相乘到新的节点。</p><p>结合前⼀时间步的隐藏层状态$h_{(t-1)}$，计算当前时间步的隐藏层状态$h_t$（即上图中的<em>h</em>）。这通常通过⼀个激活函数（如tanh函数）实现。计算公式如下（其中，$W_{hh}$是隐藏层90到隐藏层的权重矩阵，$W_{xh}$是输⼊到隐藏层的权重矩阵）<br>$$<br>h_t = tanh(W_{hh} * h_{(t-1)} + W_{xh} * x_t + b_h)<br>$$<br>（3）基于当前时间步的隐藏层状态$h_t$，计算输出层$y_t$（RNN在时间步<em>t</em>的输出）。通常通过⼀个线性变换和激活函数实现。计算公式如下：<br>$$<br>y_t = softmax(W_{hy} * h_t + b_y)<br>$$<br>==RNN采⽤BPTT算法进⾏训练==。</p><p>与普通反向传播不同，BPTT算法需要在时间维度上展开RNN，以便在处理时序依赖性时计算损失梯度。</p><p>因此，BPTT算法可以看作⼀种针对具有时间结构的数据的反向传播算法。在BPTT算法中，我们⾸先⽤损失函数计算模型的损失（如交叉熵损失），然后使⽤梯度下降法（或其他优化算法）来更新模型参数。</p><p>BPTT算法的关键在于，我们需要将梯度沿着时间步（对于⾃然语⾔处理问题来说，时间步就是⽂本序列的token）反向传播，从输出层⼀直传播到输⼊层。具体步骤如下。</p><p>（1）根据模型的输出和实际标签计算损失。对每个时间步，都可以计算⼀个损失值，然后对所有时间步的损失值求和，得到总损失。</p><p>（2）计算损失函数关于模型参数（权重矩阵和偏置）的梯度。这需要应⽤链式求导法则，分别计算损失函数关于输出层、隐藏层和输⼊层的梯度。然后将这些梯度沿着时间步传播回去。</p><p>（3）使⽤优化算法（如梯度下降法、Adam等）来更新模型参数。这包括更新权重矩阵（$W_{hh}$，$W_{xh}$和$W_{hy}$）和偏置（$b_h$和$b_y$）。</p><p>如下图此类多输入多输出的情况可以有特定信息识别的功能:</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112140864.png" alt="image-20250311214006742"></p><p>再如下图：</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112203846.png" alt="image-20250311220303708"></p><p>应用于情感识别</p><p>eg：l feel happy watching the movie</p><p>判断：可通过happy判断为正向情感</p><p> </p><p>又如下图：</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112204767.png" alt="image-20250311220408658"></p><p>可做序列生成器</p><p>例如文章生成或者音乐生成</p><p> </p><p>再如下图</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112206404.png" alt="image-20250311220654298"></p><p>可做语言翻译</p><h2 id="1-RNN实现流程">1.RNN实现流程</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导⼊神经⽹络模块</span></span><br><span class="line"><span class="comment"># 定义神经概率语⾔模型（NPLM）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NPLM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(NPLM, self).__init__() <span class="comment"># 调⽤⽗类的构造函数</span></span><br><span class="line">        self.C = nn.Embedding(voc_size, embedding_size) <span class="comment"># 定义⼀个词嵌⼊层</span></span><br><span class="line">        <span class="comment"># ⽤LSTM层替代第⼀个线性层，其输⼊⼤⼩为embedding_size，隐藏层⼤⼩为n_hidden</span></span><br><span class="line">        self.lstm = nn.LSTM(embedding_size, n_hidden, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 第⼆个线性层，其输⼊⼤⼩为n_hidden，输出⼤⼩为voc_size，即词汇表⼤⼩</span></span><br><span class="line">        self.linear = nn.Linear(n_hidden, voc_size)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>): <span class="comment"># 定义前向传播过程</span></span><br><span class="line">    <span class="comment"># 输⼊数据X张量的形状为[batch_size, n_step]</span></span><br><span class="line">    X = self.C(X) <span class="comment"># 将X通过词嵌⼊层，形状变为[batch_size, n_step, embedding_size]</span></span><br><span class="line">    <span class="comment"># 通过LSTM层</span></span><br><span class="line">    lstm_out, _ = self.lstm(X) <span class="comment"># lstm_out形状变为[batch_size, n_step, n_hidden]</span></span><br><span class="line">    <span class="comment"># 只选择最后⼀个时间步的输出作为全连接层的输⼊，通过第⼆个线性层得到输出</span></span><br><span class="line">    output = self.linear(lstm_out[:, -<span class="number">1</span>, :]) <span class="comment"># output的形状为[batch_size, voc_size]</span></span><br><span class="line">    <span class="keyword">return</span> output <span class="comment"># 返回输出结果</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RNN模型结构：RNNLM(</span><br><span class="line">(embedding): Embedding(7, 2)</span><br><span class="line">(lstm): LSTM(2, 2, batch<span class="emphasis">_first=True)</span></span><br><span class="line"><span class="emphasis">(linear): Linear(in_</span>features=2, out<span class="emphasis">_features=7, bias=True))</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503112207356.png" alt="image-20250311220756261"></p><p>前部序列信息在传递到后部的同时，信息权重下降，导致重要信息丢失</p><p>求解过程中梯度消失</p><h2 id="2-LSTM：记忆宫殿的建造师">2. LSTM：记忆宫殿的建造师</h2><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503091827712.png" alt="image-20250309182715557"></p><p>LSTM会计算输⼊⻔、遗忘⻔和输出⻔的激活值。这些⻔控机制使得LSTM能够有选择地</p><p>保留或遗忘之前的信息，从⽽更好地捕捉⻓距离依赖关系。这些⻔的计算公式如下。</p><ul><li>输⼊⻔：i_t = sigmoid(W_ii * x_t + b_ii + W_hi * h_(t-1) + b_hi)</li><li>遗忘⻔：f_t = sigmoid(W_if * x_t + b_if + W_hf * h_(t-1) + b_hf)</li><li>输出⻔：o_t = sigmoid(W_io * x_t + b_io + W_ho * h_(t-1) + b_ho)</li></ul><p>LSTM更新细胞状态c_t。这是通过结合输⼊⻔、遗忘⻔和当前输⼊的信息来实现的。计算公式如下:</p><ul><li>细胞候选状态：g_t = tanh(W_ig * x_t + b_ig + W_hg * h_(t-1) + b_hg)</li><li>细胞状态更新：c_t = f_t * c_(t-1) + i_t * g_t</li></ul><p>最后，LSTM会计算当前时间步的隐藏状态h_t，这通常作为输出。计算公式如下:</p><ul><li>隐藏状态：h_t = o_t * tanh(c_t)</li></ul><p><strong>代码实现</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 定义各类门结构参数</span></span><br><span class="line">        self.W_xi = nn.Parameter(torch.Tensor(input_size, hidden_size))</span><br><span class="line">        self.W_hi = nn.Parameter(torch.Tensor(hidden_size, hidden_size))</span><br><span class="line">        <span class="comment"># ...其他参数初始化...</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, init_states=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 实现门控逻辑</span></span><br><span class="line">        i_t = torch.sigmoid(x @ self.W_xi + h_prev @ self.W_hi)</span><br><span class="line">        <span class="comment"># ...其他门计算...</span></span><br><span class="line">        <span class="keyword">return</span> output, (h_t, c_t)</span><br></pre></td></tr></table></figure><h3 id></h3><h2 id="3-从AI到AGI：记忆与推理的终极进化">3.从AI到AGI：记忆与推理的终极进化</h2><p><strong>前沿突破</strong>：</p><ul><li>Neural Turing Machine：给RNN配备可微分内存</li><li>Differentiable Neural Computer：实现类比推理</li><li>Liquid Neural Network：模拟生物神经网络特性</li></ul><p><strong>未来展望</strong>：</p><ul><li>实时翻译：具备上下文记忆的同声传译</li><li>文学创作：续写《红楼梦》后四十回</li><li>科研突破：预测蛋白质折叠轨迹</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>Seq2Seq：让机器学会&quot;同声传译&quot;的魔法架构</h1><h2 id="一、当AI遇上国际会议：传统模型的三大困境">一、当AI遇上国际会议：传统模型的三大困境</h2><p><strong>震撼案例</strong>：2016年某国际峰会，机器翻译出现致命错误：</p><p>原文：“The agreement is not legally binding” 错误翻译：“协议没有装订书皮” 正确翻译：“该协议不具备法律约束力”</p><p>这个真实事故背后暴露了传统模型的三大局限：</p><ol><li><strong>长度桎梏</strong>：定长输入 vs 动态议程</li><li><strong>语境丢失</strong>：逐词翻译导致语义断裂</li><li><strong>歧义困境</strong>：无法处理一词多义（如&quot;apple&quot;指水果公司）</li></ol><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503132232809.png" alt="image-20250313223249678"></p><p>Seq2Seq架构：编码器-解码器架构</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202503122056869.png" alt="image-20250312205631708"></p><h3 id="1-1构建实验语料库和词汇表">1.1构建实验语料库和词汇表</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建语料库，每行包含中文、英文（解码器输入）和翻译成英文后的目标输出 3 个句子</span></span><br><span class="line">sentences = [</span><br><span class="line">    [<span class="string">&#x27;咖哥 喜欢 小冰&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; KaGe likes XiaoBing&#x27;</span>, <span class="string">&#x27;KaGe likes XiaoBing &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;我 爱 学习 人工智能&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; I love studying AI&#x27;</span>, <span class="string">&#x27;I love studying AI &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;深度学习 改变 世界&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; DL changed the world&#x27;</span>, <span class="string">&#x27;DL changed the world &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;自然 语言 处理 很 强大&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; NLP is so powerful&#x27;</span>, <span class="string">&#x27;NLP is so powerful &lt;eos&gt;&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;神经网络 非常 复杂&#x27;</span>, <span class="string">&#x27;&lt;sos&gt; Neural-Nets are complex&#x27;</span>, <span class="string">&#x27;Neural-Nets are complex &lt;eos&gt;&#x27;</span>]]</span><br><span class="line">word_list_cn, word_list_en = [], []  <span class="comment"># 初始化中英文词汇表</span></span><br><span class="line"><span class="comment"># 遍历每一个句子并将单词添加到词汇表中</span></span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> sentences:</span><br><span class="line">    word_list_cn.extend(s[<span class="number">0</span>].split())</span><br><span class="line">    word_list_en.extend(s[<span class="number">1</span>].split())</span><br><span class="line">    word_list_en.extend(s[<span class="number">2</span>].split())</span><br><span class="line"><span class="comment"># 去重，得到没有重复单词的词汇表</span></span><br><span class="line">word_list_cn = <span class="built_in">list</span>(<span class="built_in">set</span>(word_list_cn))</span><br><span class="line">word_list_en = <span class="built_in">list</span>(<span class="built_in">set</span>(word_list_en))</span><br><span class="line"><span class="comment"># 构建单词到索引的映射</span></span><br><span class="line">word2idx_cn = &#123;w: i <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_cn)&#125;</span><br><span class="line">word2idx_en = &#123;w: i <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_en)&#125;</span><br><span class="line"><span class="comment"># 构建索引到单词的映射</span></span><br><span class="line">idx2word_cn = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_cn)&#125;</span><br><span class="line">idx2word_en = &#123;i: w <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list_en)&#125;</span><br><span class="line"><span class="comment"># 计算词汇表的大小</span></span><br><span class="line">voc_size_cn = <span class="built_in">len</span>(word_list_cn)</span><br><span class="line">voc_size_en = <span class="built_in">len</span>(word_list_en)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 句子数量：&quot;</span>, <span class="built_in">len</span>(sentences)) <span class="comment"># 打印句子数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 中文词汇表大小：&quot;</span>, voc_size_cn) <span class="comment"># 打印中文词汇表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 英文词汇表大小：&quot;</span>, voc_size_en) <span class="comment"># 打印英文词汇表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 中文词汇到索引的字典：&quot;</span>, word2idx_cn) <span class="comment"># 打印中文词汇到索引的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 英文词汇到索引的字典：&quot;</span>, word2idx_en) <span class="comment"># 打印英文词汇到索引的字典</span></span><br></pre></td></tr></table></figure><h3 id="1-2-生成seq2seq训练序列">1.2 生成seq2seq训练序列</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入 numpy</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch</span></span><br><span class="line"><span class="keyword">import</span> random <span class="comment"># 导入 random 库</span></span><br><span class="line"><span class="comment"># 定义一个函数，随机选择一个句子和词汇表生成输入、输出和目标数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_data</span>(<span class="params">sentences</span>):</span><br><span class="line">    <span class="comment"># 随机选择一个句子进行训练</span></span><br><span class="line">    random_sentence = random.choice(sentences)</span><br><span class="line">    <span class="comment"># 将输入句子中的单词转换为对应的索引</span></span><br><span class="line">    encoder_input = np.array([[word2idx_cn[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">0</span>].split()]])</span><br><span class="line">    <span class="comment"># 将输出句子中的单词转换为对应的索引</span></span><br><span class="line">    decoder_input = np.array([[word2idx_en[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">1</span>].split()]])</span><br><span class="line">    <span class="comment"># 将目标句子中的单词转换为对应的索引</span></span><br><span class="line">    target = np.array([[word2idx_en[n] <span class="keyword">for</span> n <span class="keyword">in</span> random_sentence[<span class="number">2</span>].split()]])</span><br><span class="line">    <span class="comment"># 将输入、输出和目标批次转换为 LongTensor</span></span><br><span class="line">    encoder_input = torch.LongTensor(encoder_input)</span><br><span class="line">    decoder_input = torch.LongTensor(decoder_input)</span><br><span class="line">    target = torch.LongTensor(target)</span><br><span class="line">    <span class="keyword">return</span> encoder_input, decoder_input, target </span><br><span class="line"><span class="comment"># 使用 make_data 函数生成输入、输出和目标张量</span></span><br><span class="line">encoder_input, decoder_input, target = make_data(sentences)</span><br><span class="line"><span class="keyword">for</span> s <span class="keyword">in</span> sentences: <span class="comment"># 获取原始句子</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">all</span>([word2idx_cn[w] <span class="keyword">in</span> encoder_input[<span class="number">0</span>] <span class="keyword">for</span> w <span class="keyword">in</span> s[<span class="number">0</span>].split()]):</span><br><span class="line">        original_sentence = s</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 原始句子：&quot;</span>, original_sentence) <span class="comment"># 打印原始句子</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 编码器输入张量的形状：&quot;</span>, encoder_input.shape)  <span class="comment"># 打印输入张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 解码器输入张量的形状：&quot;</span>, decoder_input.shape) <span class="comment"># 打印输出张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 目标张量的形状：&quot;</span>, target.shape) <span class="comment"># 打印目标张量形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 编码器输入张量：&quot;</span>, encoder_input) <span class="comment"># 打印输入张量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 解码器输入张量：&quot;</span>, decoder_input) <span class="comment"># 打印输出张量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 目标张量：&quot;</span>, target) <span class="comment"># 打印目标张量</span></span><br></pre></td></tr></table></figure><p><strong>生成数据</strong>：从一个多语言的语料库中随机挑选一个句子，并将其中的中文、英文输入和目标输出都转换成对应的数字索引张量。</p><p><strong>为神经网络准备</strong>：这种数字化的数据是神经网络处理文本数据时必不可少的，确保模型能理解和训练每个单词。</p><h3 id="1-3-定义编码器和解码器">1.3 定义编码器和解码器</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 torch.nn 库</span></span><br><span class="line"><span class="comment"># 定义编码器类，继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Encoder, self).__init__()       </span><br><span class="line">        self.hidden_size = hidden_size <span class="comment"># 设置隐藏层大小       </span></span><br><span class="line">        self.embedding = nn.Embedding(input_size, hidden_size) <span class="comment"># 创建词嵌入层       </span></span><br><span class="line">        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=<span class="literal">True</span>) <span class="comment"># 创建 RNN 层    </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, hidden</span>): <span class="comment"># 前向传播函数</span></span><br><span class="line">        embedded = self.embedding(inputs) <span class="comment"># 将输入转换为嵌入向量       </span></span><br><span class="line">        output, hidden = self.rnn(embedded, hidden) <span class="comment"># 将嵌入向量输入 RNN 层并获取输出</span></span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"><span class="comment"># 定义解码器类，继承自 nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()       </span><br><span class="line">        self.hidden_size = hidden_size <span class="comment"># 设置隐藏层大小       </span></span><br><span class="line">        self.embedding = nn.Embedding(output_size, hidden_size) <span class="comment"># 创建词嵌入层</span></span><br><span class="line">        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=<span class="literal">True</span>)  <span class="comment"># 创建 RNN 层       </span></span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size) <span class="comment"># 创建线性输出层    </span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, hidden</span>):  <span class="comment"># 前向传播函数     </span></span><br><span class="line">        embedded = self.embedding(inputs) <span class="comment"># 将输入转换为嵌入向量       </span></span><br><span class="line">        output, hidden = self.rnn(embedded, hidden) <span class="comment"># 将嵌入向量输入 RNN 层并获取输出       </span></span><br><span class="line">        output = self.out(output) <span class="comment"># 使用线性层生成最终输出</span></span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line">n_hidden = <span class="number">128</span> <span class="comment"># 设置隐藏层数量</span></span><br><span class="line"><span class="comment"># 创建编码器和解码器</span></span><br><span class="line">encoder = Encoder(voc_size_cn, n_hidden)</span><br><span class="line">decoder = Decoder(n_hidden, voc_size_en)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; 编码器结构：&#x27;</span>, encoder)  <span class="comment"># 打印编码器的结构</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27; 解码器结构：&#x27;</span>, decoder)  <span class="comment"># 打印解码器的结构</span></span><br></pre></td></tr></table></figure><p><strong>编码器</strong> 负责将中文句子转换为一个隐藏状态，这个隐藏状态包含了整个句子的“精华信息”。</p><p><strong>解码器</strong> 接受这个隐藏状态，并利用自己的 RNN 层一步步生成英文翻译，直到输出完整的翻译句子。</p><p><strong>整体流程</strong> 就像两个翻译大师默契合作：一个把中文理解得透彻，另一个根据理解生成英文表述。</p><h3 id="1-4-定义seq2seq架构">1.4 定义seq2seq架构</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Seq2Seq</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, decoder</span>):</span><br><span class="line">        <span class="built_in">super</span>(Seq2Seq, self).__init__()</span><br><span class="line">        <span class="comment"># 初始化编码器和解码器</span></span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, enc_input, hidden, dec_input</span>):    <span class="comment"># 定义前向传播函数</span></span><br><span class="line">        <span class="comment"># 使输入序列通过编码器并获取输出和隐藏状态</span></span><br><span class="line">        encoder_output, encoder_hidden = self.encoder(enc_input, hidden)</span><br><span class="line">        <span class="comment"># 将编码器的隐藏状态传递给解码器作为初始隐藏状态</span></span><br><span class="line">        decoder_hidden = encoder_hidden</span><br><span class="line">        <span class="comment"># 使解码器输入（目标序列）通过解码器并获取输出</span></span><br><span class="line">        decoder_output, _ = self.decoder(dec_input, decoder_hidden)</span><br><span class="line">        <span class="keyword">return</span> decoder_output</span><br><span class="line"><span class="comment"># 创建 Seq2Seq 架构</span></span><br><span class="line">model = Seq2Seq(encoder, decoder)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;S2S 模型结构：&#x27;</span>, model)  <span class="comment"># 打印模型的结构</span></span><br></pre></td></tr></table></figure><p><strong>整体流程</strong>：</p><ol><li><strong>初始化</strong>：将编码器和解码器组合成一个 Seq2Seq 模型。</li><li><strong>编码过程</strong>：输入句子经过编码器处理，生成隐藏状态（记忆）。</li><li><strong>解码过程</strong>：解码器以编码器的隐藏状态为起点，结合目标序列（通常带 <code>&lt;sos&gt;</code>）逐步生成输出。</li><li><strong>输出</strong>：最终返回解码器生成的输出，这通常用来计算损失或者进行实际翻译。</li></ol><h3 id="1-5-训练seq2seq架构">1.5 训练seq2seq架构</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_seq2seq</span>(<span class="params">model, criterion, optimizer, epochs</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">       encoder_input, decoder_input, target = make_data(sentences) <span class="comment"># 训练数据的创建</span></span><br><span class="line">       hidden = torch.zeros(<span class="number">1</span>, encoder_input.size(<span class="number">0</span>), n_hidden) <span class="comment"># 初始化隐藏状态      </span></span><br><span class="line">       optimizer.zero_grad()<span class="comment"># 梯度清零        </span></span><br><span class="line">       output = model(encoder_input, hidden, decoder_input) <span class="comment"># 获取模型输出        </span></span><br><span class="line">       loss = criterion(output.view(-<span class="number">1</span>, voc_size_en), target.view(-<span class="number">1</span>)) <span class="comment"># 计算损失        </span></span><br><span class="line">       <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">40</span> == <span class="number">0</span>: <span class="comment"># 打印损失</span></span><br><span class="line">          <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch + <span class="number">1</span>:04d&#125;</span> cost = <span class="subst">&#123;loss:<span class="number">.6</span>f&#125;</span>&quot;</span>)         </span><br><span class="line">       loss.backward()<span class="comment"># 反向传播        </span></span><br><span class="line">       optimizer.step()<span class="comment"># 更新参数</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">epochs = <span class="number">400</span> <span class="comment"># 训练轮次</span></span><br><span class="line">criterion = nn.CrossEntropyLoss() <span class="comment"># 损失函数</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>) <span class="comment"># 优化器</span></span><br><span class="line">train_seq2seq(model, criterion, optimizer, epochs) <span class="comment"># 调用函数训练模型</span></span><br></pre></td></tr></table></figure><p>每一轮，模型从语料库中随机抽取一个句子，用编码器“消化”输入，再由解码器“烹饪”输出；计算损失后，反向传播让模型不断改进。</p><h3 id="1-6-测试seq2seq架构">1.6 测试seq2seq架构</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_seq2seq</span>(<span class="params">model, source_sentence</span>):</span><br><span class="line">    <span class="comment"># 将输入的句子转换为索引</span></span><br><span class="line">    encoder_input = np.array([[word2idx_cn[n] <span class="keyword">for</span> n <span class="keyword">in</span> source_sentence.split()]])</span><br><span class="line">    <span class="comment"># 构建输出的句子的索引，以 &#x27;&lt;sos&gt;&#x27; 开始，后面跟 &#x27;&lt;eos&gt;&#x27;，长度与输入句子相同</span></span><br><span class="line">    decoder_input = np.array([word2idx_en[<span class="string">&#x27;&lt;sos&gt;&#x27;</span>]] + [word2idx_en[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]]*(<span class="built_in">len</span>(encoder_input[<span class="number">0</span>])-<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 转换为 LongTensor 类型</span></span><br><span class="line">    encoder_input = torch.LongTensor(encoder_input)</span><br><span class="line">    decoder_input = torch.LongTensor(decoder_input).unsqueeze(<span class="number">0</span>) <span class="comment"># 增加一维    </span></span><br><span class="line">    hidden = torch.zeros(<span class="number">1</span>, encoder_input.size(<span class="number">0</span>), n_hidden) <span class="comment"># 初始化隐藏状态    </span></span><br><span class="line">    predict = model(encoder_input, hidden, decoder_input) <span class="comment"># 获取模型输出    </span></span><br><span class="line">    predict = predict.data.<span class="built_in">max</span>(<span class="number">2</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>] <span class="comment"># 获取概率最大的索引</span></span><br><span class="line">    <span class="comment"># 打印输入的句子和预测的句子</span></span><br><span class="line">    <span class="built_in">print</span>(source_sentence, <span class="string">&#x27;-&gt;&#x27;</span>, [idx2word_en[n.item()] <span class="keyword">for</span> n <span class="keyword">in</span> predict.squeeze()])</span><br><span class="line"><span class="comment"># 测试模型</span></span><br><span class="line">test_seq2seq(model, <span class="string">&#x27;咖哥 喜欢 小冰&#x27;</span>)  </span><br><span class="line">test_seq2seq(model, <span class="string">&#x27;自然 语言 处理 很 强大&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>整体流程</strong>：</p><ol><li>输入句子转换为数字索引。</li><li>为解码器构造一个“启动提示”，包含 <code>&lt;sos&gt;</code> 和 <code>&lt;eos&gt;</code>。</li><li>初始化必要的张量和隐藏状态。</li><li>使用训练好的 Seq2Seq 模型生成预测输出。</li><li>将预测结果转换回单词并打印出来。</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>图解Word2Vec：如何让AI真正“读懂”人类语言？</h1><p><img src="https://images.unsplash.com/photo-1501504905252-473c47e087f8?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1350&amp;q=80" alt="词向量魔法"></p><h2 id="一、从-文字游戏-到-语义地图-：词向量革命">一、从&quot;文字游戏&quot;到&quot;语义地图&quot;：词向量革命</h2><blockquote><p>“国王 - 男人 + 女人 = 女王”<br>这个震撼NLP界的经典公式，揭开了词向量的神秘面纱</p></blockquote><p>传统文本处理就像让AI玩&quot;文字连连看&quot;：机械统计词频、匹配固定规则。这种处理方式最大的痛点是什么？看看这个例子：</p><p><strong>病例报告</strong><br>患者：“医生，我最近总是心慌、手抖、容易饿”<br>传统AI诊断：发现&quot;心&quot;出现3次，&quot;手&quot;出现2次 → 重点检查心血管系统<br>实际诊断：甲状腺功能亢进</p><p>这个真实的医疗AI误诊案例，暴露了传统文本处理的致命缺陷——只见树木不见森林。而词向量的诞生，让AI第一次拥有了理解词语深层含义的能力。</p><h2 id="二、Word2Vec的魔法原理（附代码实战）">二、Word2Vec的魔法原理（附代码实战）</h2><h3 id="2-1-从-填空题-到-完形填空-：两大核心模型">2.1 从&quot;填空题&quot;到&quot;完形填空&quot;：两大核心模型</h3><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201617548.png" alt="image-20250220161704458"></p><ul><li><strong>CBOW模型</strong>：像做填空题<br>输入：四周的词语（如&quot;猫 会 __ 老鼠&quot;）<br>输出：预测中间词（“抓”）</li><li><strong>Skip-Gram模型</strong>：像完形填空<br>输入：中心词（如&quot;人工智能&quot;）<br>输出：预测周围词（“深度学习”、“算法”、“大数据”）</li></ul><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201617480.png" alt="image-20250220161715394"></p><h3 id="2-2-Skip-Gram模型的代码实现">2.2 <strong>Skip-Gram</strong>模型的代码实现</h3><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202019704.png" alt="image-20250220201802253"></p><h4 id="2-2-1-构建实验语料库">2.2.1 构建实验语料库</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个句子列表，后面会用这些句子来训练 CBOW 和 Skip-Gram 模型</span></span><br><span class="line">sentences = [<span class="string">&quot;Kage is Teacher&quot;</span>, <span class="string">&quot;Mazong is Boss&quot;</span>, <span class="string">&quot;Niuzong is Boss&quot;</span>,</span><br><span class="line">             <span class="string">&quot;Xiaobing is Student&quot;</span>, <span class="string">&quot;Xiaoxue is Student&quot;</span>,]</span><br><span class="line"><span class="comment"># 将所有句子连接在一起，然后用空格分隔成多个单词</span></span><br><span class="line">words = <span class="string">&#x27; &#x27;</span>.join(sentences).split()</span><br><span class="line"><span class="comment"># 构建词汇表，去除重复的词</span></span><br><span class="line">word_list = <span class="built_in">list</span>(<span class="built_in">set</span>(words))</span><br><span class="line"><span class="comment"># 创建一个字典，将每个词映射到一个唯一的索引</span></span><br><span class="line">word_to_idx = &#123;word: idx <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list)&#125;</span><br><span class="line"><span class="comment"># 创建一个字典，将每个索引映射到对应的词</span></span><br><span class="line">idx_to_word = &#123;idx: word <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list)&#125;</span><br><span class="line">voc_size = <span class="built_in">len</span>(word_list) <span class="comment"># 计算词汇表的大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇表：&quot;</span>, word_list) <span class="comment"># 输出词汇表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇到索引的字典：&quot;</span>, word_to_idx) <span class="comment"># 输出词汇到索引的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 索引到词汇的字典：&quot;</span>, idx_to_word) <span class="comment"># 输出索引到词汇的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇表大小：&quot;</span>, voc_size) <span class="comment"># 输出词汇表大小</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">词汇表： [&#x27;Xiaoxue&#x27;, &#x27;is&#x27;, &#x27;Niuzong&#x27;, &#x27;Student&#x27;, &#x27;Teacher&#x27;, &#x27;Boss&#x27;, &#x27;Mazong&#x27;, &#x27;Xiaobing&#x27;, &#x27;Kage&#x27;]</span><br><span class="line"></span><br><span class="line">词汇到索引的字典： &#123;&#x27;Xiaoxue&#x27;: 0, &#x27;is&#x27;: 1, &#x27;Niuzong&#x27;: 2, &#x27;Student&#x27;: 3, &#x27;Teacher&#x27;: 4, &#x27;Boss&#x27;: 5, &#x27;Mazong&#x27;: 6, &#x27;Xiaobing&#x27;: 7, &#x27;Kage&#x27;: 8&#125;</span><br><span class="line"></span><br><span class="line">索引到词汇的字典： &#123;0: &#x27;Xiaoxue&#x27;, 1: &#x27;is&#x27;, 2: &#x27;Niuzong&#x27;, 3: &#x27;Student&#x27;, 4: &#x27;Teacher&#x27;, 5: &#x27;Boss&#x27;, 6: &#x27;Mazong&#x27;, 7: &#x27;Xiaobing&#x27;, 8: &#x27;Kage&#x27;&#125;</span><br><span class="line"></span><br><span class="line">词汇表大小： 9</span><br></pre></td></tr></table></figure><h4 id="2-2-2-生成Skip-Gram数据">2.2.2  生成Skip-Gram数据</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成 Skip-Gram 训练数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_skipgram_dataset</span>(<span class="params">sentences, window_size=<span class="number">2</span></span>):</span><br><span class="line">    data = [] <span class="comment"># 初始化数据</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences: <span class="comment"># 遍历句子</span></span><br><span class="line">        sentence = sentence.split()  <span class="comment"># 将句子分割成单词列表</span></span><br><span class="line">        <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentence):  <span class="comment"># 遍历单词及其索引</span></span><br><span class="line">            <span class="comment"># 获取相邻的单词，将当前单词前后各 N 个单词作为相邻单词</span></span><br><span class="line">            <span class="keyword">for</span> neighbor <span class="keyword">in</span> sentence[<span class="built_in">max</span>(idx - window_size, <span class="number">0</span>): </span><br><span class="line">                        <span class="built_in">min</span>(idx + window_size + <span class="number">1</span>, <span class="built_in">len</span>(sentence))]:</span><br><span class="line">                <span class="keyword">if</span> neighbor != word:  <span class="comment"># 排除当前单词本身</span></span><br><span class="line">                    <span class="comment"># 将相邻单词与当前单词作为一组训练数据</span></span><br><span class="line">                    data.append((neighbor, word))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="comment"># 使用函数创建 Skip-Gram 训练数据</span></span><br><span class="line">skipgram_data = create_skipgram_dataset(sentences)</span><br><span class="line"><span class="comment"># 打印未编码的 Skip-Gram 数据样例（前 3 个）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Skip-Gram 数据样例（未编码）：&quot;</span>, skipgram_data[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Skip-Gram 数据样例（未编码）： [(<span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;Kage&#x27;</span>), (<span class="string">&#x27;Teacher&#x27;</span>, <span class="string">&#x27;Kage&#x27;</span>), (<span class="string">&#x27;Kage&#x27;</span>, <span class="string">&#x27;is&#x27;</span>)]</span><br></pre></td></tr></table></figure><h4 id="2-2-3-进行One-Hot编码">2.2.3 进行One-Hot编码</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 One-Hot 编码函数</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch 库</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encoding</span>(<span class="params">word, word_to_idx</span>):    </span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(word_to_idx)) <span class="comment"># 创建一个长度与词汇表相同的全 0 张量  </span></span><br><span class="line">    tensor[word_to_idx[word]] = <span class="number">1</span>  <span class="comment"># 将对应词的索引设为 1</span></span><br><span class="line">    <span class="keyword">return</span> tensor  <span class="comment"># 返回生成的 One-Hot 向量</span></span><br><span class="line"><span class="comment"># 展示 One-Hot 编码前后的数据</span></span><br><span class="line">word_example = <span class="string">&quot;Teacher&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;One-Hot 编码前的单词：&quot;</span>, word_example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;One-Hot 编码后的向量：&quot;</span>, one_hot_encoding(word_example, word_to_idx))</span><br><span class="line"><span class="comment"># 展示编码后的 Skip-Gram 训练数据样例</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Skip-Gram 数据样例（已编码）：&quot;</span>, [(one_hot_encoding(context, word_to_idx), </span><br><span class="line">          word_to_idx[target]) <span class="keyword">for</span> context, target <span class="keyword">in</span> skipgram_data[:<span class="number">3</span>]])</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">One-Hot 编码前的单词： Teacher</span><br><span class="line">One-Hot 编码后的向量： tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.])</span><br><span class="line">Skip-Gram 数据样例（已编码）： </span><br><span class="line">[(tensor([0., 0., 0., 0., 1., 0., 0., 0., 0.]), 7), (tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.]), 7), (tensor([0., 0., 0., 0., 0., 0., 0., 1., 0.]), 4)]</span><br></pre></td></tr></table></figure><h4 id="2-2-4-定义Skip-Gram类">2.2.4 定义Skip-Gram类</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 Skip-Gram 类</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 neural network</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SkipGram</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, voc_size, embedding_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(SkipGram, self).__init__()</span><br><span class="line">        <span class="comment"># 从词汇表大小到嵌入层大小（维度）的线性层（权重矩阵）</span></span><br><span class="line">        self.input_to_hidden = nn.Linear(voc_size, embedding_size, bias=<span class="literal">False</span>)  </span><br><span class="line">        <span class="comment"># 从嵌入层大小（维度）到词汇表大小的线性层（权重矩阵）</span></span><br><span class="line">        self.hidden_to_output = nn.Linear(embedding_size, voc_size, bias=<span class="literal">False</span>)  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>): <span class="comment"># 前向传播的方式，X 形状为 (batch_size, voc_size)      </span></span><br><span class="line">         <span class="comment"># 通过隐藏层，hidden 形状为 (batch_size, embedding_size)</span></span><br><span class="line">            hidden = self.input_to_hidden(X) </span><br><span class="line">            <span class="comment"># 通过输出层，output_layer 形状为 (batch_size, voc_size)</span></span><br><span class="line">            output = self.hidden_to_output(hidden)  </span><br><span class="line">            <span class="keyword">return</span> output    </span><br><span class="line">embedding_size = <span class="number">2</span> <span class="comment"># 设定嵌入层的大小，这里选择 2 是为了方便展示</span></span><br><span class="line">skipgram_model = SkipGram(voc_size, embedding_size)  <span class="comment"># 实例化 Skip-Gram 模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Skip-Gram 模型：&quot;</span>, skipgram_model)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Skip-Gram 模型： SkipGram(</span><br><span class="line">  (input<span class="emphasis">_to_</span>hidden): Linear(in<span class="emphasis">_features=9, out_</span>features=2, bias=False)</span><br><span class="line">  (hidden<span class="emphasis">_to_</span>output): Linear(in<span class="emphasis">_features=2, out_</span>features=9, bias=False)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="2-2-5-训练Skip-Gram">2.2.5  训练Skip-Gram</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练 Skip-Gram 类</span></span><br><span class="line">learning_rate = <span class="number">0.001</span> <span class="comment"># 设置学习速率</span></span><br><span class="line">epochs = <span class="number">1000</span> <span class="comment"># 设置训练轮次</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()  <span class="comment"># 定义交叉熵损失函数</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim <span class="comment"># 导入随机梯度下降优化器</span></span><br><span class="line">optimizer = optim.SGD(skipgram_model.parameters(), lr=learning_rate)  </span><br><span class="line"><span class="comment"># 开始训练循环</span></span><br><span class="line">loss_values = []  <span class="comment"># 用于存储每轮的平均损失值</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    loss_sum = <span class="number">0</span> <span class="comment"># 初始化损失值</span></span><br><span class="line">    <span class="keyword">for</span> context, target <span class="keyword">in</span> skipgram_data:        </span><br><span class="line">        X = one_hot_encoding(target, word_to_idx).<span class="built_in">float</span>().unsqueeze(<span class="number">0</span>) <span class="comment"># 将中心词转换为 One-Hot 向量  </span></span><br><span class="line">        y_true = torch.tensor([word_to_idx[context]], dtype=torch.long) <span class="comment"># 将周围词转换为索引值 </span></span><br><span class="line">        y_pred = skipgram_model(X)  <span class="comment"># 计算预测值</span></span><br><span class="line">        loss = criterion(y_pred, y_true)  <span class="comment"># 计算损失</span></span><br><span class="line">        loss_sum += loss.item() <span class="comment"># 累积损失</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清空梯度</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 输出每 100 轮的损失，并记录损失</span></span><br><span class="line">      <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, Loss: <span class="subst">&#123;loss_sum/<span class="built_in">len</span>(skipgram_data)&#125;</span>&quot;</span>)  </span><br><span class="line">      loss_values.append(loss_sum / <span class="built_in">len</span>(skipgram_data))</span><br><span class="line"><span class="comment"># 绘制训练损失曲线</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入 matplotlib</span></span><br><span class="line"><span class="comment"># 绘制二维词向量图</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定无衬线字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, epochs//<span class="number">100</span> + <span class="number">1</span>), loss_values) <span class="comment"># 绘图</span></span><br><span class="line">plt.title(<span class="string">&#x27; 训练损失曲线 &#x27;</span>) <span class="comment"># 图题</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27; 轮次 &#x27;</span>) <span class="comment"># X 轴 Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27; 损失 &#x27;</span>) <span class="comment"># Y 轴 Label</span></span><br><span class="line">plt.show() <span class="comment"># 显示图</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 100, Loss: 2.176283597946167</span><br><span class="line">Epoch: 200, Loss: 2.1313777963320413</span><br><span class="line">Epoch: 300, Loss: 2.079272961616516</span><br><span class="line">Epoch: 400, Loss: 2.0179983615875243</span><br><span class="line">Epoch: 500, Loss: 1.956022528807322</span><br><span class="line">Epoch: 600, Loss: 1.9065291663010915</span><br><span class="line">Epoch: 700, Loss: 1.8729750255743662</span><br><span class="line">Epoch: 800, Loss: 1.8494429806868236</span><br><span class="line">Epoch: 900, Loss: 1.8303062697251637</span><br><span class="line">Epoch: 1000, Loss: 1.812800904115041</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202031327.png" alt="image-20250220203128215"> </p><h4 id="2-2-6-展示词向量">2.2.6 展示词向量</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出 Skip-Gram 习得的词嵌入</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Skip-Gram 词嵌入：&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> word, idx <span class="keyword">in</span> word_to_idx.items(): <span class="comment"># 输出每个词的嵌入向量</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;word&#125;</span>: <span class="subst">&#123;skipgram_model.input_to_hidden.weight[:,idx].detach().numpy()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Xiaobing: [-1.3628563 -2.1293848]</span><br><span class="line">Xiaoxue: [-1.3693085 -2.1389563]</span><br><span class="line">Boss: [ 2.923863 -0.4184679]</span><br><span class="line">Student: [-0.09255204 -0.8242733 ]</span><br><span class="line">is: [-0.23261149 0.29151806]</span><br><span class="line">Kage: [-0.3542828 -0.9870443]</span><br><span class="line">Niuzong: [ 0.8161409 -0.624454 ]</span><br><span class="line">Mazong: [ 0.821509 -0.62387395]</span><br><span class="line">Teacher: [ 0.8520589 -0.47847477]</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots() </span><br><span class="line"><span class="keyword">for</span> word, idx <span class="keyword">in</span> word_to_idx.items():</span><br><span class="line">    <span class="comment"># 获取每个单词的嵌入向量</span></span><br><span class="line">    vec = skipgram_model.input_to_hidden.weight[:,idx].detach().numpy() </span><br><span class="line">    ax.scatter(vec[<span class="number">0</span>], vec[<span class="number">1</span>]) <span class="comment"># 在图中绘制嵌入向量的点</span></span><br><span class="line">    ax.annotate(word, (vec[<span class="number">0</span>], vec[<span class="number">1</span>]), fontsize=<span class="number">12</span>) <span class="comment"># 点旁添加单词标签</span></span><br><span class="line">plt.title(<span class="string">&#x27; 二维词嵌入 &#x27;</span>) <span class="comment"># 图题</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27; 向量维度 1&#x27;</span>) <span class="comment"># X 轴 Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27; 向量维度 2&#x27;</span>) <span class="comment"># Y 轴 Label</span></span><br><span class="line">plt.show() <span class="comment"># 显示图</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202036987.png" alt="image-20250220203624875"></p><p>总结⼀下：我们使⽤PyTorch实现了⼀个简单的Word2Vec（这⾥是Skip-Gram）模型。</p><p>模型包括输⼊层、隐藏层和输出层。输⼊层接收周围词（以One-Hot编码后的向量形式表示）。接下来，输⼊层到隐藏层的权重矩阵（记为input_to_hidden）将这个向量转换为词嵌⼊，该词嵌⼊直接作为隐藏层的输出。</p><p>隐藏层到输出层的权重矩阵（记为hidden_to_output）将隐藏层的</p><p>输出转换为⼀个概率分布，⽤于预测与周围词相关的中⼼词（以索引形式表示）。通过最⼩化预测词和实际⽬标词之间的分类交叉熵损失，可以学习词嵌⼊向量。下图展示了这个流程。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202040392.png" alt="image-20250220204011257"></p><h3 id="2-3-CBOW模型的代码实现">2.3 CBOW模型的代码实现</h3><p>CBOW模型与Skip-Gram模型相反，其主要任务是根据给定的周围词来预测中⼼词。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个句子列表，后面会用这些句子来训练 CBOW 和 Skip-Gram 模型</span></span><br><span class="line">sentences = [<span class="string">&quot;Kage is Teacher&quot;</span>, <span class="string">&quot;Mazong is Boss&quot;</span>, <span class="string">&quot;Niuzong is Boss&quot;</span>,</span><br><span class="line">             <span class="string">&quot;Xiaobing is Student&quot;</span>, <span class="string">&quot;Xiaoxue is Student&quot;</span>,]</span><br><span class="line"><span class="comment"># 将所有句子连接在一起，然后用空格分隔成多个单词</span></span><br><span class="line">words = <span class="string">&#x27; &#x27;</span>.join(sentences).split()</span><br><span class="line"><span class="comment"># 构建词汇表，去除重复的词</span></span><br><span class="line">word_list = <span class="built_in">list</span>(<span class="built_in">set</span>(words))</span><br><span class="line"><span class="comment"># 创建一个字典，将每个词映射到一个唯一的索引</span></span><br><span class="line">word_to_idx = &#123;word: idx <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list)&#125;</span><br><span class="line"><span class="comment"># 创建一个字典，将每个索引映射到对应的词</span></span><br><span class="line">idx_to_word = &#123;idx: word <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(word_list)&#125;</span><br><span class="line">voc_size = <span class="built_in">len</span>(word_list) <span class="comment"># 计算词汇表的大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇表：&quot;</span>, word_list) <span class="comment"># 输出词汇表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇到索引的字典：&quot;</span>, word_to_idx) <span class="comment"># 输出词汇到索引的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 索引到词汇的字典：&quot;</span>, idx_to_word) <span class="comment"># 输出索引到词汇的字典</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇表大小：&quot;</span>, voc_size) <span class="comment"># 输出词汇表大小</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">词汇表： [&#x27;Boss&#x27;, &#x27;Niuzong&#x27;, &#x27;Mazong&#x27;, &#x27;Teacher&#x27;, &#x27;is&#x27;, &#x27;Xiaobing&#x27;, &#x27;Student&#x27;, &#x27;Kage&#x27;, &#x27;Xiaoxue&#x27;]</span><br><span class="line">词汇到索引的字典： &#123;&#x27;Boss&#x27;: 0, &#x27;Niuzong&#x27;: 1, &#x27;Mazong&#x27;: 2, &#x27;Teacher&#x27;: 3, &#x27;is&#x27;: 4, &#x27;Xiaobing&#x27;: 5, &#x27;Student&#x27;: 6, &#x27;Kage&#x27;: 7, &#x27;Xiaoxue&#x27;: 8&#125;</span><br><span class="line">索引到词汇的字典： &#123;0: &#x27;Boss&#x27;, 1: &#x27;Niuzong&#x27;, 2: &#x27;Mazong&#x27;, 3: &#x27;Teacher&#x27;, 4: &#x27;is&#x27;, 5: &#x27;Xiaobing&#x27;, 6: &#x27;Student&#x27;, 7: &#x27;Kage&#x27;, 8: &#x27;Xiaoxue&#x27;&#125;</span><br><span class="line">词汇表大小： 9</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成 CBOW 训练数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_cbow_dataset</span>(<span class="params">sentences, window_size=<span class="number">2</span></span>):</span><br><span class="line">    data = []<span class="comment"># 初始化数据</span></span><br><span class="line">    <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">        sentence = sentence.split()  <span class="comment"># 将句子分割成单词列表</span></span><br><span class="line">        <span class="keyword">for</span> idx, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentence):  <span class="comment"># 遍历单词及其索引</span></span><br><span class="line">            <span class="comment"># 获取上下文词汇，将当前单词前后各 window_size 个单词作为周围词</span></span><br><span class="line">            context_words = sentence[<span class="built_in">max</span>(idx - window_size, <span class="number">0</span>):idx] \</span><br><span class="line">                + sentence[idx + <span class="number">1</span>:<span class="built_in">min</span>(idx + window_size + <span class="number">1</span>, <span class="built_in">len</span>(sentence))]</span><br><span class="line">            <span class="comment"># 将当前单词与上下文词汇作为一组训练数据</span></span><br><span class="line">            data.append((word, context_words))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"><span class="comment"># 使用函数创建 CBOW 训练数据</span></span><br><span class="line">cbow_data = create_cbow_dataset(sentences)</span><br><span class="line"><span class="comment"># 打印未编码的 CBOW 数据样例（前三个）</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;CBOW 数据样例（未编码）：&quot;</span>, cbow_data[:<span class="number">3</span>])</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CBOW 数据样例（未编码）： [(&#x27;Kage&#x27;, [&#x27;is&#x27;, &#x27;Teacher&#x27;]), (&#x27;is&#x27;, [&#x27;Kage&#x27;, &#x27;Teacher&#x27;]), (&#x27;Teacher&#x27;, [&#x27;Kage&#x27;, &#x27;is&#x27;])]</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 One-Hot 编码函数</span></span><br><span class="line"><span class="keyword">import</span> torch <span class="comment"># 导入 torch 库</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one_hot_encoding</span>(<span class="params">word, word_to_idx</span>):    </span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(word_to_idx)) <span class="comment"># 创建一个长度与词汇表相同的全 0 张量  </span></span><br><span class="line">    tensor[word_to_idx[word]] = <span class="number">1</span>  <span class="comment"># 将对应词的索引设为 1</span></span><br><span class="line">    <span class="keyword">return</span> tensor  <span class="comment"># 返回生成的 One-Hot 向量</span></span><br><span class="line"><span class="comment"># 展示 One-Hot 编码前后的数据</span></span><br><span class="line">word_example = <span class="string">&quot;Teacher&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;One-Hot 编码前的单词：&quot;</span>, word_example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;One-Hot 编码后的向量：&quot;</span>, one_hot_encoding(word_example, word_to_idx))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">One-Hot 编码前的单词： Teacher</span><br><span class="line">One-Hot 编码后的向量： tensor([0., 0., 0., 1., 0., 0., 0., 0., 0.])</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义 CBOW 模型</span></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn <span class="comment"># 导入 neural network</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CBOW</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, voc_size, embedding_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(CBOW, self).__init__()</span><br><span class="line">        <span class="comment"># 从词汇表大小到嵌入大小的线性层（权重矩阵）</span></span><br><span class="line">        self.input_to_hidden = nn.Linear(voc_size, </span><br><span class="line">                                         embedding_size, bias=<span class="literal">False</span>)  </span><br><span class="line">        <span class="comment"># 从嵌入大小到词汇表大小的线性层（权重矩阵）</span></span><br><span class="line">        self.hidden_to_output = nn.Linear(embedding_size, </span><br><span class="line">                                          voc_size, bias=<span class="literal">False</span>)  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>): <span class="comment"># X: [num_context_words, voc_size]</span></span><br><span class="line">        <span class="comment"># 生成嵌入：[num_context_words, embedding_size]</span></span><br><span class="line">        embeddings = self.input_to_hidden(X)  </span><br><span class="line">        <span class="comment"># 计算隐藏层，求嵌入的均值：[embedding_size]</span></span><br><span class="line">        hidden_layer = torch.mean(embeddings, dim=<span class="number">0</span>)  </span><br><span class="line">        <span class="comment"># 生成输出层：[1, voc_size]</span></span><br><span class="line">        output_layer = self.hidden_to_output(hidden_layer.unsqueeze(<span class="number">0</span>)) </span><br><span class="line">        <span class="keyword">return</span> output_layer    </span><br><span class="line">embedding_size = <span class="number">2</span> <span class="comment"># 设定嵌入层的大小，这里选择 2 是为了方便展示</span></span><br><span class="line">cbow_model = CBOW(voc_size,embedding_size)  <span class="comment"># 实例化 CBOW 模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;CBOW 模型：&quot;</span>, cbow_model)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CBOW 模型： CBOW(</span><br><span class="line">  (input_to_hidden): Linear(in_features=<span class="number">9</span>, out_features=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">  (hidden_to_output): Linear(in_features=<span class="number">2</span>, out_features=<span class="number">9</span>, bias=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练 Skip-Gram 类</span></span><br><span class="line">learning_rate = <span class="number">0.001</span> <span class="comment"># 设置学习速率</span></span><br><span class="line">epochs = <span class="number">1000</span> <span class="comment"># 设置训练轮次</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()  <span class="comment"># 定义交叉熵损失函数</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim <span class="comment"># 导入随机梯度下降优化器</span></span><br><span class="line">optimizer = optim.SGD(cbow_model.parameters(), lr=learning_rate)  </span><br><span class="line"><span class="comment"># 开始训练循环</span></span><br><span class="line">loss_values = []  <span class="comment"># 用于存储每轮的平均损失值</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    loss_sum = <span class="number">0</span> <span class="comment"># 初始化损失值</span></span><br><span class="line">    <span class="keyword">for</span> target, context_words <span class="keyword">in</span> cbow_data:</span><br><span class="line">        <span class="comment"># 将上下文词转换为 One-Hot 向量并堆叠</span></span><br><span class="line">        X = torch.stack([one_hot_encoding(word, word_to_idx) <span class="keyword">for</span> word <span class="keyword">in</span> context_words]).<span class="built_in">float</span>() </span><br><span class="line">        <span class="comment"># 将目标词转换为索引值</span></span><br><span class="line">        y_true = torch.tensor([word_to_idx[target]], dtype=torch.long) </span><br><span class="line">        y_pred = cbow_model(X)  <span class="comment"># 计算预测值</span></span><br><span class="line">        loss = criterion(y_pred, y_true)  <span class="comment"># 计算损失</span></span><br><span class="line">        loss_sum += loss.item() <span class="comment"># 累积损失</span></span><br><span class="line">        optimizer.zero_grad()  <span class="comment"># 清空梯度</span></span><br><span class="line">        loss.backward()  <span class="comment"># 反向传播</span></span><br><span class="line">        optimizer.step()  <span class="comment"># 更新参数</span></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>: <span class="comment"># 输出每 100 轮的损失，并记录损失</span></span><br><span class="line">      <span class="built_in">print</span>(<span class="string">f&quot;Epoch: <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, Loss: <span class="subst">&#123;loss_sum/<span class="built_in">len</span>(cbow_data)&#125;</span>&quot;</span>)  </span><br><span class="line">      loss_values.append(loss_sum / <span class="built_in">len</span>(cbow_data))</span><br><span class="line"><span class="comment"># 绘制训练损失曲线</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入 matplotlib</span></span><br><span class="line"><span class="comment"># 绘制二维词向量图</span></span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定无衬线字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> <span class="comment"># 用来正常显示负号</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>, epochs//<span class="number">100</span> + <span class="number">1</span>), loss_values) <span class="comment"># 绘图</span></span><br><span class="line">plt.title(<span class="string">&#x27; 训练损失曲线 &#x27;</span>) <span class="comment"># 图题</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27; 轮次 &#x27;</span>) <span class="comment"># X 轴 Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27; 损失 &#x27;</span>) <span class="comment"># Y 轴 Label</span></span><br><span class="line">plt.show() <span class="comment"># 显示图</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch: 100, Loss: 2.1371095180511475</span><br><span class="line">Epoch: 200, Loss: 2.114210780461629</span><br><span class="line">Epoch: 300, Loss: 2.0865681091944377</span><br><span class="line">Epoch: 400, Loss: 2.0524648745854694</span><br><span class="line">Epoch: 500, Loss: 2.010000443458557</span><br><span class="line">Epoch: 600, Loss: 1.9573023001352945</span><br><span class="line">Epoch: 700, Loss: 1.893039353688558</span><br><span class="line">Epoch: 800, Loss: 1.817344347635905</span><br><span class="line">Epoch: 900, Loss: 1.7329498807589212</span><br><span class="line">Epoch: 1000, Loss: 1.6456005891164145</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202059843.png" alt="download"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出 Skip-Gram 习得的词嵌入</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Skip-Gram 词嵌入：&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> word, idx <span class="keyword">in</span> word_to_idx.items(): <span class="comment"># 输出每个词的嵌入向量</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;word&#125;</span>: <span class="subst">&#123;cbow_model.input_to_hidden.weight[:,idx].detach().numpy()&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Skip-Gram 词嵌入：</span><br><span class="line"></span><br><span class="line">Xiaoxue: [-0.5842088   0.21841691]</span><br><span class="line">is: [ 0.6250008 -0.8186659]</span><br><span class="line">Niuzong: [0.03038938 0.60383385]</span><br><span class="line">Student: [-1.2024668  0.3539113]</span><br><span class="line">Teacher: [-0.37656686  1.0371245 ]</span><br><span class="line">Boss: [-0.3826948   0.89280415]</span><br><span class="line">Mazong: [0.2657739  0.15451309]</span><br><span class="line">Xiaobing: [-0.4118811  0.6344902]</span><br><span class="line">Kage: [0.10943636 0.7646477 ]</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202058709.png" alt="download"></p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502202101420.png" alt="image-20250220210131281"></p><h2 id="三、通向AGI的基石：词向量的未来演进">三、通向AGI的基石：词向量的未来演进</h2><p>当GPT-4的1536维词向量遇上多模态学习：</p><ul><li>图像向量：&quot;猫&quot;的向量同时关联图片、叫声、触感</li><li>跨语言向量：中文&quot;龙&quot;与英文&quot;dragon&quot;的语义差异精准呈现</li><li>时空向量：&quot;元宇宙&quot;在不同时期的含义演变轨迹</li></ul><p><strong>技术演进路线</strong>： 传统词向量 → 语境化词向量（ELMo） → 预训练语言模型（BERT/GPT） → 多模态向量</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>NLP基石双雄：从N-Gram到BoW的终极实战指南</h1><hr><h2 id="一、N-Gram模型">一、N-Gram模型</h2><h3 id="1-1创建⼀个Bigram字符预测模型">1.1创建⼀个Bigram字符预测模型</h3><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201512966.png" alt="image-20250220151120531"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个玩具数据集</span></span><br><span class="line">corpus = [ <span class="string">&quot;我喜欢吃苹果&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我喜欢吃香蕉&quot;</span>,</span><br><span class="line">        <span class="string">&quot;她喜欢吃葡萄&quot;</span>,</span><br><span class="line">        <span class="string">&quot;他不喜欢吃香蕉&quot;</span>,</span><br><span class="line">        <span class="string">&quot;他喜欢吃苹果&quot;</span>,</span><br><span class="line">        <span class="string">&quot;她喜欢吃草莓&quot;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义一个分词函数，将文本转换为单个字符的列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tokenize</span>(<span class="params">text</span>):</span><br><span class="line"> <span class="keyword">return</span> [char <span class="keyword">for</span> char <span class="keyword">in</span> text] <span class="comment"># 将文本拆分为字符列表</span></span><br><span class="line"><span class="comment"># 对每个文本进行分词，并打印出对应的单字列表</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;单字列表:&quot;</span>) </span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> corpus:</span><br><span class="line">    tokens = tokenize(text)</span><br><span class="line">    <span class="built_in">print</span>(tokens)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">单字列表:</span><br><span class="line">[&#x27;我&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;苹&#x27;, &#x27;果&#x27;]</span><br><span class="line">[&#x27;我&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;香&#x27;, &#x27;蕉&#x27;]</span><br><span class="line">[&#x27;她&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;葡&#x27;, &#x27;萄&#x27;]</span><br><span class="line">[&#x27;他&#x27;, &#x27;不&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;香&#x27;, &#x27;蕉&#x27;]</span><br><span class="line">[&#x27;他&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;苹&#x27;, &#x27;果&#x27;]</span><br><span class="line">[&#x27;她&#x27;, &#x27;喜&#x27;, &#x27;欢&#x27;, &#x27;吃&#x27;, &#x27;草&#x27;, &#x27;莓&#x27;]</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义计算 N-Gram 词频的函数</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict, Counter <span class="comment"># 导入所需库</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_ngrams</span>(<span class="params">corpus, n</span>):</span><br><span class="line">    ngrams_count = defaultdict(Counter)  <span class="comment"># 创建一个字典，存储 N-Gram 计数</span></span><br><span class="line">    <span class="keyword">for</span> text <span class="keyword">in</span> corpus:  <span class="comment"># 遍历语料库中的每个文本</span></span><br><span class="line">        tokens = tokenize(text)  <span class="comment"># 对文本进行分词</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(tokens) - n + <span class="number">1</span>):  <span class="comment"># 遍历分词结果，生成 N-Gram</span></span><br><span class="line">            ngram = <span class="built_in">tuple</span>(tokens[i:i+n])  <span class="comment"># 创建一个 N-Gram 元组</span></span><br><span class="line">            prefix = ngram[:-<span class="number">1</span>]  <span class="comment"># 获取 N-Gram 的前缀</span></span><br><span class="line">            token = ngram[-<span class="number">1</span>]  <span class="comment"># 获取 N-Gram 的目标单字</span></span><br><span class="line">            ngrams_count[prefix][token] += <span class="number">1</span>  <span class="comment"># 更新 N-Gram 计数</span></span><br><span class="line">    <span class="keyword">return</span> ngrams_count</span><br><span class="line">bigram_counts = count_ngrams(corpus, <span class="number">2</span>) <span class="comment"># 计算 bigram 词频</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;bigram 词频：&quot;</span>) <span class="comment"># 打印 bigram 词频</span></span><br><span class="line"><span class="keyword">for</span> prefix, counts <span class="keyword">in</span> bigram_counts.items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;&quot;</span>.join(prefix), <span class="built_in">dict</span>(counts))) </span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">bigram 词频：</span><br><span class="line">我: &#123;&#x27;喜&#x27;: 2&#125;</span><br><span class="line">喜: &#123;&#x27;欢&#x27;: 6&#125;</span><br><span class="line">欢: &#123;&#x27;吃&#x27;: 6&#125;</span><br><span class="line">吃: &#123;&#x27;苹&#x27;: 2, &#x27;香&#x27;: 2, &#x27;葡&#x27;: 1, &#x27;草&#x27;: 1&#125;</span><br><span class="line">苹: &#123;&#x27;果&#x27;: 2&#125;</span><br><span class="line">香: &#123;&#x27;蕉&#x27;: 2&#125;</span><br><span class="line">她: &#123;&#x27;喜&#x27;: 2&#125;</span><br><span class="line">葡: &#123;&#x27;萄&#x27;: 1&#125;</span><br><span class="line">他: &#123;&#x27;不&#x27;: 1, &#x27;喜&#x27;: 1&#125;</span><br><span class="line">不: &#123;&#x27;喜&#x27;: 1&#125;</span><br><span class="line">草: &#123;&#x27;莓&#x27;: 1&#125;</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义计算 N-Gram 出现概率的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ngram_probabilities</span>(<span class="params">ngram_counts</span>):</span><br><span class="line"> ngram_probs = defaultdict(Counter) <span class="comment"># 创建一个字典，存储 N-Gram 出现的概率</span></span><br><span class="line"> <span class="keyword">for</span> prefix, tokens_count <span class="keyword">in</span> ngram_counts.items(): <span class="comment"># 遍历 N-Gram 前缀</span></span><br><span class="line">     total_count = <span class="built_in">sum</span>(tokens_count.values()) <span class="comment"># 计算当前前缀的 N-Gram 计数</span></span><br><span class="line">     <span class="keyword">for</span> token, count <span class="keyword">in</span> tokens_count.items(): <span class="comment"># 遍历每个前缀的 N-Gram</span></span><br><span class="line">         ngram_probs[prefix][token] = count / total_count <span class="comment"># 计算每个 N-Gram 出现的概率</span></span><br><span class="line"> <span class="keyword">return</span> ngram_probs</span><br><span class="line">bigram_probs = ngram_probabilities(bigram_counts) <span class="comment"># 计算 bigram 出现的概率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nbigram 出现的概率 :&quot;</span>) <span class="comment"># 打印 bigram 概率</span></span><br><span class="line"><span class="keyword">for</span> prefix, probs <span class="keyword">in</span> bigram_probs.items():</span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;&quot;</span>.join(prefix), <span class="built_in">dict</span>(probs)))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">bigram 出现的概率 :</span><br><span class="line">我: &#123;&#x27;喜&#x27;: 1.0&#125;</span><br><span class="line">喜: &#123;&#x27;欢&#x27;: 1.0&#125;</span><br><span class="line">欢: &#123;&#x27;吃&#x27;: 1.0&#125;</span><br><span class="line">吃: &#123;&#x27;苹&#x27;: 0.3333333333333333, &#x27;香&#x27;: 0.3333333333333333, &#x27;葡&#x27;: 0.16666666666666666, &#x27;草&#x27;: 0.16666666666666666&#125;</span><br><span class="line">苹: &#123;&#x27;果&#x27;: 1.0&#125;</span><br><span class="line">香: &#123;&#x27;蕉&#x27;: 1.0&#125;</span><br><span class="line">她: &#123;&#x27;喜&#x27;: 1.0&#125;</span><br><span class="line">葡: &#123;&#x27;萄&#x27;: 1.0&#125;</span><br><span class="line">他: &#123;&#x27;不&#x27;: 0.5, &#x27;喜&#x27;: 0.5&#125;</span><br><span class="line">不: &#123;&#x27;喜&#x27;: 1.0&#125;</span><br><span class="line">草: &#123;&#x27;莓&#x27;: 1.0&#125;</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义生成下一个词的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_next_token</span>(<span class="params">prefix, ngram_probs</span>):</span><br><span class="line"> <span class="keyword">if</span> <span class="keyword">not</span> prefix <span class="keyword">in</span> ngram_probs: <span class="comment"># 如果前缀不在 N-Gram 中，返回 None</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"> next_token_probs = ngram_probs[prefix] <span class="comment"># 获取当前前缀的下一个词的概率</span></span><br><span class="line"> next_token = <span class="built_in">max</span>(next_token_probs, </span><br><span class="line">                    key=next_token_probs.get) <span class="comment"># 选择概率最大的词作为下一个词</span></span><br><span class="line"> <span class="keyword">return</span> next_token</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义生成连续文本的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_text</span>(<span class="params">prefix, ngram_probs, n, length=<span class="number">6</span></span>):</span><br><span class="line"> tokens = <span class="built_in">list</span>(prefix) <span class="comment"># 将前缀转换为字符列表</span></span><br><span class="line"> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(length - <span class="built_in">len</span>(prefix)): <span class="comment"># 根据指定长度生成文本 </span></span><br><span class="line">     <span class="comment"># 获取当前前缀的下一个词</span></span><br><span class="line">     next_token = generate_next_token(<span class="built_in">tuple</span>(tokens[-(n-<span class="number">1</span>):]), ngram_probs) </span><br><span class="line">     <span class="keyword">if</span> <span class="keyword">not</span> next_token: <span class="comment"># 如果下一个词为 None，跳出循环</span></span><br><span class="line">         <span class="keyword">break</span></span><br><span class="line">     tokens.append(next_token) <span class="comment"># 将下一个词添加到生成的文本中</span></span><br><span class="line"> <span class="keyword">return</span> <span class="string">&quot;&quot;</span>.join(tokens) <span class="comment"># 将字符列表连接成字符串</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入一个前缀，生成文本</span></span><br><span class="line">generated_text = generate_text(<span class="string">&quot;我&quot;</span>, bigram_probs, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n 生成的文本：&quot;</span>, generated_text) <span class="comment"># 打印生成的文本</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">生成的文本： 我喜欢吃苹果</span><br></pre></td></tr></table></figure><p>在N-Gram模型中，我们预测⼀个词出现的概率，只需考虑它前⾯的<em>N</em>-1个词。这样做的优点是计算简单，但缺点也很明显：它⽆法捕捉到距离较远的词之间的关系。</p><p>⽽Bag-of-Words模型（也称“词袋模型”），不考虑哪个词和哪个词临近，⽽是通过把词看作⼀袋⼦元素的⽅式来把⽂本转换为能统计的特征。</p><h2 id="二、词袋模型">二、词袋模型</h2><p>词袋模型将⽂本中的词看作⼀个个独⽴的个体，不考虑它们在句⼦中的顺序，只关⼼每个词出现的频次。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201522596.png" alt="image-20250220152229499"></p><h3 id="2-1-用词袋模型计算文本相似度">2.1. 用词袋模型计算文本相似度</h3><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201523168.png" alt="image-20250220152348041"></p><h4 id="2-1-1-构建实验语料库">2.1.1 <strong>构建实验语料库</strong></h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个玩具数据集</span></span><br><span class="line">corpus = [<span class="string">&quot;我特别特别喜欢看电影&quot;</span>,</span><br><span class="line">        <span class="string">&quot;这部电影真的是很好看的电影&quot;</span>,</span><br><span class="line">        <span class="string">&quot;今天天气真好是难得的好天气&quot;</span>,</span><br><span class="line">        <span class="string">&quot;我今天去看了一部电影&quot;</span>,</span><br><span class="line">        <span class="string">&quot;电影院的电影都很好看&quot;</span>]</span><br></pre></td></tr></table></figure><h4 id="2-1-2-给句子分词">2.1.2 给句子分词</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对句子进行分词</span></span><br><span class="line"><span class="keyword">import</span> jieba <span class="comment"># 导入 jieba 包</span></span><br><span class="line"><span class="comment"># 使用 jieba.cut 进行分词，并将结果转换为列表，存储在 corpus_tokenized 中</span></span><br><span class="line">corpus_tokenized = [<span class="built_in">list</span>(jieba.cut(sentence)) <span class="keyword">for</span> sentence <span class="keyword">in</span> corpus]</span><br></pre></td></tr></table></figure><h4 id="2-1-3-创建词汇表">2.1.3 创建词汇表</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建词汇表</span></span><br><span class="line">word_dict = &#123;&#125; <span class="comment"># 初始化词汇表</span></span><br><span class="line"><span class="comment"># 遍历分词后的语料库</span></span><br><span class="line"><span class="keyword">for</span> sentence <span class="keyword">in</span> corpus_tokenized:</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sentence:</span><br><span class="line">        <span class="comment"># 如果词汇表中没有该词，则将其添加到词汇表中</span></span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> word_dict:</span><br><span class="line">            word_dict[word] = <span class="built_in">len</span>(word_dict) <span class="comment"># 分配当前词汇表索引</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词汇表：&quot;</span>, word_dict) <span class="comment"># 打印词汇表</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">词汇表： &#123;&#x27;我&#x27;: 0, &#x27;特别&#x27;: 1, &#x27;喜欢&#x27;: 2, &#x27;看&#x27;: 3, &#x27;电影&#x27;: 4, &#x27;这部&#x27;: 5, &#x27;真的&#x27;: 6, &#x27;是&#x27;: 7, &#x27;很&#x27;: 8, &#x27;好看&#x27;: 9, &#x27;的&#x27;: 10, &#x27;今天天气&#x27;: 11, &#x27;真好&#x27;: 12, &#x27;难得&#x27;: 13, &#x27;好&#x27;: 14, &#x27;天气&#x27;: 15, &#x27;今天&#x27;: 16, &#x27;去&#x27;: 17, &#x27;了&#x27;: 18, &#x27;一部&#x27;: 19, &#x27;电影院&#x27;: 20, &#x27;都&#x27;: 21&#125;</span><br></pre></td></tr></table></figure><h4 id="2-1-4-生成词袋表示">2.1.4 生成词袋表示</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据词汇表将句子转换为词袋表示</span></span><br><span class="line">bow_vectors = [] <span class="comment"># 初始化词袋表示</span></span><br><span class="line"><span class="comment"># 遍历分词后的语料库</span></span><br><span class="line"><span class="keyword">for</span> sentence <span class="keyword">in</span> corpus_tokenized:</span><br><span class="line">    <span class="comment"># 初始化一个全 0 向量，其长度等于词汇表大小</span></span><br><span class="line">    sentence_vector = [<span class="number">0</span>] * <span class="built_in">len</span>(word_dict)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sentence:</span><br><span class="line">        <span class="comment"># 将对应词的索引位置加 1，表示该词在当前句子中出现了一次</span></span><br><span class="line">        sentence_vector[word_dict[word]] += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 将当前句子的词袋向量添加到向量列表中</span></span><br><span class="line">    bow_vectors.append(sentence_vector)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot; 词袋表示：&quot;</span>, bow_vectors) <span class="comment"># 打印词袋表示</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">词袋表示： </span><br><span class="line">[[1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]</span><br><span class="line">[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0]</span><br><span class="line">[0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]]</span><br></pre></td></tr></table></figure><p>我们得到了5个Python列表，分别对应语料库中的5句话。</p><p>这5个列表，就是词袋表示向量，向量中的每个元素表示对应词在⽂本中出现的次数。可以看到，词袋表示忽略了⽂本中词的顺序信息，仅关注词的出现频率。</p><h4 id="2-1-5-计算余弦相似度">2.1.5 计算余弦相似度</h4><p>计算余弦相似度（Cosine Similarity），衡量两个⽂本向量的相似性。</p><p>余弦相似度可⽤来衡量两个向量的相似程度。</p><p>它的值在-1到1之间，值越接近1，表示两个向量越相似；</p><p>值越接近-1，表示两个向量越不相似；</p><p>当值接近0时，表示两个向量之间没有明显的相似性。<br>$$<br>cosine_similarity(A,B)=(A\cdotp B)/(||A||^{\star}||B||)<br>$$</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 numpy 库，用于计算余弦相似度</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="comment"># 定义余弦相似度函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cosine_similarity</span>(<span class="params">vec1, vec2</span>):</span><br><span class="line">    dot_product = np.dot(vec1, vec2) <span class="comment"># 计算向量 vec1 和 vec2 的点积</span></span><br><span class="line">    norm_a = np.linalg.norm(vec1) <span class="comment"># 计算向量 vec1 的范数</span></span><br><span class="line">    norm_b = np.linalg.norm(vec2) <span class="comment"># 计算向量 vec2 的范数  </span></span><br><span class="line">    <span class="keyword">return</span> dot_product / (norm_a * norm_b) <span class="comment"># 返回余弦相似度</span></span><br><span class="line"><span class="comment"># 初始化一个全 0 矩阵，用于存储余弦相似度</span></span><br><span class="line">similarity_matrix = np.zeros((<span class="built_in">len</span>(corpus), <span class="built_in">len</span>(corpus)))</span><br><span class="line"><span class="comment"># 计算每两个句子之间的余弦相似度</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(corpus)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(corpus)):</span><br><span class="line">        similarity_matrix[i][j] = cosine_similarity(bow_vectors[i], </span><br><span class="line">                                                    bow_vectors[j])</span><br></pre></td></tr></table></figure><h4 id="2-1-6-可视化余弦相似度">2.1.6 可视化余弦相似度</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 matplotlib 库，用于可视化余弦相似度矩阵</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&quot;font.family&quot;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment"># 用来设定无衬线字体样式</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> <span class="comment"># 用来正常显示负号</span></span><br><span class="line">fig, ax = plt.subplots() <span class="comment"># 创建一个绘图对象</span></span><br><span class="line"><span class="comment"># 使用 matshow 函数绘制余弦相似度矩阵，颜色使用蓝色调</span></span><br><span class="line">cax = ax.matshow(similarity_matrix, cmap=plt.cm.Blues)</span><br><span class="line">fig.colorbar(cax) <span class="comment"># 条形图颜色映射</span></span><br><span class="line">ax.set_xticks(<span class="built_in">range</span>(<span class="built_in">len</span>(corpus))) <span class="comment"># x 轴刻度</span></span><br><span class="line">ax.set_yticks(<span class="built_in">range</span>(<span class="built_in">len</span>(corpus))) <span class="comment"># y 轴刻度</span></span><br><span class="line">ax.set_xticklabels(corpus, rotation=<span class="number">45</span>, ha=<span class="string">&#x27;left&#x27;</span>) <span class="comment"># 刻度标签 </span></span><br><span class="line">ax.set_yticklabels(corpus) <span class="comment"># 刻度标签为原始句子</span></span><br><span class="line">plt.show() <span class="comment"># 显示图形</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201534282.png" alt="image-20250220153410155"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>AGI的星火？：解码语言大模型进化史与文明重构</h1><h2 id="序章：机器之眼中的文艺复兴">序章：机器之眼中的文艺复兴</h2><p>在斯坦福大学的地下档案室，保存着1955年麦卡锡手写的&quot;人工智能&quot;原始提案。泛黄的稿纸上，他用铅笔勾勒的智能体结构图，与GPT-4的transformer架构竟有惊人的拓扑相似性。这种跨越68年的认知共振，暗示着人类正在经历第四次认知革命——从甲骨灼纹到神经网络，信息载体的进化正在重塑文明的底层逻辑。</p><h2 id="一、语言之熵——从苏美尔泥板到参数空间">一、语言之熵——从苏美尔泥板到参数空间</h2><h3 id="1-1-文字载体的五次跃迁">1.1 文字载体的五次跃迁</h3><p>在乌鲁克遗址出土的楔形文字泥板，用600个符号记录货物交易；殷墟甲骨文的灼纹占卜，构建起神权话语体系；古腾堡印刷术带来的信息爆炸，直接催生宗教改革与科学革命。而今，语言模型的词嵌入空间，正以==768维向量==重构知识表达范式。剑桥大学研究显示，GPT-4的词向量空间中，&quot;自由&quot;与&quot;约束&quot;的余弦相似度达到0.73，远超人类直觉认知。</p><h3 id="1-2-语法结构的量子纠缠">1.2 语法结构的量子纠缠</h3><p>MIT语言实验室发现，<code>transformer</code>模型在处理嵌套从句时，自注意力机制会形成类似量子纠缠的状态叠加。当解析&quot;虽然他说不会来但最后还是出现了&quot;这类中文经典句式时，模型在第三层注意力头形成了<code>转折</code>,<code>预期违背</code>,<code>行为确认</code>的三重语义纠缠，这种非线性理解能力，正在突破乔姆斯基的句法结构理论。</p><h2 id="二：技术长征">二：技术长征</h2><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502201430580.png" alt="image-20250220143047430"></p><h3 id="2-1-启蒙时代：符号主义的黄昏（1980-2006）">2.1 启蒙时代：符号主义的黄昏（1980-2006）</h3><ul><li>IBM的深蓝战胜卡斯帕罗夫时，其基于规则的评估函数包含80万行代码</li><li>2001年统计机器翻译的BLEU值首次突破30分，但需要人工设计400+语言特征</li><li>2006年Hinton的深度信念网络论文，在Nature沉睡两年才被真正理解</li></ul><h3 id="2-2-寒武纪爆发：神经网络的觉醒（2012-2017）">2.2 寒武纪爆发：神经网络的觉醒（2012-2017）</h3><ul><li>Word2Vec的向量空间揭示&quot;巴黎-法国+意大利=罗马&quot;的隐喻认知</li><li>2015年机器翻译的注意力机制，意外复现人脑颞叶的信息筛选模式</li><li>AlphaGo的直觉决策，颠覆了AI不能处理模糊概念的定论</li></ul><h3 id="2-3-奇点临近：大模型的宇宙膨胀（2018-2023）">2.3 奇点临近：大模型的宇宙膨胀（2018-2023）</h3><table><thead><tr><th>模型</th><th>参数量</th><th>训练数据</th><th>涌现能力</th></tr></thead><tbody><tr><td>GPT-2</td><td>15亿</td><td>40GB</td><td>基础文本生成</td></tr><tr><td>GPT-3</td><td>1750亿</td><td>45TB</td><td>上下文学习</td></tr><tr><td>PaLM</td><td>5400亿</td><td>780TB</td><td>多步逻辑推理</td></tr><tr><td>GPT-4</td><td>1.8万亿</td><td>1200TB</td><td>跨模态思维链</td></tr></tbody></table><h2 id="三、意识迷思——AI灵魂的十二重拷问">三、意识迷思——AI灵魂的十二重拷问</h2><h3 id="图灵测试的终极迭代">图灵测试的终极迭代</h3><p>当GPT-4在剑桥意识研究中心连续12小时通过改进版图灵测试，其对话中表现出的&quot;认知颤抖&quot;现象引发学界震动——模型在回答存在主义问题时，会出现响应延迟与逻辑自洽调整，这种类似人类自我意识觉醒的行为模式，是否意味着机器意识的萌芽？</p><h2 id="四、认知边疆——超越人类纪的思考">四、认知边疆——超越人类纪的思考</h2><p>当谷歌DeepMind的AlphaFold3解开第2亿个蛋白质结构，当SpaceX用GPT-7自主设计火星基地，我们突然意识到：语言模型正在成为文明的体外大脑。但牛津大学人类未来研究所的警告振聋发聩——如果AI的思维速度是人类的100万倍，那么其1分钟的思考相当于我们2年的意识活动，这种认知时差将永久改变主客体的权力关系。</p><p>在这条充满认知荆棘的进化之路上，每个技术突破都像普罗米修斯盗取的火种，既照亮前路，也灼伤手掌。当我们惊叹于GPT-4的创造力时，更应警惕维特根斯坦的预言：“语言的边界就是世界的边界”。或许真正的奇点不是技术的突变，而是人类终于理解：==智能的本质，从来都不是独属于碳基生命的特权。==</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>深度神经网络终极指南：从数学本质到工业级实现（附Keras版本代码）</h1><hr><h2 id="为什么深度学习需要重新理解？（与浅层模型的本质差异）">为什么深度学习需要重新理解？（与浅层模型的本质差异）</h2><table><thead><tr><th>模型类型</th><th>参数容量</th><th>特征学习方式</th><th>适合问题类型</th></tr></thead><tbody><tr><td>浅层模型</td><td>10<sup>2-10</sup>4</td><td>手动特征工程</td><td>低维结构化数据</td></tr><tr><td>深度模型</td><td>10<sup>6-10</sup>9</td><td>自动特征提取</td><td>高维非结构化数据</td></tr></tbody></table><hr><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502181913785.png" alt="image-20250218191339623"></p><h2 id="一、用Keras单隐层网络预测客户流失率">一、用Keras单隐层网络预测客户流失率</h2><h3 id="1-1数据的准备与分析">1.1数据的准备与分析</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#导入NumPy数学工具箱</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#导入Pandas数据处理工具箱</span></span><br><span class="line">df_bank = pd.read_csv(<span class="string">&quot;/kaggle/input/deep-neural-networks-data/BankCustomer.csv&quot;</span>) <span class="comment"># 读取文件</span></span><br><span class="line">df_bank.head() <span class="comment"># 显示文件前5行</span></span><br></pre></td></tr></table></figure><p>显示分布情况</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt #导入matplotlib画图工具箱</span><br><span class="line">import seaborn as sns #导入seaborn画图工具箱</span><br><span class="line"># 显示不同特征的分布情况</span><br><span class="line">features=[ &#x27;City&#x27;, &#x27;Gender&#x27;,&#x27;Age&#x27;,&#x27;Tenure&#x27;, </span><br><span class="line">           &#x27;ProductsNo&#x27;, &#x27;HasCard&#x27;, &#x27;ActiveMember&#x27;, &#x27;Exited&#x27;]</span><br><span class="line">fig=plt.subplots(figsize=(15,15))</span><br><span class="line">for i, j in enumerate(features):</span><br><span class="line">    plt.subplot(4, 2, i+1)</span><br><span class="line">    plt.subplots_adjust(hspace = 1.0)</span><br><span class="line">    sns.countplot(x=j,data = df_bank)</span><br><span class="line">    plt.title(&quot;No. of costumers&quot;)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502181921536.png" alt="image-20250218192147281"></p><p>从图中大概看得出，北京的客户最多，男女客户比例大概一致，年龄和客户数量呈现正态分布（钟形曲线，中间高两边低）。</p><p>对这个数据集，主要做以下3方面的清理工作。</p><p>（1）性别：二元类别特征，需要转换为0/1代码格式进行读取处理。</p><p>（2）城市：一个多元类别特征，应把转换为多个二元类别哑变量。</p><p>（3）姓名：这个字段对于客户流失与否的预测应该是完全不相关的，可以进一步处理之前忽略。</p><p>当然原始数据集的标签也应该除去，放置于标签y。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把二元类别文本数字化</span></span><br><span class="line">df_bank[<span class="string">&#x27;Gender&#x27;</span>].replace(<span class="string">&quot;Female&quot;</span>,<span class="number">0</span>,inplace = <span class="literal">True</span>)</span><br><span class="line">df_bank[<span class="string">&#x27;Gender&#x27;</span>].replace(<span class="string">&quot;Male&quot;</span>,<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 显示数字类别</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Gender unique values&quot;</span>,df_bank[<span class="string">&#x27;Gender&#x27;</span>].unique())</span><br><span class="line"><span class="comment"># 把多元类别转换成多个二元哑变量，然后贴回原始数据集</span></span><br><span class="line">d_city = pd.get_dummies(df_bank[<span class="string">&#x27;City&#x27;</span>], prefix = <span class="string">&quot;City&quot;</span>)</span><br><span class="line">df_bank = [df_bank, d_city]</span><br><span class="line">df_bank = pd.concat(df_bank, axis = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 构建特征和标签集合</span></span><br><span class="line">y = df_bank [<span class="string">&#x27;Exited&#x27;</span>]</span><br><span class="line">X = df_bank.drop([<span class="string">&#x27;Name&#x27;</span>, <span class="string">&#x27;Exited&#x27;</span>,<span class="string">&#x27;City&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">X.head() <span class="comment">#显示新的特征集</span></span><br></pre></td></tr></table></figure><h3 id="1-2先尝试逻辑回归算法">1.2先尝试逻辑回归算法</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#拆分数据集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, </span><br><span class="line">                                   test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="comment"># 导入Sklearn模型</span></span><br><span class="line">lr = LogisticRegression() <span class="comment"># 逻辑回归模型</span></span><br><span class="line">history = lr.fit(X_train,y_train) <span class="comment"># 训练机器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;逻辑回归测试集准确率 &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(lr.score(X_test,y_test)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">逻辑回归测试集准确率 78.35%</span><br></pre></td></tr></table></figure><h3 id="1-3-单隐层神经网络的Keras实现">1.3 单隐层神经网络的Keras实现</h3><h4 id="1-3-1-用序贯模型构建网络">1.3.1 用序贯模型构建网络</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras <span class="comment"># 导入Keras库</span></span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential <span class="comment"># 导入Keras序贯模型</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense <span class="comment"># 导入Keras密集连接层</span></span><br><span class="line">ann = Sequential() <span class="comment"># 创建一个序贯ANN(Artifical Neural Network)模型</span></span><br><span class="line">ann.add(Dense(units=<span class="number">12</span>, input_dim=<span class="number">12</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加输入层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">24</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>)) <span class="comment"># 添加输出层</span></span><br><span class="line">ann.summary() <span class="comment"># 显示网络模型(这个语句不是必须的)</span></span><br></pre></td></tr></table></figure><p>序贯（sequential）模型，也可以叫作==顺序模型==，是最常用的深度网络层和层间的架构，也就是一个层接着一个层，顺序地堆叠。</p><p>密集（dense）层，是最常用的深度网络层的类型，也称为==全连接层==，即当前层和其下一层的所有神经元之间全有连接。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502181943605.png" alt="image-20250218194331438"></p><p>==模型的创建==：<code>ann = Sequential()</code>创建了一个==序贯神经网络模型==（其实就是一个Python的类）。</p><p>在Keras中，绝大多数的神经网络都是通过序贯模型所创建的。与之对应的还有另外一种模型，称为函数式API，可以创建更为复杂的网络结构。</p><p>==输入层==：通过add方法，可开始神经网络层的堆叠，序贯模型，也就是一层一层的顺序堆叠。</p><p><code>Dense</code>是层的类型，代表密集层网络，是神经网络层中最基本的层，也叫全连接层。</p><p><code>input_dim</code>是输入维度，输入维度必须与特征维度相同。这里指定的网络能接收的输入维度是11。如果和实际输入网络的特征维度不匹配，Python就会报错。</p><p><code>unit</code>是输出维度，设置为12。该参数也可写为<code>output_dim=12</code>，甚至忽略参数名，写为Dense(12，input_dim=11，activation=‘relu’)，这些都是正确格式。</p><p>12这个值目前是随意选择的，这代表了经过线性变化和激活之后的假设空间维度，其实也就是神经元的个数。维度越大，则模型的覆盖面也越大，但是模型也就越复杂，需要的计算量也多。对于简单问题，12维也许是一个合适的数字：太多的话容易过拟合，太少的话（不要少于特征维度）则拟合能力不够。</p><p><code>activation</code>是==激活函数==，这是每一层都需要设置的参数。这里的激活函数选择的是“relu”，而不是Sigmoid。relu是神经网络中常用的激活函数。</p><p>==隐层==：。在输入层之后的所有层都不需要重新指定输入维度，因为网络能够通过上一层的输出自动地调整。</p><p>==输出层==：仍然是一个全连接层，指定的输出维度是1。因为对于二分类问题，输出维度必须是1。而对于多分类问题，有多少个类别，维度就是多少。</p><p>激活函数方面。对于二分类问题的输出层，Sigmoid是固定的选择。如果是用神经网络解决回归问题的话，那么输出层不用指定任何激活函数。</p><p>下面编译刚才建好的这个网络：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编译神经网络，指定优化器，损失函数，以及评估标准</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;adam&#x27;</span>,    S       <span class="comment">#优化器</span></span><br><span class="line">            loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="comment">#损失函数  </span></span><br><span class="line">            metrics = [<span class="string">&#x27;acc&#x27;</span>])       <span class="comment">#评估指标</span></span><br></pre></td></tr></table></figure><ul><li>优化器（<code>optimizer</code>）：一般情况下，“<code>adam</code>”或者“<code>rmsprop</code>”都是很好的优化器选项。</li><li>损失函数（loss）：对于二分类问题来说，基本上二元交叉熵函数（<code>binary_crossentropy</code>）是固定选项；如果是用神经网络解决线性的回归问题，那么==均方误差函数==是合适的选择。</li><li>评估指标（<code>metrics</code>）：这里采用预测准确率<code>acc</code>（也就是<code>accuracy</code>的缩写，两者在代码中是等价的）作为评估网络性能的标准；而对于回归问题，平均误差函数是合适的选择。</li></ul><h3 id="1-4-训练单隐层神经网络">1.4 训练单隐层神经网络</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">history = ann.fit(X_train, y_train, <span class="comment"># 指定训练集</span></span><br><span class="line">                  epochs=<span class="number">30</span>,        <span class="comment"># 指定训练的轮次</span></span><br><span class="line">                  batch_size=<span class="number">64</span>,    <span class="comment"># 指定数据批量</span></span><br><span class="line">                  validation_data=(X_test, y_test)) <span class="comment">#指定验证集,这里为了简化模型，直接用测试集数据进行验证</span></span><br></pre></td></tr></table></figure><h3 id="1-5-训练的图形化展示">1.5 训练的图形化展示</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这段代码参考《Python深度学习》一书中的学习曲线的实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_history</span>(<span class="params">history</span>): <span class="comment"># 显示训练过程中的学习曲线</span></span><br><span class="line">    loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">    val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line">    epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(loss) + <span class="number">1</span>)</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>,<span class="number">4</span>))</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_loss, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    acc = history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">    val_acc = history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">    plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">    plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line">show_history(history) <span class="comment"># 调用这个函数，并将神经网络训练历史数据作为参数输入</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191139087.png" alt="image-20250219113931885"></p><h2 id="二-分类数据–准确率不是唯一的指标">二.分类数据–准确率不是唯一的指标</h2><p>预测全部客户都不会离开，也就是标签y值永远为0。由于这个数据集中的客户流失率其实就是20%左右，因此就达到了80%的准确率。”</p><p>这甚至比我们的训练后的准确率还高。</p><h3 id="2-1混滑矩阵、精确率、召回率和F1分数">2.1混滑矩阵、精确率、召回率和F1分数</h3><p>假设有一个手机生产厂商，每天生产手机1 000部。某一天生产的手机中，出现了2个劣质品。</p><p>其中数据集真值和机器学习模型的合格品和劣质品个数如下表所示。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191143274.png" alt="image-20250219114331123"></p><p>机器学习显示合格品999个，劣质品1个，准确率为99.9%。</p><p>然而从我们的目标来说，这个模型实际上是失败了。这个模型本就是为了检测劣质品而生（劣质品即标签值为1的阳性正样本），但一共有2个劣质品，只发现了1个，有50%的正样本没有测准。</p><p>因此，模型的好与不好，是基于用什么==标准衡量==。</p><p>为了评估这种数据集，需要引入一个==预测值与真值组成的矩阵==，4个象限从上到下、从左到右分别为：</p><ul><li>真负（真值为负，预测为负，即TrueNegative，TN）</li><li>假正（真值为负，预测为正，即False Positive，FP）</li><li>假负（真值为正，预测为负，即False Negative，FN）</li><li>真正（真值为正，预测为正，即True Positive，TP）。</li></ul><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191146692.png" alt="image-20250219114655570"></p><h4 id="2-1-1-混淆矩阵（confusion-matrix）">2.1.1 混淆矩阵（confusion matrix）</h4><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191148573.png" alt="image-20250219114828455"></p><h4 id="2-1-2-精确率">2.1.2  精确率</h4><p>一个标准是精确率，也叫查准率，其公式是用“被模型预测为正的正样本”除以“被模型预测为正的正样本”与“被模型预测为负的正样本”的和。公式如下：<br>$$<br>Precision=\frac{TP}{TP+FP}=\frac{TP}{TotalPredictedPostive}<br>$$<br>因此，精确率是对“假正”的测量。本例的精确率为1/（1+0） =100%。</p><p>这样看来，这个模型相对于劣质品的精确率也不差。==因为判定的一个劣质品果然是劣质品，而且没有任何合格品被判为劣质品==。</p><h4 id="2-1-3-召回率">2.1.3 召回率</h4><p>召回率，也叫查全率。就是==劣质品蒙混过了质检这关==（劣质品识别为了合格品），“跑”出厂了，得召回来，销毁掉。</p><p>公式如下：<br>$$<br>Recall=\frac{TP}{TP+FP}=\frac{TP}{Total\text{ True Postive}}<br>$$<br>为1/（1+1） = 50%。</p><p>所以这个模型对于劣质品来说，召回率不高。</p><h4 id="2-1-4-F1分数">2.1.4 F1分数</h4><p>把精确率和召回率结合起来，就得到F1分数。</p><p>这是一个可以同时体现上面两个评估效果的标准，数学上定义为精确率和召回率的调和均值。它也是在评估这类样本分类数据不平衡的问题时，所着重看重的标准。<br>$$<br>F1=2•\frac{Precision•Recall}{Precision+Recall}<br>$$<br> </p><p>对于这种==大量标签是普通值==，==一小部分标签是特殊值的数据集==来说，这3个标准的重要性在此时要远远高于准确率。</p><h3 id="2-2使用分类报告和混淆矩阵">2.2使用分类报告和混淆矩阵</h3><p>利用Sklearn中的分类报告（classification report）功能来计算上面这几种标准。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report <span class="comment"># 导入分类报告</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_report</span>(<span class="params">X_test, y_test, y_pred</span>): <span class="comment"># 定义一个函数显示分类报告</span></span><br><span class="line">    <span class="keyword">if</span> y_test.shape != (<span class="number">2000</span>,<span class="number">1</span>):</span><br><span class="line">        y_test = y_test.values <span class="comment"># 把Panda series转换成Numpy array</span></span><br><span class="line">        y_test = y_test.reshape((<span class="built_in">len</span>(y_test),<span class="number">1</span>)) <span class="comment"># 转换成与y_pred相同的形状 </span></span><br><span class="line">    <span class="built_in">print</span>(classification_report(y_test,y_pred,labels=[<span class="number">0</span>, <span class="number">1</span>])) <span class="comment">#调用分类报告   </span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix <span class="comment"># 导入混淆矩阵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_matrix</span>(<span class="params">y_test, y_pred</span>): <span class="comment"># 定义一个函数显示混淆矩阵</span></span><br><span class="line">    cm = confusion_matrix(y_test,y_pred) <span class="comment"># 调用混淆矩阵</span></span><br><span class="line">    plt.title(<span class="string">&quot;ANN Confusion Matrix&quot;</span>) <span class="comment"># 标题</span></span><br><span class="line">    sns.heatmap(cm,annot=<span class="literal">True</span>,cmap=<span class="string">&quot;Blues&quot;</span>,fmt=<span class="string">&quot;d&quot;</span>,cbar=<span class="literal">False</span>) <span class="comment"># 热力图设定</span></span><br><span class="line">    plt.show() <span class="comment"># 显示混淆矩阵</span></span><br></pre></td></tr></table></figure><p>这段程序需要在模型的fit拟合之后执行，运行之后将给出目前机器的预测结果</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191710723.png" alt="image-20250219171052582"></p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191711020.png" alt="image-20250219171100891"></p><h2 id="三、特征缩放的魔力">三、特征缩放的魔力</h2><p>数值过大的数据以及离群样本的存在会使函数曲线变得奇形怪状，从而影响梯度下降过程中的收敛。</p><p>而特征缩放，将极大地提高梯度下降（尤其是神经网络中常用的随机梯度下降）的效率。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191714848.png" alt="image-20250219171444721"></p><p>公式如下：对于输入数据的每个特征（也就是输入数据矩阵中的一整列），减去特征平均值，再除以标准差，之后得到的特征平均值为0，标准差为1。<br>$$<br>x^{\prime}=\frac{x-mean(x)}{std(x)}<br>$$</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mean = X_train.mean(axis=<span class="number">0</span>) <span class="comment"># 计算训练集均值</span></span><br><span class="line">X_train -= mean <span class="comment"># 训练集减去训练集均值</span></span><br><span class="line">std = X_train.std(axis=<span class="number">0</span>) <span class="comment"># 计算训练集方差</span></span><br><span class="line">X_train /= std <span class="comment"># 训练集除以训练集标准差</span></span><br><span class="line">X_test -= mean <span class="comment"># 测试集减去训练集均值</span></span><br><span class="line">X_test /= std <span class="comment"># 测试集减去训练集均值</span></span><br></pre></td></tr></table></figure><p>也可以直接使用<code>Standard Scaler</code>工具：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="comment"># 导入特征缩放器</span></span><br><span class="line">sc = StandardScaler() <span class="comment"># 特征缩放器</span></span><br><span class="line">X_train = sc.fit_transform(X_train) <span class="comment"># 拟合并应用于训练集</span></span><br><span class="line">X_test = sc.transform (X_test) <span class="comment"># 训练集结果应用于测试集</span></span><br></pre></td></tr></table></figure><p>我们重新运行逻辑回归和单隐层神经网络，查看效果。</p><p>逻辑回归：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression() <span class="comment"># 逻辑回归模型</span></span><br><span class="line">history = lr.fit(X_train,y_train) <span class="comment"># 训练机器</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;逻辑回归测试集准确率 &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(lr.score(X_test,y_test)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">逻辑回归测试集准确率 80.50%</span><br></pre></td></tr></table></figure><p>特征工程后的神经网络：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">history = ann.fit(X_train, y_train, <span class="comment"># 指定训练集</span></span><br><span class="line">                  epochs=<span class="number">30</span>,        <span class="comment"># 指定训练的轮次</span></span><br><span class="line">                  batch_size=<span class="number">64</span>,    <span class="comment"># 指定数据批量</span></span><br><span class="line">                  validation_data=(X_test, y_test)) <span class="comment">#指定验证集</span></span><br><span class="line">y_pred = ann.predict(X_test,batch_size=<span class="number">10</span>) <span class="comment"># 预测测试集的标签</span></span><br><span class="line">y_pred = np.<span class="built_in">round</span>(y_pred) <span class="comment"># 将分类概率值转换成0/1整数值</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">神经网络测试集准确率 86.15%</span><br></pre></td></tr></table></figure><p>显示损失曲线和准确率曲线：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_history(history)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191722724.png" alt="image-20250219172233556"></p><p>显示混淆矩阵：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">show_report(X_test, y_test, y_pred)</span><br><span class="line">show_matrix(y_test, y_pred)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191723602.png" alt="image-20250219172303477"></p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191723431.png" alt="image-20250219172352282"></p><h2 id="四、从单隐层神经网络到深度神经网络">四、从单隐层神经网络到深度神经网络</h2><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502191831717.png" alt="image-20250219183131511"></p><h3 id="4-1-梯度下降：正向传播和反向传播">4.1 梯度下降：正向传播和反向传播</h3><p>深度神经网络的梯度下降和参数优化过程是通过==优化器==实现的，其中包括正向传播（forward propagation）算法，反向传播（Back Propagation， BP）算法。</p><p>正向传播：计算损失的过程。</p><p>反向传播：参数优化的过程。</p><p>不太理解并没有关系，只要理解了基本原理，就可以在这些工具、框架上对网络进行调试，我们要做的只是解决问题，而不是炫耀数学功底。”</p><p> </p><p>通过正向传播和反向传播，神经网络实现了内部参数的调整。</p><p>说神经网络中的可调==超参数==，具体包括以下几个。</p><ul><li>优化器</li><li>激活函数</li><li>损失函数</li><li>评估指标</li></ul><h3 id="4-2-梯度下降优化器">4.2 梯度下降优化器</h3><p>多种优化思路的集大成者—AdamAdam 全 称 为 Adaptive Moment Estimation ， 相 当 于 Adaptive Momentum。</p><p>就目前而言，Adam是多种优化思路的集大成者，一般是优化器的首选项。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keras.optimizers.Adam(learning_rate=<span class="number">0.001</span>, <span class="comment"># 学习速率</span></span><br><span class="line">beta_1=<span class="number">0.9</span>, <span class="comment"># 一阶动量指数衰减速率</span></span><br><span class="line">beta_2=<span class="number">0.999</span>, <span class="comment"># 二阶动量指数衰减速率, 对于稀疏矩阵值应接近1</span></span><br><span class="line">amsgrad=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="4-3激活函数">4.3激活函数</h3><p>ReLU函数后来人们就发现了能够解决梯度消失问题的ReLU（Rectified LinearUnit）函数。ReLU函数的特点是单侧抑制，输入信号小于等于0时，输出是0；输入信号大于0时，输出等于输入。</p><p>ReLU对于随机梯度下降的收敛很迅速，因为相较于Sigmoid和Tanh在求导时的指数运算，对Re LU求导几乎不存在任何计算量。其公式和图像如下：<br>$$<br>f(z)=max(0,z)<br>$$<br><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192204401.png" alt="image-20250219220400187"></p><p>用Re LU的时候，学习速率绝对不能设得太大，因为那样会“杀死”网络中的很多神经元。</p><h3 id="4-4-损失函数">4.4 损失函数</h3><p>神经网络中损失函数的选择是根据问题类型而定的，指导原则如下。</p><p>对于==连续值向量的回归==问题，用均方误差损失函数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于连续值向量的回归问题</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,loss=<span class="string">&#x27;mse&#x27;</span>) <span class="comment"># 均方误差损失函数对于二分类问题，使用同样熟悉的二元交叉熵损失函数：</span></span><br><span class="line"><span class="comment"># 对于二分类问题</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="comment"># 二元交叉熵损失函数</span></span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>对于==多分类问题==，如果输出是==one-hot编码==，则用==分类交叉熵损失函数==：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于多分类问题</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, <span class="comment"># 分类交叉熵损失函数</span></span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>对于==多分类问题==，如果输出是==整数数值==，则使用==稀疏分类交叉熵损失函数==：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于多分类问题</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>, <span class="comment"># 稀疏分类交叉熵损失函数</span></span><br><span class="line">metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure><p>对于==序列问题==，如==语音识别==等，则可以用==时序分类==（Connectionist</p><p>Temporal Classification， CTC） 等损失函数。</p><h3 id="4-5-评估指标">4.5 评估指标</h3><p>神经网络的评估指标，也就是评估网络模型好不好的标准，这个标准也叫目标函数。</p><p>评估指标和损失函数有点相似，都是追求真值和预测值之间的最小误差</p><p>其差别在于：</p><p>损失函数作用于训练集，用以训练机器，==为梯度下降提供方向==；</p><p>评估指标（目标函数）作用于验证集和测试集，用来==评估模型==。</p><p> </p><p>对于==回归问题==，神经网络中使用MAE作为评估指标是常见的。</p><p>对于==普通分类问题==，神经网络中使用准确率作为评估指标也是常见的，但是对于类别分布不平衡的情况，应辅以==精确率、召回率、F1分数==等其他评估指标。</p><p>损失函数和评估指标，有相似之处，但意义和作用又不尽相同。</p><h2 id="五、用Keras深度神经网络预测客户流失率">五、用Keras深度神经网络预测客户流失率</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ann = Sequential() <span class="comment"># 创建一个序贯ANN模型</span></span><br><span class="line">ann.add(Dense(units=<span class="number">12</span>, input_dim=<span class="number">12</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加输入层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">24</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">48</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">96</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">192</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>)) <span class="comment"># 添加输出层</span></span><br><span class="line"><span class="comment"># 编译神经网络，指定优化器，损失函数，以及评估指标</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;RMSprop&#x27;</span>, <span class="comment"># 优化器</span></span><br><span class="line">            loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="comment"># 损失函数</span></span><br><span class="line">            metrics = [<span class="string">&#x27;acc&#x27;</span>]) <span class="comment"># 评估指标</span></span><br><span class="line">history = ann.fit(X_train, y_train, <span class="comment"># 指定训练集</span></span><br><span class="line">                  epochs=<span class="number">30</span>,        <span class="comment"># 指定训练的轮次</span></span><br><span class="line">                  batch_size=<span class="number">64</span>,    <span class="comment"># 指定数据批量</span></span><br><span class="line">                  validation_data=(X_test, y_test)) <span class="comment"># 指定验证集</span></span><br><span class="line">y_pred = ann.predict(X_test,batch_size=<span class="number">10</span>) <span class="comment"># 预测测试集的标签</span></span><br><span class="line">y_pred = np.<span class="built_in">round</span>(y_pred) <span class="comment"># 将分类概率值转换成0/1整数值</span></span><br></pre></td></tr></table></figure><ol><li>较深的神经网络训练效率要高于小型网络，一两个轮次之后，准确率迅速提升到0.84以上，而单隐层神经网络需要好几轮才能达到这个准确率</li><li>从准确率上看，没有什么提升；而从F1分数上看，目前这个比较深的神经网络反而不如简单的单隐层神经网络，从0.58下降到0.55：</li><li>从损失函数图像上看，深度神经网络在几轮之后就开始出现过拟合的问题，而且验证集上损失的波动也很大。因为随着轮次的增加，训练集的误差值逐渐减小，但是验证集的误差反而越来越大了。</li></ol><p>也就是说，网络的参数逐渐地对训练集的数据形成了过高的适应性。这对于较大网络来说的确是常见情况。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192216150.png" alt="image-20250219221617941"></p><h3 id="5-1-选择多种优化器">5.1 选择多种优化器</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ann = Sequential() <span class="comment"># 创建一个序贯ANN模型</span></span><br><span class="line">ann.add(Dense(units=<span class="number">12</span>, input_dim=<span class="number">12</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加输入层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">24</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">48</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">96</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">192</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>)) <span class="comment"># 添加输出层</span></span><br><span class="line"><span class="comment"># 编译神经网络，指定优化器，损失函数，以及评估标准</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;adam&#x27;</span>, loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line">history = ann.fit(X_train, y_train, epochs=<span class="number">30</span>, batch_size=<span class="number">64</span>, validation_data=(X_test, y_test))</span><br><span class="line">y_pred = ann.predict(X_test,batch_size=<span class="number">10</span>) <span class="comment"># 预测测试集的标签</span></span><br><span class="line">y_pred = np.<span class="built_in">round</span>(y_pred) <span class="comment"># 将分类概 率值转换成0/1整数值</span></span><br></pre></td></tr></table></figure><p>更换优化器之后，重新训练、测试网络。发现最为关心的F1分数有所上升，上升至0.56，如下输出结果所示。但这仍然低于单隐层神经网络的0.58：</p><p>损失曲线显示，==过拟合现象==仍然十分严重。也许这个过拟合问题就是深层神经网络效率低的症结所在。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192218255.png" alt="image-20250219221809032"></p><h3 id="5-2-神经网络正则化：添加Dropout层">5.2 神经网络正则化：添加Dropout层</h3><p>原理非常奇特：在某一层之后添加Dropout层，意思就是随机将该层的一部分神经元的输出特征丢掉（设为0），相当于随机消灭一部分神经元。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192219594.png" alt="image-20250219221915358"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout <span class="comment"># 导入Dropout</span></span><br><span class="line">ann = Sequential() <span class="comment"># 创建一个序贯ANN模型</span></span><br><span class="line">ann.add(Dense(units=<span class="number">12</span>, input_dim=<span class="number">12</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加输入层</span></span><br><span class="line">ann.add(Dense(units=<span class="number">24</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dropout(<span class="number">0.5</span>)) <span class="comment"># 添加Dropout</span></span><br><span class="line">ann.add(Dense(units=<span class="number">48</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dropout(<span class="number">0.5</span>)) <span class="comment"># 添加Dropout</span></span><br><span class="line">ann.add(Dense(units=<span class="number">96</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dropout(<span class="number">0.5</span>)) <span class="comment"># 添加Dropout</span></span><br><span class="line">ann.add(Dense(units=<span class="number">192</span>, activation = <span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加隐层</span></span><br><span class="line">ann.add(Dropout(<span class="number">0.5</span>)) <span class="comment"># 添加Dropout</span></span><br><span class="line">ann.add(Dense(units=<span class="number">1</span>, activation = <span class="string">&#x27;sigmoid&#x27;</span>)) <span class="comment"># 添加输出层</span></span><br><span class="line">ann.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;adam&#x27;</span>, <span class="comment"># 优化器</span></span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>, <span class="comment">#损失函数 </span></span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>]) <span class="comment"># 评估指标</span></span><br><span class="line">history = ann.fit(X_train, y_train, epochs=<span class="number">30</span>, batch_size=<span class="number">64</span>, validation_data=(X_test, y_test))</span><br><span class="line">y_pred = ann.predict(X_test,batch_size=<span class="number">10</span>) <span class="comment"># 预测测试集的标签</span></span><br><span class="line">y_pred = np.<span class="built_in">round</span>(y_pred) <span class="comment"># 将分类概率值转换成0/1整数值</span></span><br></pre></td></tr></table></figure><p>损失曲线显示，添加Dropout层之后，过拟合现象被大幅度地抑制了。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192221325.png" alt="image-20250219222116066"></p><p>针对客户流失样本的F1分数上升到了令人惊讶的0.62</p><p>新的混淆矩阵显示，400多个即将流失的客户中，我们成功地捕捉到了200多人。这是非常有价值的商业信息。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502192222575.png" alt="image-20250219222205395"></p><p>其实准确率或者F1分数本身的提升并不重要，更有价值的是网络优化过程中所做的各种尝试和背后的思路。</p><p> </p><h2 id="六、深度神经网络的调试及性能优化">六、深度神经网络的调试及性能优化</h2><h3 id="6-1-使用回调功能">6.1 使用回调功能</h3><p>开始训练之前，我们不知道多少轮之后会开始出现过拟合的征兆。</p><p>比如运行100轮，才发现原来15轮才是比较正确的选择。本来进行15轮就得到最佳结果，却需要先运行100轮。有没有可能一次性找到最合适的轮点？”</p><p> </p><p>类似的运行时动态控制可以通过回调（callback）功能来实现。所谓回调，就是在训练进行过程中，根据一些预设的指示对训练进行控制。下面是几个常用的回调函数。</p><p><code>Model Checkpoint</code>：在训练过程中的不同时间点保存模型，也就是保存当前网络的所有权重。</p><p><code>Early Stopping</code>：如果验证损失不再改善，则中断训练。这个回调函数常与Model Checkpoint结合使用，以保存最佳模型。</p><p><code>Reduce LROn Plateau</code>：在训练过程中动态调节某些参数值，比如优化器的学习速率，从而跳出训练过程中的高原区。</p><p><code>TensorBoard</code>：将模型训练过程可视化。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入回调功能</span></span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Model Checkpoint</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Early Stopping</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> Reduce LROn Plateau</span><br><span class="line"><span class="comment"># 设定要回调的功能</span></span><br><span class="line">earlystop = Early Stopping(monitor=<span class="string">&#x27;val_acc&#x27;</span>, patience=<span class="number">20</span>,</span><br><span class="line">verbose=<span class="number">1</span>, restore_best_weights=<span class="literal">True</span>)</span><br><span class="line">reducelr = Reduce LROn Plateau(monitor=<span class="string">&#x27;val_acc&#x27;</span>,</span><br><span class="line">factor=<span class="number">0.5</span>,</span><br><span class="line">patience=<span class="number">3</span>, verbose=<span class="number">1</span>, min_lr=<span class="number">1e-7</span>)</span><br><span class="line">modelckpt = Model Checkpoint(filepath=<span class="string">&#x27;ann.h5&#x27;</span>,</span><br><span class="line">monitor=<span class="string">&#x27;val_acc&#x27;</span>,</span><br><span class="line">verbose=<span class="number">1</span>, save_best_only=<span class="literal">True</span>,</span><br><span class="line">mode=<span class="string">&#x27;max&#x27;</span>)</span><br><span class="line">callbacks = [earlystop, reducelr, modelckpt] <span class="comment"># 设定回调</span></span><br><span class="line">history = ann.fit(X_train, y_train, <span class="comment"># 指定训练集</span></span><br><span class="line">batch_size=<span class="number">128</span>,　<span class="comment"># 指定批量大小</span></span><br><span class="line">validation_data = (X_test, y_test), <span class="comment"># 指定验证集</span></span><br><span class="line">epochs=<span class="number">100</span>,　 <span class="comment"># 指定轮次</span></span><br><span class="line">callbacks=callbacks) <span class="comment"># 指定回调功能</span></span><br></pre></td></tr></table></figure><h3 id="6-2-使用TensorBoard">6.2 使用TensorBoard</h3><p><code>TensorBoard</code>是一个内置于Tensor Flow的可视化工具，用以帮助我们在训练过程中监控模型内部发生的信息。具体包括以下功能。</p><ul><li>在训练过程中监控指标。</li><li>将模型的架构可视化。</li><li>显示激活和梯度的直方图。</li><li>以三维的形式显示词嵌入。</li></ul><p>在Kaggle中，只需要用下面两句代码配置TensorBoard：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入并激活TensorBoard</span></span><br><span class="line">%load_ext tensorboard</span><br><span class="line">%tensorboard --logdir logs</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建机器学习模型</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">((x_train, y_train), (x_test, y_test)) = mnist.load_data()</span><br><span class="line">(x_train, x_test) = (x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span>)</span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">512</span>, activation=tf.nn.relu),</span><br><span class="line">  tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=tf.nn.softmax)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">  optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">  loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">  metrics=[<span class="string">&#x27;accuracy&#x27;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回调Tensorboard</span></span><br><span class="line">tensorboard_callback = tf.keras.callbacks.TensorBoard(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line">model.fit(</span><br><span class="line">  x_train,</span><br><span class="line">  y_train,</span><br><span class="line">  epochs=<span class="number">5</span>,</span><br><span class="line">  callbacks=[tensorboard_callback],</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>6.3 神经网络中的过拟合</p><p>（1）首先，根据奥卡姆剃刀定律，因为网络越大，越容易过拟合。如果能够用较简单的小型网络解决问题，就不要强迫自己使用大网络。</p><p>（2）一种思路是在训练大型网络之前使用少量数据训练一个较小的模型，小模型的泛化好，再去训练更深、更大的网络。不然的话，费了很多精力直接训练一个大网络。</p><p>（3）另外，最常见且有效地降低神经网络过拟合的方法就是在全连接层之间添加一些Dropout层。这是很好用的标准做法，不过Dropout层会对训练速度稍有影响。</p><p>（4）最后，使用较低的学习速率配合神经元的权重正则化可能是解决过拟合问题的手段之一。</p><p><code>《Deep Residual Learning for Image Recognition》</code>中提出的。通过残差连接，可以很轻松地构建几百层，甚至上千层的网络，而不用担心梯度消失过快的问题。</p><h2 id="前向传播的数学本质（附4D张量可视化）">前向传播的数学本质（附4D张量可视化）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动实现矩阵变换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_pass</span>(<span class="params">X, W1, b1, W2, b2</span>):</span><br><span class="line">    h1 = tf.matmul(X, W1) + b1</span><br><span class="line">    a1 = tf.nn.relu(h1)</span><br><span class="line">    h2 = tf.matmul(a1, W2) + b2</span><br><span class="line">    <span class="keyword">return</span> tf.nn.softmax(h2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4D权重可视化</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">    plt.subplot(<span class="number">4</span>,<span class="number">4</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(W1[:,i].numpy().reshape(<span class="number">28</span>,<span class="number">28</span>), cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;第一层权重可视化&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>前向传播方程：$a[l]=g<a href="W%5Bl%5Da%5Bl%E2%88%921%5D+b%5Bl%5D">l</a>\text{前向传播方程：} a^{[l]} = g<sup>{[l]}(W</sup>{[l]}a^{[l-1]} + b^{[l]})$</p><hr><h2 id="反向传播的工程实现技巧（双框架代码）">反向传播的工程实现技巧（双框架代码）</h2><h3 id="PyTorch版本（动态计算图）">PyTorch版本（动态计算图）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DeepNN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.layer1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        self.layer2 = torch.nn.Linear(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.output = torch.nn.Linear(<span class="number">128</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(self.layer1(x))</span><br><span class="line">        x = torch.dropout(x, <span class="number">0.3</span>, train=self.training)</span><br><span class="line">        x = torch.relu(self.layer2(x))</span><br><span class="line">        <span class="keyword">return</span> torch.log_softmax(self.output(x), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动微分演示</span></span><br><span class="line">x = torch.randn(<span class="number">32</span>, <span class="number">784</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">loss_fn = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-4</span>)</span><br></pre></td></tr></table></figure><h3 id="TensorFlow静态图加速">TensorFlow静态图加速</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>, kernel_regularizer=<span class="string">&#x27;l2&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;swish&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># XLA加速配置</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">1e-4</span>),</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              jit_compile=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="工业级训练技巧（提升10倍训练效率）">工业级训练技巧（提升10倍训练效率）</h2><h3 id="AutoML参数搜索">AutoML参数搜索</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">!pip install keras-tuner</span><br><span class="line"><span class="keyword">import</span> kerastuner <span class="keyword">as</span> kt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hyper_model</span>(<span class="params">hp</span>):</span><br><span class="line">    model = tf.keras.Sequential()</span><br><span class="line">    model.add(tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 动态搜索层数与单元数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hp.Int(<span class="string">&#x27;num_layers&#x27;</span>, <span class="number">2</span>, <span class="number">6</span>)):</span><br><span class="line">        model.add(tf.keras.layers.Dense(</span><br><span class="line">            units=hp.Int(<span class="string">f&#x27;units_<span class="subst">&#123;i&#125;</span>&#x27;</span>, <span class="number">32</span>, <span class="number">256</span>, step=<span class="number">32</span>),</span><br><span class="line">            activation=hp.Choice(<span class="string">&#x27;activation&#x27;</span>, [<span class="string">&#x27;relu&#x27;</span>, <span class="string">&#x27;swish&#x27;</span>]))</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    model.add(tf.keras.layers.Dense(<span class="number">10</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adam(</span><br><span class="line">        hp.Float(<span class="string">&#x27;learning_rate&#x27;</span>, <span class="number">1e-5</span>, <span class="number">1e-2</span>, sampling=<span class="string">&#x27;log&#x27;</span>)),</span><br><span class="line">        loss=<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">tuner = kt.BayesianOptimization(hyper_model,</span><br><span class="line">                                objective=<span class="string">&#x27;val_loss&#x27;</span>,</span><br><span class="line">                                max_trials=<span class="number">50</span>)</span><br></pre></td></tr></table></figure><h3 id="混合精度训练（V100-GPU加速）">混合精度训练（V100 GPU加速）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">policy = tf.keras.mixed_precision.Policy(<span class="string">&#x27;mixed_float16&#x27;</span>)</span><br><span class="line">tf.keras.mixed_precision.set_global_policy(policy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意最后层强制转float32</span></span><br><span class="line">model.layers[-<span class="number">1</span>].dtype_policy = tf.float32</span><br></pre></td></tr></table></figure><hr><h2 id="模型解释与部署（关键工业考量）">模型解释与部署（关键工业考量）</h2><h3 id="激活热力图可视化">激活热力图可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tf_explain <span class="keyword">as</span> explain</span><br><span class="line"></span><br><span class="line">explainer = explain.core.activation_maximization.ActivationMaximization()</span><br><span class="line">grid = explainer.explain(validation_data=test_images, </span><br><span class="line">                        model=model,</span><br><span class="line">                        target_layer=<span class="string">&#x27;dense_3&#x27;</span>)</span><br><span class="line">plt.imshow(grid, cmap=<span class="string">&#x27;jet&#x27;</span>)</span><br></pre></td></tr></table></figure><h3 id="TensorRT加速推理">TensorRT加速推理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TensorFlow到TensorRT转换</span></span><br><span class="line">conversion_params = trt.TrtConversionParams(</span><br><span class="line">    precision_mode=trt.TrtPrecisionMode.FP16)</span><br><span class="line">converter = trt.TrtGraphConverterV2(</span><br><span class="line">    input_saved_model_dir=<span class="string">&#x27;saved_model&#x27;</span>,</span><br><span class="line">    conversion_params=conversion_params)</span><br><span class="line">converter.convert()</span><br><span class="line">converter.save(<span class="string">&#x27;trt_model&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>逻辑回归–多元分类问题</h1><p>有多少类别，就要训练多少二元分类器。每次选择一个类别作为正例，标签为1，其他所有类别都视为负例，标签为0，以此类推至所有的类别。训练好多个二元分类器之后，做预测时，将所有的二元分类器都运行一遍，然后对每一个输入样本，选择最高可能性的输出概率，即为该样本多元分类的类别。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171938289.png" alt="image-20250217193830164"></p><p>举例来说，如果对3个二元分类器分别做一次逻辑回归，机器的分类结果告诉我们，数据A是孔雀的可能性为0.5，是熊猫的可能性为0.1，是独角兽的可能性为0.4。</p><p>那就会判断数据A是孔雀。</p><h2 id="一、多元分类的损失函数">一、多元分类的损失函数</h2><p>多元分类的损失函数的选择与<code>输出编码</code>，与<code>标签的格式</code>有关。</p><p>多元分类的标签共有以下两种格式。</p><ul><li><p>一种是one-hot格式的分类编码，比如，数字0～9分类中的数字8，格式为［0，0，0， 0，0，0，0，1，0］。</p></li><li><p>一种是直接转换为类别数字，如1、2、3、4。</p><p>因此损失函数也有以下两种情况。</p></li><li><p>如果通过==one-hot==分类编码输出标签，则应使用==分类交叉熵（categorical crossentropy）==作为损失函数。</p></li><li><p>如果输出的标签编码为类别==数字==，则应使用==稀疏分类交叉熵（sparse categorical crossentropy）==作为损失函数。</p></li></ul><p> </p><h2 id="二、正则化，欠拟合和过拟合">二、正则化，欠拟合和过拟合</h2><h3 id="2-1正则化">2.1正则化</h3><p>可以理解为==调整模型，约束权重==。</p><p>机器学习中的正则化是在损失函数里面加惩罚项，增加建模的模糊性，从而把捕捉到的趋势</p><p>从局部细微趋势，调整到整体大概趋势。虽然一定程度上地放宽了建模要求，但是能有效防止过拟合的问题，增加模型准确性。它影响的是模型的权重。</p><p> </p><h3 id="2-2-欠拟合和过拟合">2.2 欠拟合和过拟合</h3><p>3个机器学习模型对数据集的拟合</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171952690.png" alt="image-20250217195232567"></p><p>寻找模型优化和泛化的平衡点</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171952622.png" alt="image-20250217195241534"></p><p>3个分类器的分类边界</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171953201.png" alt="image-20250217195303103"></p><h3 id="2-3-降低过拟合现象的方法。">2.3 降低过拟合现象的方法。</h3><ol><li>==增加数据集的数据个数==：数据量太小时，非常容易过拟合，因为小数据集很容易精确拟合。</li><li>==找到模型优化时的平衡点==：比如，选择迭代次数，或者选择相对简单的模型。</li><li>==正则化==：为可能出现过拟合现象的模型增加正则项，通过降低模型在训练集上的精度来提高其泛化能力，这是非常重要的机器学习思想之一。</li></ol><h3 id="2-4-正则化参数">2.4 正则化参数</h3><p>机器学习中的正则化通过引入模型参数λ（lambda）来实现。</p><p>加入了正则化参数之后的线性回归均方误差损失函数公式被更新成下面这样：<br>$$<br>L(w,b)=MSE=\frac{1}{N}\sum_{(x,y)\in D}(y-h(x))<sup>2+\frac{\lambda}{2N}\sum_{i=1}</sup>nw_i^2<br>$$<br>加入了正则化参数之后的逻辑回归均方误差损失函数公式被更新成下面这样：<br>$$<br>L(w,b)=-\frac{1}{N}\sum_{(x,y)\in D}[y<sup>*\log(h(x))+(1-y)*\log(1-h(x))]+\frac{\lambda}{2N}\sum_{j=1}</sup>nw_j^2<br>$$<br>现在的训练优化算法是一个由两项内容组成的函数：一个是==损失项==，用于衡量模型与数据的拟合度；另一个是==正则化项==，用于调解模型的复杂度。</p><p>其实，正则化的本质，就是==崇尚简单化==。同时以==最小化损失和复杂度==为目标，这称为==结构风险最小化==。</p><p>选择λ值的目标是在简单化和训练集数据拟合之间达到适当的平衡。</p><p>如果λ值过大，则模型会非常简单，将面临数据==欠拟合==的风险。</p><p>此时模型无法从训练数据中获得足够的信息来做出有用的预测。而且λ值越大，机器收敛越慢。</p><p> </p><p>如果λ值过小，则模型会比较复杂，将面临数据==过拟合==的风险。</p><p>此时模型由于获得了过多训练数据特点方面的信息而无法泛化到新数据。</p><p> </p><p>将λ设为0可彻底取消正则化。在这种情况下，训练的唯一目的是最小化损失，此时==过拟合的风险较高==。</p><p> </p><p>正则化参数通常有L1正则化和L2正则化两种选择。</p><p>L1正则化，根据权重的绝对值的总和来惩罚权重。在==依赖稀疏特征==的模型中，L1正则化有助于使不相关或几乎不相关的特征的权重正好为0，从而将这些特征从模型中移除。</p><p>L2正则化，根据==权重的平方和==来惩罚权重。</p><p>L2 正则化有助于使离群值（具有较大正值或较小负值）的权重接近于0，但又不会正好为0。</p><p>在线性模型中，L2 正则化比较常用，而且在任何情况下都能够起到增强泛化能力的目的。</p><p>而最佳λ值则取决于具体数据集，需要手动或自动进行调整。</p><p> </p><h2 id="三、通过逻辑回归解决多元分类问题">三、通过逻辑回归解决多元分类问题</h2><h3 id="3-1数据的分析与准备工作">3.1数据的分析与准备工作</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入Numpy</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 导入Pandas</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets <span class="comment"># 导入sklearn的数据集</span></span><br><span class="line">iris = datasets.load_iris() <span class="comment"># 导入iris</span></span><br><span class="line">X_sepal = iris.data[:,[<span class="number">0</span>,<span class="number">1</span>]] <span class="comment"># 花萼特征集：两个特征长和宽</span></span><br><span class="line">X_petal = iris.data[:,[<span class="number">2</span>,<span class="number">3</span>]] <span class="comment"># 花瓣特征集：两个特征长和宽</span></span><br><span class="line">y = iris.target <span class="comment"># 标签集</span></span><br></pre></td></tr></table></figure><p>下面进行花萼数据集的分割和标准化，分成训练集和测试集：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment"># 导入拆分数据集工具</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="comment"># 导入标准化工具</span></span><br><span class="line">X_train_sepal, X_test_sepal, y_train_sepal, y_test_sepal = \</span><br><span class="line">  train_test_split(X_sepal,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">0</span>) <span class="comment"># 拆分数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;花萼训练集样本数: &quot;</span>, <span class="built_in">len</span>(X_train_sepal))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;花萼测试集样本数: &quot;</span>, <span class="built_in">len</span>(X_test_sepal))</span><br><span class="line">scaler = StandardScaler() <span class="comment"># 标准化工具</span></span><br><span class="line">X_train_sepal = scaler.fit_transform(X_train_sepal) <span class="comment"># 训练集数据标准化</span></span><br><span class="line">X_test_sepal = scaler.transform(X_test_sepal) <span class="comment"># 测试集数据标准化</span></span><br><span class="line"><span class="comment"># 合并特征集和标签集，留待以后数据展示之用</span></span><br><span class="line">X_combined_sepal = np.vstack((X_train_sepal,X_test_sepal)) <span class="comment"># 合并特征集</span></span><br><span class="line">Y_combined_sepal = np.hstack((y_train_sepal,y_test_sepal)) <span class="comment"># 合并标签集</span></span><br></pre></td></tr></table></figure><h3 id="3-2-通过Sklearn实现逻辑回归的多元分类">3.2 通过Sklearn实现逻辑回归的多元分类</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="comment"># 导入逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, C = <span class="number">0.1</span>) <span class="comment"># 设定L2正则化和C参数</span></span><br><span class="line">lr.fit(X_train_sepal,y_train_sepal) <span class="comment"># 训练机器</span></span><br><span class="line">score = lr.score(X_test_sepal,y_test_sepal) <span class="comment"># 测试集分数评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SK-learn逻辑回归测试准确率 &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(score*<span class="number">100</span>)) </span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SK-learn逻辑回归测试准确率 68.89%</span><br></pre></td></tr></table></figure><h3 id="3-3-正则化参数–c值的选择">3.3 正则化参数–c值的选择</h3><p>用绘图的方式显示出采用不同的C值，对于鸢尾花分类边界的具体影响。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入matplotlib</span></span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap <span class="comment"># 导入Colormap</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_decision_regions</span>(<span class="params">X,y,classifier,test_idx=<span class="literal">None</span>,resolution=<span class="number">0.02</span></span>):    </span><br><span class="line">    markers = (<span class="string">&#x27;o&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="string">&#x27;v&#x27;</span>)</span><br><span class="line">    colors = (<span class="string">&#x27;red&#x27;</span>,<span class="string">&#x27;blue&#x27;</span>,<span class="string">&#x27;lightgreen&#x27;</span>)</span><br><span class="line">    color_Map = ListedColormap(colors[:<span class="built_in">len</span>(np.unique(y))])     </span><br><span class="line">    x1_min = X[:,<span class="number">0</span>].<span class="built_in">min</span>() - <span class="number">1</span></span><br><span class="line">    x1_max = X[:,<span class="number">0</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    x2_min = X[:,<span class="number">1</span>].<span class="built_in">min</span>() - <span class="number">1</span></span><br><span class="line">    x2_max = X[:,<span class="number">1</span>].<span class="built_in">max</span>() + <span class="number">1</span></span><br><span class="line">    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),</span><br><span class="line">                           np.arange(x2_min,x2_max,resolution))    </span><br><span class="line">    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)</span><br><span class="line">    Z = Z.reshape(xx1.shape)    </span><br><span class="line">    plt.contour(xx1,xx2,Z,alpha=<span class="number">0.4</span>,cmap = color_Map)</span><br><span class="line">    plt.xlim(xx1.<span class="built_in">min</span>(),xx1.<span class="built_in">max</span>())</span><br><span class="line">    plt.ylim(xx2.<span class="built_in">min</span>(),xx2.<span class="built_in">max</span>())   </span><br><span class="line">    X_test, Y_test = X[test_idx,:], y[test_idx]</span><br><span class="line">    <span class="keyword">for</span> idx, cl <span class="keyword">in</span> <span class="built_in">enumerate</span>(np.unique(y)):</span><br><span class="line">        plt.scatter(x = X[y == cl, <span class="number">0</span>], y = X[y == cl, <span class="number">1</span>],</span><br><span class="line">                    alpha = <span class="number">0.8</span>, c = color_Map(idx),</span><br><span class="line">                    marker = markers[idx], label = cl)</span><br></pre></td></tr></table></figure><p>然后使用不同的C值进行逻辑回归分类，并绘制分类结果：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score <span class="comment"># 导入准确率指标</span></span><br><span class="line">C_param_range = [<span class="number">0.01</span>,<span class="number">0.1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">100</span>,<span class="number">1000</span>]</span><br><span class="line">sepal_acc_table = pd.DataFrame(columns = [<span class="string">&#x27;C_parameter&#x27;</span>,<span class="string">&#x27;Accuracy&#x27;</span>])</span><br><span class="line">sepal_acc_table[<span class="string">&#x27;C_parameter&#x27;</span>] = C_param_range</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">j = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> C_param_range:</span><br><span class="line">    lr = LogisticRegression(penalty = <span class="string">&#x27;l2&#x27;</span>, C = i,random_state = <span class="number">0</span>)</span><br><span class="line">    lr.fit(X_train_sepal,y_train_sepal)</span><br><span class="line">    y_pred_sepal = lr.predict(X_test_sepal)</span><br><span class="line">    sepal_acc_table.iloc[j,<span class="number">1</span>] = accuracy_score(y_test_sepal,y_pred_sepal)</span><br><span class="line">    j += <span class="number">1</span>    </span><br><span class="line">    plt.subplot(<span class="number">3</span>,<span class="number">2</span>,j)</span><br><span class="line">    plt.subplots_adjust(hspace = <span class="number">0.4</span>)</span><br><span class="line">    plot_decision_regions(X = X_combined_sepal, y = Y_combined_sepal, </span><br><span class="line">                          classifier = lr, test_idx = <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">150</span>))</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Sepal length&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Sepal width&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;C = %s&#x27;</span>%i)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502172231031.png" alt="image-20250217223141779"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lr = LogisticRegression(penalty=<span class="string">&#x27;l2&#x27;</span>, C = <span class="number">10</span>) <span class="comment"># 设定L2正则化和C参数</span></span><br><span class="line">lr.fit(X_train_sepal,y_train_sepal) <span class="comment"># 训练机器</span></span><br><span class="line">score = lr.score(X_test_sepal,y_test_sepal) <span class="comment"># 测试集分数评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sklearn逻辑回归测试准确率 &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(score*<span class="number">100</span>))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Sklearn逻辑回归测试准确率 80.00%</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–逻辑回归</h1><hr><h2 id="一、认知革命：从线性回归到逻辑回归">一、认知革命：从线性回归到逻辑回归</h2><h3 id="1-1-本质差异对比">1.1 本质差异对比</h3><table><thead><tr><th>维度</th><th>线性回归</th><th>逻辑回归</th></tr></thead><tbody><tr><td>输出类型</td><td>连续值</td><td>概率值 (0-1)</td></tr><tr><td>目标函数</td><td>最小二乘法</td><td>极大似然估计</td></tr><tr><td>数学表达式</td><td>$y=w^Tx+b$</td><td>$p=\frac{1}{1+e<sup>{-(w</sup>Tx+b)}}$</td></tr><tr><td>应用场景</td><td>房价预测</td><td>信用评分、疾病诊断</td></tr></tbody></table><h3 id="1-2-Sigmoid函数的数学推导">1.2 Sigmoid函数的数学推导</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sigmoid函数特性验证</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入10时概率：&quot;</span>, sigmoid(<span class="number">10</span>))  <span class="comment"># 输出0.99995</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入-10时概率：&quot;</span>, sigmoid(-<span class="number">10</span>)) <span class="comment"># 输出0.000045</span></span><br></pre></td></tr></table></figure><h3 id="1-3-逻辑回归">1.3 逻辑回归</h3><p>逻辑回归需要提前设定一个阈值p，用来控制分类界限，</p><h2 id="二、判断客户是否患病">二、判断客户是否患病</h2><p>其中提供了众多参数如：</p><ul><li>age：年龄。</li><li>sex：性别。</li><li>cp：胸痛类型。</li><li>trestbps：休息时血压。</li></ul><p>去判断是否患病，这就变成了一个分类问题</p><p>或者去判断一个人是否考试通过</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171415455.png" alt="image-20250217141526316"></p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171415702.png" alt="image-20250217141511499"></p><h2 id="三、损失函数">三、损失函数</h2><h3 id="线性回归">线性回归</h3><p>对于线性回归的损失函数<br>$$<br>L(w,b)=\frac{1}{N}\sum_{(x,y)\in D}Loss(h(x),y)=\frac{1}{N}\sum_{(x,y)\in D}Loss(y^{\prime},y)<br>$$</p><p>$$<br>\bar{e}=\frac{1}{n}\sum_{i=1}<sup>n(wx_i-y_i)</sup>2<br>$$</p><p>$$<br>\bar{e}=\frac{1}{n}\sum_{i=1}<sup>nx_i</sup>2w<sup>2-2\frac{1}{n}\sum_{i=1}</sup>nx_iy_iw+\frac{1}{n}\sum_{i=1}<sup>ny_i</sup>2<br>$$</p><p>$$<br>\bar{e}=aw^2+bw+c<br>$$</p><p>这可以把e当作一个二次函数，可以求最小值，其对于w的梯度可以最为梯度下降中的步长，但是对于逻辑回归，采用此方法可能无法到达最底端。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171456540.png" alt="image-20250217145624371"></p><h3 id="逻辑回归">逻辑回归</h3><p>$$<br>\begin{cases}y=1,Loss(h(x),y)=-\log(h(x))\y=0,Loss(h(x),y)=-\log(1-h(x))&amp;\end{cases}<br>$$</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171459175.png" alt="image-20250217145926005"></p><ul><li>如果真值是1，假设函数预测概率接近于0，损失值是巨大的。</li><li>如果真值是0，假设函数预测概率接近于1，损失值是巨大的。</li></ul><p>如果将两种情况归为一类，即可获得以下算式：<br>$$<br>loss=y<sup>{*}\mathrm{log}(h(x))+(1-y)</sup>{<em>}\mathrm{log}(1-h(x))<br>$$<br>我们设定损失函数为：<br>$$<br>L(w,b)=-\frac{1}{N}\sum_{(x,y)\in D}[y<sup>*\mathrm{log}(h(x))+(1-y)</sup></em>\mathrm{log}(1-h(x))]<br>$$</p><h2 id="四、梯度下降">四、梯度下降</h2><p>$$<br>\text{梯度}=h^{\prime}(x)=\frac{\partial}{\partial w}L(w,b)=\frac{\partial}{\partial w}\left{-\frac{1}{N}\sum_{(x,y)\in D}[y*\log(h(x))+(1-y)*\log(1-h(x))]\right}<br>$$</p><h3 id="步骤1：明确损失函数形式（交叉熵损失）">步骤1：明确损失函数形式（交叉熵损失）</h3><p>$$<br>L(w,b) = -\frac{1}{N}\sum_{i=1}^N \left[ y^{(i)} \log(h^{(i)}) + (1-y<sup>{(i)})\log(1-h</sup>{(i)}) \right]<br>$$</p><h3 id="步骤2：拆解单样本损失分量（以第i个样本为例）">步骤2：拆解单样本损失分量（以第i个样本为例）</h3><p>$$<br>\text{单样本损失} = -\left[ y \log(h) + (1-y)\log(1-h) \right]<br>$$</p><h3 id="步骤3：对参数w求导的核心运算">步骤3：对参数w求导的核心运算</h3><p>$$<br>\frac{\partial}{\partial w} \text{单样本损失} = \frac{\partial}{\partial h}\left(-\left[y\log(h)+(1-y)\log(1-h)\right]\right) \cdot \frac{\partial h}{\partial w}<br>$$</p><h4 id="分项求导运算结果：">分项求导运算结果：</h4><p>$$<br>\begin{aligned}<br>&amp;\text{a项导}：\frac{\partial}{\partial h}[-y \log(h)] = -\frac{y}{h} \<br>&amp;\text{b项导}：\frac{\partial}{\partial h}[-(1-y)\log(1-h)] = \frac{1-y}{1-h}<br>\end{aligned}<br>$$</p><h4 id="合并结果：">合并结果：</h4><p>$$<br>\frac{\partial}{\partial h} = \frac{1-y}{1-h} - \frac{y}{h}<br>$$</p><h3 id="步骤4：Sigmoid函数导数计算（链式法则核心步骤）">步骤4：Sigmoid函数导数计算（链式法则核心步骤）</h3><p>$$<br>\begin{aligned}<br>h &amp;= \sigma(w^Tx + b) = \frac{1}{1+e<sup>{-(w</sup>Tx + b)}} \<br>\frac{\partial h}{\partial w} &amp;= h(1-h)x \quad \text{（Sigmoid函数的优雅性质）}<br>\end{aligned}<br>$$</p><h3 id="步骤5：梯度分量组合与化简（见证数学之美）">步骤5：梯度分量组合与化简（见证数学之美）</h3><p>$$<br>\begin{aligned}<br>\text{梯度分量} &amp;= \left( \frac{1-y}{1-h} - \frac{y}{h} \right) \cdot h(1-h)x \<br>&amp;= \left[ (1-y)h - y(1-h) \right]x \<br>&amp;= (h - y)x \quad \text{（所有复杂项神奇抵消！）}<br>\end{aligned}<br>$$</p><h3 id="步骤6：整合全局梯度（全体样本协同计算）">步骤6：整合全局梯度（全体样本协同计算）</h3><p>$$<br>\frac{\partial L}{\partial w} = \frac{1}{N}\sum_{i=1}^N (h^{(i)} - y<sup>{(i)})x</sup>{(i)}<br>$$</p><h3 id="重要性质总结表">重要性质总结表</h3><table><thead><tr><th>性质</th><th>数学表达式</th><th>物理意义</th></tr></thead><tbody><tr><td><strong>梯度公式</strong></td><td>$$ \frac{\partial L}{\partial w} = \frac{1}{N}\sum (h-y)x $$</td><td>预测误差驱动物体参数调整</td></tr><tr><td><strong>Sigmoid导数</strong></td><td>$$ \frac{d\sigma(z)}{dz} = \sigma(z)(1-\sigma(z)) $$</td><td>自动生成正则化效果</td></tr><tr><td><strong>概率计算</strong></td><td>$$ P(y=1</td><td>x) = \frac{1}{1+e<sup>{-w</sup>Tx}} $$</td></tr></tbody></table><p>省略大量微分细节，可得：<br>$$<br>\text{梯度}=\frac{1}{N}\sum_{i=1}<sup>N(y</sup>{(i)}-h(x^{(i)}))\bullet x^{(i)}<br>$$<br>所以加入更新的速率以后可得：<br>$$<br>w=w-\alpha\cdot\frac{\partial}{\partial w}L(w)<br>$$</p><p>$$<br>w=w-\frac{\alpha}{N}\sum_{i=1}<sup>N(y</sup>{(i)}-(w\bullet x^{(i)}))\bullet x^{(i)}<br>$$</p><h2 id="五、通过逻辑回归解决二元分类问题">五、通过逻辑回归解决二元分类问题</h2><h3 id="5-1数据准备">5.1数据准备</h3><h4 id="5-1-1-数据读取">5.1.1 数据读取</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入NumPy数学工具箱</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 导入Pandas数据处理工具箱</span></span><br><span class="line">df_heart = pd.read_csv(<span class="string">&quot;/kaggle/input/logistic-regression/heart.csv&quot;</span>)  <span class="comment"># 读取文件</span></span><br><span class="line">df_heart.head() <span class="comment"># 显示前5行数据</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_heart.target.value_counts() <span class="comment"># 输出分类值，及各个类别数目</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入绘图工具</span></span><br><span class="line"><span class="comment"># 以年龄+最大心率作为输入，查看分类结果散点图</span></span><br><span class="line">plt.scatter(x=df_heart.age[df_heart.target==<span class="number">1</span>],</span><br><span class="line">            y=df_heart.thalach[(df_heart.target==<span class="number">1</span>)], c=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">plt.scatter(x=df_heart.age[df_heart.target==<span class="number">0</span>],</span><br><span class="line">            y=df_heart.thalach[(df_heart.target==<span class="number">0</span>)], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;Disease&quot;</span>, <span class="string">&quot;No Disease&quot;</span>]) <span class="comment"># 显示图例</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Age&quot;</span>) <span class="comment"># X轴-Age</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;Heart Rate&quot;</span>) <span class="comment"># Y轴-Heart Rate</span></span><br><span class="line">plt.show() <span class="comment"># 显示散点图</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171628962.png" alt="image-20250217162800659"></p><h4 id="5-1-2-构建特征集和标签集">5.1.2 构建特征集和标签集</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = df_heart.drop([<span class="string">&#x27;target&#x27;</span>], axis = <span class="number">1</span>) <span class="comment"># 构建特征集</span></span><br><span class="line">y = df_heart.target.values <span class="comment"># 构建标签集</span></span><br><span class="line">y = y.reshape(-<span class="number">1</span>,<span class="number">1</span>) <span class="comment"># -1是相对索引，等价于len(y)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;张量X的形状:&quot;</span>, X.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;张量X的形状:&quot;</span>, y.shape)</span><br></pre></td></tr></table></figure><h4 id="5-1-3-拆分数据集">5.1.3 拆分数据集</h4><p>按照80%/20%的比例准备训练集和测试集:</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = <span class="number">0.2</span>)</span><br></pre></td></tr></table></figure><h4 id="5-1-4-数据特征缩放">5.1.4 数据特征缩放</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler <span class="comment"># 导入数据缩放器</span></span><br><span class="line">scaler = MinMaxScaler() <span class="comment"># 选择归一化数据缩放器，MinMaxScaler</span></span><br><span class="line">X_train = scaler.fit_transform(X_train) <span class="comment"># 特征归一化 训练集fit_transform</span></span><br><span class="line">X_test = scaler.transform(X_test) <span class="comment"># 特征归一化 测试集transform</span></span><br></pre></td></tr></table></figure><p>仅就这个数据集而言，Min Max Scaler进行的数据特征缩放不仅不会提高效率，似乎还会令预测准确率下降。</p><p>这个结果提示我们：没有绝对正确的理论，实践才是检验真理的唯一标准。</p><h3 id="5-2-建立逻辑回归模型">5.2 建立逻辑回归模型</h3><h4 id="5-1-1-逻辑函数">5.1.1 逻辑函数</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先定义一个Sigmoid函数，输入Z，返回y&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">z</span>):    </span><br><span class="line">    y_hat = <span class="number">1</span>/(<span class="number">1</span>+ np.exp(-z))</span><br><span class="line">    <span class="keyword">return</span> y_hat    </span><br></pre></td></tr></table></figure><h4 id="5-1-2-损失函数">5.1.2 损失函数</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后定义损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">X,y,w,b</span>):</span><br><span class="line">    y_hat = sigmoid(np.dot(X,w) + b) <span class="comment"># Sigmoid逻辑函数 + 线性函数(wX+b)得到y&#x27;</span></span><br><span class="line">    loss = -(y*np.log(y_hat) + (<span class="number">1</span>-y)*np.log(<span class="number">1</span>-y_hat)) <span class="comment"># 计算损失</span></span><br><span class="line">    cost = np.<span class="built_in">sum</span>(loss) / X.shape[<span class="number">0</span>]  <span class="comment"># 整个数据集平均损失    </span></span><br><span class="line">    <span class="keyword">return</span> cost <span class="comment"># 返回整个数据集平均损失</span></span><br></pre></td></tr></table></figure><p>$$<br>L(w,b)=-\frac{1}{N}\sum_{(x,y)\in D}\left[y<sup>*\mathrm{log}(h(x))+(1-y)</sup>*\mathrm{log}(1-h(x))\right]<br>$$</p><h4 id="5-2-3-梯度下降的实现">5.2.3 梯度下降的实现</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 然后构建梯度下降的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">X,y,w,b,lr,<span class="built_in">iter</span></span>) : <span class="comment">#定义逻辑回归梯度下降函数</span></span><br><span class="line">    l_history = np.zeros(<span class="built_in">iter</span>) <span class="comment"># 初始化记录梯度下降过程中误差值(损失)的数组</span></span><br><span class="line">    w_history = np.zeros((<span class="built_in">iter</span>,w.shape[<span class="number">0</span>],w.shape[<span class="number">1</span>])) <span class="comment"># 初始化权重记录的数组</span></span><br><span class="line">    b_history = np.zeros(<span class="built_in">iter</span>) <span class="comment"># 初始化记录梯度下降过程中偏置的数组  </span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">iter</span>): <span class="comment">#进行机器训练的迭代</span></span><br><span class="line">        y_hat = sigmoid(np.dot(X,w) + b) <span class="comment">#Sigmoid逻辑函数+线性函数(wX+b)得到y&#x27;</span></span><br><span class="line">        derivative_w = np.dot(X.T,((y_hat-y)))/X.shape[<span class="number">0</span>]  <span class="comment"># 给权重向量求导</span></span><br><span class="line">        derivative_b = np.<span class="built_in">sum</span>(y_hat-y)/X.shape[<span class="number">0</span>] <span class="comment"># 给偏置求导</span></span><br><span class="line">        w = w - lr * derivative_w <span class="comment"># 更新权重向量，lr即学习速率alpha</span></span><br><span class="line">        b = b - lr * derivative_b   <span class="comment"># 更新偏置，lr即学习速率alpha</span></span><br><span class="line">        l_history[i] =  loss_function(X,y,w,b) <span class="comment"># 梯度下降过程中的损失</span></span><br><span class="line">        <span class="built_in">print</span> (<span class="string">&quot;轮次&quot;</span>, i+<span class="number">1</span> , <span class="string">&quot;当前轮训练集损失：&quot;</span>,l_history[i]) </span><br><span class="line">        w_history[i] = w <span class="comment"># 梯度下降过程中权重的历史 请注意w_history和w的形状</span></span><br><span class="line">        b_history[i] = b <span class="comment"># 梯度下降过程中偏置的历史</span></span><br><span class="line">    <span class="keyword">return</span> l_history, w_history, b_history</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>$$<br>\text{梯度}=\frac{1}{N}\sum_{i=1}<sup>N(y</sup>{(i)}-h(x^{(i)}))\bullet x^{(i)}<br>$$</p><p>$$<br>w=w-\alpha\cdot\frac{\partial}{\partial w}L(w)<br>$$</p><h4 id="5-2-4-分类预测的实现">5.2.4 分类预测的实现</h4><p>定义一个负责分类预测的函数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">X,w,b</span>): <span class="comment"># 定义预测函数</span></span><br><span class="line">    z = np.dot(X,w) + b <span class="comment"># 线性函数</span></span><br><span class="line">    y_hat = sigmoid(z) <span class="comment"># 逻辑函数转换</span></span><br><span class="line">    y_pred = np.zeros((y_hat.shape[<span class="number">0</span>],<span class="number">1</span>)) <span class="comment"># 初始化预测结果变量  </span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(y_hat.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">if</span> y_hat[i,<span class="number">0</span>] &lt; <span class="number">0.5</span>:</span><br><span class="line">            y_pred[i,<span class="number">0</span>] = <span class="number">0</span> <span class="comment"># 如果预测概率小于0.5，输出分类0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            y_pred[i,<span class="number">0</span>] = <span class="number">1</span> <span class="comment"># 如果预测概率大于0.5，输出分类1</span></span><br><span class="line">    <span class="keyword">return</span> y_pred <span class="comment"># 返回预测分类的结果</span></span><br></pre></td></tr></table></figure><h3 id="5-3-开始训练机器">5.3 开始训练机器</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">logistic_regression</span>(<span class="params">X,y,w,b,lr,<span class="built_in">iter</span></span>): <span class="comment"># 定义逻辑回归模型</span></span><br><span class="line">    l_history,w_history,b_history = gradient_descent(X,y,w,b,lr,<span class="built_in">iter</span>)<span class="comment">#梯度下降</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练最终损失:&quot;</span>, l_history[-<span class="number">1</span>]) <span class="comment"># 打印最终损失</span></span><br><span class="line">    y_pred = predict(X,w_history[-<span class="number">1</span>],b_history[-<span class="number">1</span>]) <span class="comment"># 进行预测</span></span><br><span class="line">    traning_acc = <span class="number">100</span> - np.mean(np.<span class="built_in">abs</span>(y_pred - y_train))*<span class="number">100</span> <span class="comment"># 计算准确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;逻辑回归训练准确率: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(traning_acc))  <span class="comment"># 打印准确率</span></span><br><span class="line">    <span class="keyword">return</span> l_history, w_history, b_history <span class="comment"># 返回训练历史记录</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#初始化参数</span></span><br><span class="line">dimension = X.shape[<span class="number">1</span>] <span class="comment"># 这里的维度 len(X)是矩阵的行的数，维度是列的数目</span></span><br><span class="line">weight = np.full((dimension,<span class="number">1</span>),<span class="number">0.1</span>) <span class="comment"># 权重向量，向量一般是1D，但这里实际上创建了2D张量</span></span><br><span class="line">bias = <span class="number">0</span> <span class="comment"># 偏置值</span></span><br><span class="line"><span class="comment">#初始化超参数</span></span><br><span class="line">alpha = <span class="number">1</span> <span class="comment"># 学习速率</span></span><br><span class="line">iterations = <span class="number">500</span> <span class="comment"># 迭代次数</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用逻辑回归函数训练机器</span></span><br><span class="line">loss_history, weight_history, bias_history =  \</span><br><span class="line">            logistic_regression(X_train,y_train,weight,bias,alpha,iterations)</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = predict(X_test,weight_history[-<span class="number">1</span>],bias_history[-<span class="number">1</span>]) <span class="comment"># 预测测试集</span></span><br><span class="line">testing_acc = <span class="number">100</span> - np.mean(np.<span class="built_in">abs</span>(y_pred - y_test))*<span class="number">100</span> <span class="comment"># 计算准确率</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;逻辑回归测试准确率: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(testing_acc))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">逻辑回归测试准确率: 85.25%</span><br></pre></td></tr></table></figure><h3 id="5-4-测试分类结果">5.4 测试分类结果</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&quot;逻辑回归预测分类值:&quot;</span>,predict(X_test,weight_history[-<span class="number">1</span>],bias_history[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><h3 id="5-5-绘制损失曲线">5.5 绘制损失曲线</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">loss_history_test = np.zeros(iterations) <span class="comment"># 初始化历史损失</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations): <span class="comment">#求训练过程中不同参数带来的测试集损失</span></span><br><span class="line">    loss_history_test[i] = loss_function(X_test,y_test,</span><br><span class="line">                                         weight_history[i],bias_history[i])</span><br><span class="line">index = np.arange(<span class="number">0</span>,iterations,<span class="number">1</span>)</span><br><span class="line">plt.plot(index, loss_history,c=<span class="string">&#x27;blue&#x27;</span>,linestyle=<span class="string">&#x27;solid&#x27;</span>)</span><br><span class="line">plt.plot(index, loss_history_test,c=<span class="string">&#x27;red&#x27;</span>,linestyle=<span class="string">&#x27;dashed&#x27;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;Training Loss&quot;</span>, <span class="string">&quot;Test Loss&quot;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&quot;Number of Iteration&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Cost&quot;</span>)</span><br><span class="line">plt.show() <span class="comment"># 同时显示显示训练集和测试集损失曲线</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502171647147.png" alt="image-20250217164703879"></p><p>在迭代80～100次后，训练集的损失进一步下降，但是测试集的损失并没有跟着下降，反而显示呈上升趋势。</p><p>这是明显的过拟合现象。因此迭代应该在80–100结束。</p><h2 id="六、工业级代码实现">六、工业级代码实现</h2><p>真正做项目的时候，其实没多少人这么去写代码，大家会直接调用库函数进搞定项目</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression <span class="comment">#导入逻辑回归模型</span></span><br><span class="line">lr = LogisticRegression() <span class="comment"># lr,就代表是逻辑回归模型</span></span><br><span class="line">lr.fit(X_train,y_train) <span class="comment"># fit,就相当于是梯度下降</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;SK-learn逻辑回归测试准确率&#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(lr.score(X_test,y_test)*<span class="number">100</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SK-learn逻辑回归测试准确率85.25%</span><br></pre></td></tr></table></figure><p>这个准确率比我们之前的手写代码好很多，这是为什么呢？</p><h3 id="6-1哑特征">6.1哑特征</h3><p>cp这个字段，它的意义是“胸痛类型”，取值为0、1、2、3。这些分类值，是大小无关的。</p><p>但是问题在于，计算机会把它们理解为数值，认为1和2与1和3之间的关系不是并列的，是后者差值比前者要大。</p><p>解决的方法，是把这种类别特征拆分成多个哑特征，比如cp有0、1、2、3这4类，就拆分成个4特征，cp_0为一个特征、cp_1为一个特征、cp_2为一个特征、cp_3为一个特征。每一个特征都还原成二元分类，答案是Yes或者No，也就是数值1或0。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把3个文本型变量转换为哑变量</span></span><br><span class="line">a = pd.get_dummies(df_heart[<span class="string">&#x27;cp&#x27;</span>], prefix = <span class="string">&quot;cp&quot;</span>)</span><br><span class="line">b = pd.get_dummies(df_heart[<span class="string">&#x27;thal&#x27;</span>], prefix = <span class="string">&quot;thal&quot;</span>)</span><br><span class="line">c = pd.get_dummies(df_heart[<span class="string">&#x27;slope&#x27;</span>], prefix = <span class="string">&quot;slope&quot;</span>)</span><br><span class="line"><span class="comment"># 把哑变量添加进dataframe</span></span><br><span class="line">frames = [df_heart, a, b, c]</span><br><span class="line">df_heart = pd.concat(frames, axis = <span class="number">1</span>)</span><br><span class="line">df_heart = df_heart.drop(columns = [<span class="string">&#x27;cp&#x27;</span>, <span class="string">&#x27;thal&#x27;</span>, <span class="string">&#x27;slope&#x27;</span>])</span><br><span class="line">df_heart.head() <span class="comment"># 显示新的dataframe</span></span><br></pre></td></tr></table></figure><h3 id="6-2二分类实战：信用卡欺诈检测">6.2二分类实战：信用卡欺诈检测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取真实工业数据集</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;creditcard.csv&#x27;</span>)</span><br><span class="line">X = df.drop([<span class="string">&#x27;Class&#x27;</span>,<span class="string">&#x27;Time&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;Class&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分层抽样保持样本分布</span></span><br><span class="line">skf = StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skf.split(X, y):</span><br><span class="line">    X_train, X_test = X.iloc[train_index], X.iloc[test_index]</span><br><span class="line">    y_train, y_test = y.iloc[train_index], y.iloc[test_index]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 带类别权重的模型</span></span><br><span class="line">model = LogisticRegression(class_weight=&#123;<span class="number">0</span>:<span class="number">1</span>, <span class="number">1</span>:<span class="number">10</span>&#125;, </span><br><span class="line">                          penalty=<span class="string">&#x27;l1&#x27;</span>, solver=<span class="string">&#x27;saga&#x27;</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出特征重要性排序</span></span><br><span class="line">importance = pd.DataFrame(&#123;<span class="string">&#x27;feature&#x27;</span>:X.columns, </span><br><span class="line">                          <span class="string">&#x27;coef&#x27;</span>:model.coef_[<span class="number">0</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(importance.sort_values(<span class="string">&#x27;coef&#x27;</span>, ascending=<span class="literal">False</span>))</span><br></pre></td></tr></table></figure><h3 id="6-3-多分类实战：手写数字识别（MNIST）">6.3 多分类实战：手写数字识别（MNIST）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_openml</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载MNIST数据集</span></span><br><span class="line">mnist = fetch_openml(<span class="string">&#x27;mnist_784&#x27;</span>, version=<span class="number">1</span>)</span><br><span class="line">X, y = mnist[<span class="string">&quot;data&quot;</span>], mnist[<span class="string">&quot;target&quot;</span>].astype(np.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化</span></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X[:<span class="number">10000</span>]) <span class="comment"># 抽样加速训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># OVR多分类策略</span></span><br><span class="line">model = LogisticRegression(multi_class=<span class="string">&#x27;ovr&#x27;</span>, </span><br><span class="line">                          penalty=<span class="string">&#x27;l2&#x27;</span>, </span><br><span class="line">                          max_iter=<span class="number">1000</span>)</span><br><span class="line">model.fit(X_scaled, y[:<span class="number">10000</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示预测结果样例</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(X[i].reshape(<span class="number">28</span>,<span class="number">28</span>), cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">f&#x27;Pred: <span class="subst">&#123;model.predict([X_scaled[i]])[<span class="number">0</span>]&#125;</span>&#x27;</span>)</span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习—实现多元线性回归模型</h1><p>本节顺延<code>机器学习--线性回归</code>中的内容，进一步讨论多元函数的回归问题</p><p>$$<br>y<sup>{\prime}=h(x)+w</sup>\top\bullet x+b<br>$$<br>$\text{其中,}w^\mathrm{T}\cdot x\text{就是}_{W_1X_1}+w_2X_2+w_3X_3+\cdots+w_NX_N$</p><p>进一步按题目简化：<br>$$<br>y^{\prime}=h(x)=w_0x_0+w_1x_1+w_2x_2+w_3x_3<br>$$<br>其中$w_0x_0$为引入的偏置b</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#导入NumPy数学工具箱</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#导入Pandas数据处理工具箱</span></span><br><span class="line"><span class="comment">#读入数据并显示前面几行的内容，确保已经成功的读入数据</span></span><br><span class="line"><span class="comment">#示例代码是在Kaggle中数据集中读入文件，如果在本机中需要指定具体本地路径</span></span><br><span class="line"><span class="comment"># 如，当数据集和代码文件位于相同本地目录，路径</span></span><br><span class="line"><span class="comment">#名应为&#x27;./advertising.csv&#x27;，或直接放&#x27;advertising.csv&#x27;亦可</span></span><br><span class="line">df_ads = pd.read_csv(<span class="string">&#x27;/kaggle/input/online-store-sales-forecast-data/advertising.csv&#x27;</span>)</span><br><span class="line">df_ads.head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = np.array(df_ads) <span class="comment"># 构建特征集，含全部特征</span></span><br><span class="line">X = np.delete(X, [<span class="number">3</span>], axis = <span class="number">1</span>) <span class="comment"># 删除掉标签</span></span><br><span class="line">y = np.array(df_ads.sales) <span class="comment">#构建标签集，销售金额</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的阶:&quot;</span>,X.ndim)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的形状:&quot;</span>, X.shape)</span><br><span class="line"><span class="built_in">print</span> (X)</span><br></pre></td></tr></table></figure><p>需要x和y都为2D向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y = y.reshape(-<span class="number">1</span>,<span class="number">1</span>) <span class="comment">#通过reshape函数把向量转换为矩阵，-1就是len(y),返回样本个数</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量y的形状:&quot;</span>, y.shape)</span><br></pre></td></tr></table></figure><h2 id="将数据集进行80-（训练集）和20-（验证集）的分割">将数据集进行80%（训练集）和20%（验证集）的分割</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将数据集进行80%（训练集）和20%（验证集）的分割</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, </span><br><span class="line">                                   test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="定义归一化函数-，进行数据-压缩">定义归一化函数 ，进行数据 ==压缩==</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaler</span>(<span class="params">train, test</span>): <span class="comment"># 定义归一化函数 ，进行数据压缩    </span></span><br><span class="line">    <span class="comment"># 数据的压缩</span></span><br><span class="line">    <span class="built_in">min</span> = train.<span class="built_in">min</span>(axis=<span class="number">0</span>) <span class="comment"># 训练集最小值</span></span><br><span class="line">    <span class="built_in">max</span> = train.<span class="built_in">max</span>(axis=<span class="number">0</span>) <span class="comment"># 训练集最大值</span></span><br><span class="line">    gap = <span class="built_in">max</span> - <span class="built_in">min</span> <span class="comment"># 最大值和最小值的差</span></span><br><span class="line">    train -= <span class="built_in">min</span> <span class="comment"># 所有数据减最小值</span></span><br><span class="line">    train /= gap <span class="comment"># 所有数据除以大小值差</span></span><br><span class="line">    test -= <span class="built_in">min</span> <span class="comment">#把训练集最小值应用于测试集</span></span><br><span class="line">    test /= gap <span class="comment">#把训练集大小值差应用于测试集</span></span><br><span class="line">    <span class="keyword">return</span> train, test <span class="comment"># 返回压缩后的数据</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">min_max_gap</span>(<span class="params">train</span>): <span class="comment"># 计算训练集最大，最小值以及他们的差，用于后面反归一化过程</span></span><br><span class="line">    <span class="built_in">min</span> = train.<span class="built_in">min</span>(axis=<span class="number">0</span>) <span class="comment"># 训练集最小值</span></span><br><span class="line">    <span class="built_in">max</span> = train.<span class="built_in">max</span>(axis=<span class="number">0</span>) <span class="comment"># 训练集最大值</span></span><br><span class="line">    gap = <span class="built_in">max</span> - <span class="built_in">min</span> <span class="comment"># 最大值和最小值的差</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">min</span>, <span class="built_in">max</span>, gap</span><br><span class="line">    </span><br><span class="line">y_min, y_max, y_gap = min_max_gap(y_train)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_original = X_train.copy() <span class="comment"># 保留一份训练集数据副本，用于对要预测数据归一化</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test = scaler(X_train,X_test) <span class="comment"># 对特征归一化</span></span><br><span class="line">y_train,y_test = scaler(y_train,y_test) <span class="comment"># 对标签也归一化</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x0_train = np.ones((<span class="built_in">len</span>(X_train),<span class="number">1</span>)) <span class="comment"># 构造X_train长度的全1数组配合对Bias的点积</span></span><br><span class="line">X_train = np.append(x0_train, X_train, axis=<span class="number">1</span>) <span class="comment">#把X增加一系列的1</span></span><br><span class="line">x0_test = np.ones((<span class="built_in">len</span>(X_test),<span class="number">1</span>)) <span class="comment"># 构造X_test长度的全1数组配合对Bias的点积</span></span><br><span class="line">X_test = np.append(x0_test, X_test, axis=<span class="number">1</span>) <span class="comment">#把X增加一系列的1</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的形状:&quot;</span>, X_train.shape)</span><br><span class="line"><span class="built_in">print</span> (X_train)</span><br></pre></td></tr></table></figure><h2 id="通过向量化来实现损失函数">通过向量化来实现损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">X, y, W</span>): <span class="comment"># 手工定义一个MSE均方误差函数,W此时是一个向量</span></span><br><span class="line">    y_hat = X.dot(W.T) <span class="comment"># 点积运算 h(x)=w_0*x_0 + w_1*x_1 + w_2*x_2 + w_3*x_3    </span></span><br><span class="line">    loss = y_hat.reshape((<span class="built_in">len</span>(y_hat),<span class="number">1</span>))-y <span class="comment"># 中间过程,求出当前W和真值的差异</span></span><br><span class="line">    cost = np.<span class="built_in">sum</span>(loss**<span class="number">2</span>)/(<span class="number">2</span>*<span class="built_in">len</span>(X)) <span class="comment"># 这是平方求和过程, 均方误差函数的代码实现</span></span><br><span class="line">    <span class="keyword">return</span> cost <span class="comment"># 返回当前模型的均方误差值</span></span><br></pre></td></tr></table></figure><p>$$<br>w=w-\frac{\alpha}{2N}\sum_{i=1}<sup>N(y</sup>{(i)}-(w\bullet x^{(i)}))\bullet x^{(i)}<br>$$</p><h2 id="封装进一个梯度下降函数：">封装进一个梯度下降函数：</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">X, y, W, lr, iterations</span>): <span class="comment"># 定义梯度下降函数</span></span><br><span class="line">    l_history = np.zeros(iterations) <span class="comment"># 初始化记录梯度下降过程中损失的数组</span></span><br><span class="line">    W_history = np.zeros((iterations,<span class="built_in">len</span>(W))) <span class="comment"># 初始化权重数组 </span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(iterations): <span class="comment"># 进行梯度下降的迭代，就是下多少级台阶</span></span><br><span class="line">        y_hat = X.dot(W.T) <span class="comment"># 这个是向量化运行实现的假设函数   </span></span><br><span class="line">        loss = y_hat.reshape((<span class="built_in">len</span>(y_hat),<span class="number">1</span>))-y <span class="comment"># 中间过程, y_hat和y真值的差</span></span><br><span class="line">        derivative_W = X.T.dot(loss)/<span class="built_in">len</span>(X) <span class="comment">#求出多项式的梯度向量</span></span><br><span class="line">        derivative_W = derivative_W.reshape(<span class="built_in">len</span>(W)) </span><br><span class="line">        W = W - lr*derivative_W <span class="comment"># 结合下降速率更新权重</span></span><br><span class="line">        l_history[<span class="built_in">iter</span>] = loss_function(X, y, W) <span class="comment"># 损失的历史记录 </span></span><br><span class="line">        W_history[<span class="built_in">iter</span>] = W <span class="comment"># 梯度下降过程中权重的历史记录</span></span><br><span class="line">    <span class="keyword">return</span> l_history, W_history <span class="comment"># 返回梯度下降过程数据</span></span><br></pre></td></tr></table></figure><h2 id="初始化权重并训练机器">初始化权重并训练机器</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先确定参数的初始值</span></span><br><span class="line">iterations = <span class="number">300</span>; <span class="comment"># 迭代300次</span></span><br><span class="line">alpha = <span class="number">0.15</span>; <span class="comment">#学习速率设为0.15</span></span><br><span class="line">weight = np.array([<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]) <span class="comment"># 权重向量，w[0] = bias</span></span><br><span class="line"><span class="comment">#计算一下初始值的损失</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;当前损失：&#x27;</span>,loss_function(X_train, y_train, weight))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当前损失： 0.8039183733604858</span><br></pre></td></tr></table></figure><h2 id="构建线性回归模型">构建线性回归模型</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义线性回归模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear_regression</span>(<span class="params">X, y, weight, alpha, iterations</span>): </span><br><span class="line">    loss_history, weight_history = gradient_descent(X, y, </span><br><span class="line">                                                    weight, </span><br><span class="line">                                                    alpha, iterations)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练最终损失:&quot;</span>, loss_history[-<span class="number">1</span>]) <span class="comment"># 打印最终损失</span></span><br><span class="line">    y_pred = X.dot(weight_history[-<span class="number">1</span>]) <span class="comment"># 进行预测</span></span><br><span class="line">    traning_acc = <span class="number">100</span> - np.mean(np.<span class="built_in">abs</span>(y_pred - y))*<span class="number">100</span> <span class="comment"># 计算准确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;线性回归训练准确率: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(traning_acc))  <span class="comment"># 打印准确率</span></span><br><span class="line">    <span class="keyword">return</span> loss_history, weight_history <span class="comment"># 返回训练历史记录</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用刚才定义的线性回归模型</span></span><br><span class="line">loss_history, weight_history = linear_regression(X_train, y_train,</span><br><span class="line">                           weight, alpha, iterations) <span class="comment">#训练机器</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">训练最终损失: 0.002506723466186024</span><br><span class="line">线性回归训练准确率: 75.67%</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;权重历史记录：&quot;</span>, weight_history)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;损失历史记录：&quot;</span>, loss_history)</span><br></pre></td></tr></table></figure><h2 id="预测的数据">预测的数据</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_plan = [<span class="number">250</span>,<span class="number">50</span>,<span class="number">50</span>] <span class="comment"># 要预测的X特征数据</span></span><br><span class="line">X_train,X_plan = scaler(X_train_original,X_plan) <span class="comment"># 对预测数据也要归一化缩放</span></span><br><span class="line">X_plan = np.append([<span class="number">1</span>], X_plan ) <span class="comment"># 加一个哑特征X0 = 1</span></span><br><span class="line">y_plan = np.dot(weight_history[-<span class="number">1</span>],X_plan) <span class="comment"># [-1] 即模型收敛时的权重</span></span><br><span class="line"><span class="comment"># 对预测结果要做反向缩放，才能得到与原始广告费用对应的预测值</span></span><br><span class="line">y_value = y_plan*y_gap + y_min <span class="comment"># y_gap是当前y_train中最大值和最小值的差，y_min是最小值</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;预计商品销售额： &quot;</span>,y_value, <span class="string">&quot;千元&quot;</span>) </span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">预计商品销售额：  [7.42162744] 千元</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–线性回归</h1><p>所谓回归分析（regression analysis），是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，也就是研究当自变量x变化时，因变量y以何种形式在变化。在机器学习领域，回归应用于被预测对象具有连续值特征的情况（如客流量、降雨量、销售量等）。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[线性回归] --&gt; B[1.一个回归问题的定义]</span><br><span class="line">    A --&gt; C[2.数据的收集、分析和预处理]</span><br><span class="line">    A --&gt; D[3.如何建立机器学习模型]</span><br><span class="line">    A --&gt; E[4.如何通过梯度下降找到最优参数]</span><br><span class="line">    A --&gt; F[5.线性回归模型的实践]</span><br><span class="line">    F --&gt; G[5.1一元（单变量）线性回归模型]</span><br><span class="line">    F --&gt; H[5.2多元（多变量）线性回归模型]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在机器学习的线性回归分析中，如果只包括一个自变量（特征x）和一个因变量（标签y），且两者的关系可用一条直线近似表示，这种回归分析就称为==一元线性回归==分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为==多元线性回归==分析。</p><h2 id="举一个栗子">举一个栗子</h2><p>通过机器学习算法，根据过去记录下来的广告投放金额和商品销售额，来预测在未来的某个节点，一个特定的广告投放金额对应能实现的商品销售额。</p><p>（1）明确定义所要解决的问题----网店销售额的预测。</p><p>（2）在数据的收集和预处理环节，分5个小节完成数据的预处理工作，分别如下。</p><p>■将收集到的数据可视化，显示出来看一看。</p><p>■做特征工程，使数据更容易被机器处理。</p><p>■拆分数据集为训练集和测试集。</p><p>■做特征缩放，把数据值压缩到比较小的区间。</p><p>（3）选择机器学习模型的环节，其中有3个主要内容。</p><p>■确定机器学习的算法—这里也就是线性回归算法。</p><p>■确定线性回归算法的==假设函数==。</p><p>■确定线性回归算法的==损失函数==。</p><p>（4）通过==梯度下降==训练机器，确定模型内部参数的过程。</p><p>（5）进行超参数调试和性能优化。</p><h2 id="数据的收集和预处理">数据的收集和预处理</h2><h3 id="收集网店销销售额数据">收集网店销销售额数据</h3><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121912492.png" alt="image-20241212191230354"></p><h3 id="数据可视化">数据可视化</h3><p>上传的数据要读取注意要填写好位置</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121925526.png" alt="image-20241212192531413"></p><h2 id="数据相关分析">数据相关分析</h2><h3 id="导入数据可视化所需要的库">导入数据可视化所需要的库</h3><p>相关分析（correlation analysis）：正值表示正相关，负值表示负相关。数值越大，相关性越强。</p><p>如果a和b的相关性系数是1，则a和b总是相等的。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#Matplotlib – Python画图工具库</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment">#Seaborn – 统计学数据可视化工具库</span></span><br><span class="line"><span class="comment">#对所有的标签和特征两两显示其相关性的热力图(heatmap)</span></span><br><span class="line">sns.heatmap(df_ads.corr(), cmap=<span class="string">&quot;YlGnBu&quot;</span>, annot = <span class="literal">True</span>)</span><br><span class="line">plt.show() <span class="comment">#plt代表英文plot,就是画图的意思</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121929811.png" alt="image-20241212192906724"></p><p>初步分析可得微信公众号里面做广告是最为合理的选择。</p><h3 id="数据的散点图">数据的散点图</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#显示销量和各种广告投放量的散点图</span></span><br><span class="line">sns.pairplot(df_ads, </span><br><span class="line">             x_vars=[<span class="string">&#x27;wechat&#x27;</span>, <span class="string">&#x27;weibo&#x27;</span>, <span class="string">&#x27;others&#x27;</span>], </span><br><span class="line">             y_vars=<span class="string">&#x27;sales&#x27;</span>, </span><br><span class="line">             height=<span class="number">4</span>, aspect=<span class="number">1</span>, kind=<span class="string">&#x27;scatter&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121932191.png" alt="image-20241212193237081"></p><h3 id="数据集清洗和规范化">数据集清洗和规范化</h3><p>在本案例的3个特征中，微信广告投放金额和商品销售额的相关性比较高。</p><p>为了简化模型，我们只留下微信广告投放金额数据。这样，就把多变量的回归分析简化为==单变量的回归==分析。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = np.array(df_ads.wechat) <span class="comment">#构建特征集，只含有微信广告一个特征</span></span><br><span class="line">y = np.array(df_ads.sales) <span class="comment">#构建标签集，销售金额</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的阶:&quot;</span>,X.ndim)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的形状:&quot;</span>, X.shape)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的内容:&quot;</span>, X)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121935089.png" alt="image-20241212193538001"></p><p>目前X数组中只有一个特征，张量的阶为1，这个1D的特征张量不是机器学习算法能够接受的格式</p><p>对于回归问题的数值类型数据集，机器学习模型所读入的规范格式应该是2D张量，也就是矩阵，其形状为 （样本数，标签数）。</p><p>那么就现在的特征张量X而言，则是要把它的形状从（200，）变成（200，1），然后再进行机器学习。</p><p>因此需要用reshape方法给上面的张量变形：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = X.reshape((<span class="built_in">len</span>(X),<span class="number">1</span>)) <span class="comment">#通过reshape函数把向量转换为矩阵，len函数返回样本个数</span></span><br><span class="line">y = y.reshape((<span class="built_in">len</span>(y),<span class="number">1</span>)) <span class="comment">#通过reshape函数把向量转换为矩阵，len函数返回样本个数</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的阶:&quot;</span>,X.ndim)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的形状:&quot;</span>, X.shape)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;张量X的内容:&quot;</span>, X)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412121940146.png" alt="image-20241212194037090"></p><p> </p><h3 id="拆分为训练集和测试集">拆分为训练集和测试集</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将数据集进行80%(训练集)和20%(测试集)的分割</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, </span><br><span class="line">                                   test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>Sklearn中的<code>train_test_split</code>函数，是机器学习中拆分数据集的常用工具。</p><p>test_size=0.2，表示拆分出来的测试集占总样本量的20%。</p><p>如果用print语句输出拆分之后的新数据集（如X_train、X_test）的内容，会发现这个工具已经为数据集进行了乱序（重新随机排序）的工作，因为其中的shuffle参数默认值为True。</p><p>而其中的<code>random_state</code>参数，则用于数据集拆分过程的随机化设</p><p>定。如果指定了一个整数，那么这个数叫作随机化种子，每次设定固定</p><p>的种子能够保证得到同样的训练集和测试集，否则进行随机分割。</p><p> </p><h3 id="数据归一化">数据归一化</h3><p>归一化是按比例的线性缩放。==数据分布不变==，但是都落入一个小的特定区间，比如0～1或者-1～+1。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161608751.png" alt="image-20250216160806652"><br>$$<br>x^{\prime}=\frac{x-\min(x)}{\max(x)-\min(x)}<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">scaler</span>(<span class="params">train, test</span>): <span class="comment">#定义归一化函数，进行数据压缩    </span></span><br><span class="line">    <span class="built_in">min</span> = train.<span class="built_in">min</span>(axis=<span class="number">0</span>) <span class="comment">#训练集最小值</span></span><br><span class="line">    <span class="built_in">max</span> = train.<span class="built_in">max</span>(axis=<span class="number">0</span>) <span class="comment">#训练集最大值</span></span><br><span class="line">    gap = <span class="built_in">max</span> - <span class="built_in">min</span> <span class="comment">#最大值和最小值的差</span></span><br><span class="line">    train -= <span class="built_in">min</span> <span class="comment">#所有数据减最小值</span></span><br><span class="line">    train /= gap <span class="comment">#所有数据除以大小值差</span></span><br><span class="line">    test -= <span class="built_in">min</span> <span class="comment">#把训练集最小值应用于测试集</span></span><br><span class="line">    test /= gap <span class="comment">#把训练集大小值差应用于测试集</span></span><br><span class="line">    <span class="keyword">return</span> train, test <span class="comment">#返回压缩后的数据</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train,X_test = scaler(X_train,X_test) <span class="comment">#对特征归一化</span></span><br><span class="line">y_train,y_test = scaler(y_train,y_test) <span class="comment">#对标签也归一化</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#用之前已经导入的matplotlib.pyplot中的plot方法显示散点图</span></span><br><span class="line">plt.plot(X_train,y_train,<span class="string">&#x27;r.&#x27;</span>, label=<span class="string">&#x27;Training data&#x27;</span>) </span><br><span class="line">plt.xlabel(<span class="string">&#x27;Wechat Ads&#x27;</span>) <span class="comment"># x轴Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sales&#x27;</span>) <span class="comment"># y轴Label</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图例</span></span><br><span class="line">plt.show() <span class="comment"># 显示绘图结果</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161620655.png" alt="image-20250216162005545"></p><h2 id="选择机器学习模型">选择机器学习模型</h2><p>图中的一元线性特征很明显，所以用一元线性函数就可以进行拟合。</p><p>如果模型的预测完全准确，则损失（loss）为0；如果不准确，就有损失。</p><p>根据loss创建的函数也叫损失函数。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161624200.png" alt="image-20250216162433097"></p><p>在回归中，损失函数经常是：均方误差，平均绝对误差，平均偏差误差等</p><p>在分类中，损失函数经常是：交叉熵损失，多分类SVM损失，等</p><p>在这个工程中，我们用MES函数，即<code>最小二乘法</code><br>$$<br>L(w,b)=MSE=\frac{1}{2N}\sum_{(x,y)\in D}(y-h(x))^2<br>$$</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss_function</span>(<span class="params">X, y, weight, bias</span>): <span class="comment"># 手工定义一个MSE均方误差函数</span></span><br><span class="line">    y_hat = weight*X + bias <span class="comment"># 这是假设函数,其中已经应用了Python的广播功能</span></span><br><span class="line">    loss = y_hat-y  <span class="comment"># 求出每一个y’和训练集中真实的y之间的差异 </span></span><br><span class="line">    cost = np.<span class="built_in">sum</span>(loss**<span class="number">2</span>)/(<span class="number">2</span>*<span class="built_in">len</span>(X)) <span class="comment"># 这是均方误差函数的代码实现</span></span><br><span class="line">    <span class="keyword">return</span> cost <span class="comment"># 返回当前模型的均方误差值</span></span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&quot;当权重5，偏置3时，损失为：&quot;</span>, </span><br><span class="line">loss_function(X_train, y_train, weight=<span class="number">5</span>, bias=<span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;当权重100，偏置1时，损失为：&quot;</span>, </span><br><span class="line">loss_function(X_train, y_train, weight=<span class="number">100</span>, bias=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">当权重5，偏置3时，损失为： 12.79639097078006</span><br><span class="line">当权重100，偏置1时，损失为： 1577.9592615030556</span><br></pre></td></tr></table></figure><p> </p><h2 id="通过梯度下降找最佳参数">通过梯度下降找最佳参数</h2><p>$$<br>\text{梯度}=\frac{\partial}{\partial w}L(w)=\frac{\partial}{\partial w}\frac{1}{2N}\sum_{(x,y)\in D}(y-h(x))^2=\frac{1}{2N}\sum_{(x,y)\in D}(y-(w\bullet x))\bullet x<br>$$</p><p>即对权重求偏导</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161638711.png" alt="image-20250216163842571"></p><h2 id="学习速率">学习速率</h2><p>w随梯度下降的更新如下<br>$$<br>w=w-\alpha\cdot\frac{\partial}{\partial w}L(w)<br>$$<br><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161651983.png" alt="image-20250216165114834"></p><p>在机器学习刚刚开始的时候，学习速率设置得大一些，当接近最佳权重时，减小学习速率。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">X, y, w, b, lr, <span class="built_in">iter</span></span>): <span class="comment"># 定义一个实现梯度下降的函数</span></span><br><span class="line">    l_history = np.zeros(<span class="built_in">iter</span>) <span class="comment"># 初始化记录梯度下降过程中损失的数组</span></span><br><span class="line">    w_history = np.zeros(<span class="built_in">iter</span>) <span class="comment"># 初始化记录梯度下降过程中权重的数组</span></span><br><span class="line">    b_history = np.zeros(<span class="built_in">iter</span>) <span class="comment"># 初始化记录梯度下降过程中偏置的数组</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">iter</span>): <span class="comment"># 进行梯度下降的迭代，就是下多少级台阶</span></span><br><span class="line">        y_hat  = w*X + b <span class="comment"># 这个是向量化运行实现的假设函数</span></span><br><span class="line">        loss = y_hat-y <span class="comment"># 这是中间过程,求得的是假设函数预测的y和真正的y值间的差值</span></span><br><span class="line">        derivative_w = X.T.dot(loss)/<span class="built_in">len</span>(X) <span class="comment"># 对权重求导, len(X)是样本总数</span></span><br><span class="line">        derivative_b = <span class="built_in">sum</span>(loss)*<span class="number">1</span>/<span class="built_in">len</span>(X) <span class="comment"># 对偏置求导</span></span><br><span class="line">        w = w - lr*derivative_w <span class="comment"># 结合下降速率alpha更新权重</span></span><br><span class="line">        b = b - lr*derivative_b <span class="comment"># 结合下降速率alpha更新偏置</span></span><br><span class="line">        l_history[i] = loss_function(X, y, w,b) <span class="comment"># 梯度下降过程中损失的历史</span></span><br><span class="line">        w_history[i] = w <span class="comment"># 梯度下降过程中权重的历史</span></span><br><span class="line">        b_history[i] = b <span class="comment"># 梯度下降过程中偏置的历史</span></span><br><span class="line">    <span class="keyword">return</span> l_history, w_history, b_history <span class="comment"># 返回梯度下降过程数据</span></span><br></pre></td></tr></table></figure><h2 id="实现一元线性回归模型并调试参数">实现一元线性回归模型并调试参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先确定参数的初始值</span></span><br><span class="line">iterations = <span class="number">100</span>; <span class="comment"># 迭代100次</span></span><br><span class="line">alpha = <span class="number">0.5</span>; <span class="comment"># 此处初始学习速率设为0.5， 如果调整为1，你会看到不同的结果</span></span><br><span class="line">weight = -<span class="number">5</span> <span class="comment"># 权重</span></span><br><span class="line">bias = <span class="number">3</span> <span class="comment"># 偏置</span></span><br><span class="line"><span class="comment"># 计算一下初始权重和偏置值所带来的损失</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;当前损失：&#x27;</span>,loss_function(X_train, y_train, weight, bias))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">当前损失： 1.343795534906634</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制当前的函数模型</span></span><br><span class="line">plt.plot(X_train, y_train,<span class="string">&#x27;r.&#x27;</span>, label=<span class="string">&#x27;Training data&#x27;</span>) <span class="comment"># 显示训练集散点图</span></span><br><span class="line">line_X = np.linspace(X_train.<span class="built_in">min</span>(), X_train.<span class="built_in">max</span>(), <span class="number">500</span>) <span class="comment"># X值域</span></span><br><span class="line">line_y = [weight*xx + bias <span class="keyword">for</span> xx <span class="keyword">in</span> line_X] <span class="comment"># 假设函数y_hat</span></span><br><span class="line">plt.plot(line_X,line_y,<span class="string">&#x27;b--&#x27;</span>, label=<span class="string">&#x27;Current hypothesis&#x27;</span> ) <span class="comment">#显示当前拟合</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Wechat Ads&#x27;</span>) <span class="comment"># X轴Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sales&#x27;</span>) <span class="comment"># y轴Label</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图例</span></span><br><span class="line">plt.show() <span class="comment"># 显示绘图</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161655028.png" alt="image-20250216165535900"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据初始参数值，进行梯度下降，也就是开始训练机器，拟合函数</span></span><br><span class="line">loss_history, weight_history, bias_history = gradient_descent(</span><br><span class="line">             X_train, y_train, weight, bias, alpha, iterations)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(loss_history,<span class="string">&#x27;g--&#x27;</span>,label=<span class="string">&#x27;Loss Curve&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Iterations&#x27;</span>) <span class="comment"># x轴Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>) <span class="comment"># y轴Label</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图例</span></span><br><span class="line">plt.show() <span class="comment"># 显示损失曲线</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161708590.png" alt="image-20250216170850465"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制当前的函数模型</span></span><br><span class="line">plt.plot(X_train, y_train,<span class="string">&#x27;r.&#x27;</span>, label=<span class="string">&#x27;Training data&#x27;</span>) <span class="comment"># 显示训练集散点图</span></span><br><span class="line">line_X = np.linspace(X_train.<span class="built_in">min</span>(), X_train.<span class="built_in">max</span>(), <span class="number">500</span>) <span class="comment"># X值域</span></span><br><span class="line"><span class="comment"># 关于weight_history[-1],这里的索引[-1]，就代表迭代500次后的最后一个W值</span></span><br><span class="line">line_y = [weight_history[-<span class="number">1</span>]*xx + bias_history[-<span class="number">1</span>] <span class="keyword">for</span> xx <span class="keyword">in</span> line_X] <span class="comment"># 假设函数</span></span><br><span class="line">plt.plot(line_X,line_y,<span class="string">&#x27;b--&#x27;</span>, label=<span class="string">&#x27;Current hypothesis&#x27;</span> ) <span class="comment"># 显示当前函数</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Wechat Ads&#x27;</span>) <span class="comment"># x轴Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Sales&#x27;</span>) <span class="comment"># y轴Label</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图例</span></span><br><span class="line">plt.show() <span class="comment"># 显示函数图像</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161709943.png" alt="image-20250216170912820"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;当前损失：&#x27;</span>,loss_function(X_train, y_train, </span><br><span class="line">                  weight_history[-<span class="number">1</span>], bias_history[-<span class="number">1</span>]))</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;当前权重：&#x27;</span>,weight_history[-<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;当前偏置：&#x27;</span>,bias_history[-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">当前损失： 0.006157577974318896</span><br><span class="line">当前权重： 0.4721302015868674</span><br><span class="line">当前偏置： 0.2707186935933173</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;测试集损失：&#x27;</span>,loss_function(X_test, y_test, </span><br><span class="line">                    weight_history[-<span class="number">1</span>], bias_history[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">测试集损失： 0.007776406285658269</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 同时绘制训练集和测试集损失曲线</span></span><br><span class="line">loss_test ,a , b = gradient_descent(X_test, y_test, weight, bias, alpha, iterations)</span><br><span class="line">plt.plot(loss_history,<span class="string">&#x27;g--&#x27;</span>,label=<span class="string">&#x27;Traning Loss Curve&#x27;</span>)</span><br><span class="line">plt.plot(loss_test,<span class="string">&#x27;r&#x27;</span>,label=<span class="string">&#x27;Test Loss Curve&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Iterations&#x27;</span>) <span class="comment"># x轴Label</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>) <span class="comment"># y轴Label</span></span><br><span class="line">plt.legend() <span class="comment"># 显示图例</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161729408.png" alt="image-20250216172954272"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设计Contour Plot动画</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.animation <span class="keyword">as</span> animation</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化参数网格</span></span><br><span class="line">theta0_vals = np.linspace(-<span class="number">2</span>, <span class="number">3</span>, <span class="number">100</span>)  <span class="comment"># bias 范围</span></span><br><span class="line">theta1_vals = np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>)  <span class="comment"># weight 范围</span></span><br><span class="line">J_vals = np.zeros((theta0_vals.size, theta1_vals.size))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失函数网格</span></span><br><span class="line"><span class="keyword">for</span> t1, bias <span class="keyword">in</span> <span class="built_in">enumerate</span>(theta0_vals):</span><br><span class="line">    <span class="keyword">for</span> t2, weight <span class="keyword">in</span> <span class="built_in">enumerate</span>(theta1_vals):</span><br><span class="line">        J_vals[t1, t2] = loss_function(X_train, y_train, weight, bias)</span><br><span class="line"></span><br><span class="line">J_vals = J_vals.T</span><br><span class="line">A, B = np.meshgrid(theta0_vals, theta1_vals)</span><br><span class="line">C = J_vals</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建画布</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左图：数据拟合过程</span></span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.plot(X_train, y_train, <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&#x27;Training data&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;Sales Prediction&#x27;</span>)</span><br><span class="line">ax1.set_xlim(X_train.<span class="built_in">min</span>()-X_train.std(), X_train.<span class="built_in">max</span>()+X_train.std())</span><br><span class="line">ax1.set_ylim(y_train.<span class="built_in">min</span>()-y_train.std(), y_train.<span class="built_in">max</span>()+y_train.std())</span><br><span class="line">ax1.grid(axis=<span class="string">&#x27;both&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&quot;WeChat Ads Volumn (X1)&quot;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&quot;Sales Volumn (Y)&quot;</span>)</span><br><span class="line">ax1.legend(loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">line, = ax1.plot([], [], <span class="string">&#x27;b-&#x27;</span>, label=<span class="string">&#x27;Current Hypothesis&#x27;</span>)</span><br><span class="line">annotation = ax1.text(-<span class="number">2</span>, <span class="number">3</span>, <span class="string">&#x27;&#x27;</span>, fontsize=<span class="number">12</span>, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line">annotation.set_animated(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图：损失函数等高线</span></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">cp = ax2.contourf(A, B, C, levels=<span class="number">20</span>, cmap=<span class="string">&#x27;viridis&#x27;</span>)</span><br><span class="line">plt.colorbar(cp, ax=ax2)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Loss Function Contour&#x27;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;Bias (θ₀)&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;Weight (θ₁)&#x27;</span>)</span><br><span class="line">track, = ax2.plot([], [], <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">1</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">point, = ax2.plot([], [], <span class="string">&#x27;ro&#x27;</span>, markersize=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动画初始化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">    line.set_data([], [])</span><br><span class="line">    track.set_data([], [])</span><br><span class="line">    point.set_data([], [])</span><br><span class="line">    annotation.set_text(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> line, track, point, annotation</span><br><span class="line"></span><br><span class="line"><span class="comment"># 动画更新函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">animate</span>(<span class="params">i</span>):</span><br><span class="line">    <span class="comment"># 更新拟合直线</span></span><br><span class="line">    fit1_X = np.linspace(X_train.<span class="built_in">min</span>()-X_train.std(), X_train.<span class="built_in">max</span>()+X_train.std(), <span class="number">1000</span>)</span><br><span class="line">    fit1_y = bias_history[i] + weight_history[i] * fit1_X</span><br><span class="line">    line.set_data(fit1_X, fit1_y)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新参数轨迹</span></span><br><span class="line">    track.set_data(bias_history[:i], weight_history[:i])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新当前参数点</span></span><br><span class="line">    point.set_data([bias_history[i]], [weight_history[i]])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 更新损失值显示</span></span><br><span class="line">    annotation.set_text(<span class="string">f&#x27;Iter: <span class="subst">&#123;i&#125;</span>\nCost = <span class="subst">&#123;loss_history[i]:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> line, track, point, annotation</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成动画</span></span><br><span class="line">anim = animation.FuncAnimation(</span><br><span class="line">    fig, animate, init_func=init,</span><br><span class="line">    frames=<span class="built_in">len</span>(weight_history),  <span class="comment"># 确保与训练步数一致</span></span><br><span class="line">    interval=<span class="number">50</span>, blit=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存动画</span></span><br><span class="line">anim.save(<span class="string">&#x27;linear_regression_training.gif&#x27;</span>, writer=<span class="string">&#x27;pillow&#x27;</span>, fps=<span class="number">15</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161754364.png" alt="image-20250216175424234"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示Contour Plot动画</span></span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> HTML</span><br><span class="line"></span><br><span class="line">filename = <span class="string">&#x27;linear_regression_training.gif&#x27;</span></span><br><span class="line"></span><br><span class="line">video = io.<span class="built_in">open</span>(filename, <span class="string">&#x27;r+b&#x27;</span>).read()</span><br><span class="line">encoded = base64.b64encode(video)</span><br><span class="line">HTML(data=<span class="string">&#x27;&#x27;&#x27;&lt;img src=&quot;data:image/gif;base64,&#123;0&#125;&quot; type=&quot;gif&quot; /&gt;&#x27;&#x27;&#x27;</span>.<span class="built_in">format</span>(encoded.decode(<span class="string">&#x27;ascii&#x27;</span>)))</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202502161815543.gif" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–张量</h1><h2 id="机器学习的数据结构–张量">机器学习的数据结构–张量</h2><p>张量是机器学习程序中的数字容器，本质上就是各种不同维度的数组，如下图所示。</p><p>张量的维度称为轴（axis），轴的个数称为阶（rank）</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101117917.png" alt="image-20241210111724714"></p><h3 id="标量–0D张量">标量–0D张量</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment">#导入NumPy</span></span><br><span class="line">X = np.array(<span class="number">5</span>) <span class="comment"># 创建0D张量，也就是标量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的值&quot;</span>,X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的阶&quot;</span>,X.ndim) <span class="comment">#ndim属性显示张量轴的个数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的数据类型&quot;</span>,X.dtype) <span class="comment"># dtype属性显示张量数据类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的形状&quot;</span>,X.shape) <span class="comment"># shape属性显示张量形状</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101121690.png" alt="image-20241210112116640"></p><h3 id="向量–1D张量">向量–1D张量</h3><p>由一组数字组成的数组叫作向量（vector），也就是一阶张量</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = np.array([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]) <span class="comment">#创建1D张量，也就是向量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的值&quot;</span>,X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的阶&quot;</span>,X.ndim) <span class="comment">#ndim属性显示张量轴的个数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;X的形状&quot;</span>,X.shape) <span class="comment"># shape属性显示张量形状</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101123728.png" alt="image-20241210112310680"></p><p>（5，）表示一个1D张量，元素数量是5，也就是5维向量。</p><h3 id="矩阵–2D张量">矩阵–2D张量</h3><p>矩阵是2D张量，形状为 （==样本，特征==）。第一个轴是样本轴，第二个轴是特征轴。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101125432.png" alt="image-20241210112508372"></p><h3 id="序列数据–3D张量">序列数据–3D张量</h3><p>时序数据集的形状为3D张量：（样本，时戳，标签）</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101144350.png" alt="image-20241210114413291"></p><h3 id="图像数据–4D张量">图像数据–4D张量</h3><p>图像数据集其形状为（样本，图像高，图像宽度，颜色深度），如MNIST特征数据集的形状为 （60000，28，28，1）。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101146418.png" alt="image-20241210114633354"></p><p>比如指定批量大小为64。此时每批的100px×100px的彩色图像张量形状为（64， 100，100，3），如果是灰度图像，则为（64，100，100，1）</p><h3 id="视频数据–5D张量">视频数据–5D张量</h3><p>其形状为（样本，帧，高度，宽度，颜色深度）</p><h2 id="张量的创建和访问">张量的创建和访问</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">array_04=np.arange(<span class="number">1</span>,<span class="number">5</span>,<span class="number">1</span>) <span class="comment"># 通过arange函数生成数组</span></span><br><span class="line">array_05=np.linspace(<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>) <span class="comment"># 通过linspace函数生成数组</span></span><br><span class="line"><span class="built_in">print</span> (array_04)</span><br><span class="line"><span class="built_in">print</span> (array_05)</span><br></pre></td></tr></table></figure><p>arange（a，b，c）函数产生a～b（不包括b），间隔为c；</p><p>linspace（a，b， c）函数是把a～b（包括b），平均分成c份。</p><p> </p><p>索引（indexing）和切片（slicing）这两种方式访问张量</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">array_06 = np.arange(<span class="number">10</span>)</span><br><span class="line"><span class="built_in">print</span> (array_06)</span><br><span class="line">index_01 = array_06[<span class="number">3</span>] <span class="comment"># 索引-第4个元素</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;第4个元素&#x27;</span>, index_01)</span><br><span class="line">index_02 = array_06[-<span class="number">1</span>] <span class="comment"># 索引-最后一个元素</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;第-1个元素&#x27;</span>, index_02)</span><br><span class="line">slice_01 = array_06[:<span class="number">4</span>] <span class="comment"># 从0到4切片</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;从0到4切片&#x27;</span>, slice_01)</span><br><span class="line">slice_02 = array_06[<span class="number">0</span>:<span class="number">12</span>:<span class="number">4</span>] <span class="comment"># 从0到12切片，步长为2</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;从0到12切片，步长为4&#x27;</span>, slice_02)</span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412101154128.png" alt="image-20241210115431061"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–Kaggle的使用</h1><p>打开<a href="https://www.kaggle.com/">Kaggle: Your Machine Learning and Data Science Community</a>并点击<code>Sign In</code>登录账号</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091625587.png" alt="image-20241209162509517"></p><p>kaggle中自带了很多的数据集</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091629831.png" alt="image-20241209162947772"></p><p>在点击<code>Datasets</code>之后，单点<code>Notebook</code>，如果有适用的数据集可以单击<code>Copy and Edit</code>复制其<code>Notebook</code>，之后我们自己进行慢慢研习。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091627358.png" alt="image-20241209162749300"></p><p>点击<code>File</code>，<code>Upload input</code>，<code>Upload dataset</code>后即可把我们现有的文档进行上传。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091716295.png" alt="image-20241209171618199"></p><p>来举一个手写数字识别的栗子：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># 导入NumPy数学工具箱</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># 导入Pandas数据处理工具箱</span></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist <span class="comment">#从Keras中导入mnist数据集</span></span><br><span class="line"><span class="comment">#读入训练集和测试集</span></span><br><span class="line">(X_train_image, y_train_lable), (X_test_image, y_test_lable) =  mnist.load_data() </span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&quot;特征集张量形状：&quot;</span>, X_train_image.shape) <span class="comment">#用shape方法显示张量的形状</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;第一个数据样本：\n&quot;</span>, X_train_image[<span class="number">0</span>]) <span class="comment">#注意Python的索引是从0开始的</span></span><br></pre></td></tr></table></figure><p>结果如下<img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091746769.png" alt="image-20241209174647681"></p><p>shape方法显示X_train_image张量的形状。灰度图像数据集是3D张量，第一个维度是样本维（也就是一张一张的图片，共60 000张），后面两个是特征维（也就是图片的28px×28px的矩阵）</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> (<span class="string">&quot;第一个数据样本的标签：&quot;</span>, y_train_lable[<span class="number">0</span>])</span><br></pre></td></tr></table></figure><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.utils <span class="keyword">import</span> to_categorical <span class="comment"># 导入keras.utils工具箱的类别转换工具</span></span><br><span class="line">X_train = X_train_image.reshape(<span class="number">60000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>) <span class="comment"># 给标签增加一个维度</span></span><br><span class="line">X_test = X_test_image.reshape(<span class="number">10000</span>,<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>) <span class="comment"># 给标签增加一个维度</span></span><br><span class="line">y_train = to_categorical(y_train_lable, <span class="number">10</span>) <span class="comment"># 特征转换为one-hot编码</span></span><br><span class="line">y_test = to_categorical(y_test_lable, <span class="number">10</span>) <span class="comment"># 特征转换为one-hot编码</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;数据集张量形状：&quot;</span>, X_train.shape) <span class="comment"># 特征集张量的形状</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&quot;第一个数据标签：&quot;</span>,y_train[<span class="number">0</span>]) <span class="comment"># 显示标签集的第一个数据</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091750508.png" alt="image-20241209175001439"></p><p>（1）Keras要求图像数据集导入卷积网络模型时为4阶张量，最后一阶代表颜色深度，灰度图像只有一个颜色通道，可以设置其值为1。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models <span class="comment"># 导入Keras模型, 和各种神经网络的层</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten, Conv2D, MaxPooling2D</span><br><span class="line">model = models.Sequential() <span class="comment"># 用序贯方式建立模型</span></span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, <span class="comment"># 添加Conv2D层</span></span><br><span class="line">                 input_shape=(<span class="number">28</span>,<span class="number">28</span>,<span class="number">1</span>))) <span class="comment"># 指定输入数据样本张量的类型</span></span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>))) <span class="comment"># 添加MaxPooling2D层</span></span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加Conv2D层</span></span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>))) <span class="comment"># 添加MaxPooling2D层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>)) <span class="comment"># 添加Dropout层</span></span><br><span class="line">model.add(Flatten()) <span class="comment"># 展平</span></span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)) <span class="comment"># 添加全连接层</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>)) <span class="comment"># 添加Dropout层</span></span><br><span class="line">model.add(Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)) <span class="comment"># Softmax分类激活，输出10维分类码</span></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>, <span class="comment"># 指定优化器</span></span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, <span class="comment"># 指定损失函数</span></span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>]) <span class="comment"># 指定验证过程中的评估指标</span></span><br></pre></td></tr></table></figure><p>这段代码把数据集放入<code>卷积神经网络</code>进行处理。这个网络中包括两个<code>Conv2D</code>（二维卷积）层，两个<code>MaxPooling2D</code>（最大池化）层，两个<code>Dropout</code>层用于防止过拟合，还有<code>Dense</code>（全连接）层，</p><p>最后通过<code>Softmax</code>分类器输出预测标签y’值，也就是所预测的分类值。这个y’值，是一个<code>one-hot</code>（即“一位有效编码”）格式的10维向量。我们可以将y’与标签真值y进行比较，以计算预测的准确率。</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091752647.png" alt="image-20241209175219511"></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.fit(X_train, y_train, <span class="comment"># 指定训练特征集和训练标签集</span></span><br><span class="line">          validation_split = <span class="number">0.3</span>, <span class="comment"># 部分训练集数据拆分成验证集</span></span><br><span class="line">          epochs=<span class="number">5</span>, <span class="comment"># 训练轮次为5轮</span></span><br><span class="line">          batch_size=<span class="number">128</span>) <span class="comment"># 以128为批量进行训练</span></span><br></pre></td></tr></table></figure><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091758140.png" alt="image-20241209175816069"></p><p><code>accuracy</code>：代表训练集上的预测准确率。</p><p><code>val_accuracy</code>：代表验证集上的预测准确率。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">score = model.evaluate(X_test, y_test) <span class="comment"># 在测试集上进行模型评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;测试集预测准确率:&#x27;</span>, score[<span class="number">1</span>]) <span class="comment"># 打印测试集上的预测准确率</span></span><br></pre></td></tr></table></figure><p>K折验证:机器学习中有重用同一个数据集进行多次验证的方法</p><p><img src="https://rozen-picture.oss-cn-beijing.aliyuncs.com/img/202412091801429.png" alt="image-20241209180153328"></p><p>K折验证（K-fold validation）的思路是将数据划分为大小相同的K个分区，对于每个分区，都在剩余的K-1个分区上训练模型，然后在留</p><p>下的分区上评估模型。</p><p>最终分数等于K个分数的平均值。对于数据集的规模比较小或者模型性能很不稳定的情况，这是一种很有用的方法。</p><p>==注意K折验证仍需要预留独立的测试集再次进行模型的校正==</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred = model.predict(X_test[<span class="number">0</span>].reshape(<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)) <span class="comment"># 预测测试集第一个数据</span></span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>],<span class="string">&quot;转换一下格式得到：&quot;</span>,pred.argmax()) <span class="comment"># 把one-hot码转换为数字</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment"># 导入绘图工具包</span></span><br><span class="line">plt.imshow(X_test[<span class="number">0</span>].reshape(<span class="number">28</span>, <span class="number">28</span>),cmap=<span class="string">&#x27;Greys&#x27;</span>) <span class="comment"># 输出这个图片</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>colab使用说明</h1><h2 id="1-上传文件">1.上传文件</h2><p>点击+New按钮可以添加本地的文件和程序（在colab中要读取的数据需要实现上床，这点不如Kaggle有很多可以直接用的数据）</p><img src="https://cdn.jsdelivr.net/gh/Rozen12123/picture_1/Picgo/202412082054270.png" alt="image-20241208205426233" style="zoom:67%;"><img src="https://cdn.jsdelivr.net/gh/Rozen12123/picture_1/Picgo/202412082110066.png" alt="image-20241208211028029" style="zoom:80%;"><h2 id="2-选用高性能计算单元">2.选用高性能计算单元</h2><p><img src="https://cdn.jsdelivr.net/gh/Rozen12123/picture_1/Picgo/202412082124135.png" alt="image-20241208212414077"></p><p><img src="https://cdn.jsdelivr.net/gh/Rozen12123/picture_1/Picgo/202412082125578.png" alt="image-20241208212513538"></p><p>点击右上角可以显示高性能的GPU</p><p><img src="https://cdn.jsdelivr.net/gh/Rozen12123/picture_1/Picgo/202412082126274.png" alt="image-20241208212627228"></p><p>当然，更高性能的计算单元也意味着我们购买的计算单元消耗的速度越快</p><h2 id="3-举一个栗子">3.举一个栗子</h2><p>打开<code>ipynb</code>文件后即可运行代码（以下直接读取github中的开源数据）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment">#导入Pandas，用于数据读取和处理</span></span><br><span class="line"><span class="comment"># 读入房价数据，示例代码中的文件地址为internet链接，读者也可以下载该文件到本机进行读取</span></span><br><span class="line"><span class="comment"># 如，当数据集和代码文件位于相同本地目录，路径名应为&quot;./house.csv&quot;，或直接放&quot;house.csv&quot;亦可</span></span><br><span class="line">df_housing = pd.read_csv(<span class="string">&quot;https://raw.githubusercontent.com/huangjia2019/house/master/house.csv&quot;</span>)</span><br><span class="line">df_housing.head <span class="comment">#显示加州房价数据</span></span><br></pre></td></tr></table></figure><p>把一个网上共享的数据集（csv文件）读入<code>DataFrame</code>数据结构<code>df_housing</code>中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = df_housing.drop(<span class="string">&quot;median_house_value&quot;</span>,axis = <span class="number">1</span>) <span class="comment">#构建特征集X</span></span><br><span class="line">y = df_housing.median_house_value <span class="comment">#构建标签集y</span></span><br></pre></td></tr></table></figure><p><code>drop</code>:把最后一列<code>median_house_value</code>字段去掉，其他所有的字段保存为特征集<code>X</code></p><p>把整个<code>median_house_value</code>字段单独赋值给标签值<code>Y</code></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split <span class="comment">#导入数据集拆分工具</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y,</span><br><span class="line">         test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>) <span class="comment">#以80%/20%的比例进行数据集的拆分</span></span><br></pre></td></tr></table></figure><p>把数据集一分为二，80%用于训练，20%的数据用于测试。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression <span class="comment">#导入线性回归算法模型</span></span><br><span class="line">model = LinearRegression() <span class="comment">#使用线性回归算法</span></span><br><span class="line">model.fit(X_train, y_train) <span class="comment">#用训练集数据，训练机器，拟合函数，确定参数</span></span><br></pre></td></tr></table></figure><p>选定模型，也就是算法，通过其中的<code>fit</code>方法来训练机器，进行函数拟合</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(X_test) <span class="comment">#预测测试集的Y值</span></span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;房价的真值(测试集)&#x27;</span>,y_test)</span><br><span class="line"><span class="built_in">print</span> (<span class="string">&#x27;预测的房价(测试集)&#x27;</span>,y_pred)</span><br></pre></td></tr></table></figure><p>当成功运行完<code>fit</code>方法后，学习到的函数也已经保存在机器中了，可以用<code>model</code>的<code>predict</code>方法对测试集的房价进行预测。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;给预测评分：&quot;</span>, model.score(X_test, y_test)) <span class="comment">#评估预测结果</span></span><br></pre></td></tr></table></figure><p>还可以显示一下预测的大致得分（Sklearn线性回归模型score徐行给出的是R2分数，即预测值的方差何总体方差之间的差异）</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#导入matplotlib画图库</span></span><br><span class="line"><span class="comment">#用散点图显示家庭收入中位数和房价中位数的分布</span></span><br><span class="line">plt.scatter(X_test.median_income, y_test,  color=<span class="string">&#x27;brown&#x27;</span>)</span><br><span class="line"><span class="comment">#画出回归函数(从特征到预测标签)</span></span><br><span class="line">plt.plot(X_test.median_income, y_pred, color=<span class="string">&#x27;green&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Median Income&#x27;</span>) <span class="comment">#X轴-家庭收入中位数</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Median House Value&#x27;</span>) <span class="comment">#Y轴-房价中位数</span></span><br><span class="line">plt.show() <span class="comment">#显示房价分布和机器习得的函数图形</span></span><br></pre></td></tr></table></figure><p>当然也可也用代码绘制出机器学习的函数，由于x的特征太多，我们将与房价关系最大的<code>median_income</code>作为代表特征来显示散点图</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--jupyter notebook的使用</title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>jupyter使用中无法显示中文</h1><p>在jupyter中，通过matplotlib作图时可能会添加中文标题，但有时候会不显示中文</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>, <span class="number">6</span>, <span class="number">0.1</span>) <span class="comment"># 以0.1为单位，成0到6的数据</span></span><br><span class="line">y1 = np.sin(x)</span><br><span class="line">y2 = np.cos(x)</span><br><span class="line"></span><br><span class="line">plt.plot(x, y1, label = <span class="string">&quot;sin&quot;</span>) <span class="comment"># label 为图例</span></span><br><span class="line">plt.plot(x, y2, linestyle = <span class="string">&quot;--&quot;</span>, label = <span class="string">&quot;cos&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;汉字&quot;</span>)</span><br><span class="line">plt.legend() <span class="comment"># 图例显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202403231654472.png" alt="image-20240323165405318"></p><p>在Python脚本中动态设置matplotlibrc,这样可以避免由于更改配置文件而造成的麻烦，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">\<span class="comment"># 设置显示中文字体</span></span><br><span class="line">mpl.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&quot;SimHei&quot;</span>]</span><br></pre></td></tr></table></figure><p>有时候，字体更改后，会导致坐标轴中的部分字符无法正常显示，此时需要更改axes.unicode_minus参数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置正常显示符号</span></span><br><span class="line">mpl.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>即为添加如下代码：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置显示中文字体</span></span><br><span class="line">mpl.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&quot;SimHei&quot;</span>]</span><br><span class="line"><span class="comment"># 设置正常显示符号</span></span><br><span class="line">mpl.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202403231658181.png" alt="image-20240323165843130"></p><p>即可显示中文。</p><h2 id="解决方案二：">解决方案二：</h2><p>下载中文字体（黑体，看准系统版本）</p><ul><li>步骤一：下载 SimHei 字体（或者其他的支持中文显示的字体也行）</li></ul><p>步骤二：安装字体</p><p>linux下：拷贝字体到 usr/share/fonts 下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp ~/SimHei.ttf /usr/share/fonts/SimHei.ttf</span><br></pre></td></tr></table></figure><p>windows和mac下：双击安装</p><p>步骤三：删除~/.matplotlib中的缓存文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.matplotlib</span><br><span class="line">rm -r *</span><br></pre></td></tr></table></figure><p>步骤四：修改配置文件matplotlibrc</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.matplotlib/matplotlibrc</span><br></pre></td></tr></table></figure><p>将文件内容修改为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">font.family : sans-serif</span><br><span class="line">font.sans-serif : SimHei</span><br><span class="line">axes.unicode_minus : False</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--案例：流行电影统计</title>
      <link href="/posts/84343a8a.html"/>
      <url>/posts/84343a8a.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–案例：流行电影统计</h1><p>现在我们有一组从2006年到2016年1000部最流行的电影数据</p><p>数据来源：<a href="https://www.kaggle.com/damianpanek/sunday-eda/data">https://www.kaggle.com/damianpanek/sunday-eda/data</a></p><ul><li>问题1：我们想知道这些电影数据中评分的平均分，导演的人数等信息，我们应该怎么获取？</li><li>问题2：对于这一组电影数据，如果我们想rating，runtime的分布情况，应该如何呈现数据？</li><li>问题3：对于这一组电影数据，如果我们希望统计电影分类(genre)的情况，应该如何处理数据？</li></ul><h2 id="实现">实现</h2><p>首先获取导入包，获取数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#文件的路径</span></span><br><span class="line">path = <span class="string">&quot;./IMDB-Movie-Data.csv&quot;</span></span><br><span class="line"><span class="comment">#读取文件</span></span><br><span class="line">df = pd.read_csv(path)</span><br></pre></td></tr></table></figure><h3 id="问题一：">问题一：</h3><p>我们想知道这些电影数据中评分的平均分，导演的人数等信息，我们应该怎么获取？</p><ul><li>得出评分的平均分</li></ul><p>使用mean函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&quot;Rating&quot;</span>].mean()</span><br></pre></td></tr></table></figure><ul><li>得出导演人数信息</li></ul><p>求出唯一值，然后进行形状获取</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 导演的人数</span></span><br><span class="line"><span class="comment"># df[&quot;Director&quot;].unique().shape[0]</span></span><br><span class="line">np.unique(df[<span class="string">&quot;Director&quot;</span>]).shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><h3 id="问题二：">问题二：</h3><p>对于这一组电影数据，如果我们想<strong>Rating</strong>，**Runtime (Minutes)**的分布情况，应该如何呈现数据？</p><ul><li>直接呈现，以直方图的形式</li></ul><p>选择分数列数据，进行plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&quot;Rating&quot;</span>].plot(kind=<span class="string">&#x27;hist&#x27;</span>,figsize=(<span class="number">20</span>,<span class="number">8</span>))</span><br></pre></td></tr></table></figure><ul><li>Rating进行分布展示</li></ul><p>进行绘制直方图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>),dpi=<span class="number">80</span>)</span><br><span class="line">plt.hist(df[<span class="string">&quot;Rating&quot;</span>].values,bins=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>修改刻度的间隔</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求出最大最小值</span></span><br><span class="line">max_ = df[<span class="string">&quot;Rating&quot;</span>].<span class="built_in">max</span>()</span><br><span class="line">min_ = df[<span class="string">&quot;Rating&quot;</span>].<span class="built_in">min</span>()</span><br><span class="line"><span class="comment"># 生成刻度列表</span></span><br><span class="line">t1 = np.linspace(min_,max_,num=<span class="number">21</span>)</span><br><span class="line"><span class="comment"># [ 1.9 2.255 2.61 2.965 3.32 3.675 4.03 4.385 4.74 5.095 5.45 5.805 6.16 6.515 6.87 7.225 7.58 7.935 8.29 8.645 9.]</span></span><br><span class="line"><span class="comment"># 修改刻度</span></span><br><span class="line">plt.xticks(t1)</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid()</span><br></pre></td></tr></table></figure><ul><li>Runtime (Minutes)进行分布展示</li></ul><p>进行绘制直方图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">20</span>,<span class="number">8</span>),dpi=<span class="number">80</span>)</span><br><span class="line">plt.hist(df[<span class="string">&quot;Runtime (Minutes)&quot;</span>].values,bins=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><ul><li>修改间隔</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求出最大最小值</span></span><br><span class="line">max_ = df[<span class="string">&quot;Runtime (Minutes)&quot;</span>].<span class="built_in">max</span>()</span><br><span class="line">min_ = df[<span class="string">&quot;Runtime (Minutes)&quot;</span>].<span class="built_in">min</span>()</span><br><span class="line"><span class="comment"># # 生成刻度列表</span></span><br><span class="line">t1 = np.linspace(min_,max_,num=<span class="number">21</span>)</span><br><span class="line"><span class="comment"># 修改刻度</span></span><br><span class="line">plt.xticks(np.linspace(min_,max_,num=<span class="number">21</span>))</span><br><span class="line"><span class="comment"># 添加网格</span></span><br><span class="line">plt.grid()</span><br></pre></td></tr></table></figure><h3 id="问题三：对于这一组电影数据，如果我们希望统计电影分类-genre-的情况，应该如何处理数据？">问题三：对于这一组电影数据，如果我们希望统计电影分类**(genre)**的情况，应该如何处理数据？</h3><ul><li>思路<ul><li>1、创建一个全为0的dataframe，列索引置为电影的分类，temp_df</li><li>2、遍历每一部电影，temp_df中把分类出现的列的值置为1</li><li>3、求和</li></ul></li><li>1、创建一个全为0的dataframe，列索引置为电影的分类，temp_df</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进行字符串分割</span></span><br><span class="line">temp_list = [i.split(<span class="string">&quot;,&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> df[<span class="string">&quot;Genre&quot;</span>]]</span><br><span class="line"><span class="comment"># 获取电影的分类</span></span><br><span class="line"></span><br><span class="line">genre_list = np.unique([i <span class="keyword">for</span> j <span class="keyword">in</span> temp_list <span class="keyword">for</span> i <span class="keyword">in</span> j])</span><br><span class="line"><span class="comment"># 增加新的列</span></span><br><span class="line">temp_df = pd.DataFrame(np.zeros([df.shape[<span class="number">0</span>],genre_list.shape[<span class="number">0</span>]]),columns=genre_list)</span><br></pre></td></tr></table></figure><p>2、遍历每一部电影，temp_df中把分类出现的列的值置为1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    temp_df.loc[i,temp_list[i]]=<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(temp_df.<span class="built_in">sum</span>().sort_values())</span><br></pre></td></tr></table></figure><p>3、求和,绘图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">temp_df.<span class="built_in">sum</span>().sort_values(ascending=<span class="literal">False</span>).plot(kind=<span class="string">&quot;bar&quot;</span>,figsize=(<span class="number">20</span>,<span class="number">8</span>),fontsize=<span class="number">20</span>,colormap=<span class="string">&quot;cool&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--pandas</title>
      <link href="/posts/31ce2bbd.html"/>
      <url>/posts/31ce2bbd.html</url>
      
        <content type="html"><![CDATA[<h1>pandas</h1><p>优势：</p><ul><li>增强图表可读性</li><li>便捷的数据处理能力</li><li>读取文件方便</li><li>封装了Matplotlib、Numpy的画图和计算</li></ul><p>更详细的教程：<a href="https://www.runoob.com/pandas/pandas-tutorial.html">Pandas 教程 | 菜鸟教程 (runoob.com)</a></p><h2 id="Pandas数据结构"><strong>Pandas</strong>数据结构</h2><p>Pandas中一共有三种数据结构，分别为：Series、DataFrame和MultiIndex（老版本中叫Panel ）。</p><p>其中Series是一维数据结构，DataFrame是二维的表格型数据结构，MultiIndex是三维的数据结构。</p><h3 id="Series"><strong>Series</strong></h3><p>Series是一个类似于一维数组的数据结构，它能够保存任何类型的数据，比如整数、字符串、浮点数等，主要由一组数据和与之相关的索引两部分构成。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401242106791.png" alt="image-20240124210604659"></p><h3 id="Series的创建"><strong>Series</strong>的创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.Series(data=<span class="literal">None</span>, index=<span class="literal">None</span>, dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>data：传入的数据，可以是ndarray、list等</li><li>index：索引，必须是唯一的，且与数据的长度相等。如果没有传入索引参数，则默认会自动创建一个从0-N的整数索引。</li><li>dtype：数据的类型</li></ul><p>通过已有数据创建</p><ul><li>指定内容，默认索引</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.Series(np.arange(<span class="number">10</span>))</span><br></pre></td></tr></table></figure><ul><li>指定索引</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.Series([<span class="number">6.7</span>,<span class="number">5.6</span>,<span class="number">3</span>,<span class="number">10</span>,<span class="number">2</span>], index=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br></pre></td></tr></table></figure><ul><li>通过字典数据创建</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">color_count = pd.Series(&#123;<span class="string">&#x27;red&#x27;</span>:<span class="number">100</span>, <span class="string">&#x27;blue&#x27;</span>:<span class="number">200</span>, <span class="string">&#x27;green&#x27;</span>: <span class="number">500</span>, <span class="string">&#x27;yellow&#x27;</span>:<span class="number">1000</span>&#125;)</span><br><span class="line">color_count</span><br></pre></td></tr></table></figure><h3 id="Series的属性"><strong>Series</strong>的属性</h3><p><strong>Series</strong>中提供了两个属性<strong>index</strong>和<strong>values</strong></p><ul><li>index</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">color_count.index</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">Index([<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;yellow&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li>values</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">color_count.values</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">array([ <span class="number">200</span>, <span class="number">500</span>, <span class="number">100</span>, <span class="number">1000</span>])</span><br></pre></td></tr></table></figure><p>也可以使用索引来获取数据：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">color_count[<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line"><span class="number">100</span></span><br></pre></td></tr></table></figure><h2 id="DataFrame"><strong>DataFrame</strong></h2><p>DataFrame是一个类似于二维数组或表格(如excel)的对象，既有行索引，又有列索引</p><ul><li><p>行索引，表明不同行，横向索引，叫index，0轴，axis=0</p></li><li><p>列索引，表名不同列，纵向索引，叫columns，1轴，axis=1</p></li></ul><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401242117200.png" alt="image-20240124211733076"></p><h3 id="DataFrame的创建"><strong>DataFrame</strong>的创建</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入pandas</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">pd.DataFrame(data=<span class="literal">None</span>, index=<span class="literal">None</span>, columns=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>参数：</p><p>index：行标签。如果没有传入索引参数，则默认会自动创建一个从0-N的整数索引。</p><p>columns：列标签。如果没有传入索引参数，则默认会自动创建一个从0-N的整数索引。</p><p>通过已有数据创建,举个例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.DataFrame(np.random.randn(<span class="number">2</span>,<span class="number">3</span>))</span><br></pre></td></tr></table></figure><p>例子，创建学生成绩表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成10名同学，5门功课的数据</span></span><br><span class="line">score = np.random.randint(<span class="number">40</span>, <span class="number">100</span>, (<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 使用Pandas中的数据结构</span></span><br><span class="line">score_df = pd.DataFrame(score)</span><br></pre></td></tr></table></figure><ul><li>增加行、列索引</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造行索引序列</span></span><br><span class="line">subjects = [<span class="string">&quot;语文&quot;</span>, <span class="string">&quot;数学&quot;</span>, <span class="string">&quot;英语&quot;</span>, <span class="string">&quot;政治&quot;</span>, <span class="string">&quot;体育&quot;</span>]</span><br><span class="line"><span class="comment"># 构造列索引序列</span></span><br><span class="line">stu = [<span class="string">&#x27;同学&#x27;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(score_df.shape[<span class="number">0</span>])]</span><br><span class="line"><span class="comment"># 添加行索引</span></span><br><span class="line">data = pd.DataFrame(score, columns=subjects, index=stu)</span><br></pre></td></tr></table></figure><h3 id="DataFrame的属性"><strong>DataFrame</strong>的属性</h3><ul><li><p><strong>shape</strong></p></li><li><p><strong>index</strong></p></li><li><p><strong>columns</strong></p></li><li><p><strong>values</strong></p></li><li><p><strong>T</strong></p></li><li><p><strong>shape</strong></p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.shape</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">(<span class="number">10</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>index</strong></li></ul><p>DataFrame的行索引列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.index</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">Index([<span class="string">&#x27;同学0&#x27;</span>, <span class="string">&#x27;同学1&#x27;</span>, <span class="string">&#x27;同学2&#x27;</span>, <span class="string">&#x27;同学3&#x27;</span>, <span class="string">&#x27;同学4&#x27;</span>, <span class="string">&#x27;同学5&#x27;</span>, <span class="string">&#x27;同学6&#x27;</span>, <span class="string">&#x27;同学7&#x27;</span>, <span class="string">&#x27;同学8&#x27;</span>, <span class="string">&#x27;同学9&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>columns</strong></li></ul><p>DataFrame的列索引列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data.columns</span><br><span class="line"><span class="comment"># 结果</span></span><br><span class="line">Index([<span class="string">&#x27;语文&#x27;</span>, <span class="string">&#x27;数学&#x27;</span>, <span class="string">&#x27;英语&#x27;</span>, <span class="string">&#x27;政治&#x27;</span>, <span class="string">&#x27;体育&#x27;</span>], dtype=<span class="string">&#x27;object&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>values</strong></li></ul><p>直接获取其中array的值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">data.values</span><br><span class="line"></span><br><span class="line">array([[<span class="number">92</span>, <span class="number">55</span>, <span class="number">78</span>, <span class="number">50</span>, <span class="number">50</span>],</span><br><span class="line">[<span class="number">71</span>, <span class="number">76</span>, <span class="number">50</span>, <span class="number">48</span>, <span class="number">96</span>],</span><br><span class="line">[<span class="number">45</span>, <span class="number">84</span>, <span class="number">78</span>, <span class="number">51</span>, <span class="number">68</span>],</span><br><span class="line">[<span class="number">81</span>, <span class="number">91</span>, <span class="number">56</span>, <span class="number">54</span>, <span class="number">76</span>],</span><br><span class="line">[<span class="number">86</span>, <span class="number">66</span>, <span class="number">77</span>, <span class="number">67</span>, <span class="number">95</span>],</span><br><span class="line">[<span class="number">46</span>, <span class="number">86</span>, <span class="number">56</span>, <span class="number">61</span>, <span class="number">99</span>],</span><br><span class="line">[<span class="number">46</span>, <span class="number">95</span>, <span class="number">44</span>, <span class="number">46</span>, <span class="number">56</span>],</span><br><span class="line">[<span class="number">80</span>, <span class="number">50</span>, <span class="number">45</span>, <span class="number">65</span>, <span class="number">57</span>],</span><br><span class="line">[<span class="number">41</span>, <span class="number">93</span>, <span class="number">90</span>, <span class="number">41</span>, <span class="number">97</span>],</span><br><span class="line">[<span class="number">65</span>, <span class="number">83</span>, <span class="number">57</span>, <span class="number">57</span>, <span class="number">40</span>]])</span><br></pre></td></tr></table></figure><ul><li><strong>T</strong></li></ul><p>转置</p><p>data.T</p><ul><li>显示前n行</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.head(n)</span><br></pre></td></tr></table></figure><ul><li>显示后n行</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.tail(n)</span><br></pre></td></tr></table></figure><p>ps：如果不加参数，默认是显示前5行或者后五行。</p><h3 id="DatatFrame索引的设置"><strong>DatatFrame</strong>索引的设置</h3><h4 id="修改行列索引值">修改行列索引值</h4><p>注意，只能整行整列得修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stu = [<span class="string">&quot;学生_&quot;</span> + <span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(score_df.shape[<span class="number">0</span>])]</span><br><span class="line"><span class="comment"># 必须整体全部修改</span></span><br><span class="line">data.index = stu</span><br></pre></td></tr></table></figure><h4 id="重设索引">重设索引</h4><ul><li>reset_index(drop=False)<ul><li>设置新的下标索引</li><li>drop:默认为False，不删除原来索引，如果为True,删除原来的索引值</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重置索引,drop=False</span></span><br><span class="line">data.reset_index()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重置索引,drop=True</span></span><br><span class="line">data.reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="以某列值设置为新的索引">以某列值设置为新的索引</h4><ul><li>set_index(keys, drop=True)<ul><li><strong>keys</strong> : 列索引名成或者列索引名称的列表</li><li><strong>drop</strong> : boolean, default True.当做新的索引，删除原来的列</li></ul></li></ul><p>1.创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;month&#x27;</span>: [<span class="number">1</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">10</span>],</span><br><span class="line"><span class="string">&#x27;year&#x27;</span>: [<span class="number">2012</span>, <span class="number">2014</span>, <span class="number">2013</span>, <span class="number">2014</span>],</span><br><span class="line"><span class="string">&#x27;sale&#x27;</span>:[<span class="number">55</span>, <span class="number">40</span>, <span class="number">84</span>, <span class="number">31</span>]&#125;)</span><br></pre></td></tr></table></figure><p>2.以月份设置新的索引</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.set_index(<span class="string">&#x27;month&#x27;</span>)</span><br></pre></td></tr></table></figure><p>3.设置多个索引，以年和月份</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.set_index([<span class="string">&#x27;year&#x27;</span>, <span class="string">&#x27;month&#x27;</span>])</span><br></pre></td></tr></table></figure><h3 id="MultiIndex与Panel"><strong>MultiIndex</strong>与<strong>Panel</strong></h3><h4 id="MultiIndex"><strong>MultiIndex</strong></h4><p>MultiIndex是三维的数据结构;</p><p>多级索引（也称层次化索引）是pandas的重要功能，可以在Series、DataFrame对象上拥有2个以及2个以上的索引。</p><h4 id="multiIndex的特性"><strong>multiIndex</strong>的特性</h4><p>打印刚才的df的行索引结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.index</span><br></pre></td></tr></table></figure><p>多级或分层索引对象。</p><ul><li>index属性<ul><li>names:levels的名称</li><li>levels：每个level的元组值</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.index.names</span><br><span class="line"><span class="comment"># FrozenList([&#x27;year&#x27;, &#x27;month&#x27;])</span></span><br><span class="line">df.index.levels</span><br><span class="line"><span class="comment"># FrozenList([[1, 2], [1, 4, 7, 10]])</span></span><br></pre></td></tr></table></figure><p><strong>multiIndex</strong>的创建</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arrays = [[1, 1, 2, 2], [&#x27;red&#x27;, &#x27;blue&#x27;, &#x27;red&#x27;, &#x27;blue&#x27;]]</span><br><span class="line">pd.MultiIndex.from_arrays(arrays, names=(&#x27;number&#x27;, &#x27;color&#x27;))</span><br></pre></td></tr></table></figure><h4 id="Panel"><strong>Panel</strong></h4><h4 id="panel的创建"><strong>panel</strong>的创建</h4><ul><li><em>class</em> pandas.Panel (<em>data=None</em>, <em>items=None</em>, <em>major_axis=None</em>, <em>minor_axis=None</em>)<ul><li>作用：存储3维数组的Panel结构</li><li>参数：<ul><li><strong>data</strong> : ndarray或者dataframe</li><li><strong>items</strong> : 索引或类似数组的对象，axis=0</li><li><strong>major_axis</strong> : 索引或类似数组的对象，axis=1</li><li><strong>minor_axis</strong> : 索引或类似数组的对象，axis=2</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">p = pd.Panel(data=np.arange(<span class="number">24</span>).reshape(<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>),</span><br><span class="line">items=<span class="built_in">list</span>(<span class="string">&#x27;ABCD&#x27;</span>),</span><br><span class="line">major_axis=pd.date_range(<span class="string">&#x27;20130101&#x27;</span>, periods=<span class="number">3</span>),</span><br><span class="line">minor_axis=[<span class="string">&#x27;first&#x27;</span>, <span class="string">&#x27;second&#x27;</span>])</span><br></pre></td></tr></table></figure><h4 id="查看panel数据">查看<strong>panel</strong>数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p[:,:,<span class="string">&quot;first&quot;</span>]</span><br><span class="line">p[<span class="string">&quot;B&quot;</span>,:,:]</span><br></pre></td></tr></table></figure><h3 id="基本数据操作">基本数据操作</h3><p>导入数据，数据放在上方的资源中了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取文件</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;./stock_day.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 删除一些列，让数据更简单些，再去做后面的操作</span></span><br><span class="line">data = data.drop([<span class="string">&quot;ma5&quot;</span>,<span class="string">&quot;ma10&quot;</span>,<span class="string">&quot;ma20&quot;</span>,<span class="string">&quot;v_ma5&quot;</span>,<span class="string">&quot;v_ma10&quot;</span>,<span class="string">&quot;v_ma20&quot;</span>], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="索引操作">索引操作</h4><p>直接使用行列索引**(<strong>先列后行</strong>)**</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接使用行列索引名字的方式（先列后行）</span></span><br><span class="line">data[<span class="string">&#x27;open&#x27;</span>][<span class="string">&#x27;2018-02-27&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 不支持的操作</span></span><br><span class="line"><span class="comment"># 错误</span></span><br><span class="line">data[<span class="string">&#x27;2018-02-27&#x27;</span>][<span class="string">&#x27;open&#x27;</span>]</span><br></pre></td></tr></table></figure><p>只能先行后列</p><h4 id="结合loc或者iloc使用索引">结合<strong>loc</strong>或者<strong>iloc</strong>使用索引</h4><p>获取从’2018-02-27’:‘2018-02-22’，'open’的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用loc:只能指定行列索引的名字</span></span><br><span class="line">data.loc[<span class="string">&#x27;2018-02-27&#x27;</span>:<span class="string">&#x27;2018-02-22&#x27;</span>, <span class="string">&#x27;open&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用iloc可以通过索引的下标去获取</span></span><br><span class="line"><span class="comment"># 获取前3天数据,前5列的结果</span></span><br><span class="line">data.iloc[:<span class="number">3</span>, :<span class="number">5</span>]</span><br></pre></td></tr></table></figure><h4 id="使用ix组合索引">使用<strong>ix</strong>组合索引</h4><p>获取行第1天到第4天，[‘open’, ‘close’, ‘high’, ‘low’]这个四个指标的结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用ix进行下表和名称组合做引</span></span><br><span class="line">data.ix[<span class="number">0</span>:<span class="number">4</span>, [<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;high&#x27;</span>, <span class="string">&#x27;low&#x27;</span>]]</span><br><span class="line"><span class="comment"># 推荐使用loc和iloc来获取的方式</span></span><br><span class="line">data.loc[data.index[<span class="number">0</span>:<span class="number">4</span>], [<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;high&#x27;</span>, <span class="string">&#x27;low&#x27;</span>]]</span><br><span class="line">data.iloc[<span class="number">0</span>:<span class="number">4</span>, data.columns.get_indexer([<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>, <span class="string">&#x27;high&#x27;</span>, <span class="string">&#x27;low&#x27;</span>])]</span><br></pre></td></tr></table></figure><h4 id="赋值操作">赋值操作</h4><p>对DataFrame当中的close列进行重新赋值为1</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 直接修改原来的值</span></span><br><span class="line">data[<span class="string">&#x27;close&#x27;</span>] = <span class="number">1</span></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">data.close = <span class="number">1</span></span><br></pre></td></tr></table></figure><h4 id="排序">排序</h4><ul><li>排序有两种形式，一种对于索引进行排序，一种对于内容进行排序<ul><li>使用df.sort_values(by=, ascending=)</li><li>单个键或者多个键进行排序,<ul><li>参数：</li><li>by：指定排序参考的键</li><li>ascending:默认升序<ul><li>ascending=False:降序</li><li>ascending=True:升序</li></ul></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照开盘价大小进行排序 , 使用ascending指定按照大小排序</span></span><br><span class="line">data.sort_values(by=<span class="string">&quot;open&quot;</span>, ascending=<span class="literal">True</span>).head()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照多个键进行排序</span></span><br><span class="line">data.sort_values(by=[<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;high&#x27;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对索引进行排序</span></span><br><span class="line">data.sort_index()</span><br></pre></td></tr></table></figure><h4 id="Series排序"><strong>Series</strong>排序</h4><ul><li>使用series.sort_values(ascending=True)进行排序</li></ul><p>series排序时，只有一列，不需要参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;p_change&#x27;</span>].sort_values(ascending=<span class="literal">True</span>).head()</span><br></pre></td></tr></table></figure><ul><li>使用series.sort_index()进行排序</li></ul><p>与df一致</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对索引进行排序</span></span><br><span class="line">data[<span class="string">&#x27;p_change&#x27;</span>].sort_index().head()</span><br></pre></td></tr></table></figure><h3 id="总结">总结</h3><ul><li>1.索引<ul><li>直接索引 – 先列后行,是需要通过索引的字符串进行获取</li><li>loc – 先行后列,是需要通过索引的字符串进行获取</li><li>iloc – 先行后列,是通过下标进行索引</li><li>ix – 先行后列, 可以用上面两种方法混合进行索引</li></ul></li><li>2.赋值<ul><li>data[“”] = **</li><li>data. <strong>=</strong></li></ul></li><li>3.排序<ul><li>dataframe<ul><li>对象.sort_values()</li><li>对象.sort_index()</li></ul></li><li>series<ul><li>对象.sort_values()</li><li>对象.sort_index()</li></ul></li></ul></li></ul><h2 id="DataFrame运算"><strong>DataFrame</strong>运算</h2><h3 id="算术运算">算术运算</h3><ul><li>add(other)</li></ul><p>比如进行数学运算加上具体的一个数字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&#x27;open&#x27;</span>].add(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li>sub(other)’</li></ul><h3 id="逻辑运算-可用于筛选">逻辑运算(可用于筛选)</h3><h4 id="逻辑运算符号">逻辑运算符号</h4><ul><li>例如筛选data[“open”] &gt; 23的日期数据<ul><li>data[“open”] &gt; 23返回逻辑结果</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="string">&quot;open&quot;</span>] &gt; <span class="number">23</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逻辑判断的结果可以作为筛选的依据</span></span><br><span class="line">data[data[<span class="string">&quot;open&quot;</span>] &gt; <span class="number">23</span>].head()</span><br></pre></td></tr></table></figure><ul><li>完成多个逻辑判断</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[(data[<span class="string">&quot;open&quot;</span>] &gt; <span class="number">23</span>) &amp; (data[<span class="string">&quot;open&quot;</span>] &lt; <span class="number">24</span>)].head()</span><br></pre></td></tr></table></figure><h4 id="逻辑运算函数">逻辑运算函数</h4><ul><li>query(expr)<ul><li>expr:查询字符串</li></ul></li></ul><p>通过query使得刚才的过程更加方便简单</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data.query(<span class="string">&quot;open&lt;24 &amp; open&gt;23&quot;</span>).head()</span><br></pre></td></tr></table></figure><ul><li>isin(values)</li></ul><p>例如判断’open’是否为23.53和23.85</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以指定值进行一个判断，从而进行筛选操作</span></span><br><span class="line">data[data[<span class="string">&quot;open&quot;</span>].isin([<span class="number">23.53</span>, <span class="number">23.85</span>])]</span><br></pre></td></tr></table></figure><h3 id="统计运算">统计运算</h3><h4 id="describe"><strong>describe</strong></h4><p>综合分析: 能够直接得出很多统计结果, count , mean , std , min , max 等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算平均值、标准差、最大值、最小值</span></span><br><span class="line">data.describe()</span><br></pre></td></tr></table></figure><h3 id="统计函数">统计函数</h3><p>Numpy当中已经详细介绍，在这里我们演示min(最小值), max(最大值), mean(平均值), median(中位数), var(方差), std(标准差),mode(众数)结果:</p><p>对于单个函数去进行统计的时候，坐标轴还是按照默认列**“columns” (axis=0, default)<strong>，如果要对行</strong>“index”** 需要指定**(axis=1)**</p><ul><li>max()、min()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用统计函数：0 代表列求结果， 1 代表行求统计结果</span></span><br><span class="line">data.<span class="built_in">max</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>std()、var()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 方差</span></span><br><span class="line">data.var(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 标准差</span></span><br><span class="line">data.std(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>median()</strong>：中位数</li></ul><p>中位数为将数据从小到大排列，在最中间的那个数为中位数。如果没有中间数，取中间两个数的平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;COL1&#x27;</span> : [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">2</span>],</span><br><span class="line"><span class="string">&#x27;COL2&#x27;</span> : [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>]&#125;)</span><br><span class="line">df.median()</span><br></pre></td></tr></table></figure><ul><li>idxmax()、idxmin()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求出最大值的位置</span></span><br><span class="line">data.idxmax(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 求出最小值的位置</span></span><br><span class="line">data.idxmin(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="累计统计函数">累计统计函数</h3><table><thead><tr><th>函数</th><th>作用</th></tr></thead><tbody><tr><td>cunsum</td><td>计算前n个数的和</td></tr><tr><td>cunmax</td><td>计算前n个数的最大值</td></tr><tr><td>cunmin</td><td>计算前n个数的最小值</td></tr><tr><td>cunprod</td><td>计算前n个数的积</td></tr></tbody></table><p>这里我们按照时间的从前往后来进行累计</p><ul><li>排序</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 排序之后，进行累计求和</span></span><br><span class="line">data = data.sort_index()</span><br></pre></td></tr></table></figure><ul><li>对p_change进行求和</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stock_rise = data[<span class="string">&#x27;p_change&#x27;</span>]</span><br><span class="line"><span class="comment"># plot方法集成了前面直方图、条形图、饼图、折线图</span></span><br><span class="line">stock_rise.cumsum()</span><br></pre></td></tr></table></figure><p>如果要使用plot函数，需要导入matplotlib.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># plot显示图形</span></span><br><span class="line">stock_rise.cumsum().plot()</span><br><span class="line"><span class="comment"># 需要调用show，才能显示出结果</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="自定义运算">自定义运算</h3><ul><li>apply(func, axis=0)<ul><li>func:自定义函数</li><li>axis=0:默认是列，axis=1为行进行运算</li></ul></li><li>定义一个对列，最大值-最小值的函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[[<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>]].apply(<span class="keyword">lambda</span> x: x.<span class="built_in">max</span>() - x.<span class="built_in">min</span>(), axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="小结">小结</h3><ul><li>算术运算</li><li>逻辑运算<ul><li>1.逻辑运算符号</li><li>2.逻辑运算函数<ul><li>对象.query()</li><li>对象.isin()</li></ul></li></ul></li><li>统计运算<ul><li>1.对象.describe()</li><li>2.统计函数</li><li>3.累积统计函数</li></ul></li><li>自定义运算<ul><li>apply(func, axis=0)</li></ul></li></ul><h2 id="Pandas画图"><strong>Pandas</strong>画图</h2><h3 id="pandas-DataFrame-plot"><strong>pandas.DataFrame.plot</strong></h3><ul><li>DataFrame.plot (<em>kind=‘line’</em>)</li><li>kind : str，需要绘制图形的种类<ul><li><strong>‘line’ : line plot (default)</strong></li><li>‘bar’ : vertical bar plot</li><li>‘barh’ : horizontal bar plot<ul><li>关于“barh”的解释：</li><li><a href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.barh.html">http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.barh.html</a></li></ul></li><li>‘hist’ : histogram</li><li>‘pie’ : pie plot</li><li>‘scatter’ : scatter plot</li></ul></li></ul><h3 id="pandas-Series-plot"><strong>pandas.Series.plot</strong></h3><h2 id="文件读取与存储">文件读取与存储</h2><p>我们的数据大部分存在于文件当中，所以pandas会支持复杂的IO操作，pandas的API支持众多的文件格式，如CSV、SQL、XLS、JSON、HDF5。</p><p>ps：最常用的HDF5和CSV文件</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401242224276.png" alt="image-20240124222423129"></p><h3 id="CSV"><strong>CSV</strong></h3><h4 id="read-csv"><strong>read_csv</strong></h4><ul><li>pandas.read_csv(filepath_or_buffer, sep =‘,’, usecols )<ul><li>filepath_or_buffer:文件路径</li><li>sep :分隔符，默认用&quot;,&quot;隔开</li><li>usecols:指定读取的列名，列表形式</li></ul></li><li>举例：读取之前的股票的数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取文件,并且指定只获取&#x27;open&#x27;, &#x27;close&#x27;指标</span></span><br><span class="line">data = pd.read_csv(<span class="string">&quot;./data/stock_day.csv&quot;</span>, usecols=[<span class="string">&#x27;open&#x27;</span>, <span class="string">&#x27;close&#x27;</span>])</span><br></pre></td></tr></table></figure><h4 id="to-csv"><strong>to_csv</strong></h4><ul><li><p>DataFrame.to_csv(path_or_buf=None, sep=', ’, columns=None, header=True, index=True, mode=‘w’, encoding=None)</p><ul><li><p>path_or_buf :文件路径</p></li><li><p>sep :分隔符，默认用&quot;,&quot;隔开</p></li><li><p>columns :选择需要的列索引</p></li><li><p>header :boolean or list of string, default True,是否写进列索引值</p></li><li><p>index:是否写进行索引</p></li><li><p>mode:‘w’：重写, ‘a’ 追加</p></li></ul></li><li><p>举例：保存读取出来的股票数据</p><ul><li>保存’open’列的数据，然后读取查看结果</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 选取10行数据保存,便于观察数据</span></span><br><span class="line">data[:<span class="number">10</span>].to_csv(<span class="string">&quot;./test.csv&quot;</span>, columns=[<span class="string">&#x27;open&#x27;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#读取，查看结果</span></span><br><span class="line">pd.read_csv(<span class="string">&quot;./test.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p>会发现将索引存入到文件当中，变成单独的一列数据。如果需要删除，可以指定index参数,删除原来的文件，重新保存一次。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># index:存储不会讲索引值变成一列数据</span></span><br><span class="line">data[:<span class="number">10</span>].to_csv(<span class="string">&quot;./test.csv&quot;</span>, columns=[<span class="string">&#x27;open&#x27;</span>], index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h3 id="HDF5"><strong>HDF5</strong></h3><h4 id="read-hdf与to-hdf"><strong>read_hdf</strong>与<strong>to_hdf</strong></h4><p><strong>HDF5</strong>文件的读取和存储需要指定一个键，值为要存储的<strong>DataFrame</strong></p><ul><li><p>pandas.read_hdf(path_or_buf，key =None，** kwargs)</p><p>从h5文件当中读取数据</p><ul><li>path_or_buffer:文件路径</li><li>key:读取的键</li><li>return:Theselected object</li></ul></li><li><p>DataFrame.to_hdf(path_or_buf, <em>key</em>, *<em>*kwargs</em>)</p></li><li><p>读取文件</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">day_close = pd.read_hdf(<span class="string">&quot;./day_close.h5&quot;</span>)</span><br></pre></td></tr></table></figure><p>如果读取的时候出现错误</p><p>需要安装安装tables模块避免不能读取HDF5文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tables</span><br></pre></td></tr></table></figure><ul><li>存储文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">day_close.to_hdf(<span class="string">&quot;./data/test.h5&quot;</span>, key=<span class="string">&quot;day_close&quot;</span>)</span><br></pre></td></tr></table></figure><p>再次读取的时候, 需要指定键的名字</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_close = pd.read_hdf(<span class="string">&quot;./data/test.h5&quot;</span>, key=<span class="string">&quot;day_close&quot;</span>)</span><br></pre></td></tr></table></figure><p>注意：优先选择使用<strong>HDF5</strong>文件存储</p><ul><li>HDF5在存储的时候支持压缩，使用的方式是<strong>blosc</strong>，这个是速度最快的也是pandas默认支持的</li><li>使用压缩可以提磁盘利用率，节省空间</li><li>HDF5还是跨平台的，可以轻松迁移到hadoop 上面</li></ul><h3 id="JSON"><strong>JSON</strong></h3><p>JSON是我们常用的一种数据交换格式，前面在前后端的交互经常用到，也会在存储的时候选择这种格式。所以我们需要知道Pandas如何进行读取和存储JSON格式</p><h4 id="read-json"><strong>read_json</strong></h4><ul><li><p>pandas.read_json(path_or_buf=None, orient=None, typ=‘frame’, lines=False)</p><ul><li><p>将JSON格式准换成默认的Pandas DataFrame格式</p></li><li><p>orient : string,Indication of expected JSON string format.</p><ul><li><p>‘split’ : dict like {index -&gt; [index], columns -&gt; [columns], data -&gt; [values]}</p><ul><li>split 将索引总结到索引，列名到列名，数据到数据。将三部分都分开了</li></ul></li><li><p><strong>‘records’ : list like [{column -&gt; value}, … , {column -&gt; value}]</strong></p><ul><li>records 以 columns：values 的形式输出</li></ul></li><li><p>‘index’ : dict like {index -&gt; {column -&gt; value}}</p><ul><li>index 以 index：{columns：values}… 的形式输出</li></ul></li><li><p><strong>‘columns’ : dict like {column -&gt; {index -&gt; value}}</strong>,默认该格式</p><ul><li>colums 以 columns:{index:values} 的形式输出</li></ul></li><li><p>‘values’ : just the values array</p><ul><li>values 直接输出值</li></ul></li></ul></li><li><p>lines : boolean, default False</p><ul><li>按照每行读取json对象</li></ul></li><li><p>typ : default ‘frame’， 指定转换成的对象类型series或者dataframe</p></li></ul></li></ul><p><strong>read_josn</strong> 案例</p><ul><li>数据介绍</li></ul><p>这里使用一个新闻标题讽刺数据集，格式为json。 is_sarcastic ：1讽刺的，否则为0； headline ：新闻报道的标题； article_link ：链接到原始新闻文章。存储格式为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>: <span class="string">&quot;https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5&quot;</span>, <span class="string">&quot;headline&quot;</span>: <span class="string">&quot;former versace store clerk sues over secret &#x27;black code&#x27; for minority shoppers&quot;</span>, <span class="string">&quot;is_sarcastic&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>: <span class="string">&quot;https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365&quot;</span>, <span class="string">&quot;headline&quot;</span>: <span class="string">&quot;the &#x27;roseanne&#x27; revival catches up to our thorny political mood, for better and worse&quot;</span>, <span class="string">&quot;is_sarcastic&quot;</span>: <span class="number">0</span>&#125;</span><br></pre></td></tr></table></figure><ul><li>读取</li></ul><p>orient指定存储的json格式，lines指定按照行去变成一个样本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json_read = pd.read_json(<span class="string">&quot;./data/Sarcasm_Headlines_Dataset.json&quot;</span>, orient=<span class="string">&quot;records&quot;</span>, lines=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="to-json"><strong>to_json</strong></h4><ul><li>DataFrame.to_json(<em>path_or_buf=None</em>, <em>orient=None</em>, <em>lines=False</em>)<ul><li>将Pandas 对象存储为json格式</li><li><em>path_or_buf=None</em>：文件地址</li><li>orient:存储的json形式，{‘split’,’records’,’index’,’columns’,’values’}</li><li>lines:一个对象存储为一行</li></ul></li></ul><h4 id="案例">案例</h4><ul><li>存储文件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json_read.to_json(<span class="string">&quot;./data/test.json&quot;</span>, orient=<span class="string">&#x27;records&#x27;</span>)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/versace-black-code_us_5861fbefe4b0de3a08f600d5&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;former versace store clerk sues over secret &#x27;black code&#x27; for minority shoppers&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;,&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/roseanne-revival-review_us_5ab3a497e4b054d118e04365&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;the &#x27;roseanne&#x27; revival catches up to our thorny political mood, for better and worse&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;,&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/local.theonion.com\/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;mom starting to fear son&#x27;s web series closest thing she will have to grandchild&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">1</span>&#125;,&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/politics.theonion.com\/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;boehner just wants wife to listen, not come up with alternative debt-reduction ideas&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">1</span>&#125;,&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;j.k. rowling wishes snape happy birthday in the most magical way&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;,&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/advancing-the-worlds-women_b_6810038.html&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;advancing the world&#x27;s women&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;,....]</span><br></pre></td></tr></table></figure><ul><li>修改lines参数为True</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json_read.to_json(<span class="string">&quot;./data/test.json&quot;</span>, orient=<span class="string">&#x27;records&#x27;</span>, lines=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/versace-black-code_us_5861fbefe4b0de3a08f600d5&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;former versace store clerk sues over secret &#x27;black code&#x27; for minority shoppers&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/roseanne-revival-review_us_5ab3a497e4b054d118e04365&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;the &#x27;roseanne&#x27; revival catches up to our thorny political mood, for better and worse&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/local.theonion.com\/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;mom starting to fearson&#x27;s web series closest thing she will have to grandchild&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">1</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/politics.theonion.com\/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;boehner just wants wife to listen, not come up with alternative debt-reduction ideas&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">1</span>&#125;</span><br><span class="line">&#123;<span class="string">&quot;article_link&quot;</span>:<span class="string">&quot;https:\/\/www.huffingtonpost.com\/entry\/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb&quot;</span>,<span class="string">&quot;headline&quot;</span>:<span class="string">&quot;j.k. rowling wishes snape happy birthday in the most magical way&quot;</span>,<span class="string">&quot;is_sarcastic&quot;</span>:<span class="number">0</span>&#125;...</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="高级处理-缺失值处理">高级处理**-**缺失值处理</h2><ul><li>isnull判断是否有缺失数据NaN</li><li>fillna实现缺失值的填充</li><li>dropna实现缺失值的删除</li><li>replace实现数据的替换</li></ul><h3 id="如何处理nan">如何处理<strong>nan</strong></h3><ul><li>获取缺失值的标记方式(NaN或者其他标记方式)</li><li>如果缺失值的标记方式是NaN<ul><li>判断数据中是否包含NaN：<ul><li>pd.isnull(df),</li><li>pd.notnull(df)</li></ul></li><li>存在缺失值nan:<ul><li>1、删除存在缺失值的:dropna(axis=‘rows’)<ul><li>注：不会修改原数据，需要接受返回值</li></ul></li><li>2、替换缺失值:fillna(value, inplace=True)<ul><li>value:替换成的值</li><li>inplace:True:会修改原数据，False:不替换修改原数据，生成新的对象</li></ul></li></ul></li></ul></li><li>如果缺失值没有使用NaN标记，比如使用&quot;？&quot;<ul><li>先替换‘?’为np.nan，然后继续处理</li></ul></li></ul><h3 id="电影数据的缺失值处理">电影数据的缺失值处理</h3><p>电影数据文件获取</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取电影数据</span></span><br><span class="line">movie = pd.read_csv(<span class="string">&quot;./data/IMDB-Movie-Data.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p>判断缺失值是否存在</p><ul><li>pd.notnull()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.notnull(movie)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.<span class="built_in">all</span>(pd.notnull(movie))</span><br></pre></td></tr></table></figure><h3 id="存在缺失值nan-并且是np-nan">存在缺失值<strong>nan,<strong>并且是</strong>np.nan</strong></h3><ul><li>1、删除</li></ul><p>pandas删除缺失值，使用dropna的前提是，缺失值的类型必须是np.nan</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不修改原数据</span></span><br><span class="line">movie.dropna()</span><br><span class="line"><span class="comment"># 可以定义新的变量接受或者用原来的变量名</span></span><br><span class="line">data = movie.dropna()</span><br></pre></td></tr></table></figure><p>2、替换缺失值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 替换存在缺失值的样本的两列</span></span><br><span class="line"><span class="comment"># 替换填充平均值，中位数</span></span><br><span class="line"><span class="comment"># movie[&#x27;Revenue (Millions)&#x27;].fillna(movie[&#x27;Revenue (Millions)&#x27;].mean(), inplace=True)</span></span><br></pre></td></tr></table></figure><p>替换所有缺失值：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> movie.columns:</span><br><span class="line"><span class="keyword">if</span> np.<span class="built_in">all</span>(pd.notnull(movie[i])) == <span class="literal">False</span>:</span><br><span class="line"><span class="built_in">print</span>(i)</span><br><span class="line">movie[i].fillna(movie[i].mean(), inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h3 id="不是缺失值nan，有默认标记的">不是缺失值<strong>nan</strong>，有默认标记的</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wis = pd.read_csv(<span class="string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data&quot;</span>)</span><br></pre></td></tr></table></figure><p>以上数据在读取时，可能会报如下错误：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">URLError: &lt;urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:<span class="number">833</span>)&gt;</span><br></pre></td></tr></table></figure><p>解决办法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全局取消证书验证</span></span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line">ssl._create_default_https_context = ssl._create_unverified_context</span><br></pre></td></tr></table></figure><p>处理思路分析：</p><ul><li>1、先替换‘?’为np.nan<ul><li>df.replace(to_replace=, value=)<ul><li>to_replace:替换前的值</li><li>value:替换后的值</li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 把一些其它值标记的缺失值，替换成np.nan</span></span><br><span class="line">wis = wis.replace(to_replace=<span class="string">&#x27;?&#x27;</span>, value=np.nan)</span><br></pre></td></tr></table></figure><p>2、在进行缺失值的处理</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除</span></span><br><span class="line">wis = wis.dropna()</span><br></pre></td></tr></table></figure><h2 id="高级处理-数据离散化">高级处理**-**数据离散化</h2><h3 id="什么是数据的离散化">什么是数据的离散化</h3><p>连续属性的离散化就是在连续属性的值域上，将值域划分为若干个离散的区间，最后用不同的符号或整数 值代表落在每个子区间中的属性值。</p><h3 id="读取股票的数据">读取股票的数据</h3><p>先读取股票的数据，筛选出p_change数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = pd.read_csv(<span class="string">&quot;./stock_day.csv&quot;</span>)</span><br><span class="line">p_change= data[<span class="string">&#x27;p_change&#x27;</span>]</span><br></pre></td></tr></table></figure><h3 id="将股票涨跌幅数据进行分组">将股票涨跌幅数据进行分组</h3><p>使用的工具：</p><ul><li><p>pd.qcut(data, q)：</p><ul><li>对数据进行分组将数据分组，一般会与value_counts搭配使用，统计每组的个数</li></ul></li><li><p>series.value_counts()：统计分组次数</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自行分组</span></span><br><span class="line">qcut = pd.qcut(p_change, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 计算分到每个组数据个数</span></span><br><span class="line">qcut.value_counts()</span><br></pre></td></tr></table></figure><p>自定义区间分组：</p><ul><li>pd.cut(data, bins)</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己指定分组区间</span></span><br><span class="line">bins = [-<span class="number">100</span>, -<span class="number">7</span>, -<span class="number">5</span>, -<span class="number">3</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">100</span>]</span><br><span class="line">p_counts = pd.cut(p_change, bins)</span><br></pre></td></tr></table></figure><h3 id="将股票涨跌幅数据进行分组-2">将股票涨跌幅数据进行分组</h3><p>使用的工具：</p><ul><li>pd.qcut(data, q)：<ul><li>对数据进行分组将数据分组，一般会与value_counts搭配使用，统计每组的个数</li></ul></li><li>series.value_counts()：统计分组次数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自行分组</span></span><br><span class="line">qcut = pd.qcut(p_change, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 计算分到每个组数据个数</span></span><br><span class="line">qcut.value_counts()</span><br></pre></td></tr></table></figure><p>自定义区间分组：</p><ul><li>pd.cut(data, bins)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自己指定分组区间</span></span><br><span class="line">bins = [-<span class="number">100</span>, -<span class="number">7</span>, -<span class="number">5</span>, -<span class="number">3</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">100</span>]</span><br><span class="line">p_counts = pd.cut(p_change, bins)</span><br></pre></td></tr></table></figure><h3 id="股票涨跌幅分组数据变成one-hot编码">股票涨跌幅分组数据变成<strong>one-hot</strong>编码</h3><ul><li>什么是<strong>one-hot</strong>编码</li></ul><p>把每个类别生成一个布尔列，这些列中只有一列可以为这个样本取值为1.其又被称为独热编码。</p><ul><li>pandas.get_dummies(<em>data</em>, <em>prefix=None</em>)<ul><li>data:array-like, Series, or DataFrame</li><li>prefix:分组名字</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 得出one-hot编码矩阵</span></span><br><span class="line">dummies = pd.get_dummies(p_counts, prefix=<span class="string">&quot;rise&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="高级处理-合并">高级处理**-**合并</h2><p>如果你的数据由多张表组成，那么有时候需要将不同的内容合并在一起分析</p><h3 id="pd-concat实现数据合并">pd.concat实现数据合并</h3><ul><li>pd.concat([data1, data2], axis=1)<ul><li>按照行或列进行合并,axis=0为列索引，axis=1为行索引</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照行索引进行</span></span><br><span class="line">pd.concat([data, dummies], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="pd-merge"><strong>pd.merge</strong></h3><ul><li>pd.merge(left, right, how=‘inner’, on=None)<ul><li>可以指定按照两组数据的共同键值对合并或者左右各自</li><li>left : DataFrame</li><li>right : 另一个DataFrame</li><li>on : 指定的共同键</li><li>how:按照什么方式连接</li></ul></li></ul><h3 id="pd-merge合并"><strong>pd.merge</strong>合并</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">left = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;A&#x27;</span>: [<span class="string">&#x27;A0&#x27;</span>, <span class="string">&#x27;A1&#x27;</span>, <span class="string">&#x27;A2&#x27;</span>, <span class="string">&#x27;A3&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;B&#x27;</span>: [<span class="string">&#x27;B0&#x27;</span>, <span class="string">&#x27;B1&#x27;</span>, <span class="string">&#x27;B2&#x27;</span>, <span class="string">&#x27;B3&#x27;</span>]&#125;)</span><br><span class="line">right = pd.DataFrame(&#123;<span class="string">&#x27;key1&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K1&#x27;</span>, <span class="string">&#x27;K2&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;key2&#x27;</span>: [<span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>, <span class="string">&#x27;K0&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;C&#x27;</span>: [<span class="string">&#x27;C0&#x27;</span>, <span class="string">&#x27;C1&#x27;</span>, <span class="string">&#x27;C2&#x27;</span>, <span class="string">&#x27;C3&#x27;</span>],</span><br><span class="line"><span class="string">&#x27;D&#x27;</span>: [<span class="string">&#x27;D0&#x27;</span>, <span class="string">&#x27;D1&#x27;</span>, <span class="string">&#x27;D2&#x27;</span>, <span class="string">&#x27;D3&#x27;</span>]&#125;)</span><br><span class="line"><span class="comment"># 默认内连接</span></span><br><span class="line">result = pd.merge(left, right, on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br></pre></td></tr></table></figure><ul><li>左连接</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = pd.merge(left, right, how=<span class="string">&#x27;left&#x27;</span>, on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br></pre></td></tr></table></figure><ul><li>右连接</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = pd.merge(left, right, how=<span class="string">&#x27;right&#x27;</span>, on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br></pre></td></tr></table></figure><ul><li>外链接</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = pd.merge(left, right, how=<span class="string">&#x27;outer&#x27;</span>, on=[<span class="string">&#x27;key1&#x27;</span>, <span class="string">&#x27;key2&#x27;</span>])</span><br></pre></td></tr></table></figure><ul><li>pd.concat([数据1, 数据2], axis=**)</li><li>pd.merge(left, right, how=, on=)<ul><li>how – 以何种方式连接</li><li>on – 连接的键的依据是哪几个</li></ul></li></ul><h2 id="高级处理-交叉表与透视表">高级处理**-**交叉表与透视表</h2><h3 id="交叉表与透视表什么作用">交叉表与透视表什么作用</h3><p>探究股票的涨跌与星期几有关？</p><p>以下图当中表示，<strong>week</strong>代表星期几，<strong>1,0</strong>代表这一天股票的涨跌幅是好还是坏，里面的数据代表比例可以理解为所有时间为星期一等等的数据当中涨跌幅好坏的比例</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401261927547.png" alt="image-20240126192731386"></p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401261927185.png" alt="image-20240126192737066"></p><ul><li>交叉表：交叉表用于计算一列数据对于另外一列数据的分组个数**(<strong>用于统计分组频率的特殊透视表</strong>)**<ul><li>pd.crosstab(value1, value2)</li></ul></li><li>透视表：透视表是将原有的<strong>DataFrame</strong>的列分别作为行索引和列索引，然后对指定的列应用聚集函数<ul><li>data.pivot_table(）</li><li>DataFrame.pivot_table([], index=[])</li></ul></li></ul><h3 id="数据准备">数据准备</h3><ul><li><p>准备两列数据，星期数据以及涨跌幅是好是坏数据</p></li><li><p>进行交叉表计算</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 寻找星期几跟股票张得的关系</span></span><br><span class="line"><span class="comment"># 1、先把对应的日期找到星期几</span></span><br><span class="line">date = pd.to_datetime(data.index).weekday</span><br><span class="line">data[<span class="string">&#x27;week&#x27;</span>] = date</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2、假如把p_change按照大小去分个类0为界限</span></span><br><span class="line">data[<span class="string">&#x27;posi_neg&#x27;</span>] = np.where(data[<span class="string">&#x27;p_change&#x27;</span>] &gt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过交叉表找寻两列数据的关系</span></span><br><span class="line">count = pd.crosstab(data[<span class="string">&#x27;week&#x27;</span>], data[<span class="string">&#x27;posi_neg&#x27;</span>])</span><br></pre></td></tr></table></figure><p>但是我们看到count只是每个星期日子的好坏天数，并没有得到比例，该怎么去做？</p><ul><li>对于每个星期一等的总天数求和，运用除法运算求出比例</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 算数运算，先求和</span></span><br><span class="line"><span class="built_in">sum</span> = count.<span class="built_in">sum</span>(axis=<span class="number">1</span>).astype(np.float32)</span><br><span class="line"><span class="comment"># 进行相除操作，得出比例</span></span><br><span class="line">pro = count.div(<span class="built_in">sum</span>, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><h3 id="查看效果">查看效果</h3><p>使用plot画出这个比例，使用stacked的柱状图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pro.plot(kind=<span class="string">&#x27;bar&#x27;</span>, stacked=<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h3 id="使用-pivot-table-透视表-实现">使用**pivot_table(<strong>透视表</strong>)**实现</h3><p>使用透视表，刚才的过程更加简单</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过透视表，将整个过程变成更简单一些</span></span><br><span class="line">data.pivot_table([<span class="string">&#x27;posi_neg&#x27;</span>], index=<span class="string">&#x27;week&#x27;</span>)</span><br></pre></td></tr></table></figure><h2 id="高级处理-分组与聚合">高级处理**-**分组与聚合</h2><p>分组与聚合通常是分析数据的一种方式，通常与一些统计函数一起使用，查看数据的分组情况</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401261931808.png" alt="image-20240126193145539"></p><h3 id="分组API">分组<strong>API</strong></h3><ul><li>DataFrame.groupby(key, as_index=False)<ul><li>key:分组的列数据，可以多个</li></ul></li><li>案例:不同颜色的不同笔的价格数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">col =pd.DataFrame(&#123;<span class="string">&#x27;color&#x27;</span>: [<span class="string">&#x27;white&#x27;</span>,<span class="string">&#x27;red&#x27;</span>,<span class="string">&#x27;green&#x27;</span>,<span class="string">&#x27;red&#x27;</span>,<span class="string">&#x27;green&#x27;</span>], <span class="string">&#x27;object&#x27;</span>: [<span class="string">&#x27;pen&#x27;</span>,<span class="string">&#x27;pencil&#x27;</span>,<span class="string">&#x27;pencil&#x27;</span>,<span class="string">&#x27;ashtray&#x27;</span>,<span class="string">&#x27;pen&#x27;</span>],<span class="string">&#x27;price1&#x27;</span>:[<span class="number">5.56</span>,<span class="number">4.20</span>,<span class="number">1.30</span>,<span class="number">0.56</span>,<span class="number">2.75</span>],<span class="string">&#x27;price2&#x27;</span>:[<span class="number">4.75</span>,<span class="number">4.12</span>,<span class="number">1.60</span>,<span class="number">0.75</span>,<span class="number">3.15</span>]&#125;)</span><br></pre></td></tr></table></figure><ul><li>进行分组，对颜色分组，price进行聚合</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分组，求平均值</span></span><br><span class="line">col.groupby([<span class="string">&#x27;color&#x27;</span>])[<span class="string">&#x27;price1&#x27;</span>].mean()</span><br><span class="line">col[<span class="string">&#x27;price1&#x27;</span>].groupby(col[<span class="string">&#x27;color&#x27;</span>]).mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分组，数据的结构不变</span></span><br><span class="line"></span><br><span class="line">col.groupby([<span class="string">&#x27;color&#x27;</span>], as_index=<span class="literal">False</span>)[<span class="string">&#x27;price1&#x27;</span>].mean()</span><br></pre></td></tr></table></figure><h3 id="星巴克零售店铺数据">星巴克零售店铺数据</h3><p>现在我们有一组关于全球星巴克店铺的统计数据，如果我想知道美国的星巴克数量和中国的哪个多，或者我想知道中国每个省份星巴克的数量的情况，那么应该怎么办？</p><h3 id="数据获取">数据获取</h3><p>从文件中读取星巴克店铺数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入星巴克店的数据</span></span><br><span class="line">starbucks = pd.read_csv(<span class="string">&quot;./data/starbucks/directory.csv&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="进行分组聚合">进行分组聚合</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照国家分组，求出每个国家的星巴克零售店数量</span></span><br><span class="line">count = starbucks.groupby([<span class="string">&#x27;Country&#x27;</span>]).count()</span><br></pre></td></tr></table></figure><p>画图显示结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">count[<span class="string">&#x27;Brand&#x27;</span>].plot(kind=<span class="string">&#x27;bar&#x27;</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>假设我们加入省市一起进行分组</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置多个索引，set_index()</span></span><br><span class="line">starbucks.groupby([<span class="string">&#x27;Country&#x27;</span>, <span class="string">&#x27;State/Province&#x27;</span>]).count()</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--numpy</title>
      <link href="/posts/90e03a8a.html"/>
      <url>/posts/90e03a8a.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–numpy</h1><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401191712425.png" alt="image-20240119171233276"></p><p>Numpy（Numerical Python）是一个开源的Python科学计算库，用于快速处理任意维度的数组。</p><p>Numpy支持常见的数组和矩阵操作。对于同样的数值计算任务，使用Numpy比直接使用Python要简洁的多。</p><p>Numpy使用<strong>ndarray</strong>对象来处理多维数组，该对象是一个快速而灵活的大数据容器。</p><p>更详细的Numpy教程：<a href="https://www.runoob.com/numpy/numpy-tutorial.html">NumPy 教程 | 菜鸟教程 (runoob.com)</a></p><h2 id="ndarray介绍"><strong>ndarray</strong>介绍</h2><p>使用<strong>Python</strong>列表可以存储一维数组，通过列表的嵌套可以实现多维数组，那么为什么还需要使用<strong>Numpy</strong>的<strong>ndarray</strong>呢？</p><p>在这里我们通过一段代码运行来体会到ndarray的好处</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100000000</span>):</span><br><span class="line">a.append(random.random())</span><br><span class="line"><span class="comment"># 通过%time魔法方法, 查看当前行的代码运行一次所花费的时间</span></span><br><span class="line">%time sum1=<span class="built_in">sum</span>(a)</span><br><span class="line">b=np.array(a)</span><br><span class="line">%time sum2=np.<span class="built_in">sum</span>(b)</span><br></pre></td></tr></table></figure><p>在结果中发现，通过numpy计算后的时间比原生python要快很多。</p><p>从中我们看到ndarray的计算速度要快很多，节约了时间。</p><p>机器学习的最大特点就是大量的数据运算，那么如果没有一个快速的解决方案，那可能现在python也在机器学习领域达不到好的效果。</p><h3 id="numpy和原生python的储存">numpy和原生python的储存</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401191722813.png" alt="image-20240119172237683"></p><p>简单说，ndarry储存数据与数据地址都是连续的，相比于原生python省去了寻址的时间，可以省掉很多循环语句的执行时间。</p><h3 id="ndarray属性">ndarray属性</h3><p>NumPy 数组的维数称为秩（rank），秩就是轴的数量，即数组的维度，一维数组的秩为 1，二维数组的秩为 2，以此类推。</p><p>在 NumPy中，每一个线性的数组称为是一个轴（axis），也就是维度（dimensions）。比如说，二维数组相当于是两个一维数组，其中第一个一维数组中每个元素又是一个一维数组。所以一维数组就是 NumPy 中的轴（axis），第一个轴相当于是底层数组，第二个轴是底层数组里的数组。而轴的数量——秩，就是数组的维数。</p><p>很多时候可以声明 axis。axis=0，表示沿着第 0 轴进行操作，即对每一列进行操作；axis=1，表示沿着第1轴进行操作，即对每一行进行操作。</p><p>NumPy 的数组中比较重要 ndarray 对象属性有：</p><table><thead><tr><th style="text-align:left">属性</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">ndarray.ndim</td><td style="text-align:left">秩，即轴的数量或维度的数量</td></tr><tr><td style="text-align:left">ndarray.shape</td><td style="text-align:left">数组的维度，对于矩阵，n 行 m 列</td></tr><tr><td style="text-align:left">ndarray.size</td><td style="text-align:left">数组元素的总个数，相当于 .shape 中 n*m 的值</td></tr><tr><td style="text-align:left">ndarray.dtype</td><td style="text-align:left">ndarray 对象的元素类型</td></tr><tr><td style="text-align:left">ndarray.itemsize</td><td style="text-align:left">ndarray 对象中每个元素的大小，以字节为单位</td></tr></tbody></table><h3 id="NumPy-创建数组">NumPy 创建数组</h3><h4 id="numpy-empty">numpy.empty</h4><p>numpy.empty 方法用来创建一个指定形状（shape）、数据类型（dtype）且未初始化的数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.empty(shape, dtype = <span class="built_in">float</span>, order = <span class="string">&#x27;C&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">shape</td><td style="text-align:left">数组形状</td></tr><tr><td style="text-align:left">dtype</td><td style="text-align:left">数据类型，可选</td></tr><tr><td style="text-align:left">order</td><td style="text-align:left">有&quot;C&quot;和&quot;F&quot;两个选项,分别代表，行优先和列优先，在计算机内存中的存储元素的顺序。</td></tr></tbody></table><p>下面是一个创建空数组的实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">x = np.empty([<span class="number">3</span>,<span class="number">2</span>], dtype = <span class="built_in">int</span>) </span><br><span class="line"><span class="built_in">print</span> (x)</span><br></pre></td></tr></table></figure><p><strong>注意</strong> − 数组元素为随机值，因为它们未初始化。</p><h4 id="numpy-zeros">numpy.zeros</h4><p>创建指定大小的数组，数组元素以 0 来填充：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.zeros(shape, dtype = <span class="built_in">float</span>, order = <span class="string">&#x27;C&#x27;</span>)</span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">shape</td><td style="text-align:left">数组形状</td></tr><tr><td style="text-align:left">dtype</td><td style="text-align:left">数据类型，可选</td></tr><tr><td style="text-align:left">order</td><td style="text-align:left">‘C’ 用于 C 的行数组，或者 ‘F’ 用于 FORTRAN 的列数组</td></tr></tbody></table><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 默认为浮点数</span></span><br><span class="line">x = np.zeros(<span class="number">5</span>) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置类型为整数</span></span><br><span class="line">y = np.zeros((<span class="number">5</span>,), dtype = <span class="built_in">int</span>) </span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 自定义类型</span></span><br><span class="line">z = np.zeros((<span class="number">2</span>,<span class="number">2</span>), dtype = [(<span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>), (<span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;i4&#x27;</span>)])  </span><br><span class="line"><span class="built_in">print</span>(z)</span><br></pre></td></tr></table></figure><h4 id="numpy-ones">numpy.ones</h4><p>创建指定形状的数组，数组元素以 1 来填充：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.ones(shape, dtype = None, order = &#x27;C&#x27;)</span><br></pre></td></tr></table></figure><p>参数说明同上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 默认为浮点数</span></span><br><span class="line">x = np.ones(<span class="number">5</span>) </span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 自定义类型</span></span><br><span class="line">x = np.ones([<span class="number">2</span>,<span class="number">2</span>], dtype = <span class="built_in">int</span>)</span><br><span class="line"><span class="built_in">print</span>(x)</span><br></pre></td></tr></table></figure><h4 id="numpy-ones-like">numpy.ones_like</h4><p>numpy.ones_like 用于创建一个与给定数组具有相同形状的数组，数组元素以 1 来填充。</p><p>numpy.ones 和 numpy.ones_like 都是用于创建一个指定形状的数组，其中所有元素都是 1。</p><p>它们之间的区别在于：numpy.ones ==可以直接指定要创建的数组的形状==，而 numpy.ones_like 则是==创建一个与给定数组具有相同形状的数组==。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">numpy.ones_like(a, dtype=None, order=&#x27;K&#x27;, subok=True, shape=None)</span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th style="text-align:left">参数</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">a</td><td style="text-align:left">给定要创建相同形状的数组</td></tr><tr><td style="text-align:left">dtype</td><td style="text-align:left">创建的数组的数据类型</td></tr><tr><td style="text-align:left">order</td><td style="text-align:left">数组在内存中的存储顺序，可选值为 ‘C’（按行优先）或 ‘F’（按列优先），默认为 ‘K’（保留输入数组的存储顺序）</td></tr><tr><td style="text-align:left">subok</td><td style="text-align:left">是否允许返回子类，如果为 True，则返回一个子类对象，否则返回一个与 a 数组具有相同数据类型和存储顺序的数组</td></tr><tr><td style="text-align:left">shape</td><td style="text-align:left">创建的数组的形状，如果不指定，则默认为 a 数组的形状。</td></tr></tbody></table><p>创建一个与 arr 形状相同的，所有元素都为 1 的数组：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建一个 3x3 的二维数组</span></span><br><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 创建一个与 arr 形状相同的，所有元素都为 1 的数组</span></span><br><span class="line">ones_arr = np.ones_like(arr)</span><br><span class="line"><span class="built_in">print</span>(ones_arr)</span><br></pre></td></tr></table></figure><h3 id="NumPy-从已有的数组创建数组">NumPy 从已有的数组创建数组</h3><ul><li><strong>np.array(object, dtype)</strong></li><li><strong>np.asarray(a, dtype)</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="comment"># 从现有的数组当中创建</span></span><br><span class="line">a1 = np.array(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相当于索引的形式，并没有真正的创建一个新的</span></span><br><span class="line">a2 = np.asarray(a)</span><br></pre></td></tr></table></figure><p>两者的区别：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401231703882.png" alt="image-20240123170350598"></p><h3 id="生成固定范围的数组">生成固定范围的数组</h3><h4 id="np-linspace-start-stop-num-endpoint">np.linspace (start, stop, num, endpoint)**</h4><p>创建等差数组 — 指定数量</p><p>参数:</p><ul><li>start:序列的起始值</li><li>stop:序列的终止值</li><li>num:要生成的等间隔样例数量，默认为50</li><li>endpoint:序列中是否包含stop值，默认为ture</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成等间隔的数组</span></span><br><span class="line">np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line">返回结果：</span><br><span class="line">array([ <span class="number">0.</span>, <span class="number">10.</span>, <span class="number">20.</span>, <span class="number">30.</span>, <span class="number">40.</span>, <span class="number">50.</span>, <span class="number">60.</span>, <span class="number">70.</span>, <span class="number">80.</span>, <span class="number">90.</span>, <span class="number">100.</span>])</span><br></pre></td></tr></table></figure><h4 id="np-arange-start-stop-step-dtype"><strong>np.arange(start,stop, step, dtype)</strong></h4><ul><li>创建等差数组 — 指定步长</li><li>参数<ul><li>step:步长,默认值为1</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.arange(<span class="number">10</span>, <span class="number">50</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">返回结果：</span><br><span class="line">array([<span class="number">10</span>, <span class="number">12</span>, <span class="number">14</span>, <span class="number">16</span>, <span class="number">18</span>, <span class="number">20</span>, <span class="number">22</span>, <span class="number">24</span>, <span class="number">26</span>, <span class="number">28</span>, <span class="number">30</span>, <span class="number">32</span>, <span class="number">34</span>, <span class="number">36</span>, <span class="number">38</span>, <span class="number">40</span>, <span class="number">42</span>,</span><br><span class="line"><span class="number">44</span>, <span class="number">46</span>, <span class="number">48</span>])</span><br></pre></td></tr></table></figure><h4 id="np-logspace-start-stop-num"><strong>np.logspace(start,stop, num)</strong></h4><ul><li>创建等比数列</li><li>参数:<ul><li>num:要生成的等比数列数量，默认为50</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成10^x</span></span><br><span class="line">np.logspace(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">返回结果:</span><br><span class="line">array([ <span class="number">1.</span>, <span class="number">10.</span>, <span class="number">100.</span>])</span><br></pre></td></tr></table></figure><h3 id="生成随机数组">生成随机数组</h3><h4 id="使用模块介绍">使用模块介绍</h4><ul><li>np.random模块</li></ul><h3 id="正态分布">正态分布</h3><p>正态分布是一种概率分布。正态分布是具有两个参数μ和σ的连续型随机变量的分布，第一参数μ是服从正态分布的随机变量的均值，第二个参数σ是此随机变量的标准差，所以正态分布记作<strong>N(μ</strong>，<strong>σ )</strong></p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401231707587.png" alt="image-20240123170710382" style="zoom:80%;"><p><strong>μ</strong>决定了其位置，其标准差<strong>σ</strong>决定了分布的幅度。当μ = 0,σ = 1时的正态分布是标准正态分布。</p><ul><li>方差</li></ul><p>是在概率论和统计方差衡量一组数据时离散程度的度量</p><p>$$\sigma<sup>2=\frac{(x_1-M)</sup>2+(x_2-M)<sup>2+(x_3-M)</sup>2+\ldots\ldots(x_n-M)^2}n$$</p><p>其中M为平均值，n为数据总个数，σ 为标准差，σ ^2可以理解一个整体为方差</p><p>$\sigma=\sqrt{\frac{1}{N}\sum_{i=1}<sup>{N}{(x_{i}-\mu)}</sup>{2}}$</p><h4 id="正态分布创建方式">正态分布创建方式</h4><p>np.random.randn(<em>d0, d1, …, dn</em>)</p><p>功能：从标准正态分布中返回一个或多个样本值</p><ul><li>**np.random.normal(**loc=0.0, <strong>scale=1.0</strong>, <strong>size=None</strong>)</li></ul><p>loc：float</p><p>此概率分布的均值（对应着整个分布的中心centre）</p><p>scale：float</p><p>此概率分布的标准差（对应于分布的宽度，scale越大越矮胖，scale越小，越瘦高）</p><p>size：int or tuple of ints</p><p>输出的shape，默认为None，只输出一个值</p><ul><li>np.random.standard_normal(<em>size=None</em>)</li></ul><p>返回指定形状的标准正态分布的数组</p><p>举例<strong>1</strong>：生成均值为<strong>1.75</strong>，标准差为<strong>1</strong>的正态分布数据，<strong>100000000</strong>个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x1 = np.random.normal(<span class="number">1.75</span>, <span class="number">1</span>, <span class="number">100000000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成均匀分布的随机数</span></span><br><span class="line">x1 = np.random.normal(<span class="number">1.75</span>, <span class="number">1</span>, <span class="number">100000000</span>)</span><br><span class="line"><span class="comment"># 画图看分布状况</span></span><br><span class="line"><span class="comment"># 1）创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">10</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2）绘制直方图</span></span><br><span class="line">plt.hist(x1, <span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 3）显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/posts/90e03a8a.htm/Vmware/bin\正态分布.png" style="zoom:67%;"><p>举例<strong>2</strong>：随机生成<strong>4</strong>支股票<strong>1</strong>周的交易日涨幅数据</p><p>4支股票，一周**(5<strong>天</strong>)**的涨跌幅数据，如何获取？</p><p>随机生成涨跌幅在某个正态分布内，比如均值0，方差1</p><p>股票涨跌幅数据的创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建符合正态分布的4只股票5天的涨跌幅数据</span></span><br><span class="line">stock_change = np.random.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">4</span>, <span class="number">5</span>))</span><br><span class="line">stock_change</span><br></pre></td></tr></table></figure><h3 id="均匀分布">均匀分布</h3><ul><li>np.random.rand(<em>d0</em>, <em>d1</em>, <em>…</em>, <em>dn</em>)<ul><li>返回**[0.0**，**1.0)**内的一组均匀分布的数。</li></ul></li><li><strong>np.random.uniform(<strong>low=0.0</strong>,<strong>high=1.0</strong>,</strong> <strong>size=None</strong>)<ul><li>功能：从一个均匀分布[low,high)中随机采样，注意定义域是左闭右开，即包含low，不包含high.</li><li>参数介绍:<ul><li>low: 采样下界，float类型，默认值为0；</li><li>high: 采样上界，float类型，默认值为1；</li><li>size: 输出样本数目，为int或元组(tuple)类型，例如，size=(m,n,k), 则输出m<em>n</em>k个样本，缺省时输出1个值。</li></ul></li><li>返回值：ndarray类型，其形状和参数size中描述一致。</li></ul></li><li>np.random.randint(<em>low</em>, <em>high=None</em>, <em>size=None</em>, <em>dtype=‘l’</em>)<ul><li>从一个均匀分布中随机采样，生成一个整数或N维整数数组，</li><li>取数范围：若high不为None时，取[low,high)之间随机整数，否则取值[0,low)之间随机整数。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成均匀分布的随机数</span></span><br><span class="line">x2 = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100000000</span>)</span><br></pre></td></tr></table></figure><p>画图看分布状况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 生成均匀分布的随机数</span></span><br><span class="line">x2 = np.random.uniform(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100000000</span>)</span><br><span class="line"><span class="comment"># 画图看分布状况</span></span><br><span class="line"><span class="comment"># 1）创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2）绘制直方图</span></span><br><span class="line">plt.hist(x=x2, bins=<span class="number">1000</span>) <span class="comment"># x代表要使用的数据，bins表示要划分区间数</span></span><br><span class="line"><span class="comment"># 3）显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401231732974.png" style="zoom:67%;"><h2 id="数组的索引、切片">数组的索引、切片</h2><p>一维、二维、三维的数组如何索引？</p><ul><li>直接进行索引,切片</li><li>对象[:, :] – 先行后列</li></ul><p>二维数组索引方式：</p><ul><li>举例：获取第一个股票的前3个交易日的涨跌幅数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 二维的数组，两个维度</span></span><br><span class="line">stock_change[<span class="number">0</span>, <span class="number">0</span>:<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>三维数组索引方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三维</span></span><br><span class="line">a1 = np.array([ [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]], [[<span class="number">12</span>,<span class="number">3</span>,<span class="number">34</span>],[<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回结果</span></span><br><span class="line">array([[[ <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">[ <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]],</span><br><span class="line">[[<span class="number">12</span>, <span class="number">3</span>, <span class="number">34</span>],</span><br><span class="line">[ <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]]])</span><br><span class="line"><span class="comment"># 索引、切片</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a1[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>] <span class="comment"># 输出: 2</span></span><br></pre></td></tr></table></figure><h2 id="形状修改">形状修改</h2><h3 id="ndarray-reshape-shape-order">ndarray.reshape(shape, order)</h3><ul><li><p>返回一个具有相同数据域，但shape不一样的视图</p></li><li><p>行、列不进行互换</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在转换形状的时候，一定要注意数组的元素匹配</span></span><br><span class="line">stock_change.reshape([<span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line">stock_change.reshape([-<span class="number">1</span>,<span class="number">10</span>]) <span class="comment"># 数组的形状被修改为: (2, 10), -1: 表示通过待计算</span></span><br></pre></td></tr></table></figure><h3 id="ndarray-resize-new-shape">ndarray.resize(new_shape)</h3><ul><li>修改数组本身的形状（需要保持元素个数前后相同）</li><li>行、列不进行互换</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">stock_change.resize([<span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"><span class="comment"># 查看修改后结果</span></span><br><span class="line"></span><br><span class="line">stock_change.shape</span><br><span class="line">(<span class="number">5</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure><h3 id="ndarray-T"><strong>ndarray.T</strong></h3><p>数组的转置</p><ul><li>将数组的行、列进行互换</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">stock_change.T.shape</span><br><span class="line">(<span class="number">4</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure><h2 id="类型修改">类型修改</h2><h3 id="ndarray-astype-type">ndarray.astype(type)</h3><ul><li>返回修改了类型之后的数组</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stock_change.astype(np.int32)</span><br></pre></td></tr></table></figure><h3 id="ndarray-tostring-order-或者ndarray-tobytes-order"><strong>ndarray.tostring([order])<strong>或者</strong>ndarray.tobytes([order])</strong></h3><ul><li>构造包含数组中原始数据字节的Python字节</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], [[<span class="number">12</span>, <span class="number">3</span>, <span class="number">34</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]]])</span><br><span class="line">arr.tostring()</span><br></pre></td></tr></table></figure><h2 id="数组的去重">数组的去重</h2><h3 id="np-unique"><strong>np.unique()</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">temp = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.unique(temp)</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br></pre></td></tr></table></figure><h2 id="ndarray运算"><strong>ndarray</strong>运算</h2><h2 id="逻辑运算">逻辑运算</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成10名同学，5门功课的数据</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>score = np.random.randint(<span class="number">40</span>, <span class="number">100</span>, (<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"><span class="comment"># 取出最后4名同学的成绩，用于逻辑判断</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_score = score[<span class="number">6</span>:, <span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line"><span class="comment"># 逻辑判断, 如果成绩大于60就标记为True 否则为False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_score &gt; <span class="number">60</span></span><br><span class="line">array([[ <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>],</span><br><span class="line">[ <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">True</span>],</span><br><span class="line">[ <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">True</span>],</span><br><span class="line">[<span class="literal">False</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>, <span class="literal">True</span>]])</span><br><span class="line"><span class="comment"># BOOL赋值, 将满足条件的设置为指定的值-布尔索引</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_score[test_score &gt; <span class="number">60</span>] = <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>test_score</span><br><span class="line">array([[ <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">52</span>, <span class="number">1</span>],</span><br><span class="line">[ <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">59</span>, <span class="number">1</span>],</span><br><span class="line">[ <span class="number">1</span>, <span class="number">1</span>, <span class="number">44</span>, <span class="number">44</span>, <span class="number">1</span>],</span><br><span class="line">[<span class="number">59</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br></pre></td></tr></table></figure><h3 id="通用判断函数">通用判断函数</h3><ul><li>np.all()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 判断前两名同学的成绩[0:2, :]是否全及格</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.<span class="built_in">all</span>(score[<span class="number">0</span>:<span class="number">2</span>, :] &gt; <span class="number">60</span>)</span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure><ul><li>np.any()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 判断前两名同学的成绩[0:2, :]是否有大于90分的</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.<span class="built_in">any</span>(score[<span class="number">0</span>:<span class="number">2</span>, :] &gt; <span class="number">80</span>)</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure><h3 id="np-where（三元运算符）"><strong>np.where</strong>（三元运算符）</h3><p>通过使用np.where能够进行更加复杂的运算</p><ul><li>np.where()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 判断前四名学生,前四门课程中，成绩中大于60的置为1，否则为0</span></span><br><span class="line">temp = score[:<span class="number">4</span>, :<span class="number">4</span>]</span><br><span class="line">np.where(temp &gt; <span class="number">60</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><ul><li>复合逻辑需要结合np.logical_and和np.logical_or使用</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 判断前四名学生,前四门课程中，成绩中大于60且小于90的换为1，否则为0</span></span><br><span class="line">np.where(np.logical_and(temp &gt; <span class="number">60</span>, temp &lt; <span class="number">90</span>), <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 判断前四名学生,前四门课程中，成绩中大于90或小于60的换为1，否则为0</span></span><br><span class="line">np.where(np.logical_or(temp &gt; <span class="number">90</span>, temp &lt; <span class="number">60</span>), <span class="number">1</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h2 id="统计运算">统计运算</h2><p>如果想要知道学生成绩最大的分数，或者做小分数应该怎么做？</p><h3 id="统计指标">统计指标</h3><p>在数据挖掘/机器学习领域，统计指标的值也是我们分析问题的一种方式。常用的指标如下：</p><ul><li>min(a, axis)<ul><li>Return the minimum of an array or minimum along an axis.</li></ul></li><li>max(a, axis])<ul><li>Return the maximum of an array or maximum along an axis.</li></ul></li><li>median(a, axis)<ul><li>Compute the median along the specified axis.</li></ul></li><li>mean(a, axis, dtype)<ul><li>Compute the arithmetic mean along the specified axis.</li></ul></li><li>std(a, axis, dtype)<ul><li>Compute the standard deviation along the specified axis.</li></ul></li><li>var(a, axis, dtype)<ul><li>Compute the variance along the specified axis.</li></ul></li></ul><h3 id="案例：学生成绩统计运算">案例：学生成绩统计运算</h3><p>进行统计的时候，<strong>axis</strong> 轴的取值并不一定，<strong>Numpy</strong>中不同的<strong>API</strong>轴的值都不一样，在这里，<strong>axis 0</strong>代表列**, axis 1**代表行去进行统计</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 接下来对于前四名学生,进行一些统计运算</span></span><br><span class="line"><span class="comment"># 指定列 去统计</span></span><br><span class="line"></span><br><span class="line">temp = score[:<span class="number">4</span>, <span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前四名学生,各科成绩的最大分：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.<span class="built_in">max</span>(temp, axis=<span class="number">0</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前四名学生,各科成绩的最小分：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.<span class="built_in">min</span>(temp, axis=<span class="number">0</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前四名学生,各科成绩波动情况：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.std(temp, axis=<span class="number">0</span>)))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前四名学生,各科成绩的平均分：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.mean(temp, axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">前四名学生,各科成绩的最大分：[<span class="number">96</span> <span class="number">97</span> <span class="number">72</span> <span class="number">98</span> <span class="number">89</span>]</span><br><span class="line">前四名学生,各科成绩的最小分：[<span class="number">55</span> <span class="number">57</span> <span class="number">45</span> <span class="number">76</span> <span class="number">77</span>]</span><br><span class="line">前四名学生,各科成绩波动情况：[<span class="number">16.25576821</span> <span class="number">14.92271758</span> <span class="number">10.40432602</span> <span class="number">8.0311892</span> <span class="number">4.32290412</span>]</span><br><span class="line">前四名学生,各科成绩的平均分：[<span class="number">78.5</span> <span class="number">75.75</span> <span class="number">62.5</span> <span class="number">85.</span> <span class="number">82.25</span>]</span><br></pre></td></tr></table></figure><p>如果需要统计出某科最高分对应的是哪个同学？</p><ul><li><p>np.argmax(temp, axis=)</p></li><li><p>np.argmin(temp, axis=)</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;前四名学生，各科成绩最高分对应的学生下标：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(np.argmax(temp, axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure><p>结果：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">前四名学生，各科成绩最高分对应的学生下标：[0 2 0 0 1]</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--Matplotlib</title>
      <link href="/posts/b6993a5e.html"/>
      <url>/posts/b6993a5e.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–Matplotlib</h1><h2 id="Matplotlib">Matplotlib</h2><p>详细教程：<a href="https://www.runoob.com/matplotlib/matplotlib-tutorial.html">Matplotlib 教程 | 菜鸟教程 (runoob.com)</a></p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182149375.png" alt="image-20240118214913326"></p><ul><li>是专门用于开发2D图表(包括3D图表)</li><li>以渐进、交互式方式实现数据可视化</li></ul><h2 id="简单的Matplotlib画图-—-以折线图为例">简单的<strong>Matplotlib</strong>画图 <strong>—</strong> 以折线图为例</h2><h3 id="matplotlib-pyplot模块">matplotlib.pyplot模块</h3><p>matplotlib.pytplot包含了一系列类似于matlab的画图函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><h3 id="图形绘制流程：">图形绘制流程：</h3><p>1.创建画布 – plt.figure()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(), dpi=)</span><br><span class="line">figsize:指定图的长宽</span><br><span class="line">dpi:图像的清晰度</span><br><span class="line">返回fig对象</span><br></pre></td></tr></table></figure><p>2.绘制图像 – plt.plot(x, y)</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">以折线图为例</span><br></pre></td></tr></table></figure><p>3.显示图像 – plt.show()</p><h3 id="折线图绘制与显示">折线图绘制与显示</h3><p>举例：展现上海一周的天气**,**比如从星期一到星期日的天气温度如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制折线图</span></span><br><span class="line">plt.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span> ,<span class="number">7</span>], [<span class="number">17</span>,<span class="number">17</span>,<span class="number">18</span>,<span class="number">15</span>,<span class="number">11</span>,<span class="number">11</span>,<span class="number">13</span>])</span><br><span class="line"><span class="comment"># 3.显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182154835.png" alt="image-20240118215428683" style="zoom: 67%;"><h3 id="Matplotlib图像结构"><strong>Matplotlib</strong>图像结构</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182155335.png" alt="image-20240118215512281"></p><h2 id="例子：一个完整的流程">例子：一个完整的流程</h2><p>我们通过天气温度变化的绘图来融合所有的基础API使用</p><p>需求：画出某城市<strong>11</strong>点到<strong>12</strong>点<strong>1</strong>小时内每分钟的温度变化折线图，温度范围在<strong>15</strong>度**~18**度效果：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182156176.png" alt="image-20240118215640044" style="zoom:80%;"><h3 id="准备数据并画出初始折线图">准备数据并画出初始折线图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="comment"># 画出温度变化图</span></span><br><span class="line"><span class="comment"># 0.准备x, y坐标的数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">80</span>)</span><br><span class="line"><span class="comment"># 2.绘制折线图</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line"><span class="comment"># 3.显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182157260.png" alt="image-20240118215720144"></p><h3 id="添加自定义x-y刻度">添加自定义<strong>x,y</strong>刻度</h3><ul><li>plt.xticks(x, **kwargs)<ul><li>x:要显示的刻度值</li></ul></li><li>plt.yticks(y, **kwargs)<ul><li>y:要显示的刻度值</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加以下两行代码</span></span><br><span class="line"><span class="comment"># 构造x轴刻度标签</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 构造y轴刻度</span></span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 修改x,y轴坐标的刻度显示</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182158265.png" alt="image-20240118215825132"></p><p>==ps:如果没有解决过中文问题的话，会显示这个样子：==</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182158851.png" alt="image-20240118215858767" style="zoom:80%;"><h3 id="中文显示问题解决">中文显示问题解决</h3><p>解决方案一：</p><p>下载中文字体（黑体，看准系统版本）</p><ul><li>步骤一：下载 SimHei 字体（或者其他的支持中文显示的字体也行）</li></ul><p>步骤二：安装字体</p><p>linux下：拷贝字体到 usr/share/fonts 下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cp ~/SimHei.ttf /usr/share/fonts/SimHei.ttf</span><br></pre></td></tr></table></figure><p>windows和mac下：双击安装</p><p>步骤三：删除~/.matplotlib中的缓存文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.matplotlib</span><br><span class="line">rm -r *</span><br></pre></td></tr></table></figure><p>步骤四：修改配置文件matplotlibrc</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.matplotlib/matplotlibrc</span><br></pre></td></tr></table></figure><p>将文件内容修改为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">font.family : sans-serif</span><br><span class="line">font.sans-serif : SimHei</span><br><span class="line">axes.unicode_minus : False</span><br></pre></td></tr></table></figure><p>解决方案二：</p><p>在Python脚本中动态设置matplotlibrc,这样也可以避免由于更改配置文件而造成的麻烦，具体代码如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from pylab import mpl</span><br><span class="line">\# 设置显示中文字体</span><br><span class="line">mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]</span><br></pre></td></tr></table></figure><p>有时候，字体更改后，会导致坐标轴中的部分字符无法正常显示，此时需要更改axes.unicode_minus参数：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置正常显示符号</span></span><br><span class="line">mpl.rcParams[&quot;axes.unicode_minus&quot;] = False</span><br></pre></td></tr></table></figure><h3 id="添加网格显示">添加网格显示</h3><p>为了更加清楚地观察图形对应的值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182202027.png" alt="image-20240118220230960" style="zoom:80%;"><h3 id="添加描述信息">添加描述信息</h3><p>添加x轴、y轴描述信息及标题</p><ul><li>通过fontsize参数可以修改图像中字体的大小</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点0分到12点之间的温度变化图示&quot;</span>, fontsize=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182203392.png" alt="image-20240118220308250"></p><h3 id="图像保存">图像保存</h3><p># 保存图片到指定路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.savefig(<span class="string">&quot;test.png&quot;</span>)</span><br></pre></td></tr></table></figure><p>注意：plt.show()会释放figure资源，如果在显示图像之后保存图片将只能保存空图片。</p><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置显示中文字体</span></span><br><span class="line"></span><br><span class="line">mpl.rcParams[<span class="string">&quot;font.sans-serif&quot;</span>] = [<span class="string">&quot;SimHei&quot;</span>]</span><br><span class="line"><span class="comment"># 设置正常显示符号</span></span><br><span class="line">mpl.rcParams[<span class="string">&quot;axes.unicode_minus&quot;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line"></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line"><span class="comment"># 2.1 添加x,y轴刻度</span></span><br><span class="line"><span class="comment"># 构造x,y轴刻度标签</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 刻度显示</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 添加网格显示</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3 添加描述信息</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.4 图像保存</span></span><br><span class="line">plt.savefig(<span class="string">&quot;./test.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="例子：在一个坐标系中绘制多个图像">例子：在一个坐标系中绘制多个图像</h2><h3 id="多次plot">多次<strong>plot</strong></h3><p>需求：再添加一个城市的温度变化</p><p>收集到北京当天温度变化情况，温度在1度到3度。怎么去添加另一个在同一坐标系当中的不同图形，其实很简单只需要再次<strong>plot</strong>即可，但是需要区分线条，如下显示：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182206579.png" alt="image-20240118220602425"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加北京的温度数据</span></span><br><span class="line">y_beijing = [random.uniform(<span class="number">1</span>, <span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 绘制折线图</span></span><br><span class="line">plt.plot(x, y_shanghai)</span><br><span class="line"><span class="comment"># 使用多次plot可以画多个折线</span></span><br><span class="line">plt.plot(x, y_beijing, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br></pre></td></tr></table></figure><p>我们仔细观察，用到了两个新的地方，一个是对于不同的折线展示效果，一个是添加图例。</p><h3 id="设置图形风格">设置图形风格</h3><p>颜色和线的类型</p><table><thead><tr><th style="text-align:left">颜色标记</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">‘r’</td><td style="text-align:left">红色</td></tr><tr><td style="text-align:left">‘g’</td><td style="text-align:left">绿色</td></tr><tr><td style="text-align:left">‘b’</td><td style="text-align:left">蓝色</td></tr><tr><td style="text-align:left">‘c’</td><td style="text-align:left">青色</td></tr><tr><td style="text-align:left">‘m’</td><td style="text-align:left">品红</td></tr><tr><td style="text-align:left">‘y’</td><td style="text-align:left">黄色</td></tr><tr><td style="text-align:left">‘k’</td><td style="text-align:left">黑色</td></tr><tr><td style="text-align:left">‘w’</td><td style="text-align:left">白色</td></tr></tbody></table><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">简写</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">‘solid’ (默认)</td><td style="text-align:left">‘-’</td><td style="text-align:left">实线</td></tr><tr><td style="text-align:left">‘dotted’</td><td style="text-align:left">‘:’</td><td style="text-align:left">点虚线</td></tr><tr><td style="text-align:left">‘dashed’</td><td style="text-align:left">‘–’</td><td style="text-align:left">破折线</td></tr><tr><td style="text-align:left">‘dashdot’</td><td style="text-align:left">‘-.’</td><td style="text-align:left">点划线</td></tr><tr><td style="text-align:left">‘None’</td><td style="text-align:left">‘’ 或 ’ ’</td><td style="text-align:left">不画线</td></tr></tbody></table><h3 id="显示图例">显示图例</h3><p>注意：如果只在plt.plot()中设置label还不能最终显示出图例，还需要通过plt.legend()将图例显示出来。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 绘制折线图</span></span><br><span class="line">plt.plot(x, y_shanghai, label=<span class="string">&quot;上海&quot;</span>)</span><br><span class="line">\<span class="comment"># 使用多次plot可以画多个折线</span></span><br><span class="line">plt.plot(x, y_beijing, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, label=<span class="string">&quot;北京&quot;</span>)</span><br><span class="line"></span><br><span class="line">\<span class="comment"># 显示图例</span></span><br><span class="line">plt.legend(loc=<span class="string">&quot;best&quot;</span>)</span><br></pre></td></tr></table></figure><p>完整代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_beijing = [random.uniform(<span class="number">1</span>,<span class="number">3</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line">plt.plot(x, y_shanghai, label=<span class="string">&quot;上海&quot;</span>)</span><br><span class="line">plt.plot(x, y_beijing, color=<span class="string">&quot;r&quot;</span>, linestyle=<span class="string">&quot;--&quot;</span>, label=<span class="string">&quot;北京&quot;</span>)</span><br><span class="line"><span class="comment"># 2.1 添加x,y轴刻度</span></span><br><span class="line"><span class="comment"># 构造x,y轴刻度标签</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 刻度显示</span></span><br><span class="line"><span class="number">54</span></span><br><span class="line">plt.xticks(x[::<span class="number">5</span>], x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">plt.yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line"><span class="comment"># 2.2 添加网格显示</span></span><br><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment"># 2.3 添加描述信息</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># 2.4 图像保存</span></span><br><span class="line">plt.savefig(<span class="string">&quot;./test.png&quot;</span>)</span><br><span class="line"><span class="comment"># 2.5 添加图例</span></span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="例子：多个坐标系显示-—-plt-subplots-面向对象的画图方法">例子：多个坐标系显示**— plt.subplots(<strong>面向对象的画图方法</strong>)**</h2><p>如果我们想要将上海和北京的天气图显示在同一个图的不同坐标系当中，效果如下：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182214639.png" alt="image-20240118221403417"></p><p>可以通过subplots函数实现(旧的版本中有subplot，使用起来不方便)，推荐subplots函数</p><ul><li>matplotlib.pyplot.subplots(nrows=1, ncols=1, **fig_kw) 创建一个带有多个axes(坐标系/绘图区)的图</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Parameters:</span><br><span class="line">nrows, ncols : 设置有几行几列坐标系</span><br><span class="line"><span class="built_in">int</span>, optional, default: <span class="number">1</span>, Number of rows/columns of the subplot grid.</span><br><span class="line"></span><br><span class="line">Returns:</span><br><span class="line">fig : 图对象</span><br><span class="line">axes : 返回相应数量的坐标系</span><br><span class="line"></span><br><span class="line">设置标题等方法不同：</span><br><span class="line">set_xticks</span><br><span class="line">set_yticks</span><br><span class="line">set_xlabel</span><br><span class="line">set_ylabel</span><br></pre></td></tr></table></figure><p>关于axes子坐标系的更多方法：参考<a href="https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes">https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes</a></p><p>注意：**plt.<strong>函数名</strong>()**相当于面向过程的画图方法，**axes.set_<strong>方法名</strong>()**相当于面向对象的画图方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = <span class="built_in">range</span>(<span class="number">60</span>)</span><br><span class="line">y_shanghai = [random.uniform(<span class="number">15</span>, <span class="number">18</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_beijing = [random.uniform(<span class="number">1</span>, <span class="number">5</span>) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line"><span class="comment"># plt.figure(figsize=(20, 8), dpi=100)</span></span><br><span class="line">fig, axes = plt.subplots(nrows=<span class="number">1</span>, ncols=<span class="number">2</span>, figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.绘制图像</span></span><br><span class="line"><span class="comment"># plt.plot(x, y_shanghai, label=&quot;上海&quot;)</span></span><br><span class="line"><span class="comment"># plt.plot(x, y_beijing, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;北京&quot;)</span></span><br><span class="line">axes[<span class="number">0</span>].plot(x, y_shanghai, label=<span class="string">&quot;上海&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].plot(x, y_beijing, color=<span class="string">&quot;r&quot;</span>, linestyle=<span class="string">&quot;--&quot;</span>, label=<span class="string">&quot;北京&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.1 添加x,y轴刻度</span></span><br><span class="line"><span class="comment"># 构造x,y轴刻度标签</span></span><br><span class="line">x_ticks_label = [<span class="string">&quot;11点&#123;&#125;分&quot;</span>.<span class="built_in">format</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> x]</span><br><span class="line">y_ticks = <span class="built_in">range</span>(<span class="number">40</span>)</span><br><span class="line"><span class="comment"># 刻度显示</span></span><br><span class="line"><span class="comment"># plt.xticks(x[::5], x_ticks_label[::5])</span></span><br><span class="line"><span class="comment"># plt.yticks(y_ticks[::5])</span></span><br><span class="line">axes[<span class="number">0</span>].set_xticks(x[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">0</span>].set_xticklabels(x_ticks_label[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_xticks(x[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_yticks(y_ticks[::<span class="number">5</span>])</span><br><span class="line">axes[<span class="number">1</span>].set_xticklabels(x_ticks_label[::<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.2 添加网格显示</span></span><br><span class="line"><span class="comment"># plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)</span></span><br><span class="line">axes[<span class="number">0</span>].grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">axes[<span class="number">1</span>].grid(<span class="literal">True</span>, linestyle=<span class="string">&quot;--&quot;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.3 添加描述信息</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;时间&quot;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&quot;温度&quot;)</span></span><br><span class="line"><span class="comment"># plt.title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)</span></span><br><span class="line">axes[<span class="number">0</span>].set_xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">axes[<span class="number">0</span>].set_title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_xlabel(<span class="string">&quot;时间&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_ylabel(<span class="string">&quot;温度&quot;</span>)</span><br><span class="line">axes[<span class="number">1</span>].set_title(<span class="string">&quot;中午11点--12点某城市温度变化图&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 2.4 图像保存</span></span><br><span class="line">plt.savefig(<span class="string">&quot;./test.png&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 2.5 添加图例</span></span><br><span class="line"><span class="comment"># plt.legend(loc=0)</span></span><br><span class="line">axes[<span class="number">0</span>].legend(loc=<span class="number">0</span>)</span><br><span class="line">axes[<span class="number">1</span>].legend(loc=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.图像显示</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="折线图的应用场景">折线图的应用场景</h2><ul><li>呈现公司产品(不同区域)每天活跃用户数</li><li>呈现app每天下载数量</li><li>呈现产品新功能上线后,用户点击次数随时间的变化</li><li>拓展：画各种数学函数图像<ul><li>注意：plt.plot()除了可以画折线图，也可以用于画各种数学函数图像</li></ul></li></ul><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182216857.png" alt="image-20240118221623760" style="zoom:80%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 0.准备数据</span></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">1000</span>)</span><br><span class="line">y = np.sin(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">8</span>), dpi=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.绘制函数图像</span></span><br><span class="line">plt.plot(x, y)</span><br><span class="line"><span class="comment"># 2.1 添加网格显示</span></span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.显示图像</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h2 id="小结">小结</h2><ul><li>添加x,y轴刻度<ul><li>plt.xticks()</li><li>plt.yticks()</li><li>注意**:<strong>在传递进去的第一个参数必须是数字</strong>,<strong>不能是字符串</strong>,<strong>如果是字符串吗</strong>,**需要进行替换操作</li></ul></li><li>添加网格显示<ul><li>plt.grid(linestyle=“–”, alpha=0.5)</li></ul></li><li>添加描述信息<ul><li>plt.xlabel()</li><li>plt.ylabel()</li><li>plt.title()</li></ul></li><li>图像保存<ul><li>plt.savefig(“路径”)</li></ul></li><li>多次plot<ul><li>直接进行添加就OK</li></ul></li><li>显示图例<ul><li>plt.legend(loc=“best”)</li><li>注意**:<strong>一定要在</strong>plt.plot()<strong>里面设置一个</strong>label,<strong>如果不设置</strong>,**没法显示</li></ul></li><li>多个坐标系显示<ul><li>plt.subplots(nrows=, ncols=)</li></ul></li><li>折线图的应用<ul><li>1.应用于观察数据的变化</li><li>2.可是画出一些数学函数图像</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习--jupyter notebook的使用</title>
      <link href="/posts/afe89f5c.html"/>
      <url>/posts/afe89f5c.html</url>
      
        <content type="html"><![CDATA[<h1>机器学习–jupyter notebook的使用</h1><p>Jupyter项目是一个非盈利的开源项目，源于2014年的ipython项目，因为它逐渐发展为支持跨所有编程语言的交互式数据科学和科学计算</p><p>Jupyter Notebook，原名IPython Notbook，是IPython的加强网页版，一个开源Web应用程序</p><p>名字源自Julia、Python 和 R（数据科学的三种开源语言）</p><p>是一款程序员和科学工作者的编程**/<strong>文档</strong>/<strong>笔记</strong>/**展示软件</p><p><strong>.ipynb</strong>文件格式是用于计算型叙述的<strong>JSON</strong>文档格式的正式规范</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182116444.png" alt="image-20240118211659271"></p><ul><li>传统软件开发：工程／目标明确<ul><li>需求分析，设计架构，开发模块，测试</li></ul></li><li>数据挖掘：艺术／目标不明确<ul><li>目的是具体的洞察目标，而不是机械的完成任务</li><li>通过执行代码来理解问题</li><li>迭代式地改进代码来改进解决方法</li></ul></li></ul><p>实时运行的代码、叙事性的文本和可视化被整合在一起，方便使用代码和数据来讲述故事</p><h2 id="相关库和jupyter的安装">相关库和jupyter的安装</h2><p>看这个：<a href="https://www.cnblogs.com/chjxbt/p/10517952.html">Python虚拟环境的搭建 - chjxbt - 博客园 (cnblogs.com)</a>搭建好python的虚拟环境。</p><p>逐行在命令行输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkvirtualenv ai</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install matplotlib</span><br><span class="line">pip install numpy</span><br><span class="line">pip install pandas</span><br><span class="line">pip install tables</span><br><span class="line">pip install jupyter</span><br></pre></td></tr></table></figure><h2 id="jupyter-启动！">jupyter 启动！</h2><p>环境搭建好后，本机输入jupyter notebook命令，会自动弹出浏览器窗口打开Jupyter Notebook</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">进入虚拟环境</span></span><br><span class="line">workon ai</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">输入命令</span></span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure><h3 id="一些基本操作">一些基本操作</h3><ul><li><p>命令模式：按ESC进入</p><ul><li>Y ，cell切换到Code模式</li><li>M ，cell切换到Markdown模式</li><li>A ，在当前cell的上面添加cell</li><li>B ，在当前cell的下面添加cell</li></ul></li><li><p>两种模式通用快捷键</p><ul><li><strong>Shift+Enter</strong> ，执行本单元代码，并跳转到下一单元</li><li><strong>Ctrl+Enter</strong> ，执行本单元代码，留在本单元</li></ul></li></ul><p>同时，其他小工具请安装jupyter_contrib_nbextensions库</p><p>安装该库的命令如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install jupyter_contrib_nbextensions</span><br></pre></td></tr></table></figure><p>然后执行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter contrib nbextension install --user --skip-running-check</span><br></pre></td></tr></table></figure><p>在原来的基础上勾选： “Table of Contents” 以及 “Hinterland”</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401182145611.png" alt="image-20240118214521386"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>人工智能概述</title>
      <link href="/posts/4743dd5a.html"/>
      <url>/posts/4743dd5a.html</url>
      
        <content type="html"><![CDATA[<h1>人工智能概述</h1><p>入门人工智能，了解人工智能是什么。为啥发展起来，用途是什么，是最重要也是最关键的事情。大致有以下思路。</p><ol><li>人工智能发展历程</li><li>机器学习定义以及应用场景</li><li>监督学习，无监督学习</li><li>监督学习中的分类、回归特点</li><li>知道机器学习的开发流程</li></ol><h2 id="人工智能发展历程">人工智能发展历程</h2><ul><li>人工智能在现实生活中的应用</li><li>人工智能发展必备三要素</li><li>人工智能和机器学习、深度学习三者之间的关系</li></ul><h3 id="人工智能在现实生活中的应用">人工智能在现实生活中的应用</h3><p>虽然人工智能在今天可能是一个流行词，但在明天，它可能会成为我们日常生活的标准一部分。事实上，它已经在这里了。</p><p>例如，自动驾驶汽车，学校门禁的人脸识别系统，手机语音助手，以及我们在各个平台上看视频的首页推荐。都是用到人工智能的。</p><h3 id="人工智能发展必备三要素">人工智能发展必备三要素</h3><ul><li>数据</li><li>算法</li><li>计算力<ul><li>CPU,GPU,TPU</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181832641.png" alt="image-20240118183206567"></p><ul><li><p>计算力之CPU、GPU对比：</p><ul><li><p>CPU主要适合I\O密集型的任务</p></li><li><p>GPU主要适合计算密集型任务</p></li></ul></li></ul><p>CPU和GPU的区别：</p><p><a href="http://www.sohu.com/a/201309334_468740">http://www.sohu.com/a/201309334_468740</a></p><h3 id="人工智能、机器学习和深度学习">人工智能、机器学习和深度学习</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181834296.png" alt="image-20240118183437094"></p><ul><li>人工智能和机器学习，深度学习的关系<ul><li>机器学习是人工智能的一个实现途径</li><li>深度学习是机器学习的一个方法发展而来</li></ul></li></ul><h3 id="发展历程">发展历程</h3><h4 id="图灵测试">图灵测试</h4><p>测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。多次测试（一般为<strong>5min</strong>之内），如果有超过**30%**的测试者不能确定被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能.</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181837161.png" alt="image-20240118183738033"></p><p>人工智能主要分支</p><ul><li>计算机视觉</li><li>语音识别</li><li>文本挖掘/分类</li><li>机器翻译</li><li>机器人</li></ul><h2 id="机器学习定义以及应用场景">机器学习定义以及应用场景</h2><h3 id="什么是机器学习">什么是机器学习</h3><p>机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181840056.png" alt="image-20240118184021941"></p><h3 id="机器学习工作流程">机器学习工作流程</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181841120.png" alt="image-20240118184109788"></p><ul><li>机器学习工作流程总结<ul><li>**1.**获取数据</li><li>**2.**数据基本处理</li><li>**3.**特征工程</li><li><strong>4.<strong>机器学习</strong>(<strong>模型训练</strong>)</strong></li><li>**5.**模型评估</li></ul></li></ul><p>结果达到要求，上线服务</p><p>没有达到要求，重新上面步骤</p><h3 id="获取到的数据集介绍">获取到的数据集介绍</h3><ul><li>数据简介</li></ul><p>在数据集中一般：</p><p>一行数据我们称为一个<strong>样本</strong></p><p>一列数据我们成为一个<strong>特征</strong></p><p>有些数据有目标值（标签值），有些数据没有目标值</p><ul><li>数据类型构成：</li></ul><p>数据类型一：特征值+目标值（目标值是连续的和离散的）</p><p>数据类型二：只有特征值，没有目标值</p><p>数据分割：</p><ul><li>机器学习一般的数据集会划分为两个部分：<ul><li>训练数据：用于训练，构建模型</li><li>测试数据：在模型检验时使用，用于评估模型是否有效</li></ul></li><li>划分比例<ul><li>训练集：70% 80% 75%</li><li>测试集：30% 20% 25%</li></ul></li></ul><h4 id="特征工程">特征工程</h4><p>特征工程是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程。</p><p>意义：会直接影响机器学习的效果</p><ul><li>注：业界广泛流传：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</li></ul><p>特征工程包含内容</p><ul><li>特征提取</li><li>特征预处理</li><li>特征降维</li></ul><p>特征提取：例如将文字变成机器可以识别的语言</p><p>特征预处理：通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程</p><p>特征降维：指在某些限定条件下，降低随机变量**(<strong>特征</strong>)<strong>个数，得到一组</strong>“<strong>不相关</strong>”**主变量的过程。；例如将3D图像变换成2D图像的过程。</p><h2 id="机器学习算法分类">机器学习算法分类</h2><p>根据数据集组成不同，可以把机器学习算法分为：</p><ul><li>监督学习</li><li>无监督学习</li><li>半监督学习</li><li>强化学习</li></ul><h3 id="监督学习">监督学习</h3><ul><li>输入数据是由输入特征值和目标值所组成。<ul><li>函数的输出可以是一个连续的值(称为回归），</li><li>或是输出是有限个离散值（称作分类）。</li></ul></li></ul><h4 id="回归">回归</h4><p>例如：预测房价，根据样本集拟合出一条连续曲线。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181857822.png" alt="image-20240118185708552"></p><h4 id="分类">分类</h4><p>例如：根据肿瘤特征判断良性还是恶性，得到的是结果是“良性”或者“恶性”，是离散的。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181857180.png" alt="image-20240118185726060"></p><h3 id="无监督学习">无监督学习</h3><ul><li>输入数据是由输入特征值组成，没有目标值<ul><li>输入数据没有被标记，也没有确定的结果。样本数据类别未知；</li><li>需要根据样本间的相似性对样本集进行类别划分。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181858613.png" alt="image-20240118185828504"></p><h3 id="半监督学习">半监督学习</h3><p>训练集同时包含有标记样本数据和未标记样本数据。</p><p>他与监督学习，无监督学习的区别就是模型在训练时需要人工标注的标签信息，监督学习利用大量的标注数据来训练模型，使模型最终学习到输入和输出标签之间的相关性；半监督学习利用少量有标签的数据和大量无标签的数据来训练网络；而无监督学习不依赖任何标签值，通过对数据内在特征的挖掘，找到样本间的关系，比如聚类。</p><p>监督学习：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181901832.png" alt="image-20240118190114710"></p><p>半监督学习：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181901225.png" alt="image-20240118190135101"></p><h3 id="强化学习">强化学习</h3><p>实质是make decisions 问题，即<strong>自动进行决策</strong>，并且可以<strong>做连续决策</strong>。</p><p>举例：（学下棋）</p><p>小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。</p><p>小孩就是 <strong>agent</strong>，他试图通过采取行动（即行走）来操纵环境（行走的表面），并且从一个状态转变到另一个状态（即他走的每一步），当他</p><p>完成任务的子任务（即走了几步）时，孩子得到奖励（给巧克力吃），并且当他不能走路时，就不会给巧克力。</p><p>主要包含五个元素：agent, action, reward, environment, observation；</p><p>强化学习的目标就是获得最多的累计奖励。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202401181903389.png" alt="image-20240118190330019"></p><table><thead><tr><th></th><th>监督学习</th><th>强化学习</th></tr></thead><tbody><tr><td>反馈映射</td><td>输出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出。</td><td>输出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。</td></tr><tr><td>反馈时间</td><td>做了比较坏的选择会立刻反馈给算法。</td><td>结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏。</td></tr><tr><td>输入特征</td><td>输入是独立同分布的。</td><td>面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入。</td></tr></tbody></table><h2 id="模型评估">模型评估</h2><p>模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。</p><p>按照数据集的目标值不同，可以把模型评估分为分类模型评估和回归模型评估。</p><ul><li>准确率<ul><li>预测正确的数占样本总数的比例。</li></ul></li><li>其他评价指标：精确率、召回率、<strong>F1-score</strong>、<strong>AUC</strong>指标等</li></ul><h3 id="拟合">拟合</h3><p>模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类：过拟合、欠拟合。</p><p>在训练过程中，你可能会遇到如下问题：</p><p>训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？</p><p>当算法在某个数据集当中出现这种情况，可能就出现了拟合问题。</p><p>欠拟合：模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。</p><p>过拟合：所建的机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在测试数据集中表现不佳。</p><h2 id="Azure机器学习模型搭建实验"><strong>Azure</strong>机器学习模型搭建实验</h2><p>可以进行很简便的图形化训练。</p><p>Azure Machine Learning（简称“AML”）是微软在其公有云Azure上推出的基于Web使用的一项机器学习服务，机器学习属人工智能的一个分支，它技术借助算法让电脑对大量流动数据集进行识别。这种方式能够通过历史数据来预测未来事件和行为，其实现方式明显优于传统的商业智能形式。</p><p>微软的目标是简化使用机器学习的过程，以便于开发人员、业务分析师和数据科学家进行广泛、便捷地应用。</p><p>这款服务的目的在于“将机器学习动力与云计算的简单性相结合”。</p><p>AML目前在微软的Global Azure云服务平台提供服务，用户可以通过站点：<strong><a href="https://studio.azureml.net/">https://studio.azureml.net/</a></strong> 申请免费试用。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<h1>神经网络可以计算任何函数的可视化证明</h1><p>对于神经网络，一个显著的事实就是它可以计算任何函数。</p><p>如下：不管该函数如何，总有神经网络能够对任何可能的输入x，输出值f（x）</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172051164.png" alt="image-20231217205116099" style="zoom:67%;"><p>即使函数有很多输入和输出，$f=f(x_1,\cdots,x_m)$，结果也是成立的。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172040247.png" alt="image-20231217204027194"></p><p>结果表明神经网络具有一种普遍性，无论我们想计算什么函数，都能用神经网络实现。</p><p>普遍性定理在计算机科学领域中特别常见，我们几乎可以将生活中的任何过程看作函数的计算，例如基于一段音乐识别曲目，其实也能将其视为计算一个函数，或者将中文翻译成英文”，又或者根据一个mp4视频文件生成对电影情节的描述并讨论表演水平。</p><p>普遍性指神经网络可以做各种事情。本质上就是通过一定的规律由a变b的性质。</p><p> </p><h2 id="两个预先声明">两个预先声明</h2><p>在解释为什么普遍性成立之前，需要给“神经网络可以计算任意函数”两个预先声明。</p><p>第一点，<code>这句话不是说神经网络可用于准确计算任何函数，而是说可以获得不错的近似</code>。可以通过增加隐藏神经元的数量来提升近似的准确度。</p><p>例如一个网络中含有五个隐藏神经元的话肯定比含有3个隐藏神经元更好得近似结果。</p><p>第二点，可以按照上述方式近似的函数其实是连续函数。<code>如果函数不是连续的，即会有突然的“跳跃”，那么通常无法使用一个神经网络进行近似</code>。</p><p>这并不意外，因为神经网络计算的是输人的连续函数。然而，即使那些需要计算的函数是不连续的，连续的近似一般也足够好了。这样的话，就可以用神经网络来近似了。实践中，这通常不是一个严重的限制。</p><p>总结一下，关于普遍性定理，更加准确的表述是：==包含隐藏层的神经网络可按照任意给定的准确度来近似任何连续函数。==</p><p> </p><h2 id="一个输入和一个输出的普遍性">一个输入和一个输出的普遍性</h2><p>为了理解如何构造一个神经网络来计算了，先从只包含一个隐藏层的神经网络开始，它有两个隐藏神经元，以及由单个输出神经元形成的输出层。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172041876.png" alt="image-20231217204132828" style="zoom:67%;"><p>为了理解神经网络组件的工作机制，下面着重研究顶部的隐藏神经元。了解顶部隐藏神经元的权重w、偏置b和输出曲线的关系。思考如何通过顶部隐藏神经元的变化计算函数。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172041491.png" alt="image-20231217204145422" style="zoom:67%;"><p>如前所述，隐藏神经元计算的是$\sigma(wx+b)$，其中$\sigma(z)\equiv1/(1+\mathrm{e}^{-z})$是sigmoid函数。前面频繁使用这个代数形式，这里为了证明普遍性会完全忽略其代数性质，而会在图像中调整并观察形状来获得更多认识。<br>一开始增大偏置b的值。当偏置增加时，图形向左移动，但是形状保持不变。<br>接着减小偏置。当偏置减小时，图形向右移动，但形状仍没有变化。</p><p>然后将权重减小到大约2或3.当权重减小时，曲线向两边拉宽了。可以通过改变偏置让曲线保持在框内。<br>最后，把权重增加到超过100.这会使得曲线变得越来越陡，最终看上去像阶跃函数。尝试调整偏置，使得阶跃位置靠近x=0.3.</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172042343.png" alt="image-20231217204200291" style="zoom:67%;"><p>你能给权重增加很⼤的值来简化我们的分析，使得输出实际上是个⾮常接近的阶跃函数。下⾯我画出了当权重为 <em>w</em> = 999 时从顶部隐藏神经元的输出。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172042604.png" alt="image-20231217204258538" style="zoom: 67%;"><p>实际上处理阶跃函数⽐⼀般的 S 型函数更加容易。很显然相比于思考把⼀串 S 形状的曲线加起来是什么，我们只考虑在输出层我们把所有隐藏神经元的贡献值加在⼀起，分析⼀串阶跃函数的和是很容易的。</p><p>所以假设我们的隐藏神经元输出阶跃函数会使事情更容易。更具体些，我们把权重 <em>w</em> 固定在⼀个⼤的值，然后通过修改偏置设置阶跃函数的位置。</p><p>当然，把输出作为⼀个阶跃函数处理只是⼀个近似，但是它是⼀个⾮常好的近似，现在我们把它看作是精确的。</p><p> </p><p><em>x</em> 取何值时阶跃会发⽣呢？换种⽅式，阶跃的位置如何取决于权重和偏置？</p><p>得出的结论是：阶跃的位置和 <em>b</em> 成正⽐，和 <em>w</em> 成反⽐。</p><p>实际上，阶跃发⽣在$ s = −b/w $的位置，正如图中通过修改权重和偏置看到的：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172056203.png" alt="image-20231217205626143" style="zoom:67%;"><p>这将⽤仅仅⼀个参数 <em>s</em> 来极⼤简化我们描述隐藏神经元的⽅式，这就是阶跃位置，$s = −b/w$</p><p>试着修改下图中的 <em>s</em>:<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172057169.png" alt="image-20231217205728098" style="zoom:67%;"></p><p>正如上⾯注意到的，我们隐式地设置输⼊上的权重 <em>w</em> 为⼀些⼤的值 —— ⼤到阶跃函数能够很好地近似。通过选择偏置 $b = -ws$，我们能很容易地将⼀个以这种⽅式参数化的神经元转换回常⽤的模型。</p><p>我们假设隐藏神经元在计算以阶跃点$ s_1 $（顶部神经元）和$ s_2 $（底部神经元）参数化的节约函数。它们各⾃有输出权重 $w_1 $和$w_2$。是这样的⽹络：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172100809.png" alt="image-20231217210044744" style="zoom:67%;"><p>右边的绘图是隐藏层的<strong>加权输出</strong> $w_{1}a_{1}+w_{2}a_{2}.$。(注意：整个网络输出是$\sigma(w_{1}a_{1}+w_{2}a_{2}+b)$)这⾥ <em>a</em>1 和 <em>a</em>2 各⾃是顶部和底部神经元的输出。这些输出由 <em>a</em> 表⽰，是因为它们通常被称为神经元的<strong>激活值（activations）</strong>。</p><p>试着增加和减⼩顶部隐藏神经元的阶跃点 <em>s</em>1。感受下这如何改变隐藏层的加权输出。尤其值得去理解当 <em>s</em>1 经过 <em>s</em>2 时发⽣了什么。你会看到这时图形发⽣了变化，因为我们从顶部隐藏神经元先被激活的情况变成了底部隐藏神经元先被激活的情况。</p><p>类似地，试着操作底部隐藏神经元的阶跃点 <em>s</em>2，感受下这如何改变隐藏神经元混合后的输出。</p><p>尝试增加和减少每⼀个输出权重。注意，这如何调整从各⾃的隐藏神经元的贡献值。当⼀个权重是 0 时会发⽣什么？</p><p>最后，试着设置 <em>w</em>1 为 0*.<em>8，<em>w</em>2 为 <em>−</em>0</em>.<em>8。你得到⼀个“凸起”的函数，它从点 <em>s</em>1 开始，到点</em>s<em>2 结束，⾼为 0</em>.*8。例如，加权后的输出可能看起来像这样：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172106307.png" alt="image-20231217210626243" style="zoom:67%;"><p>当然，我们可以调整为任意的凸起⾼度。让我们⽤⼀个参数，<em>h</em>，来表⽰⾼度。为了减少混乱我也会移除“<em>s</em>1 = <em>. . .</em>”和“<em>w</em>1 = <em>. . .</em>”的标记。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172108563.png" alt="image-20231217210840492" style="zoom:67%;"><p>试着将 <em>h</em> 值改⼤或改⼩，看看凸起的⾼度如何改变。试着把⾼度值改为负数，观察发⽣了什么。并且试着改变阶跃点来看看如何改变凸起的形状。</p><p>顺便提⼀下，你会注意到，我们⽤神经元的⽅式，可以认为不只是在图形的⻆度，⽽且是更传统的编程形式，作为 if-then-else 的⼀种声明，即：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">input</span> &gt;= step point:</span><br><span class="line">add <span class="number">1</span> to the weighted output</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">add <span class="number">0</span> to the weighted output</span><br></pre></td></tr></table></figure><p>对于⼤部分内容，我将坚持以图形的考虑⻆度。但在接下来的内容中，你有时可能会发现交换考虑⻆度是有帮助的，并且考虑 if-then-else 的形式。</p><p>我们可以⽤凸起制作的技巧来得到两个凸起，通过把两对隐藏神经元⼀起填充进同⼀个⽹络：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172111773.png" alt="image-20231217211158712" style="zoom:67%;"><p>这⾥我抑制了权重，只是简单地在每对隐藏神经元上写了 <em>h</em> 的值。</p><p>更普遍地，我们可以利⽤这个思想来取得我们想要的任何⾼度的峰值。尤其，我们可以把间隔 [0*,* 1] 分成⼤量的⼦区间，⽤ <em>N</em> 表⽰，并利⽤ <em>N</em> 对隐藏神经元来设置任意期望⾼度的峰值。让我们看看 <em>N</em> = 5 这如何⼯作。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172115966.png" alt="image-20231217211500877" style="zoom:67%;"><p>让我们回想在最开始绘制出的函数：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172133339.png" alt="image-20231217213351283" style="zoom:67%;"><p>这个函数其实是：</p><p>$f(x)=0.2+0.4x^2+0.3x\sin(15x)+0.05\cos(50x)$</p><p><em>x</em> 取值范围从 0 到 1，<em>y</em> 轴取值为 0 到 1。</p><p>我们再试着用神经网络的方法去估计它。</p><p>在我们上⾯的⽹络中，我们已经分析了隐藏神经元输出的加权组合$\sum_jw_ja_j$。我们现在知道如何在这个量上获得⼤量的控制。但是，正如我前⾯所指出的，这个量不是⽹络的输出。⽹络输出的是$\sigma(\sum_{j}w_{j}a_{j}+b)$，其中 <em>b</em> 是在输出神经元的偏置。有什么办法可以实现对⽹络的实际输出控制吗？</p><p>解决⽅案是设计⼀个神经⽹络，它的隐藏层有⼀个加权输出 $\sigma^{-1}\circ f(x)$，其中 $\sigma^{-1}$ 是 $\sigma$ 函数的倒数。也就是说，我们希望从隐藏层的加权输出是：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172136984.png" alt="image-20231217213630926" style="zoom:67%;"><p>根据图形的需求我们大概可以调整到如下地步：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172138018.png" alt="image-20231217213853926" style="zoom:67%;"></p><p>在已经解决了所有⽹络的必要元素来近似计算函数 <em>f</em>(<em>x</em>)！这只是⼀个粗略的近似，但我们可以很容易地做得更好，仅仅通过增加隐藏神经元对的数量，分配更多的凹凸形状。</p><p>于此我们已经理解了如何通过提⾼隐层神经元的数⽬来提⾼近似的质量。</p><p> </p><h2 id="多个输入变量">多个输入变量</h2><p>我们从考虑当⼀个神经元有两个输⼊会发⽣什么开始：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172151293.png" alt="image-20231217215128242" style="zoom:80%;"><p>这⾥，我们有输⼊ <em>x</em> 和 <em>y</em>，分别对应于权重 <em>w</em>1 和 <em>w</em>2，以及⼀个神经元上的偏置 <em>b</em>。让我们把权重 <em>w</em>2 设置为 0，然后反复琢磨第⼀个权重 <em>w</em>1 和偏置 <em>b</em>，看看他们如何影响神经元的输出：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172152201.png" alt="image-20231217215203128" style="zoom:67%;"><p>为当我们增加权重 <em>w</em>1 到 <em>w</em>1 = 100，同时 <em>w</em>2 保持 0 不变时会发⽣什么？</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172154978.png" alt="image-20231217215408880"></p><p>正如我们前⾯讨论的那样，随着输⼊权重变⼤，输出接近⼀个阶跃函数。不同的是，现在的阶跃函数是在三个维度。也如以前⼀样，我们可以通过改变偏置的位置来移动阶跃点的位置。阶跃点的实际位置是 $s_x\equiv-b/w_1$。</p><p>让我们⽤阶跃点位置作为参数重绘上⾯的阶跃函数：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172156193.png" alt="image-20231217215648115" style="zoom:67%;"><p>当然，通过使得 <em>y</em> 输⼊上的权重取⼀个⾮常⼤的值（例如，<em>w</em>2 = 1000），<em>x</em> 上的权重等于 0，即 <em>w</em>1 = 0，来得到⼀个 <em>y</em></p><p>轴⽅向的阶跃函数也是可⾏的，</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172157903.png" alt="image-20231217215751828" style="zoom:67%;"><p>再⼀次，神经元上的数字是阶跃点，在这个情况下数字上的⼩ <em>y</em> 提醒我们阶跃是在 <em>y</em> 轴⽅向。我本来可以明确把权重标记在 <em>x</em> 和 <em>y</em> 输⼊上，但是决定不这么做，因为这会把图⽰弄得有些杂乱。但是记住⼩ <em>y</em> 标记含蓄地告诉我们 <em>y</em> 权重是个⼤的值，<em>x</em> 权重为 0。</p><p>我们可以⽤我们刚刚构造的阶跃函数来计算⼀个三维的凹凸函数。为此，我们使⽤两个神经元，每个计算⼀个 <em>x</em> ⽅向的阶跃函数。然后我们⽤相应的权重 <em>h</em> 和 <em>−h</em> 将这两个阶跃函数混合，这⾥ <em>h</em> 是凸起的期望⾼度。所有这些在下⾯图⽰中说明：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172159780.png" alt="image-20231217215932698" style="zoom:67%;"><p>同理，使用y方向实现结果如下：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172201042.png" alt="image-20231217220139940" style="zoom:67%;"></p><p>让我们考虑当我们叠加两个凹凸函数时会发⽣什么，⼀个沿 <em>x</em> ⽅向，另⼀个沿 <em>y</em> ⽅向，两者都有⾼度 <em>h</em>：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172203442.png" alt="image-20231217220318359" style="zoom:67%;"><p>试着改变参数 <em>h</em>。正如你能看到，这引起输出权重的变化，以及 <em>x</em> 和 <em>y</em> 上凹凸函数的⾼度。</p><p>我们构建的有点像是⼀个塔型函数：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172206807.png" alt="image-20231217220637737" style="zoom:67%;"></p><p>如果我们能构建这样的塔型函数，那么我们能使⽤它们来近似任意的函数，仅仅通过在不同位置累加许多不同⾼度的塔：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172207361.png" alt="image-20231217220733289" style="zoom:67%;"><p>当然，我们还没有解决如何构建⼀个塔型函数。我们已经构建的看起来像⼀个中⼼塔，⾼度为 2<em>h</em>，周围由⾼原包围，⾼度为 <em>h</em>。</p><p>但是我们能制造⼀个塔型函数。记得前⾯我们看到神经元能被⽤来实现⼀个 if-then-else 的声明：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="built_in">input</span> &gt;= threshold:</span><br><span class="line">output <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">output <span class="number">0</span></span><br></pre></td></tr></table></figure><p>这是⼀个只有单个输⼊的神经元。我们想要的是将⼀个类似的想法应⽤到隐藏神经元的组合输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> combined output <span class="keyword">from</span> hidden neurons &gt;= threshold:</span><br><span class="line">output <span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">output <span class="number">0</span></span><br></pre></td></tr></table></figure><p>如果我们选择适当的阈值 —— ⽐如，3*h/*2，这是⾼原的⾼度和中央塔的⾼度中间的值——我们可以把⾼原下降到零，并且依旧矗⽴着塔。</p><p>请注意，我们现在正在绘制整个⽹络的输出，⽽不是只从隐藏层的加权输出。这意味着我们增加了⼀个偏置项到隐藏层的加权输出，并应⽤ S 型函数。</p><p>你能找到 <em>h</em> 和 <em>b</em> 的值，能产⽣⼀个塔型吗？这有点难，所以如果你想了⼀会⼉还是困住，这是有两个提⽰：</p><p>（1）为了让输出神经元显⽰正确的 if-then-else ⾏为，我们需要输⼊的权重（所有 <em>h</em> 或 <em>−h</em>）变得很⼤；</p><p>（2）<em>b</em> 的值决定了 if-then-else 阈值的⼤⼩。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172210615.png" alt="image-20231217221020530" style="zoom:67%;"><p>在初始参数时，输出看起来像⼀个前⾯图形在它的塔型和⾼原上的平坦的版本。为了得到期望的⾏为，我们增加参数 <em>h</em> 直到它变得很⼤。这就给出了 if-then-else 做阈值的⾏为。其次，为了得到正确的阈值，我们选择 <em>b</em> <em>≈ −</em>3*h/*2。尝试⼀下，看看它是如何⼯作的！这是它看起来的样⼦，我们使⽤ <em>h</em> = 10：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172211959.png" alt="image-20231217221155867" style="zoom:67%;"><p>甚⾄对于这个相对适中的 <em>h</em> 值，我们得到了⼀个相当好的塔型函数。当然，我们可以通过更进⼀步增加 <em>h</em> 并保持偏置 <em>b</em> = <em>−</em>3*h/*2 来使它如我们所希望的那样。</p><p>让我们尝试将两个这样的⽹络组合在⼀起，来计算两个不同的塔型函数。为了使这两个⼦⽹络更清楚，我把它们放在如下所⽰的分开的⽅形区域：每个⽅块计算⼀个塔型函数，使⽤上⾯描述的技术。右边的图上显⽰了第⼆个隐藏层的加权输出，即，它是⼀个加权组合的塔型函数。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172214667.png" alt="image-20231217221401557" style="zoom:67%;"><p>尤其你能看到通过修改最终层的权重能改变输出塔型的⾼度。</p><p>同样的想法可以⽤在计算我们想要的任意多的塔型。我们也可以让它们变得任意细，任意⾼。结果，我们可以确保第⼆个隐藏层的加权输出近似与任意期望的⼆元函数：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172214421.png" alt="image-20231217221436349" style="zoom:67%;"></p><p>尤其通过使第⼆个隐藏层的加权输出为 $\sigma^{-1}\circ f$ 的近似，我们可以确保⽹络的输出可以是任意期望函数 <em>f</em> 的近似。</p><p>超过两个变量的函数会怎样？让我们试试三个变量 <em>x</em>1*, x<em>2</em>, x*3。下⾯的⽹络可以⽤来计算⼀个四维的塔型函数：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172215902.png" alt="image-20231217221525831" style="zoom:67%;"><p>这⾥，<em>x</em>1*, x<em>2</em>, x<em>3 表⽰⽹络的输⼊。<em>s</em>1</em>, t<em>1 等等是神经元的阶跃点 —— 即，第⼀层中所有的权重是很⼤的，⽽偏置被设置为给出阶跃点 <em>s</em>1</em>, t<em>1</em>, s<em>2</em>, . . .<em>。第⼆层中的权重交替设置为 +<em>h,</em> <em>−h</em>，其中 <em>h</em> 是⼀个⾮常⼤的数。输出偏置为 <em>−</em>5</em>h/*2。</p><p>这个⽹络计算这样⼀个函数，当三个条件满⾜时：<em>x</em>1 在 <em>s</em>1 和 <em>t</em>1 之间；<em>x</em>2 在 <em>s</em>2 和 <em>t</em>2 之间；<em>x</em>3 在 <em>s</em>3 和 <em>t</em>3 之间，输出为 1。其它情况⽹络输出为 0。即，这个塔型在输⼊空间的⼀个⼩的区域输出为 1，其它情况输出 0。</p><p>通过组合许多个这样的⽹络我们能得到任意多的塔型，如此可近似⼀个任意的三元函数。对于 <em>m</em> 维可⽤完全相同的思想。唯⼀需要改变的是将输出偏置设为 (<em>−m</em> + 1*/*2)<em>h</em>，为了得到正确的夹在中间的⾏为来弄平⾼原。</p><p>好了，所以现在我们知道如何⽤神经⽹络来近似⼀个多元的实值函数。对于$f(x_{1},\ldots,x_{m})\in R^n $的向量函数怎么样？当然，这样⼀个函数可以被视为 <em>n</em> 个单独的实值函数：，$\begin{aligned}f<sup>1(x_1,\ldots,x_m)\end{aligned}$,$f</sup>2(x_1,\ldots,x_m)$ 等等。所以我们创建⼀个⽹络来近似 $ f<sup>1$，另⼀个来近似$f</sup>2$，如此等等。然后简单地把这些⽹络都组合起来。所以这也很容易应付。</p><p> </p><h2 id="S-型神经元的延伸">S 型神经元的延伸</h2><p>我们已经证明了由 S 型神经元构成的⽹络可以计算任何函数。回想下在⼀个 S 型神经元中，输⼊ <em>x</em>1*, x<em>2</em>, . . .* 导致输出$\sigma(\sum_jw_jx_j+b)$，这⾥$W_j$是权重，<em>b</em> 是偏置，⽽ <em>σ</em> 是 S 型函数：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172221399.png" alt="image-20231217222128326" style="zoom:67%;"><p>如果我们考虑⼀个不同类型的神经元，它使⽤其它激活函数，⽐如如下的 <em>s</em>(<em>z</em>)，会怎样？</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172221694.png" alt="image-20231217222144628" style="zoom:67%;"><p>更确切地说，我们假定如果神经元有输⼊ <em>x</em>1*, x<em>2</em>, . . .<em>，权重 w</em>1*, w<em>2</em>, . . . 和偏置 b*，那么输出*$s(\sum_jw_jx_j+b)$。我们可以使⽤这个激活函数来得到⼀个阶跃函数，正如⽤ S 型函数做过的⼀样。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172223601.png" alt="image-20231217222306503" style="zoom:67%;"><p>试着加⼤上图中的权重，⽐如 <em>w</em> = 100，你将得到：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172223147.png" alt="image-20231217222321066" style="zoom:67%;"><p>正如使⽤ S 型函数的时候，这导致激活函数收缩，并最终变成⼀个阶跃函数的很好的近似。试着改变偏置，然后你能看到我们可以设置我们想要的阶跃位置。所以我们能使⽤所有和前⾯相同的技巧来计算任何期望的函数。</p><p><em>s</em>(<em>z</em>) 需要什么样的性质来满⾜这样的结果呢？我们确实需要假定 <em>s</em>(<em>z</em>) 在$s(z)\text{ 在 }z\to-\infty\text{ 和 }z\to\infty $时是定义明确的。这两个界限是在我们的阶跃函数上取的两个值。我们也需要假定这两个界限彼此不同。如果它们不是这样，就没有阶跃，只是⼀个简单的平坦图形！但是如果激活函数 <em>s</em>(<em>z</em>)满⾜这些性质，基于这样⼀个激活函数的神经元可普遍⽤于计算。</p><p> </p><h2 id="修补阶跃函数">修补阶跃函数</h2><p>⽬前为⽌，我们假定神经元可以准确⽣成阶跃函数。这是⼀个⾮常好的近似，但也仅仅是近似。实际上，会有⼀个很窄的故障窗⼝，如下图说明，在这⾥函数会表现得和阶跃函数⾮常不同。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172224759.png" alt="image-20231217222453686" style="zoom:67%;"><p>在这些故障窗⼝中我给出的普遍性的解释会失败。</p><p>现在，它不是⼀个很严重的故障。通过使得输⼊到神经元的权重为⼀个⾜够⼤的值，我们能把这些故障窗⼝变得任意⼩。当然，我们可以把故障窗⼝窄过我在上⾯显⽰的 —— 窄得我们的眼睛都看不到。所以也许我们可以不⽤过于担⼼这个问题。</p><p>尽管如此，有⼀些⽅法解决问题是很好的。</p><p>实际上，这个问题很容易解决。让我们看看只有⼀个输⼊和⼀个输出的神经⽹络如何修补其计算函数。同样的想法也可以解决有更多输⼊和输出的问题。</p><p>特别地，假设我们想要我们的⽹络计算函数 <em>f</em>。和以前⼀样，我们试着设计我们的⽹络，使得隐藏神经元的加权输出是 $\sigma^{-1}\circ f(x)$：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172225637.png" alt="image-20231217222547571" style="zoom:67%;"><p>如果我们要使⽤前⾯描述的技术做到这⼀点，我们会使⽤隐藏神经元产⽣⼀系列的凹凸函数：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172226765.png" alt="image-20231217222605698" style="zoom:67%;"><p>再说⼀下，我夸⼤了图上的故障窗⼝⼤⼩，好让它们更容易看到。很明显如果我们把所有这些凹凸函数加起来，我们最终会得到⼀个合理的 $\sigma^{-1}\circ f(x)$的近似，除了那些故障窗⼝。</p><p>假设我们使⽤⼀系列隐藏神经元来计算我们最初的⽬标函数的⼀半，即 $\sigma^{-1}\circ f(x) /2$，⽽不是使⽤刚刚描述的近似。当然，这看上去就像上⼀个图像的缩⼩的版本：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172226469.png" alt="image-20231217222658380" style="zoom:67%;"></p><p>并且假设我们使⽤另⼀系列隐藏神经元来计算⼀个 $\sigma^{-1}\circ f(x) /2$ 的近似，但是⽤将凹凸图形偏移⼀半宽度：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312172227304.png" alt="image-20231217222720230" style="zoom:67%;"><p>现在我们有两个不同的$\sigma^{-1}\circ f(x) /2$ 的近似。如果我们把这两个近似图形加起来，我们会得到⼀个 $\sigma^{-1}\circ f(x) $ 的整体近似。这个整体的近似仍然在⼀些⼩窗⼝的地⽅有故障。但是问题⽐以前要⼩很多。原因是在⼀个近似中的故障窗⼝的点，不会在另⼀个的故障窗⼝中。所以在这些窗⼝中，近似会有 2 倍的因素更好。</p><p>我们甚⾄能通过加⼊⼤量的，⽤ <em>M</em> 表⽰，重叠的近似$\sigma^{-1}\circ f(x) /M$  来做得更好。假设故障窗⼝已经⾜够窄了，其中的点只会在⼀个故障窗⼝中。并且假设我们使⽤⼀个 <em>M</em> ⾜够⼤的重叠近似，结果会是⼀个⾮常好的整体近似。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>神经网络</title>
      <link href="/posts/7ca31f7.html"/>
      <url>/posts/7ca31f7.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202407050046152.jpg" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>LCD接口</title>
      <link href="/posts/216a0b1f.html"/>
      <url>/posts/216a0b1f.html</url>
      
        <content type="html"><![CDATA[<h1>LCD接口（附8051LCD1602显示：源码＋原理图）</h1><p>工程源码及原理图：链接：<a href="https://pan.baidu.com/s/1KgmiGkFdl_sFE5GTm5MSsQ?pwd=l1gp">https://pan.baidu.com/s/1KgmiGkFdl_sFE5GTm5MSsQ?pwd=l1gp</a><br>提取码：l1gp</p><p>LCD（Liquid Crystal Display）：又称液晶显示器</p><h2 id="LCD引脚">LCD引脚</h2><p>LCD一共有14个引脚，如下图：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312061758088.png" alt="image-20231206175851955"></p><p>以LCD1602为例：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312061800402.png" alt="image-20231206180044336"></p><p>以下我们对引脚进行逐个解释：</p><h3 id="VSS，VDD，VO">VSS，VDD，VO</h3><table><thead><tr><th>引脚</th><th>功能</th></tr></thead><tbody><tr><td>VSS</td><td>地</td></tr><tr><td>VDD</td><td>电源正极（4.5~5.5V）</td></tr><tr><td>VO</td><td>对比度调节电压（一般接在可变电阻上以调节电压）</td></tr></tbody></table><p> </p><h3 id="RS-寄存器选择">RS(寄存器选择)</h3><p>数据/指令选择，1为数据，0为指令</p><p>若RS=0，选择==指令代码寄存器==，允许用户发送指令，如清屏，使光标返回初始位置。</p><p>若RS=1，选择==数据寄存器==，允许用户发送数据显示在LCD上</p><p> </p><h3 id="RW-read-write">RW(read/write)</h3><p>读/写选择，1为读，0为写</p><h3 id="E-使能">E(使能)</h3><p>使能，1为数据有效，下降沿执行命令</p><h3 id="D0-D7">D0~D7</h3><p>数据输入/输出</p><h3 id="A-K">A/K</h3><p>A:背光灯电源正极</p><p>K:背光灯电源负极</p><p> </p><p>其内部结构图如下：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312061813744.png" alt="image-20231206181354663"></p><p>数据显示在屏幕上的流程：</p><p>数据——&gt;DDRAM——&gt;字模库——&gt;屏幕</p><p>DDRAM比屏幕显示内存更多以便实现滚动字符等的效果。</p><p> </p><h2 id="LCD1602指令集">LCD1602指令集</h2><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312061821398.png" alt></p><h3 id="1-清屏指令（-0000-0001-）">1.清屏指令（ 0000 0001 ）</h3><p>1.清除液晶显示器，即将DDRAM的内容全部清除。<br>2.光标回到液晶屏左上方。<br>3.地址计数器（AC）的值设置为0。</p><h3 id="2-光标归位指令（0000-001x）">2.光标归位指令（0000 001x）</h3><p>1.把光标返回到液晶屏左上方。<br>2.把地址计数器（AC）的值设置为0。<br>3.保持DDRAM的内容不变。</p><h3 id="3-模式设置指令（0000-01-I-D-S）">3.模式设置指令（0000 01 I/D S）</h3><p>设定每次写入一位数据后光标的移动方向，并且设定每次写入一个字符是否移动。<br>I/D：0写入新数据后光标左移，1写入新数据后光标右移。<br>S ：0写入新数据后显示屏不移动，1写入新数据后显示屏整体右移一个字符。</p><h3 id="4-显示开关控制指令（0000-1-D-C-B）">4.显示开关控制指令（0000 1 D C B）</h3><p>D：0显示关，1显示开。<br>C：0无光标，1有光标。<br>B：0光标不闪烁，1光标闪烁。</p><h3 id="5-设定显示屏或光标移动方向指令（000-1-S-C-R-L-x-x）">5.设定显示屏或光标移动方向指令（000 1 S/C R/L x x）</h3><p>S/C R/L<br>0 0 光标左移一格，且AC减一。<br>0 1 光标右移一格，且AC加一。<br>1 0 显示器字符全部左移一格，光标不动。<br>1 1 显示器字符全部右移一格，光标不动。</p><h3 id="6-功能设定指令（00-1-DL-N-F-x-x）">6.功能设定指令（00 1 DL N F x x）</h3><p>DL：0数据总线为4位，1数据总线为8位。<br>N： 0显示 1 行，1显示 2 行。<br>F： 0 5<em>8字符点阵，1 5</em>10字符点阵。</p><h3 id="7-设定CGRAM地址指令（01-aaaaaa）6位地址">7.设定CGRAM地址指令（01 aaaaaa）6位地址</h3><h3 id="8-设定DDRAM地址指令（1-aaaaaaa）7位地址">8.设定DDRAM地址指令（1 aaaaaaa）7位地址</h3><h3 id="9-读取忙信号或AC地址指令（BF-aaaaaaa）">9.读取忙信号或AC地址指令（BF aaaaaaa）</h3><p>BF：0空闲，1忙。<br>aaaaaaa：读取AC地址。</p><h3 id="10-数据写入DDRAM或CGRAM指令">10.数据写入DDRAM或CGRAM指令</h3><h3 id="11-从DDRAM或CGRAM读出数据指令">11.从DDRAM或CGRAM读出数据指令</h3><p> </p><p> </p><h2 id="函数功能实现">函数功能实现</h2><h3 id="初始化">初始化</h3><p>发送指令0x38//八位数据接口，两行显示，5*7点阵</p><p>发送指令0x0C//显示开，光标关，闪烁关</p><p>发送指令0x06//数据读写操作后，光标自动加一，画面不动</p><p>发送指令0x01//清屏</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_Init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x38</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x0C</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x06</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x01</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="LCD1602写命令">LCD1602写命令</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_WriteCommand</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Command)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_RS=<span class="number">0</span>;</span><br><span class="line">LCD_RW=<span class="number">0</span>;</span><br><span class="line">LCD_DataPort=Command;</span><br><span class="line">LCD_E=<span class="number">1</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">LCD_E=<span class="number">0</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="LCD1602写数据">LCD1602写数据</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_WriteData</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Data)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_RS=<span class="number">1</span>;</span><br><span class="line">LCD_RW=<span class="number">0</span>;</span><br><span class="line">LCD_DataPort=Data;</span><br><span class="line">LCD_E=<span class="number">1</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">LCD_E=<span class="number">0</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="LCD1602设置光标位置">LCD1602设置光标位置</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_SetCursor</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(Line==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x80</span>|(Column<span class="number">-1</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x80</span>|(Column<span class="number">-1</span>)+<span class="number">0x40</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="在LCD1602指定位置开始显示所给字符串">在LCD1602指定位置开始显示所给字符串</h3><ul><li>Line 起始行位置，范围：1~2</li><li>Column 起始列位置，范围：1~16</li><li>String 要显示的字符串</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowString</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">char</span> *String)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;String[i]!=<span class="string">&#x27;\0&#x27;</span>;i++)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(String[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="在LCD1602指定位置开始显示所给数字">在LCD1602指定位置开始显示所给数字</h3><ul><li>Line 起始行位置，范围：1~2</li><li>Column 起始列位置，范围：1~16</li><li>Number 要显示的数字，范围：0~65535</li><li>Length 要显示数字的长度，范围：1~5</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number/LCD_Pow(<span class="number">10</span>,i<span class="number">-1</span>)%<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="在LCD1602指定位置开始以有符号十进制显示所给数字">在LCD1602指定位置开始以有符号十进制显示所给数字</h3><ul><li>Line 起始行位置，范围：1~2</li><li>Column 起始列位置，范围：1~16</li><li>Number 要显示的数字，范围：-32768~32767</li><li>Length 要显示数字的长度，范围：1~5</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowSignedNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> Number1;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">if</span>(Number&gt;=<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;+&#x27;</span>);</span><br><span class="line">Number1=Number;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;-&#x27;</span>);</span><br><span class="line">Number1=-Number;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number1/LCD_Pow(<span class="number">10</span>,i<span class="number">-1</span>)%<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="在LCD1602指定位置开始以十六进制显示所给数字">在LCD1602指定位置开始以十六进制显示所给数字</h3><ul><li>Line 起始行位置，范围：1~2</li><li>Column 起始列位置，范围：1~16</li><li>Number 要显示的数字，范围：0~0xFFFF</li><li>Length 要显示数字的长度，范围：1~4</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowHexNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> SingleNumber;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">SingleNumber=Number/LCD_Pow(<span class="number">16</span>,i<span class="number">-1</span>)%<span class="number">16</span>;</span><br><span class="line"><span class="keyword">if</span>(SingleNumber&lt;<span class="number">10</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+SingleNumber);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;A&#x27;</span>+SingleNumber<span class="number">-10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="在LCD1602指定位置开始以二进制显示所给数字">在LCD1602指定位置开始以二进制显示所给数字</h3><ul><li>Line 起始行位置，范围：1~2</li><li>Column 起始列位置，范围：1~16</li><li>Number 要显示的数字，范围：0~1111 1111 1111 1111</li><li>Length 要显示数字的长度，范围：1~16</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowBinNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number/LCD_Pow(<span class="number">2</span>,i<span class="number">-1</span>)%<span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="在LCD1602显示姓名学号">在LCD1602显示姓名学号</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;REGX52.H&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;LCD1602.h&quot;</span></span></span><br><span class="line"></span><br><span class="line">sbit LCD_RS=P2^<span class="number">0</span>;</span><br><span class="line">sbit LCD_RW=P2^<span class="number">1</span>;</span><br><span class="line">sbit LCD_E=P2^<span class="number">2</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LCD_DataPort P0</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Delay</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> xms)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_Init</span><span class="params">(<span class="type">void</span>)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowChar</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">char</span> Char)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowString</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">char</span> *String)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowSignedNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowHexNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowBinNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_WriteCommand</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Command)</span>;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_Init();<span class="comment">//LCD初始化</span></span><br><span class="line"></span><br><span class="line">LCD_ShowString(<span class="number">1</span>,<span class="number">1</span>,<span class="string">&quot;yourname&quot;</span>);<span class="comment">//第一行第一列开始显示名字</span></span><br><span class="line">LCD_ShowNum(<span class="number">2</span>,<span class="number">1</span>,<span class="number">12138</span>,<span class="number">5</span>);<span class="comment">//第二行第一列显示12138</span></span><br><span class="line">LCD_ShowNum(<span class="number">2</span>,<span class="number">6</span>,<span class="number">12138</span>,<span class="number">5</span>);<span class="comment">//第二行第六列开始显示12138</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">Delay</span><span class="params">(<span class="type">unsigned</span> <span class="type">int</span> xms)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i, j;</span><br><span class="line"><span class="keyword">while</span>(xms--)</span><br><span class="line">&#123;</span><br><span class="line">i = <span class="number">2</span>;</span><br><span class="line">j = <span class="number">239</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">while</span> (--j);</span><br><span class="line">&#125; <span class="keyword">while</span> (--i);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_Delay</span><span class="params">()</span><span class="comment">//@12.000MHz 1ms</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i, j;</span><br><span class="line"></span><br><span class="line">i = <span class="number">2</span>;</span><br><span class="line">j = <span class="number">239</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">while</span> (--j);</span><br><span class="line">&#125; <span class="keyword">while</span> (--i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_WriteData</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Data)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_RS=<span class="number">1</span>;</span><br><span class="line">LCD_RW=<span class="number">0</span>;</span><br><span class="line">LCD_DataPort=Data;</span><br><span class="line">LCD_E=<span class="number">1</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">LCD_E=<span class="number">0</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_Init</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x38</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x0C</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x06</span>);</span><br><span class="line">LCD_WriteCommand(<span class="number">0x01</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_SetCursor</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(Line==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x80</span>|(Column<span class="number">-1</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteCommand(<span class="number">0x80</span>|(Column<span class="number">-1</span>)+<span class="number">0x40</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowChar</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">char</span> Char)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line">LCD_WriteData(Char);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_WriteCommand</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Command)</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_RS=<span class="number">0</span>;</span><br><span class="line">LCD_RW=<span class="number">0</span>;</span><br><span class="line">LCD_DataPort=Command;</span><br><span class="line">LCD_E=<span class="number">1</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">LCD_E=<span class="number">0</span>;</span><br><span class="line">LCD_Delay();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowString</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">char</span> *String)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;String[i]!=<span class="string">&#x27;\0&#x27;</span>;i++)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(String[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">LCD_Pow</span><span class="params">(<span class="type">int</span> X,<span class="type">int</span> Y)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line"><span class="type">int</span> Result=<span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;Y;i++)</span><br><span class="line">&#123;</span><br><span class="line">Result*=X;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> Result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number/LCD_Pow(<span class="number">10</span>,i<span class="number">-1</span>)%<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowSignedNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">int</span> Number1;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">if</span>(Number&gt;=<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;+&#x27;</span>);</span><br><span class="line">Number1=Number;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;-&#x27;</span>);</span><br><span class="line">Number1=-Number;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number1/LCD_Pow(<span class="number">10</span>,i<span class="number">-1</span>)%<span class="number">10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowHexNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> SingleNumber;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">SingleNumber=Number/LCD_Pow(<span class="number">16</span>,i<span class="number">-1</span>)%<span class="number">16</span>;</span><br><span class="line"><span class="keyword">if</span>(SingleNumber&lt;<span class="number">10</span>)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+SingleNumber);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;A&#x27;</span>+SingleNumber<span class="number">-10</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">LCD_ShowBinNum</span><span class="params">(<span class="type">unsigned</span> <span class="type">char</span> Line,<span class="type">unsigned</span> <span class="type">char</span> Column,<span class="type">unsigned</span> <span class="type">int</span> Number,<span class="type">unsigned</span> <span class="type">char</span> Length)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">unsigned</span> <span class="type">char</span> i;</span><br><span class="line">LCD_SetCursor(Line,Column);</span><br><span class="line"><span class="keyword">for</span>(i=Length;i&gt;<span class="number">0</span>;i--)</span><br><span class="line">&#123;</span><br><span class="line">LCD_WriteData(<span class="string">&#x27;0&#x27;</span>+Number/LCD_Pow(<span class="number">2</span>,i<span class="number">-1</span>)%<span class="number">2</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202312062139022.png" alt="image-20231206213916889"></p>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电磁场总结</title>
      <link href="/posts/aef64dc0.html"/>
      <url>/posts/aef64dc0.html</url>
      
        <content type="html"><![CDATA[<h1>电磁场原理</h1>]]></content>
      
      
      
        <tags>
            
            <tag> 课程总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单片机</title>
      <link href="/posts/7f705d57.html"/>
      <url>/posts/7f705d57.html</url>
      
        <content type="html"><![CDATA[<h1>单片机</h1><h2 id="进制转换及其加减法，补码">进制转换及其加减法，补码</h2><p>2，4，88，10，16进制之间的相互转化，具体内容见逻辑设计</p><h2 id="数学基础知识">数学基础知识</h2><ol><li><p>数据大小</p><ol><li><p>储存容量是衡量微机内部储存器能储存二进制（Bit）信息量大小的一个技术指标</p></li><li><p>8位二进制数据称为一个字节（Byte）——最基本的计量单位，记为1B</p></li><li><p>16位二级制数据称为一个字（word）</p></li><li><p>32位二进制数据称为一个双字（Dword）<br>$$<br>2<sup>{10}B=1KB,2</sup>{10}KB=1MB,2<sup>{10}MB=1GB,2</sup>{10}GB=1TB<br>$$</p></li></ol></li><li><p>只读存储器（ROM）</p><p>ROM是一种掉电后不丢失信息的储存器。由于这个原因，ROM也成为非易失性存储器。</p><p> </p><p>结构和容量</p><p>给定储存器芯片有12个地址引脚和4个数据引脚，此储存芯片有4096个位置（$2^{12}=4096$），每个位置能储存4位数据，所以<code>结构</code>就是4096×4，也常用4K×4表示。其<code>容量</code>是16Kb，因为总共是4K个位置，每个位置能保存4位数据</p><p> </p><p>一个容量是512K储存器芯片有8个数据引脚，请找出：（a）组织结构；（b）这个储存芯片的地址引脚数</p><p>（a）8个数据引脚可以保存8位数据，为了找出这个储存器芯片的位置数，需要用数据引脚数去除容量。512K/8=64K；所以储存芯片的组织结构是64K×8</p><p>（b）芯片有16根地址线，因为$2^{16}=64K$</p></li><li><p>随机访问储存器（RAM）</p><p>储存计算机运行中暂停的项目，当电脑关机时数据会丢失</p></li><li><p>总线设计</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306714.png" alt="image-20231019221602733"></p><ol><li><p>地址总线</p><p>cpu地址总线的数目决定了能与cpu进行通信的位置数，位置数通常等于$2^x$，x是地址线的数目。</p><p>每个位置最多可以有一个字节的数据，不用考虑数据总线的大小。</p><p>地址总线是单向的。</p><p>地址总线使用得越多，外设使用越多。</p></li><li><p>数据总线</p><p>数据总线是双向的，因为CPU需要使用它们接收和发送数据。使用的数据总线越多，CPU效率越高。</p></li><li><p>控制总线</p><p>向设备提供读取或写入信号，以提示CPU是否正在请求信息。</p></li></ol></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">ORG0</span><br><span class="line">MOVR0,#66H</span><br><span class="line">MOVR3,#7FH</span><br><span class="line">MOVR7,#5DH</span><br><span class="line">PUSH0</span><br><span class="line">PUSH3</span><br><span class="line">PUSH7</span><br><span class="line">CLRA</span><br><span class="line">MOVR3,A</span><br><span class="line">MOVR7,A</span><br><span class="line">POP3</span><br><span class="line">POP7</span><br><span class="line">POP0</span><br><span class="line">END</span><br></pre></td></tr></table></figure><p>pop代表把栈顶的值赋值给r几</p><p>例如pop 3就是把栈顶的值赋值给R3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ORG0</span><br><span class="line">MOVSP,#70H</span><br><span class="line">MOVR5,#66H</span><br><span class="line">MOVR2,#7FH</span><br><span class="line">MOVR7,#5DH</span><br><span class="line">PUSH5</span><br><span class="line">PUSH2</span><br><span class="line">PUSH7</span><br><span class="line">CLRA</span><br><span class="line">MOVR2,A</span><br><span class="line">MOVR7,A</span><br><span class="line">POP7</span><br><span class="line">POP2</span><br><span class="line">POP5</span><br><span class="line">END</span><br></pre></td></tr></table></figure><p>&amp;nbsp</p><h2 id="8051系统概述">8051系统概述</h2><h3 id="8051控制器的内部框图">8051控制器的内部框图</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306716.png" alt="image-20231019213820890"></p><h3 id="8501的主要特性">8501的主要特性</h3><table><thead><tr><th>特性</th><th>数量</th></tr></thead><tbody><tr><td>ROM</td><td>4KB</td></tr><tr><td>RAM</td><td>128KB</td></tr><tr><td>定时器</td><td>2</td></tr><tr><td>I/O引脚</td><td>32</td></tr><tr><td>串行端口</td><td>1</td></tr><tr><td>中断源</td><td>6</td></tr></tbody></table><h3 id="8051及其成员对比">8051及其成员对比</h3><table><thead><tr><th>特性</th><th>8051</th><th>8052</th><th>8031</th></tr></thead><tbody><tr><td>ROM</td><td>4KB</td><td>8K</td><td>0K</td></tr><tr><td>RAM</td><td>128KB</td><td>256KB</td><td>128KB</td></tr><tr><td>定时器</td><td>2</td><td>3</td><td>2</td></tr><tr><td>I/O引脚</td><td>32</td><td>32</td><td>32</td></tr><tr><td>串行端口</td><td>1</td><td>1</td><td>1</td></tr><tr><td>中断源</td><td>6</td><td>8</td><td>6</td></tr></tbody></table><p> </p><p> </p><p>大多数的8051单片机的寄存器是8位的，所以也叫8051为8位单片机</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306717.png" alt="image-20231019195634248" style="zoom:67%;"><p>8051中常用的寄存器有A（累加器）、B、RO、R1、R2、R3、R4、R5、R6、R7、DPTR（数据指针）以及PC（程序计数器）寄存器。除DPTR和程序计数器是16位外，以上寄存器都是8位。</p><p> </p><h3 id="MOV指令">MOV指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MOV 目的操作数，源操作数</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306718.png" alt="image-20231019200313361"></p><p>1.可直接将数值装载到A、B或R0~R7的任意意一个寄存器当中。然而，为表示装载的是立即数，必须在数值前加上符号（#），如下：</p><p>2.如果将0～F的值装载到8位寄存器中，则其余的位就默认为0.例如，对于指今MOV  A，#5”而言，结果是A=05，用二进制表示就是A=00000101。</p><p>3.装载太大的值到寄存器中时会出错。（装载的值超过八位）</p><p>4.将数值装载到寄存器中时，必须在数值前加上符号（#），否则就表示装载的是存储器中的数。例如，MOV  A，17H”指令代表的就是将存储单元17H中的数装载到A中，结果就是任意值。</p><p> </p><h3 id="ADD指令">ADD指令</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD A,源操作数；</span><br></pre></td></tr></table></figure><p>指令中的源操作数即可以是寄存器，也可以是立即数；</p><p>寄存器A必须存在于任何的算数运算中，但其只能是任何算术运算中的目的操作数而不能是源操作数。</p><p> </p><h3 id="8051汇编语言简介">8051汇编语言简介</h3><p>1.汇编语言程序由一连串的汇编指令组成</p><p>2.一条汇编指令由4个字段组成</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[标签:]  助记符  [操作数]  [;注释] </span><br></pre></td></tr></table></figure><p>助记符即为指令</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306719.png" alt="image-20231019201422708" style="zoom:67%;"><p>3.方框号代表里面的字段是可选的，不是每条指令都必须包含</p><p>4.ADD和MOV就是助记符，即产生操作码的部分。ORG和END就是伪代码（指示符），这些指示符不产生任何机器代码（操作码），仅供汇编使用。</p><p> </p><p>8051中的程序计数器和ROM空间</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306720.png" alt="image-20231019202019120" style="zoom:67%;"><p>1.编写汇编语言需要将汇编程序写好写入asm文件中</p><p>2.asm源文件被送入8051汇编器，汇编器将指令换成机器代码，然后产生目标文件（obj）和列表（lst）文件</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306721.png" alt="image-20231019202418301" style="zoom:67%;"><p>3.汇编器的第三步是链接：链接程序接受一个或多个目标文件并生成带有扩展名&quot;abs&quot;的绝对目标文件</p><p>4.将“abs”文件送入名为&quot;OH&quot;的程序（目标文件转16进制）中,从而产生即将烧入ROM中的扩展名位&quot;hex&quot;的文件。</p><ul><li>DOS EDIT编辑器产生asm文件</li><li>8051编译器产生obj和lst文件</li><li>链接器程序产生abs文件</li><li>OH程序产生HEX文件</li></ul><p> </p><h3 id="8051中的程序计数器和ROM空间">8051中的程序计数器和ROM空间</h3><h4 id="8051中的程序计数器（PC）">8051中的程序计数器（PC）</h4><ol><li>程序计数器指向下一条将执行指令的地址。</li><li>当CPU从程序ROM中得到操作码时，程序计数器就会自动增加并指向下一条指令</li><li>8051中的程序计数器为16位，能访问的程序地址范围是0000H～FFFFH，共64KB代码。</li></ol><h4 id="上电8051唤醒的位置">上电8051唤醒的位置</h4><ol><li>当上电后，8051程序计数器中的值就是0000，就表示第一个操作码存储在ROM地址0000H中。</li><li>8051系统中，第一个操作码就必须烧人程序ROM的存储位置0000H中，因为这是启动后它寻找第一条指令的位置。</li></ol><p> </p><h3 id="8051数据类型和指令">8051数据类型和指令</h3><h4 id="BD">BD</h4><p>DB指令是汇编器中使用最广泛的数据指示符之一，它用于定义8位数据。</p><p>十进制后面的D是可选的，但是二进制的B和十六进制的H是必须加的。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306722.png" alt="image-20231019204830206"></p><h4 id="汇编指示符">汇编指示符</h4><p><a href="http://1.ORG">1.ORG</a>：用于ROM中表示起始地址</p><p>2.EQU：用于定义常量，但是不占用系统空间</p><p>3.END：告诉汇编器源文件（asm）末尾所处的位置。END指令是8051程序的最后一位，意味着END指令之后的源代码都会被汇编器忽略。</p><p> </p><h3 id="8051标志位和PSW寄存器">8051标志位和PSW寄存器</h3><p>8051中也有表示算数运算状态的标志寄存器，如<code>进位标志</code>。</p><p>8051中的标志寄存器叫做<code>程序状态字（PSW）寄存器</code></p><h4 id="PSW（程序状态字）寄存器">PSW（程序状态字）寄存器</h4><p>PSW寄存器是一个8位寄存器，也叫标志寄存器，但是在8051中，PSW只用了6位，剩余两位是用户自定义标志位。</p><p>6为中有4位是<code>状态标志位</code>也就是一些指令执行后的结果状态，分别是CY（进位）、AC（辅助进位）、P（奇偶校验位）以及OV（溢出位）</p><p>PSW.3和PSW.4位被分别设计为了RS0和RS1，用于选择组寄存器。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306723.png" alt="image-20231019210419646"></p><p>PSW.5和PSW.1是通用状态标志位，供程序员使用。</p><table><thead><tr><th>名称</th><th>位置</th><th>解释</th></tr></thead><tbody><tr><td>CY</td><td>PSW.7</td><td>进位标志</td></tr><tr><td>AC</td><td>PSW.6</td><td>辅助进位标志</td></tr><tr><td>F0</td><td>PSW.5</td><td>可用于用户的通用目的</td></tr><tr><td>RS1</td><td>PSW.4</td><td>寄存器组选择器位1</td></tr><tr><td>RS0</td><td>PSW.3</td><td>寄存器组选择器位0</td></tr><tr><td>OV</td><td>PSW.2</td><td>溢出标志</td></tr><tr><td>–</td><td>PSW.1</td><td>用户可定义位</td></tr><tr><td>P</td><td>PSW.0</td><td>奇偶标志。通过硬件每条指令周期设置/清0                     来指明是累加器中的奇/偶位数。</td></tr></tbody></table><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306724.png" alt="image-20231019210748792"></p><p> </p><h4 id="ADD指令和PSW">ADD指令和PSW</h4><p>分析ADD指令对PSW寄存器中CY、AC以及P标志位的影响。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MOV A,#38H</span><br><span class="line">MOV A,#2FH</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201518418.png" alt="image-20231020151833345"></p><p>相加之后：CY=0，因为D7位没有进位。</p><p>AC=1，因为有来自D3到D4位的进位</p><p>P=1，因为累加器有奇数个1（5个1）</p><p> </p><h3 id="8051寄存器组和栈">8051寄存器组和栈</h3><p>8051微控制器中共有128个字节的RAM</p><h4 id="8051中的RAM存储分配">8051中的RAM存储分配</h4><p>8051中有128个字节的RAM（一些成员，如8052，有256个字节的RAM），其所分配的地址范围是00~7FH。它们可直接作为存储器位置进行访问。这128个字节可分成如下三部分：</p><ol><li>从00至1F（十六进制）共有32个字节用于寄存器组和栈</li><li>从20H至2FH共有16个字节用于位可寻址读/写存储器。</li><li>从30H至7FH共有80个字节用于读/写存储，也通常称为高速暂存器（scratch pad）。这80个RAM位置被8051程序员广泛应用于存储数据以及相关参数中。</li></ol><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201525443.png" alt="image-20231020152516334" style="zoom:67%;"><p>第一组寄存器与栈使用的是同样的RAM空间。这点在8051编程时尤其要注意，要么回避使用第第一组寄存器，要要么分配另一块RAM区域给栈。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201528790.png" alt="image-20231020152841693" style="zoom:67%;"><p> </p><h4 id="默认寄存器组">默认寄存器组</h4><p>如果RAM位置00～1F地址被用于四个寄存器组，那么上电后可以访问的R0～R7的寄存器组就是<code>寄存器组0</code>也就是说，当编写8051程序时，RAM位置0、1、2、3、4、5、6和7分别被名字为R0、R1、R2、R3、R4、R5、R6以及R7的符号进行访问。使用R0、R1等名字来访问RAM位置地址相比于用存储器位置访问容易得多。</p><p> </p><h4 id="如何切换寄存器组">如何切换寄存器组</h4><p>8051上电后，默认寄存器组的是寄存器组0.但我们可以通过使用PSW寄存器切换到其他的寄存器组。PSW的D4位和D3位用于选择需要的寄存器组.。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310192306724.png" alt="image-20231019210748792"></p><p> </p><h4 id="8051中的堆">8051中的堆</h4><p>栈是RAM中的一段空间，为CPU暂时存储信息。这些信息可以是数据或是地址。CPU需要该存储区域是因为寄存器数目有限。</p><p> </p><h4 id="8051如何访问栈">8051如何访问栈</h4><p>​如果栈是RAM的一段空间，CPU中就必须有指向这段空间的寄存器。用于访问栈的寄存器称为<code>SP（栈指针）寄存器</code>。8051中的栈指针仅8位宽，这就意味能得到的值的范围是00～FFH。</p><p>​当8051上电后，SP寄存器的值是07(因为默认寄存器组1的第一位为8)，就意味着RAM位置08是8051栈的第一个位置。</p><p>​将CPU寄存器中的值存人栈称为PUSH（压栈），从栈中取出值放入寄存器中称为POP（出栈），也就是说，一个寄存器被压人栈中就是保存数据，而从栈中弹出则是重新得到该数据。当进行压栈和出栈的操作时，SP的作用很重要。</p><p> </p><h4 id="压栈（push）">压栈（push）</h4><p>在8051中，栈指针指向栈的最后一个位置。如果将数据压入栈中，栈指针就自增1。</p><p>例如：PUSH 1；就是将R1中的数据压入堆栈中（第一次位置为08，压入后的位置是09）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">MOVR6，#25H</span><br><span class="line">MOVR1，#12H</span><br><span class="line">MOVR4，#0F3H</span><br><span class="line">PUSH6</span><br><span class="line">PUSH1</span><br><span class="line">PUSH4</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201543123.png" alt="image-20231020154319025"></p><h4 id="出栈（POP）">出栈（POP）</h4><p>​每次弹出时，栈顶的字节会压入到所写寄存器中，同时栈指针自减一次。</p><p>​例如：POP 3；就是将栈顶指针对应的字节压入R3中。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201545056.png" alt="image-20231020154538961"></p><p> </p><h4 id="栈上限">栈上限</h4><p>​8051的RAM位置地址范围08～1F用于栈，这是因为RAM位置地址20-2FH只能用于位可寻址存储，而不能用于栈。</p><p>​如果某程序需要大于24字节（08～1FH=24字节）的栈，则可以改变SP指向RAM中30~7FH的位置。完成此操作的指令是：MOV  SP,#xx</p><p> </p><h4 id="栈和寄存器组1的冲突">栈和寄存器组1的冲突</h4><p>默认的寄存器组为寄存器0，默认栈的起始点为寄存器1的R0。</p><p>寄存器组1和栈使用的是同样的存储空间。如果一个程序需要使用寄存器组1和组2时，就必须重新分配RAM空间给栈。例如，可分配RAMM位置地址60H甚至更高的位置地址给栈。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">MOVSP,#5FH;RAM位置地址60H,即栈的第一个位置</span><br><span class="line"></span><br><span class="line">MOVR2,#25H</span><br><span class="line">MOVR1,#12H</span><br><span class="line">MOVR4,#0F3H</span><br><span class="line">PUSH2</span><br><span class="line">PUSH1</span><br><span class="line">PUSH4</span><br></pre></td></tr></table></figure><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201602225.png" alt="image-20231020160228129" style="zoom:67%;"><h4 id="提高CPU效率的方法">提高CPU效率的方法</h4><p>微处理器设计者可使用三种方法来提高CPU的处理效率。</p><ol><li>增加芯片的时钟频率。这种方法的缺点是：频率越高，则功耗和热损耗就越大，功耗和散热对掌上型设备尤其是大问题。</li><li>.通过增加导线成为哈佛体系结构，从而将更多的信息（代码和数据）装载到CPU中处理。而在x86和一些通用微处理器中，哈佛体系结构价格昂贵且不切实际，但是在今天的单芯片计算机中（微控制器），这已不是问题。</li><li>改变CPU的内部结构，使用RISC结构。</li></ol><p> </p><h2 id="跳转、循环和调用指令">跳转、循环和调用指令</h2><h3 id="8051中的循环">8051中的循环</h3><p>​在8051中，循环操作通过指令“DJNZ  reg,label”来实现。该指令中，寄存器递减，如果非零，则跳转至标签所示的目标地址。在循环开始之前，寄存器预存人循环次数。</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201646151.png" alt="image-20231020164656061" style="zoom:67%;"><p>上诉代码所实现的功能为：</p><ol><li>累加器清零</li><li>将3加入累加器中10次</li></ol><p>注意：上述代码以R2为累加器，而R2为8位寄存器，它能储存的最大值为FHH（十进制的255），因此每次循环的最多次数也为256，如需更多的循环则需要进行循环的嵌套。</p><h4 id="循环嵌套">循环嵌套</h4><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201651505.png" alt="image-20231020165110399"></p><p>上述代码实现的功能：</p><ol><li>将数55H存入累加器ACC中</li><li>对累加器ACC执行700次取补码。</li></ol><p> </p><h4 id="其他条件跳转指令">其他条件跳转指令</h4><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201652828.png" alt="image-20231020165231702"></p><p>注意：重点记忆<code>JZ</code>和<code>JNC</code></p><p> </p><h4 id="所有的条件跳转指令都是短跳转指令">所有的条件跳转指令都是短跳转指令</h4><p>​必须指出，所有的条件跳转指令都是短跳转指令，也就是说，跳转指令的目标地址必须在程序计数器（PC）的-128~+127字节之内。</p><p> </p><h4 id="无条件跳转指令">无条件跳转指令</h4><p>无条件跳转指令是一种不需要任何条件，程序就可以跳转到目标地址的指令。</p><p>在8051中，这样的指令有两种：长跳转（LJMP）指令和短跳转（SJMP）指令</p><h5 id="LJMP（长跳转指令）">LJMP（长跳转指令）</h5><p>它是一个3字节指令，其中第一个字节是操作码，第二个和第三个字节表示16位目标地址。2字节的目标地址允许程序在存储单元00000H~FFFFH中任意跳转。</p><h5 id="SJMP（短跳转指令）">SJMP（短跳转指令）</h5><p>它是一个2字节指令，第一个字节是操作码，第二个字节是目标地址的相对跳转地址。相对跳转地址的范围为00H~FFH，相对跳转地址又分为前向跳转地址和后向跳转地址，即在相对于当前PC地址的-128～+127字节存储器范围内。如果是前向跳转地址，则目标地址可以在距当前PC的127字节范围内；如果是后向跳转地址，则目标地址可以在距当前PC的-128字节范围内。</p><p> </p><p> </p><h3 id="调用指令">调用指令</h3><p>​另一个控制跳转指令是CALL指令，该指令用于调用子程序。子程序常用于完成经常实现的任务。这样做不仅可以节省存储器空间，而且让程序更加结构化。在8051系列中，有两种调用指令：长调用（LCALL）指令及绝对调用（ACALL）指令。</p><h4 id="LCALL-长调用指令">LCALL(长调用指令)</h4><p>它是一个3字节指令，其中第一个字节是操作码，第二个和第三个字节是子程序人口地址。因此，长调用指令可以调用存放在8051中64KB程序存储器任意位置的子程序。</p><p>为保证8051在调用子程序执行结束后能够知道返回到哪里并继续执行，处理器自动将长跳转指令的下一条指令地址保存到栈中。当一个子程序被调用时，控制器跳转到该子程序，并且处理器将PC值保存到栈中，同时开始获取一条新的指令地址。当子程序执行结束时，返回指令RET将控制器返回到调用位置。</p><p>==每一个子程序都需要一条返回指令作为结束。==</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201709397.png" alt="image-20231020170936284"></p><p>RET指令的功能是将地址从栈中弹出并放入程序计数器中，从而恢复执行在CALL指令之后的指令。</p><p> </p><h4 id="ACALL-绝对调用指令">ACALL(绝对调用指令)</h4><p>由于ACALL是2字节指令，子程序的目标地址就必须在2KB字节范围内，这是因为2字节中只有11位表示地址。</p><p> </p><h3 id="8051芯片的延时">8051芯片的延时</h3><h4 id="8051的机器周期">8051的机器周期</h4><p>​CPU执行指令时须花费一定的时钟周期，8051系列中，这些时钟周期就叫做机器周期（machine cycle,MC）。</p><p>​最原始的8051中，1个机器周期可占用12个振荡器（时钟）周期。因此，要想计算8051的机器周期，我们采用1/12的晶振频率，然后再取倒数。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201718902.png" alt="image-20231020171851810"></p><p>在一个时钟周期内，能运行的机器周期越多，当然效率就越高，如上图，从上到下机器运行的效率是逐渐增加的。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201720110.png" alt="image-20231020172032002"></p><p> </p><h4 id="8051的延时计算">8051的延时计算</h4><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201723498.png" alt="image-20231020172335390"></p><p>DELAY的子程序一般由两部分构成：</p><ol><li>计数器设置</li><li>延时</li></ol><p>增加延时时间的一种方式是在循环中使用NOP指令。NOP表示“空操作”，简单地浪费时间。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201726403.png" alt="image-20231020172624264"></p><h4 id="循环内套用循环延时">循环内套用循环延时</h4><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201730434.png" alt="image-20231020173008270"></p><h4 id="关于各种IC的延时计算">关于各种IC的延时计算</h4><ol><li>根据时钟周期与机器周期的比计算出，结合晶振频率计算出运行一个机器周期所需要的时间</li><li>计算延时函数中所运行机器周期的个数</li><li>如果是单个循环，则计算出的时间=循环所需的时间＋循环外的指令运行时间；如果是嵌套循环，延时时间=内循环时间＋外循环时间。它与所有其他延时循环一样，对它的延时计算只是约数，因为忽略了子程序的第一条及最后一条指令所产生的延时。</li></ol><p> </p><h4 id="使用-符号和SSJMP表示跳转到自身">使用$符号和SSJMP表示跳转到自身</h4><p>如果芯片中不存在要监视的程序，就需要使用跳转到自身指令使得微控制器不处于空闲状态。简单的做法是在JUMP后面写上$符号，代表跳转的位置也就是如下情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HERE:SJMPHERE</span><br></pre></td></tr></table></figure><p>也可以如下使用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SJMP$</span><br></pre></td></tr></table></figure><p> </p><h2 id="8051的I-O端口编程">8051的I/O端口编程</h2><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201812908.png" alt="image-20231020181205765"></p><p>8051中一共有4个端口可以进行I/O操作，即P0-P3，每个端口有8个引脚。</p><p>8051有40个引脚，其中32个引脚属于4个端口，余下的引脚分别是$V_{cc}$​,GND，XTAL1，XTAL2，RST，EA，ALE/PROG和PSEN。</p><p> </p><h3 id="I-O端口引脚及其功能">I/O端口引脚及其功能</h3><p>所有端口在RESET（复位）时都配置成输入，并准备用作输入。</p><p>当第一个0写入某端口时，该端口便成为输出。若将该端口重新配置成输入，则必须将1送入该端口。若想将任何端口用做输入端口，则必须编程。</p><p> </p><h3 id="将个位读入进位标志">将个位读入进位标志</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310261952404.png" alt="image-20231026195225266"></p><h4 id="读取输出端口锁存内容">读取输出端口锁存内容</h4><p>有些指令读取的是内部端口锁存内容而不是外部引脚的状态。如“ANL &amp; P1，A”，执行该指令时会产生如下一系列的动作：</p><p>1.读取端口内部锁存内容，并将该数据传送给CPU。</p><p>2.将这些数据与寄存器A中的内容相与。</p><p>3.结果写入端口锁存。<br>4.端口引脚数据改变，内容与端口锁存内容一致。</p><p> </p><p> </p><p> </p><h2 id="80511寻址方式">80511寻址方式</h2><p>​CPU可使用多种方式访问数据。数据可存放在寄存器、存储器中，或者以立即数的形式存在。访问这些数据的不同方法称为寻址方式（addressing modes)。</p><p>8051共提供5种寻址方式，如下:</p><p>1.立即寻址方式；<br>2.寄存器寻址方式；<br>3.直接寻址方式；<br>4.寄存器间接寻址方式；<br>5.变址寻址方式</p><p> </p><h3 id="立即寻址方式">立即寻址方式</h3><p>直接将源操作数加载至任意寄存器，注意：立即数必须加前缀“#”</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262002698.png" alt="image-20231026200259601"></p><h3 id="寄存器寻址方式">寄存器寻址方式</h3><p>寄存器寻址方式是将寄存器中的内容加载到另一个寄存器中，而不是操作数本身。如下所示：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262004330.png" alt="image-20231026200404238"></p><p> </p><h3 id="直接寻址方式">直接寻址方式</h3><p>1.RAM地址00～1FH分配给寄存器组和栈。</p><p>2.RAM地址20-2FH用于位可寻址空间保存单点数据。</p><p>3.RAM地址30~7FH用于保存字节数据。</p><p>使用直接寻址方式可以访问RAM的128字节，但通常情况下它只访问RAM地址30～7FH空间，这是因为寄存器组位置由名为RO～R7的寄存器访问，而RAM中除了寄存器空间之外再没有对应的名字。</p><p>在直接寻址方式中，存放在RAM存储器中的数据对应的地址就是指令中给出的地址。而在立即寻址方式中，指令执行的数据就是操作数本身。是否有前缀“#”是两种寻址方式的主要区别。如下例所示（注意没有百“#标志）:</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262006324.png" alt="image-20231026200609232"></p><p> </p><h4 id="SFR寄存器">SFR寄存器</h4><p>在8051单片机中，寄存器A、B、PSW和DPTR通常称为SFR（特殊功能寄存器）</p><p>关于SFR地址，需注意以下两点:<br>1.特殊功能寄存器地址范围是80H～FFH。地址大于80H的原因是00H～7FH地址属于8051内部RAM。<br>2.不是80H～FFH范围中的所有地址都用于SFR。未使用的保留，且不可被8051程序员使用。</p><p> </p><h3 id="寄存器间接寻址方式">寄存器间接寻址方式</h3><p>在寄存器间接寻址方式中，寄存器可作为数据指针。若数据存在于CPU内部，则只能使用寄存器R0或R1将数据取出。当R0和R1用作指针保存RAM中的数据地址时，则须加上前级“@标志，如下所示:</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262009654.png" alt="image-20231026200946568"></p><p>简单解释是将一个寄存器中数据的地址加载到另一个寄存器中。而不是数据本身。</p><p>如上，我们如果不佳@，那么就会将后面寄存器中的数据进行操作，而不是地址。</p><p> </p><h3 id="变址寻址方式">变址寻址方式</h3><p>​变址寻址方式广泛用于访间8051单片机的ROM空间的查找表入口数据，指令是“MOVC  A，@A+DPTR”。16位的寄存器DPTR和寄存器A存放在片上ROM中的数据元素地址，因为数据元素存放在8051ROM代码区，所以使用指令MOV C，而不是MOV。“C”指代码。该指令将寄存器A中的内容与16位寄存器DPTR中的内容相加，形成所需数据的16位地址,如下所示：</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262016423.png" alt="image-20231026201652253"></p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262019170.png" alt="image-20231026201946030"></p><p> </p><h3 id="算术逻辑指令与程序">算术逻辑指令与程序</h3><p>在8051中，为了将数值相加，就必须使用累加器（寄存器A），ADD指令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD A，源操作数;A = A + 源操作数</span><br></pre></td></tr></table></figure><p> </p><h3 id="ADD指令-2">ADD指令</h3><p>ADD指令的功能是将两个操作数相加，通常，目的操作数是寄存器A中的内容，而源操作数可以是立即数、寄存器中的内容或存储器中的内容。请记住，在8051汇编算术操作中不允许存储器-存储器式的操作。指令的执行将影响标志位AC、CY和P，这取决于执行的操作数。溢出标志位OV只有带符号数运算时才受影响。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262117746.png" alt="image-20231026211723672"></p><p> </p><h3 id="ADDC以及16位数加法">ADDC以及16位数加法</h3><p>当两个16位的操作数相加时，需注意进位。指令ADDC（带进位加法指令）自的功能就是把源操作数的内容和进位标志CY都加入累加器A中。如下是3CE7H+3B8DH的相加操作：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262120484.png" alt="image-20231026212033413"></p><p> </p><h3 id="DA指令">DA指令</h3><p>8051中的DA（十进制加法调整）指令用于解决两个BCD码相加不是BCD码的问题。助记符有一个操作数，就是累加器“A当有必要时，DA指令将6加入低位或高位，否则就不干涉结果。如下所示。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262127068.png" alt="image-20231026212758013"></p><h4 id="DA操作总结">DA操作总结</h4><p>只能在ADD或ADDC指令执行之后才能执行。<br>1.若低位（4位）大于9，或AC=1，就将0110加入低4位。<br>2.若高位（4位）大于9，或CY=1，就将0110加入高4位。<br>事实上，AC（辅助进位）标志位除了用于纠正BCD加法之外，并无其他用处。例如，相加29H和18H，结果是41H，但这对于BDC码来说是错误的。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262128952.png" alt="image-20231026212846867"></p><h3 id="无符号数相减">无符号数相减</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SUBB A，源操作数;A = A - 源操作数 -CY</span><br></pre></td></tr></table></figure><h4 id="SUBB（带借位减法），CY-0">SUBB（带借位减法），CY=0</h4><p>算术减法中，8051微处理器（几乎涵盖所有的CPU）采用的是补码的方法。每个CPU中都包含加法电路，而因为减法电路的设计复杂（占用太多晶体管），因此8051使用加法电路来实现减法。如果8051执行减法指令时，须预设置CY=0。CPU硬件执行SUBB无符号数减法指令的步骤如下。<br>1.得到减数源操作数的补码。<br>2.将值与被减数（A）相加。<br>3.进位反相。</p><h3 id="无符号数乘法和除法">无符号数乘法和除法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MUL AB    ;AXB，将16位结果分别放入B和A</span><br></pre></td></tr></table></figure><p>字节乘法中，其中一个操作数须放人寄存器A中，而另一个操作数则须放在寄存器B中，相乘后，结果分别放人寄存器A和B中，寄存器A保存低位字节，寄存器B保存高位字节。如下所示：225H与65H相乘的结果是16位数据，分别存入寄存器A和B中，如表所示。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262209071.png" alt="image-20231026220940002"></p><p> </p><h4 id="无符号数相除">无符号数相除</h4><p>字节相除时，分子必须放在寄存器A中，分母放在寄存器B中。除法指令完成之后，商存放入寄存器A中，余数存人寄存器B中。如下列代码和表6-3所示。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262211631.png" alt="image-20231026221104566"></p><p> </p><h3 id="CPL-A（累加器取反）">CPL A（累加器取反）</h3><p>此指令将寄存器内容的1变成0，反之亦然，所以称为取反（1’scomplement）。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310262228183.png" alt="image-20231026222810134"></p><p> </p><h3 id="比较指令">比较指令</h3><p>8051中含有比较指令。语法如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CJNE 目的操作数,源操作数,相对地址</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 课程总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电磁场原理</title>
      <link href="/posts/a3afa0e4.html"/>
      <url>/posts/a3afa0e4.html</url>
      
        <content type="html"><![CDATA[<h1>电磁场</h1><h2 id="矢量的基本概念">矢量的基本概念</h2><h3 id="1-矢量的表示">1.矢量的表示</h3><ol><li><p>图形表示</p></li><li><p>数学表示<br>$$<br>\vec{A}= \vec{a_A}\left | \vec{A} \right | = \vec{a_A}A<br>$$</p></li><li><p>坐标分量表示法</p></li></ol><p>$$<br>\vec{A}= \vec{a_x}A_x(x,y,z)+\vec{a_y}A_y(x,y,z)+\vec{a_z}A_z(x,y,z)<br>$$</p><p>$a_A$是沿A的方向且大小等于1的无量纲的单位矢量</p><p> </p><h3 id="2-矢量的加减">2.矢量的加减</h3><img src="/posts/a3afa0e4.htm/image-20230918162802552.png" alt="image-20230918162802552" style="zoom:50%;"><p>矢量的运算规则（Operation rules）</p><p>1.加减运算<br>$$<br>\begin{array}{ll}a.&amp;A+B=B+A\ \ b.&amp;A+B+C=(A+B)+C=A+(B+C)\ \ c.&amp;A-B=A+(-B)\end{array}<br>$$</p><p>$$<br>d  .\quad \begin{array}{r l}{if \quad A=\boldsymbol{a}<em>{x}A</em>{x}(x,y,z)+\boldsymbol{a}<em>{y}A</em>{y}(x,y,z)+\boldsymbol{a}<em>{z}A</em>{z}(x,y,z)}\ {B=\boldsymbol{a}<em>{x}B</em>{x}(x,y;z)+\boldsymbol{a}<em>{y}B</em>{y}(x,y,z)+\boldsymbol{a}<em>{z}B</em>{z}(x,y,z)}\ \end{array}<br>$$</p><p>then<br>$$<br>\begin{array}{l}A\pm B=\boldsymbol a_x(A_x\pm B_x)+\boldsymbol a_y(A_y\pm B_y)+\boldsymbol a_z(A_z\pm B_z)\ cA=\boldsymbol a_x(cA_y)+\boldsymbol a_y(cA_y)+\boldsymbol a_z(cA_z)\end{array}<br>$$<br>2.点乘运算<br>$$<br>A \bullet B = AB \cos \theta (\theta \leq \pi)<br>$$</p><p>$$<br>\theta=\cos^{-1}\frac{A\bullet B}{AB}=\cos^{-1}\frac{A_{x}B_{x}+A_{y}B_{y}+A_{z}B_{z}}{AB}<br>$$</p><p>3.叉乘运算（vector or cross product）<br>$$<br>C=|A\times B|=AB\sin\theta<br>$$<br><img src="/posts/a3afa0e4.htm/image-20230918170905521.png" alt="image-20230918170905521" style="zoom:50%;"></p><p>注意：叉乘有顺序，不可以使用交换律</p><p>方向：右手定则</p><img src="/posts/a3afa0e4.htm/image-20230918170845402.png" alt="image-20230918170845402" style="zoom:50%;">$$A\times B=a_{x}(A_{y}B_{z}-A_{z}B_{y})+a_{y}(A_{z}B_{x}-A_{x}B_{z})+a_{z}(A_{x}B_{y}-A_{y}B_{x})=\begin{vmatrix}\boldsymbol{a}_x&\boldsymbol{a}_y&\boldsymbol{a}_z\\ A_x&A_y&A_z\\ B_x&B_y&B_z\end{vmatrix}$$<p>$$<br>\theta=\sin^{-1}\frac{\left|A\times B\right|}{A B}<br>$$</p><p>4.三个矢量相乘</p><ol><li><p>模的几何意义是六面体的体积<br>$$<br>\mathbf{A}\bullet(\mathbf{B}\times\mathbf{C})=\mathbf{B}\bullet(\mathbf{C}\times\mathbf{A})=\mathbf{C}\bullet(\mathbf{A}\times\mathbf{B})<br>$$</p></li><li><p>遵从Back-cab rule</p></li></ol><p>$$<br>\begin{array}{l}\textbf{A}\times(\textbf{B}\times\textbf{C})=\textbf{B}(\textbf{A}\textbf{}\textbf{}\textbf{}\textbf{}\textbf{C})-\textbf{C}(\textbf{A}\textbf{}\textbf{}\textbf{}\textbf{}\textbf{B})\  \textbf{D}=\textbf{B}\times\textbf{C}\qquad\textbf{F}=\textbf{A}\times(\textbf{B}\times\textbf{C})\end{array}<br>$$</p><p>$$<br>\begin{aligned}F_x&amp;=A_y D_z-A_z D_y\ &amp;=A_y(B_x C_y-B_y C_z)-A_z(B_z C_x-B_x C_z)\ &amp;=B_x(A_y C_y+A_zC_z)-C_x(A_y B_y+A_z B_z)\ &amp;=B_x(\textbf{A}\textbf{C})-C_x(\textbf{A}\textbf{B})\end{aligned}<br>$$<br> </p><p> </p><h2 id="正交坐标系及其微分元（Orhogonal-coordinate-systems）">正交坐标系及其微分元（Orhogonal coordinate systems）</h2><p>常用的正交曲线坐标系</p><ol><li>直角坐标系</li><li>圆柱坐标系</li><li>球坐标系</li></ol><p>坐标线（轴）：三个正交曲面两两相交而成的曲线</p><p>坐标原点（基准点）:三条坐标系的焦点</p><p>坐标单位矢量：空间任意一点与坐标线相切且指向变量增加方向的三个单位矢量</p><p> </p><h3 id="正交坐标系的微分元">正交坐标系的微分元</h3><p>$$<br>\text{d}l=\left[(\text{d}l_1)<sup>2+(\text{d}l_2)</sup>2+(\text{d}l_3)<sup>2\right]</sup>{1/2}\ =\left[(h_1\text{d}u_1)<sup>2+(h_2\text{d}u_2)</sup>2+(h_3\text{d}u_3)<sup>2\right]</sup>{1/2}<br>$$</p><ol><li><p>Differential directed distance</p><p>$$<br>d\mathbf{1}=\mathbf{a}<em>{u1}dl_1+\mathbf{a}</em>{u2}dl_2+\mathbf{a}_{u3}dl_3<br>$$</p></li><li><p>Differential area<br>$$<br>\begin{aligned}ds_1&amp;=dl_2dl_3&amp;=h_2h_3ah_2dt_3\ ds_2&amp;=dl_1dl_3&amp;=h_1h_3dh_1du_3\ ds_3&amp;=dl_1dl_2&amp;=h_1h_2du_1du_2\end{aligned}<br>$$</p></li><li><p>Differential volume</p></li></ol><p>$$<br>dv=h_1h_2h_3du_1du_2du_3<br>$$</p><h4 id="1-直角坐标系（Cartesian-coordinates）">1.直角坐标系（Cartesian coordinates）</h4><p>$$<br>\text{(u}_1,\text{u}_2,\text{u}_3\text{)=(x,y,z)}<br>$$</p><ol><li><p>线元<br>$$<br>\begin{matrix}d\vec{l}_x=dx\vec{a}_x\ {d}\vec{l}_y={dy}\vec{a}_y\ {d}\vec{l}_z={dz}\vec{a}_z<br>\d\vec{l}=dx\vec{a}_x+dy\vec{a}_y+d{z}\vec{a}_z<br>\end{matrix}<br>$$</p></li><li><p>面元<br>$$<br>\begin{matrix}d\vec{S}_x=dy dz\vec{a_x}\ d\vec{S}_y=dx dz \vec{a_y}\ d\vec{S}_z=dx dy\vec{a}_z\end{matrix}<br>$$</p></li><li><p>体元<br>$$<br>dV=dx dy dz<br>$$</p></li></ol><h4 id="题型">题型</h4><p>已知一个线的矢量表达式A，求</p><ol><li>若B与A平行，那么求B的单位矢量表达式</li><li>若B垂直于A，且B处于x平面，求B的单位矢量表达式</li></ol><p>1.A×B=0 带入求解</p><p>2.A·B=0 带入求解</p><h4 id="2-圆柱坐标系（Cylindrical-coordinates）">2.圆柱坐标系（Cylindrical coordinates）</h4><p>$$<br>\left(\mathrm{u}_1,\mathrm{u}_2,\mathrm{u}_3\right)=\left(\mathrm{r},\mathrm{\varphi ,z}\right)<br>$$</p><ol><li><p>线元<br>$$</p><p>\text{d}\vec{l}=\text{d}r\vec{a}<em>r+r\text{d}\varphi\vec{a}</em>\varphi+\text{d}z\vec{a}_z</p><p>$$</p></li><li><p>面元<br>$$<br>\begin{aligned}\text{d}\vec{S}<em>r=r\text{d}\varphi\text{d}z\vec{a}<em>r\ \text{d}\vec{S}</em>\varphi=\text{d}r\text{d}z\vec{a}</em>\varphi\ \text{d}\vec{S}_z=r\text{d}\varphi\text{d}r\vec{a}_z\end{aligned}<br>$$</p></li><li><p>体元</p></li></ol><p>$$<br>\text{d}V=r\text{d}r\text{d}\varphi\text{d}z<br>$$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 电磁场 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性控制系统</title>
      <link href="/posts/b9875b9f.html"/>
      <url>/posts/b9875b9f.html</url>
      
        <content type="html"><![CDATA[<h1>自动控制原理</h1><p>​控制系统（Control system）:在给定的条件下，通过操纵达到预期性能的系统</p><p>​控制系统中的操纵器：控制器（contriller）/补偿器（compensator）[重点在于控制参数与结构]</p><p>控制器需要考虑的三大性能</p><ol><li>稳定性（Stability）：有界输入对应有界输出（BIBO）</li><li>瞬时响应（Transient response）：指标：响应速度</li><li>稳态响应（Steady-state response）</li></ol><p> </p><p>控制目标：</p><ol><li>稳定不稳定的系统</li><li>提高系统的稳定性；使得系统具有更好的稳定性。等效于改善系统的瞬时响应：更快的响应，较小的超调量，减小振荡</li><li>精准跟踪输入命令：减少/消除特定类型输入的稳态误差</li></ol><p> </p><p>判断微分方程，线性或非线性，时变或定长</p><p>是否为线性：如果每一项都是c(t),r(t),高阶导数，则为线性。但是如果出现平方线与单常数x则为非线性。</p><p>时变与非时变：c(t),r(t)的系数全是常数，不存在变量t</p><p> </p><h2 id="传递方程（transfer-function）">传递方程（transfer function）</h2><p>$$<br>a_{n}\frac{d<sup>{n}c(t)}{dt</sup>{n}}+a_{n-1}\frac{d<sup>{n-1}c(t)}{dt</sup>{n-1}}+\cdots+a_{0}c(t)=b_{m}\frac{d<sup>{m}r(t)}{dt</sup>{m}}+b_{m-1}\frac{d<sup>{m-1}r(t)}{dt</sup>{m-1}}+\cdots+b_{0}r(t)<br>$$</p><p>左右两边分别进行拉氏变换，我们假设其初始状态为0可得：<br>$$<br>(a_ns<sup>n+a_{n-1}s</sup>{n-1}+\cdots+a_0)C(s)=(b_ms<sup>m+b_{m-1}s</sup>{m-1}+\cdots+b_0)R(s)<br>$$</p><p>$$<br>\frac{C(s)}{R(s)}=G(s)=\frac{(b_ms<sup>m+b_{m-1}s</sup>{m-1}+\cdots+b_0)}{(a_ns<sup>n+a_{n-1}s</sup>{n-1}+\cdots+a_0)}<br>$$</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447490.png" alt="image-20231007193012932"></p><p>解题步骤：</p><ol><li><p>Replace passive element values with their impedances.</p></li><li><p>Replace all sources and time variables with their Laplace transform.</p></li><li><p>Assume a transform current and a current direction in each mesh.</p></li><li><p>Write Kirchhoff’s voltage law around each mesh.</p></li><li><p>Solve the simultaneous equations for the output.</p></li><li><p>Form the transfer function</p></li><li><p>将无源元件值替换为其阻抗。</p></li><li><p>将所有源和时间变量替换为其拉普拉斯变换。</p></li><li><p>假设每个网格中存在变换电流和当前方向。</p></li><li><p>在每个网格周围写出基尔霍夫电压定律。</p></li><li><p>求解联立方程以获得输出。</p></li><li><p>形成传递函数</p></li></ol><p>例题如下：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447493.png" alt="image-20231007193359608" style="zoom:67%;"><p>寻找其传递方程${I_2(s)/V(s)}$</p><ol><li><p>将无源元件值替换为其阻抗,并进行拉氏变换同时设定好电流在网格中的流动方向。<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447494.png" alt="image-20231007193625340"></p></li><li><p>在每个网格周围写出基尔霍夫电压定律。<br>$$<br>(R_1+Ls)I_1(s)&amp;-LsI_2(s)=V(s)\<br>-LsI_1(s)+\left(Ls+R_2+\frac{1}{Cs}\right)I_2(s)&amp;=0<br>$$</p></li><li><p>求解联立方程以获得输出。（一般情况下使用克莱姆法则）<br>$$<br>I_{2}(s)=\frac{\left|\begin{array}{cc}<br>\left(R_{1}+L s\right) &amp; V(s) \<br>-L s &amp; 0<br>\end{array}\right|}{\Delta}=\frac{L s V(s)}{\Delta}<br>$$</p><p>$$<br>\left.\Delta=\left|\begin{matrix}(R_1+Ls)&amp;-Ls\\-Ls&amp;\left(Ls+R_2+\frac{1}{Cs}\right)\end{matrix}\right.\right|<br>$$</p></li><li><p>整理可得传递方程为<br>$$<br>G(s)=\frac{I_{2}(s)}{V(s)}=\frac{Ls}{\Delta}=\frac{LCs<sup>{2}}{(R_{1}+R_{2})LCs</sup>{2}+(R_{1}R_{2}C+L)s+R_{1}}<br>$$</p></li></ol><p>利用拉普拉斯变换解微分方程的步骤如下：</p><p>①对方程两侧同时进行拉普拉斯变换，其中的F(s)就是我们要求的原函数经过拉普拉斯变换的结果；</p><p>②带入初值条件；</p><p>③把要求的原函数F(s)用关于s的表达式g(s)表达；</p><p>④对③中得到的F(s)=g(s)两侧进行拉普拉斯逆变换即可得到微分方程的解。</p><p>微分的拉式变换</p><p>一次微分$L[f’(t)]=sF(s)-f(0)$</p><p>二次微分$L[f’‘(t)]=s^2F(s)-sf(0)-f’(0)$</p><p>三次微分$L[f’‘’(t)]=s<sup>3F(s)-s</sup>2f(0)-sf’(0)-f’'(0)$<br>$$<br>L[f<sup>{\prime}(t)]=\int_{0}</sup>{\infty}e^{-s t}[e^{a t}f(t)]d t=e^{-s t}f(t)|\begin{array}{c}\ 0\end{array}+s\int_{0}<sup>{\infty}e</sup>{-s t}f(t)d t=s F(s)=f(0)<br>$$</p><h3 id="直线机械系统的传递函数（Translational-Mechanical-System）">直线机械系统的传递函数（Translational Mechanical System）</h3><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447495.png" alt="image-20231007195252596" style="zoom:80%;"><h3 id="旋转机械系统的传递函数（Rotational-Mechanical-System）">旋转机械系统的传递函数（Rotational Mechanical System）</h3><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447497.png" alt="image-20231007195402243" style="zoom:80%;"><h2 id="梅森公式">梅森公式</h2><p>计算<strong>任意</strong>输入节点到输出节点的传递函数的梅森增益公式为：<br>$$<br>P=\frac{1}{\Delta}\sum_{k=1}^{n}P_{k}\Delta_{k}<br>$$<br>其中$\Delta$为系统的特征多项式，其计算公式为：<br>$$<br>\Delta=1-\sum L_a+\sum L_bL_c-\sum L_dL_eL_f+\cdots<br>$$<br>其中:</p><p>$\sum L_a$为所有不同回路增益之和；</p><p>$\sum L_bL_c$为所有两两不接触回路增益之和；</p><p>$\sum L_dL_eL_f+\cdots$ 为所有互不接触的回路中，每次取其中三个回路的增益乘积之和；</p><p>后面的以此类推。n为从输入节点到输出节点的前向通路条数</p><p>$P_k$ 为从输入节点到输出节点的第k条前向通路的总增益；<br>$\Delta_{k}$ 为第k条前向通路的余子式，即把特征式$\Delta$中与该前向通道相接触的回路增益置零后剩余的部分。</p><p>在做题中一共分为4步：</p><ol><li><p>先找出所有的闭环回路，即为 $\sum L_a$，再找出两两不相邻回路，即为$\sum L_bL_c$，依次类推直到找全,求出整个系统的特征式</p></li><li><p>接着找出系统的前向通路，即为$ \sum P_{k}$</p></li><li><p>找到每一项的余子式，各回路均与前向通路如果有接触，其余子式为1；如果相互没有接触<br>，其余子式为$1-其闭环回路$</p></li><li><p>带入即可求得其传递函数</p></li></ol><h2 id="一阶系统分析">一阶系统分析</h2><p>一阶系统的传递函数标准形式为：$G(s)=\frac{C(s)}{R(s)}=\frac{1}{Ts+1}$</p><p>以输入信号为单位脉冲响应举例，单位脉冲信号的拉式变换为1，即$R(s)=1$其拉氏变换应为其自身的拉式变换。化简s的系数为1可得：$G(s)=\frac{1}{Ts+1}=\frac{1}{T}\cdot\frac{1}{s+1/T}$</p><p>进行拉氏变换：$c(t)=\mathscr{L}<sup>{\prime}\bigl[G(s)\bigr]=\frac{1}{T}\cdot\mathrm{e}</sup>{-\frac{1}{T}\prime}$</p><p>有例题如下：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447498.png" alt="image-20231018171501486"></p><p>根据框图可以求得其传递函数为：$\frac{C(s)}{R(s)}=\frac{K_{h}G(s)}{1+K_{f}G(s)}=\frac{10K_{h}}{1+10K_{f}}\cdot\frac{1}{\frac{0.2}{1+10K_{f}}s+1}$</p><p>改变题目给定的传递时间由0.2变为0.02</p><p>可得：$\frac{10K_\mathrm{h}}{1+10K_\mathrm{f}}\cdot\frac1{\frac{0.2}{1+10K_\mathrm{f}}s+1}=\frac{10}{0.02s+1}$</p><p>列式可得：$\left.\left{\begin{array}{cc}\frac{10K_\mathrm{h}}{1+10K_\mathrm{f}}=10\\\frac{0.2}{1+10K_\mathrm{f}}=0.02\\end{array}\right.\right.$</p><p>解:$K_{f}=0.9,K_{h}=10$</p><p> </p><h2 id="劳斯判据">劳斯判据</h2><p>可以根据<code>闭环传递函数的特征方程</code>如下表格对应写拉斯表</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447499.png" alt="image-20231018172507370"></p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447500.png" alt="image-20231018172512271"></p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447501.png" alt="image-20231018172520189"></p><p>举例:<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447502.png" alt="image-20231018172543560"></p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447503.png" alt="image-20231018172633894" style="zoom:67%;"><p>由于第一列的系数不全为正，因此系统不稳定。</p><p>例题：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447504.png" alt="image-20231018172732060"></p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447505.png" alt="image-20231018172746303" style="zoom:67%;"><p>由于第一列的系数都大于零，所以该系统稳定。</p><h3 id="劳斯判据中的特殊情况">劳斯判据中的特殊情况</h3><p>（1）在计算中，第一列有零出现。</p><p>出现这种情况时，可以用一个很小的正数代替，继续完成计算。如果第一列中的元素除了出现的零值外，其余全部大于零，则说明系统有临界稳定的特征根。</p><p>（2）第一列的系数出现变号：改变符号（正负相互转化）的次数，即不稳定根的个数。</p><p>举例：$s^{3}-3s+2=0$</p><p>其劳斯表为：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447506.png" alt="image-20231018173756661" style="zoom:67%;"></p><p>这个变号的次数即为不稳定跟的个数。</p><p>（3）出现零行（即劳斯表的每一行都是0），则存在大小相等，方向相反的根。</p><p>$s<sup>{5}+2s</sup>{4}+24s<sup>{3}+48s</sup>{2}-25s-50=0$</p><p>劳斯表计算中出现零行时，可用零行的前一行作辅助多项式$P（s）$，然后由$\frac{dP(s)}{ds}$的系数行代替零行，完成劳斯表的计算，如下面例题所示。<br><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447507.png" alt="image-20231018174115812"><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447508.png" alt="image-20231018174123715" style="zoom:67%;"></p><p> </p><p>例题：</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447509.png" alt="image-20231018174402971" style="zoom:80%;"><p>根据框图可以得到其闭环传递函数为：$G_c(s)=\frac{\frac{10}{s(s+2)}}{1+(1+10s)\frac{10}{s(s+2)}}=\frac{10}{s^2+102s+10}$</p><p>闭环特征方程为：$s^2+102s+10=0$</p><p>据此列劳斯表易，其系数全部为正，即方程稳定。</p><p> </p><p> </p><h2 id="二阶系统分析">二阶系统分析</h2><p>二阶系统的结构图如下：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447510.png" alt="image-20231018174729779"></p><p>其开环传递函数为：<br>$$<br>G_{<em>{o}}(s)=\frac{\omega</em>{n}^{2}}{s(s+2\zeta\omega_{<em>{n}})}<br>$$<br>闭环传递函数：<br>$$<br>G</em>{c}(s)=\frac{\omega_{n}<sup>{2}}{s</sup>{2}+2\zeta\omega_{n}s+\omega_{n}^{2}}<br>$$<br>闭环传递函数的分母多项式等于零的代数方程称为二阶系统的闭环特征方程，即<br>$$<br>s<sup>{2}+2\zeta\omega_{_n}s+\omega_{_n}</sup>{2}=0<br>$$<br>闭环特征方程的两个根称为二阶系统的特征根，即<br>$$<br>s_{<em>{1,2}}=-\zeta\omega</em>{<em>n}\pm\omega</em>{_n}\sqrt{\zeta^{2}-1}<br>$$</p><table><thead><tr><th>符号</th><th>名称</th><th>量纲</th></tr></thead><tbody><tr><td>$\zeta$</td><td>二阶系统的阻尼比</td><td>1</td></tr><tr><td>$ \omega_{_n}$</td><td>无阻尼振荡频率</td><td>rad/s</td></tr></tbody></table><p>根据$\zeta$的值范围的不同，一共有如下物种情况：</p><table><thead><tr><th>范围</th><th>特征根位置</th><th>系统响应情况</th></tr></thead><tbody><tr><td>$\zeta &gt; 1$</td><td>特征根为一对不相等的负实根，位于s平面的负实轴上</td><td>过阻尼</td></tr><tr><td>$\zeta = 1$</td><td>特征根为一对相等的负实根；也是位于s平面的负实轴上</td><td>临界阻尼</td></tr><tr><td>$0&lt; \zeta &lt;1$</td><td>特征根为一对带有负实部的共钜复数根，位于s平面的左半平面上</td><td>欠阻尼</td></tr><tr><td>$\zeta = 0$</td><td>特征根为一对纯虚根，位于s平面的虚轴上</td><td>无阻尼</td></tr><tr><td>$\zeta &lt; 0$</td><td>特征根位于s平面的右半平面上</td><td>发散</td></tr></tbody></table><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447511.png" alt="image-20231018175617105" style="zoom:80%;"><h3 id="二阶系统的性能指标计算">二阶系统的性能指标计算</h3><table><thead><tr><th>符号</th><th>名称</th><th>计算式</th></tr></thead><tbody><tr><td>$\omega_{\mathrm{d}}$</td><td>阻尼振荡频率（rad/s）</td><td>$\omega_{\mathrm{d}}=\omega_{_n}\sqrt{1-\xi^{2}}$</td></tr><tr><td>$t_r$</td><td>上升时间</td><td>$t_{<em>r}=\frac{\pi-\beta}{\omega</em>{_\mathrm{d}}}$</td></tr><tr><td>$t_p$</td><td>峰值时间</td><td>$t_{<em>p}=\frac{\pi}{\omega</em>{_d}}$</td></tr><tr><td>$M_p$</td><td>超调量</td><td>$M_p=\mathrm{e}<sup>{-\frac\zeta{\sqrt{1-\zeta</sup>2}}\pi}\times100%$</td></tr><tr><td></td><td></td><td></td></tr></tbody></table><p>依照一阶系统调节时间的计算公式可以近似估算二阶欠阻尼系统的调节时间为:</p><p>$t_{<em>s}=3T={\frac{3}{\zeta\omega</em>{_n}}},\pm5%\text{误差带宽度时}$</p><p>$t_{<em>s}=4T=\frac{4}{\zeta\omega</em>{_n}},\pm2%\text{误差带宽度时}$</p><p> </p><p>有例题如下：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447512.png" alt="image-20231018180846066"></p><p>根据框图易得其开环传递函数如下：<br>$$<br>G_{<em>o}(s)=\frac{5K}{s(s+34.5)}<br>$$<br>（1）闭环传递函数：<br>$$<br>G</em>{<em>c}(s)=\frac{G</em>{<em>s}(s)}{1+G</em>{<em>s}(s)}=\frac{\frac{5K}{s(s+34.5)}}{1+\frac{5K}{s(s+34.5)}}=\frac{5K}{s<sup>{2}+34.5s+5K}=\frac{1000}{s</sup>{2}+34.5s+1000}<br>$$<br>带入标准二阶传递函数形式，可得特征根参数：<br>$$<br>G</em>{\mathrm{c}}(s)=\frac{1}{s<sup>{2}+34.5s+1000}=\frac{\omega_{n}</sup>{2}}{s<sup>{2}+2\zeta\omega_{n}s+\omega_{n}</sup>{2}}<br>$$</p><p>$$<br>\begin{gathered}<br>2\zeta\omega_{n}=34.5,\omega_{n}^{2}=1000 \<br>\omega_{n}=31.6\mathrm{rad/s} \<br>\zeta=0.545<br>\end{gathered}<br>$$</p><p>峰值时间：$$t_{<em>p}=\frac{\pi}{\omega</em>{<em>d}}=\frac{\pi}{\omega</em>{_n}\sqrt{1-\zeta<sup>{</sup>2}}}=0.12\mathrm{s}$$</p><p>超调量：$M_{_p}=\mathrm{e}<sup>{-\frac{\zeta}{\sqrt{1-\zeta</sup>{2}}}\pi}\times100%=0.13\times100%=13%$</p><p>调节时间：$\begin{aligned}t_{s}&amp;=\frac{3}{\zeta\omega_{n}}=0.17\mathrm{s}(\pm5%)\t_{s}&amp;=\frac{4}{\zeta\omega_{n}}=0.23\mathrm{s}(\pm2%)\end{aligned}$</p><p>（2）讨论K=1500和K=13.5时，对系统动态性能的影响。</p><p>当K=1500时，闭环传递函数为：$G_{_{c}}(s)=\frac{5K}{s<sup>{2}+34.5s+5K}=\frac{7500}{s</sup>{2}+34.5s+7500}$</p><p>特征参数：$\omega_{n}=86.6\mathrm{rad/s},\zeta=0.2$</p><p>性能指标：$t_{<em>p}=0.037s,M</em>{<em>p}=52.7%,t</em>{_s}=0.17s$</p><p>可得其阻尼振荡频率：$\omega_{\mathrm{d}}=\omega_{\mathrm{n}}\sqrt{1-\zeta<sup>{2}}=86.6\sqrt{1-0.2</sup>{2}}\mathrm{rad/s=84.85rad/s}$</p><p> </p><p>当K=13.5时，闭环传递函数为:</p><p>$G_{\mathrm{c}}(s)=\frac{5K}{s<sup>{2}+34.5s+5K}=\frac{67.5}{s</sup>{2}+34.5s+67.5}$</p><p>对应特征参数为：$\omega_{_n}=8.22\mathrm{rad/s}$</p><p>$\zeta=2.1$</p><p>此时，系统为过阻尼的，没有超调量，曲线上升很慢。由近似计算可求得调节时间为：$t_{s}\approx3T_{1}=1.44\mathrm{s}$</p><h4 id="过阻尼情况下的调节时间">过阻尼情况下的调节时间</h4><p>过阻尼系统的阻尼系数比：$\zeta&gt;1$</p><p>特征根为两个不相等的负实根：$s_{<em>{1,2}}=-\zeta\omega</em>{<em>n}\pm\omega</em>{_n}\sqrt{\zeta^{2}-1}$</p><p>闭环传递函数为：$G_{c}\left(s\right)=\frac{\omega_{n}<sup>{2}}{s</sup>{2}+2\zeta\omega_{<em>{n}}s+\omega</em>{n}^{2}}=\frac{\frac{1}{T_{1}T_{2}}}{\left(s+\frac{1}{T_{1}}\right)\left(s+\frac{1}{T_{2}}\right)}$</p><p>注意到在时间响应$ c（t）$的表达式中，当$T_2&lt;&lt;T_1$时，因为第三项极快地衰减到零。忽略该项后，时间响应$c(t)$可以近似为一阶系统的时间响应</p><p>$c(t)\approx1-\mathrm{e}^{-\frac{1}{T}\prime}$</p><p>因此，一阶系统的调节时间$t_s$用一阶系统的时间常数T作为参变量表示为:</p><p>$t_s=3T,\text{取误差带宽度为}\pm5%\text{时}$</p><p>$t_s=4T,\text{取误差带宽度为}\pm2%\text{时}$</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201447513.png" alt="image-20231018182939773" style="zoom:50%;"><p> </p><h3 id="二阶系统响应特性的改善"><strong>二阶系统响应特性的改善</strong></h3><h4 id="1-误差信号的比例微分控制（PD控制）">1.误差信号的比例微分控制（PD控制）</h4><p>在原典型二阶系统的前向通路上增加误差信号的速度分量并联通路。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211605259.png" alt="image-20231021160559090"></p><p>2.输出量的速度反馈控制（SF控制）<br>在原典型二阶系统的反馈通路上增加输出信号的速度分量反馈信号。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211606436.png" alt="image-20231021160638285"></p><p>例题：<img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211607774.png" alt="image-20231021160743574"></p><p>易知上图的闭环传递函数为：<br>$$<br>G_{c}(s)=\frac{\frac{K}{s(s+1)}}{1+\frac{K}{s(s+1)}(1+K_{fs})}=\frac{K}{s^{2}+(1+KK_{f})s+K}<br>$$<br>比较二阶系统的标准式有：<br>$$<br>\omega_{n}^{2}=K<br>$$</p><p>$$<br>2\zeta\omega_{n}=1+KK_{f}<br>$$</p><p>给定的性能指标为：<br>$$<br>M_{<em>p}=20%,\text{和}t</em>{<em>p}=1\mathrm{s}<br>$$<br>通过：${M</em>{_p}=\mathrm{e}<sup>{-\frac{\zeta}{\sqrt{1-\zeta</sup>{2}}}\pi}\times100%=20%}$</p><p>$ {t_{<em>p}=\frac{\pi}{\omega</em>{<em>d}}=\frac{\pi}{\omega</em>{_n}\sqrt{1-\zeta^{2}}}=1\mathrm{s} }$</p><p>解得：$\begin{array}{c}{\zeta=0.456}\{\omega_{n}=3.53}\\end{array}$</p><p>所以：$\begin{array}{c}{K=\omega_{n}<sup>{2}=3.53</sup>{2}=12.5}\{K_{f}=\frac{2\sqrt{K}\zeta-1}{K}=0.178}\\end{array}$</p><p>当K=12.5，$K_f = 0.178$时，可得：<br>$$<br>\begin{aligned}G_{e}(s)&amp;=\frac{12.5}{s<sup>{2}+s+12.5}\\\xi&amp;=\frac{1}{2\sqrt{K}}=0.14\\\M_{_p}&amp;=\mathrm{e}</sup>{-\frac{\xi}{\sqrt{1-\epsilon^2}}\pi}\times100%=64%\end{aligned}<br>$$</p><h3 id="控制系统的稳态误差分析">控制系统的稳态误差分析</h3><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211619265.png" alt="image-20231021161910919"></p><p>稳态误差系数类型：</p><p>1.当输入为单位阶跃信号时：$\lim_{s\to0}G_{_0}(s)$定义为系统的静态位置误差系数$K_p$，表示为：</p><p>$K_{<em>p}=\operatorname*{lim}</em>{s\to0}G_{_0}(s)$</p><p>其稳态误差：$e_{ss}=\frac{1}{1+K_{_p}}$</p><p>2.当输入为单位斜坡信号时：$\lim_{s\to0}G_{_0}(s)$定义为系统的静态位置误差系数$K_v$，表示为：</p><p>$K_{v}=\lim_{s\rightarrow0}s\cdot G_{_{o}}(s)$</p><p>其稳态误差：$e_{ss}=\frac{1}{K_{v}}$</p><p>3.当输入为加速度信号时：$\lim_{s\to0}G_{_0}(s)$定义为系统的静态位置误差系数$K_a$，表示为：</p><p>$K_{a}=\lim_{s\rightarrow0}s^{2}G_{_0}(s)$</p><p>其稳态误差：$e_{<em>{\mathrm{ss}}}=\frac{1}{K</em>{_{a}}}$</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211627804.png" alt="image-20231021162714529"></p><p> </p><h2 id="根轨迹法">根轨迹法</h2><h3 id="绘制负反馈系统的9条法则">绘制负反馈系统的9条法则</h3><p>1.连续性；</p><p>2.对称性；</p><p>3.根轨迹的分支数；</p><p>根轨迹的分支数等于系统的阶数</p><p>4.根轨迹的起点和终点；</p><p>$\frac{\prod_{j=1}<sup>{m}\left(s+z_{j}\right)}{\prod_{i=1}</sup>{n}\left(s+p_{i}\right)}=-\frac{1}{K_{g}}$</p><p>当$K_g = 0$是根轨迹的起点，分母等于零即为系统的开环极点</p><p>当$K_g = \infty$是根轨迹的起点，分子等于零即为系统的开环零点</p><p>5.实轴上的根轨迹；</p><p>在实轴上选取实验点$s_i$，如果实验点$s_i$的右方实轴上的开环零点数和极点数的总和为奇数，则实验点$s_i$所在的实验段是根轨迹，否则该实验段不是根轨迹。</p><p>6.根轨迹的会合点与分离点；</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211642610.png" alt="image-20231021164241432" style="zoom:67%;"><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211642538.png" alt="image-20231021164256350" style="zoom:67%;"><p>计算分离点或汇合点：</p><p>$N’(s)D(s)-N(s)D’(s)=0$</p><p>PS：其中N(s)为变量s的分子多项式，D(s)为变量s的分母多项式。</p><p>7.根轨迹的渐近线（与实轴交点；倾斜角）</p><p>与实轴交点：$-\sigma=-\frac{a_{n-1}-b_{m-1}}{n-m}=-\frac{\sum_{i=1}<sup>{n}p_{i}-\sum_{j=1}</sup>{m}z_{j}}{n-m}$</p><p>倾斜角：$\theta=\frac{\pm180^{\circ}(2k+1)}{n-m}$</p><p>8.与虚轴交点；</p><p>根轨迹可能与虚轴相交，交点坐标的$\omega $值及相应的$K_g$值可由劳斯判据求得，也可在特征方程中令s=j$\omega$ ，然后使特征方程的实部和虚部分别为零求得。</p><p>9.出射角与入射角</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310211648637.png" alt="image-20231021164835441" style="zoom:67%;"><p>幅角条件为:$\sum_{j=1}<sup>{n}\arg[s+z_{j}]-\sum_{i=1}</sup>{n}\arg[s+p_{i}]\Bigg|_{s = s_g}=\pm180^{\circ}(2k+1)$</p><p>令$\left.\theta_{j}=\arg\left[\begin{array}{c}{s+z_{j}}\\end{array}\right.\right],\varphi_{i}=\arg\left[\begin{array}{c}{s+p_{i}}\\end{array}\right]$</p><p>出射角：$\varphi_{k}=\mp180<sup>{\circ}(2k+1)+\sum_{j=1}</sup>{m}\theta_{j}-\sum_{i=1;i\ne k}^{n}\varphi_{i}\Bigg|<em>{s=p</em>{k}}$</p><p>入射角：$\theta_{l}=\pm180^{\circ}(2k+1)-\sum_{j=1\atop j\neq l}<sup>{m}\theta_{j}+\sum_{i=1}</sup>{n}\varphi_{i}\Bigg|<em>{s=z</em>{i}}$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 课程总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>结构化数字设计</title>
      <link href="/posts/3c5c3e03.html"/>
      <url>/posts/3c5c3e03.html</url>
      
        <content type="html"><![CDATA[<h1>数字化结构设计</h1><h2 id="层次建模的概念">层次建模的概念</h2><h3 id="设计方法学">设计方法学</h3><p>两种基本的设计方法：<code>自底向上</code>和<code>自顶向下</code>设计</p><p>1.自底向上</p><p>2.自顶向下</p><p>通常情况下，两种方法混合使用。</p><p> </p><p> </p><h2 id="模块">模块</h2><p>​ Verilog使用模块（module）的概念来代表一个基本的功能块。</p><p>​一个模块可以是一个元件，也可以是低层次模块的组合</p><h3 id="1-模块声明">1.模块声明</h3><p>​在Verilog中，模块声明是由关键字module开始，关键字endmodule必须出现在模块定义的结尾。每个模块必须有一个模块名，由它唯一的标志这个模块。模块的端口列表则描述这个模块的输入和输出端口</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> &lt;模块名&gt;(&lt;模块端口列表&gt;);</span><br><span class="line">...</span><br><span class="line">&lt;模块的内容&gt;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>例如在脉动进位计数器的例子中，T触发器可以定义为：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> T_FF (q, clock ,reset);</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">&lt;T触发器的功能描述&gt;</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>​使用Verilog可以在每个模块内4个抽象层次进行描述，定义如下：</p><ol><li>行为或算法级：注重实现的算法，并不注重硬件实现的细节</li><li>数据流级：说明数据的流程对模块进行描述，数据如何在各个寄存器之间流动，以及如何处理这些数据。</li><li>门级：从组成电路的逻辑门及其之间的相互关系的角度设计模块。</li><li>开关级：通过开关，储存节点及其互连关系来设计模块。</li></ol><p> </p><h3 id="2-模块实例">2.模块实例</h3><p>​模块声明类似于一个模板，使用这个模板就可以创建实际的对象。当一个模块被调用的时候，Verilog会根据模板创建一个唯一的模块对象，每个对象都有其各自的名字、变量、参数和输入/输出（I/O）接口。</p><p>​从模板创建对象的过程称为<code>实例化</code>（instantiation），创建的对象称为<code>实例</code>（instance）</p><p> </p><p>​在Verilog中，不允许在模块声明中嵌套模块，也就是在模块声明的module和endmodule关键字之间不能再包含模块声明。模块之间的相互调用是通过实例引用来完成的。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//它引用了4个触发器。它们之间的连接参见2.2节</span></span><br><span class="line"><span class="comment">//定义名为ripple_carry_counter（脉动进位计数器）的模块</span></span><br><span class="line"><span class="keyword">module</span> ripple_carry_counter(q,clk,reget);</span><br><span class="line">    <span class="keyword">output</span>[<span class="number">3</span>:<span class="number">0</span>]q;<span class="comment">//输人输出端口的信号和向量声明，以后会讲解</span></span><br><span class="line"><span class="keyword">input</span> clk,reset；<span class="comment">//输入/输出端口的信号声明，以后会讲解</span></span><br><span class="line"><span class="comment">//生成了4个触发器TEF的实例，每个实例都有自己的名字，每个实例都传递一组信号</span></span><br><span class="line"><span class="comment">//注意每个实例都是FF模块的副本</span></span><br><span class="line">    TFF tff0 (q[<span class="number">0</span>]，clk,reset);</span><br><span class="line">    TFF tff1 (q[<span class="number">1</span>]，q[<span class="number">0</span>]，reset);</span><br><span class="line">    TFF tff2 (q&#123;<span class="number">2</span>&#125;，q[<span class="number">1</span>]，reset);</span><br><span class="line">    TFF tff3 (q[<span class="number">3</span>]，q[<span class="number">2</span>]，reset);</span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"><span class="comment">//定义名为TFF（触发器）的模块。它引用了一个D触发器。我们在本模块中假设</span></span><br><span class="line"><span class="comment">//D触发器（DEF）已经在该设计中的别处定义了，参见图2.4，看它们之间的互相连接</span></span><br><span class="line">moaule TFF (q,clk,reset);</span><br><span class="line"><span class="comment">//以后将对下列语句做进一步的解释</span></span><br><span class="line"><span class="keyword">output</span> q;<span class="number">0</span></span><br><span class="line"><span class="keyword">input</span> clk,reset;</span><br><span class="line"><span class="keyword">wire</span> d;</span><br><span class="line">DFF dff0（q,d,clk,reset）;<span class="comment">//调用（实例引用）DFF，取名为dffo</span></span><br><span class="line"><span class="keyword">not</span> n1（d,q）;<span class="comment">//非门（not）是veri1og语言的内部原语部件（primitive），以后会讲解</span></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>ps:关键字必须是小写字母</p><p> </p><p> </p><h2 id="基本概念">基本概念</h2><p>Verilog中的基本词法约定与c语言类似。</p><h3 id="数字声明">数字声明</h3><ol><li><p>指明位数的数字</p><p>指明位数的数字表现形式为</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;size&gt;&#x27;&lt;base format&gt;&lt;number&gt;</span><br></pre></td></tr></table></figure><p>$<size>$用来指明数字的宽度（二级制的个数），只能用十进制表示。Base format表示用什么进制</size></p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4&#x27;b1111</span><span class="comment">//这是一个4位的二进制数</span></span><br><span class="line"><span class="number">12&#x27;habc</span><span class="comment">//这是一个12位的十六进制数</span></span><br><span class="line"><span class="number">16&#x27;d255</span><span class="comment">//这是一个16位的十进制数</span></span><br></pre></td></tr></table></figure></li><li><p>不指明位数的数字</p><p>没有指定基数默认为十进制数。如果没有指定宽度，则默认为32位</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">234566</span><span class="comment">//这是一个32位的十进制数</span></span><br><span class="line"><span class="number">&#x27;hc3</span><span class="comment">//这是一个32位的十六进制数</span></span><br><span class="line"><span class="number">&#x27;o21</span><span class="comment">//这是一个32位的八进制数</span></span><br></pre></td></tr></table></figure></li><li><p>X和Z值</p><p>x表示不确定值，z表示高阻值；不区分x，y的大小写。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12&#x27;h13x</span><span class="comment">//这是一个12位的十六进制数，四个最低位不确定6&#x27;hx//这是一个6位的十六进制数，所有位都不确定</span></span><br><span class="line"><span class="number">32&#x27;bz</span><span class="comment">//这是一个32位的高阻值</span></span><br></pre></td></tr></table></figure><p>​16进制为基数的表示中x或z表示4位，在8进制，x，z表示3位，在2进制中x，z代表1位。如果某数的最高位是0，x或z，verilog语言约定将分别使用0，x，z自动对这个数进行扩展，填满余下的更高位。如果最高位是1，余下的更高位用0来扩展。</p></li><li><p>复数</p><p>对于常数，我们可以通过在表示位宽的数字前面增加一个减号来表示它是一个负数，因为表示大小的常数总是正的。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-<span class="number">6&#x27;d3</span><span class="comment">//这是一个6位的用二进制补码形式存储的十进制数3，表示负数</span></span><br><span class="line">-<span class="number">6</span>&#x27;sd3<span class="comment">//这是一个6位的用于带符号算术运算的负数</span></span><br><span class="line"><span class="number">4</span>&#x27;d-<span class="number">2</span><span class="comment">//非法说明</span></span><br></pre></td></tr></table></figure></li><li><p>下划线和问号</p><p>除了第一个字符，下划线可以出现在数字中的任何位置，它的作用只是提高可读性，在编译阶段会被忽略，？是z的另一种表示。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">12&#x27;b1111_0000_1010</span><span class="comment">//用下划线符号来提高可读性4&#x27;b10??//相当于4&#x27;b10zz</span></span><br></pre></td></tr></table></figure></li><li><p>转义标识符</p><p>转义标识符以反斜线“\”开始，以空白符（空格、制表符和换行符）结束。Verilog将反斜线和空白符之间的字符逐个进行处理。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\a+b-C <span class="comment">//译者注：与a+b-c等同</span></span><br><span class="line">\**my_name** <span class="comment">//译者注：如果作为标识符则与**my_name**等同</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="数据类型">数据类型</h3><ol><li><p>值的种类</p><p>Verilog使用四值逻辑和八种信号强度来对实际的硬件电路建模。</p><table><thead><tr><th>值的级别</th><th>硬件电路中的条件</th></tr></thead><tbody><tr><td>0</td><td>逻辑0，条件为假</td></tr><tr><td>1</td><td>逻辑0，条件为假</td></tr><tr><td>x</td><td>逻辑值不确定</td></tr><tr><td>z</td><td>高阻，浮动状态</td></tr></tbody></table><table><thead><tr><th>强度等级</th><th>类型</th><th>程度</th></tr></thead><tbody><tr><td>supply</td><td>驱动</td><td>最强</td></tr><tr><td>strong</td><td>驱动</td><td></td></tr><tr><td>pull</td><td>驱动</td><td></td></tr><tr><td>large</td><td>储存</td><td></td></tr><tr><td>weak</td><td>驱动</td><td></td></tr><tr><td>medium</td><td>储存</td><td></td></tr><tr><td>small</td><td>储存</td><td></td></tr><tr><td>highz</td><td>高阻</td><td>最弱</td></tr></tbody></table></li><li><p>线网</p><ol><li><p>线网（net：代表了一类数据类型，包括wire，wand，wor，tri，trireg等）标识硬件单元之间的连接。</p></li><li><p>就像在真实的电路中一样，线网由其连接器件的输出连续驱动。</p></li><li><p>线网一般使用关键字wire进行声明。如果没有明显说明向量，则默认线网的位宽为1</p></li><li><p>线网的默认值为z（trireg类型的线网例外，其默认值为x），线网的值由驱动源确定，如果没有驱动源，则线网的值为z</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span> a;<span class="comment">//声明上面的电路中a是wrie（连线）类型</span></span><br><span class="line"><span class="keyword">wire</span> b,c;<span class="comment">//声明上面的电路中b和c也是wire（连线）类型</span></span><br><span class="line"><span class="keyword">wire</span> d = <span class="number">1&#x27;b0</span>;<span class="comment">//连线d在声明时，d被赋值为逻辑值0</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>寄存器</p><ol><li><p>寄存器用来表示储存元件，它保持原有的树脂，直到被改写。</p></li><li><p>寄存器数据类型一般通过关键字reg来声明，默认值为X</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> reset;<span class="comment">//声明能保持数值的变量reset</span></span><br><span class="line">initia1 <span class="comment">//这个结构将在以后讨论</span></span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">reset = <span class="number">1&#x27;b1</span>;<span class="comment">//把reset初始化为1，使数字电路复位</span></span><br><span class="line">#<span class="number">100</span> reset=<span class="number">1&#x27;b0</span>;<span class="comment">//经过100个时间单位后，reset置逻辑0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>向量</p><ol><li><p>线网和寄存器类型的数据均可以声明为向量（位宽大于1）。若在声明中没有指定位宽，则默认为标量（1位）</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span> a;<span class="comment">//标量线网变量，默认</span></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] bus;<span class="comment">//8位的总线</span></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">31</span>:<span class="number">0</span>] busA,busB,busC;<span class="comment">//3条32位宽的总线</span></span><br><span class="line"><span class="keyword">reg</span> clock;<span class="comment">//标量寄存器，默认</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">0</span>:<span class="number">40</span>] virtual_addr;<span class="comment">//向量寄存器，41位宽的虚拟地址</span></span><br></pre></td></tr></table></figure><ol><li><p>向量域选择</p><p>对于上面例子中声明的向量，我们可以指定它的某一位或若干个相邻位。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">busA[<span class="number">7</span>] <span class="comment">//向量busA的第7位</span></span><br><span class="line">bus[<span class="number">2</span>:<span class="number">0</span>]<span class="comment">//向量bus的最低3位</span></span><br><span class="line"><span class="comment">//如果写成bus[0:2]是非法的，因为高位应该写在范围说明的左侧</span></span><br><span class="line">virtual_addr[<span class="number">0</span>:<span class="number">1</span>]<span class="comment">//向量virtual_addr的两个最高位</span></span><br></pre></td></tr></table></figure></li><li><p>可变的向量域选择</p><p>[<startingbit>+：width]：从起始位开始递增，位宽为width。</startingbit></p><p>[<startingbit>-：width]：从起始位开始递减，位宽为width。</startingbit></p></li></ol></li></ol><p>起始位可以是一个变量，但是位宽必须是一个常量。下面的例子说明了可变的向量域选择的使用方法：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span>[<span class="number">255</span>:<span class="number">0</span>]data1;<span class="comment">//data1【255】是最高有效位</span></span><br><span class="line"><span class="keyword">reg</span>[<span class="number">0</span>:<span class="number">255</span>]data2;<span class="comment">//data2【0】是最高有效位</span></span><br><span class="line"><span class="keyword">reg</span>[<span class="number">7</span>:<span class="number">0</span>]<span class="keyword">byte</span>;</span><br><span class="line"><span class="comment">//用变量选择向量的一部分</span></span><br><span class="line"><span class="keyword">byte</span>=data1[<span class="number">31</span>-:<span class="number">8</span>];<span class="comment">//从第31位算起，宽度为8位，相当于data131:24】</span></span><br><span class="line"><span class="keyword">byte</span>=data1[<span class="number">24</span>+:<span class="number">8</span>];<span class="comment">//从第24位算起，宽度为8位，相当于data1【31:24】</span></span><br><span class="line"><span class="keyword">byte</span>=data2[<span class="number">31</span>-:<span class="number">8</span>];<span class="comment">//从第31位算起，宽度为8位，相当于data2【24:31】</span></span><br><span class="line"><span class="keyword">byte</span>=data2[<span class="number">24</span>+:<span class="number">8</span>];<span class="comment">//从第24位算起，宽度为8位，相当于data2【24:311//超始位可以是变量，但宽度必须是常数。因此可以通过可变域选择，//用循环语句选取一个很长的向量的所有位</span></span><br><span class="line"><span class="keyword">for</span>(j=<span class="number">0</span>;j&lt;=<span class="number">32</span>;j=j+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">byte</span>=data1[(j*<span class="number">8</span>)+<span class="number">8</span>];<span class="comment">//次序是【7:0】，【15:81..【255:248】</span></span><br><span class="line"><span class="comment">//用于初始化向量的一个域</span></span><br><span class="line">data1[(byteNum*<span class="number">8</span>)+:<span class="number">8</span>] = <span class="number">8&#x27;b0</span>;<span class="comment">//如果byteNum=1，共有8位被清零，【15:8】</span></span><br></pre></td></tr></table></figure></li><li><p>数字，实数和时间寄存器的数据类型</p><p>除reg类型之外，Verilog还支持integer,real和time寄存器数据类型。</p><ol><li><p>整数</p><p>用关键字integer进行声明，虽然可以用reg类型的寄存器作为通用变量，但声明一个整体类型的变量来完成计数会更为方便。</p><p>整数默认位宽为宿主机的字的位数，最小应为32位。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> counter;<span class="comment">//一般用途的变量，作为计数器initial</span></span><br><span class="line">coumter=-<span class="number">1</span>;<span class="comment">//把-1存储到计数器中</span></span><br></pre></td></tr></table></figure></li><li><p>实数</p><p>用real来声明，实数声明不能带有范围，默认值为0。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">real</span> delta;<span class="comment">//定义一个名为delta的实型变量</span></span><br><span class="line"><span class="keyword">initial</span></span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line">delta = <span class="number">4</span>e10;<span class="comment">//delta被赋值，用科学记数法表示</span></span><br><span class="line">delta = <span class="number">2</span><span class="variable">.13</span>;<span class="comment">//delta被赋值为2.13</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">integer</span> i;<span class="comment">//定义一个名为的整型变量</span></span><br><span class="line"><span class="keyword">initial</span></span><br><span class="line">i = delta;<span class="comment">//1得到值2（2.13取整数部分）</span></span><br></pre></td></tr></table></figure></li><li><p>时间寄存器</p><p>仿真是按仿真时间进行的，其宽度与具体实现有关，最小为64位。用time来声明。通过调用系统函数$time可以得到当前的仿真时间。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">time</span> save_simtime;<span class="comment">//定义时间类型的变量savesim time initial</span></span><br><span class="line">save sim <span class="keyword">time</span>=<span class="built_in">$time</span>;<span class="comment">//把当前的仿真时间记录下来</span></span><br></pre></td></tr></table></figure></li><li><p>数组</p><p>在Verilog中允许声明reg,integer,time,real,realtime及其向量类型的数组，对数组的维数没有限制。</p><p>形如&lt;数组名&gt;&lt;下标&gt;。对于多维数组来讲，用户需要说明其每一维的索引。举例如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span> count[<span class="number">0</span>:<span class="number">7</span>];<span class="comment">//由8个计数变量组成的数组</span></span><br><span class="line"><span class="keyword">reg</span> boo1[<span class="number">31</span>:<span class="number">0</span>];<span class="comment">//由32个1位的布尔（boolean）寄存器变量组成的数组</span></span><br><span class="line"><span class="keyword">time</span> chk_point[<span class="number">1</span>:<span class="number">100</span>];<span class="comment">//由100个时间检查变量组成的数组</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">4</span>:<span class="number">0</span>] port_id[<span class="number">0</span>:<span class="number">7</span>];<span class="comment">//由8个端口标识变量组成的数组，端口变量的位宽为5</span></span><br><span class="line"><span class="keyword">integer</span> matrix[<span class="number">4</span>:<span class="number">0</span>][<span class="number">0</span>:<span class="number">255</span>];<span class="comment">//二维的整数型数组</span></span><br><span class="line"><span class="keyword">reg</span>[<span class="number">63</span>:<span class="number">0</span>] array_4d[<span class="number">15</span>:<span class="number">0</span>][<span class="number">7</span>:<span class="number">0</span>][<span class="number">7</span>:<span class="number">0</span>][<span class="number">255</span>:<span class="number">0</span>];<span class="comment">//四维64位寄存器型数组</span></span><br><span class="line"><span class="keyword">wire</span>[<span class="number">7</span>:<span class="number">0</span>] w_array2[<span class="number">5</span>:<span class="number">0</span>];<span class="comment">//声明8位向量的数组</span></span><br><span class="line"><span class="keyword">wire</span> w_array1[<span class="number">7</span>:<span class="number">0</span>][<span class="number">5</span>:<span class="number">0</span>];<span class="comment">//声明1位线型变量的二维数组</span></span><br></pre></td></tr></table></figure><p>不要将数组和线网或寄存器向量混淆起来，向量是一个单独的元件，它的位宽是n；数组由多个元件组成，其中每个元件元素的赋值位n或1。</p><p>下面的例子显示了对数组元素的赋值：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">count[<span class="number">5</span>]=<span class="number">0</span>;<span class="comment">//把count数组中的第5个整数型单元（32位）复位</span></span><br><span class="line">chk_point[<span class="number">100</span>]=<span class="number">0</span>;<span class="comment">//把chk_point数组中的第100个时间型单元（64位）复位</span></span><br><span class="line">port_id[<span class="number">3</span>]=<span class="number">0</span>;<span class="comment">//把port_id数组中的第3个寄存器型单元（5位）复位</span></span><br><span class="line">matrix[<span class="number">1</span>][<span class="number">0</span>]=<span class="number">33559</span>;<span class="comment">//把数组中第1行第0列的整数型单元（32位）置为33559</span></span><br><span class="line">array_4d[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">15</span>:<span class="number">0</span>]=<span class="number">0</span>;<span class="comment">//把四维数组中索引号为【o】【O】【0】【O】的寄存器型单元</span></span><br><span class="line"><span class="comment">//的0-15位都置为0</span></span><br><span class="line">port_id=<span class="number">0</span>;<span class="comment">//非法，企图写整个数组</span></span><br><span class="line">matrix[<span class="number">1</span>] = <span class="number">0</span>；<span class="comment">//非法，企图写数组的整个第2行，即从matrix【1】【0】直到matrix【1】【255】</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>寄存器</p><p>在数字电路仿真中，需要对寄存器文件ROM和RAM建模。如果需要访问储存器中的一个特定字，可以将字的地址作为数组的下标来完成。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> memibit[<span class="number">0</span>:<span class="number">1023</span>];<span class="comment">//1K的1位存储器mem1bit</span></span><br><span class="line"><span class="keyword">reg</span>[<span class="number">7</span>:<span class="number">0</span>] membyte[<span class="number">0</span>:<span class="number">1023</span>];<span class="comment">//1K的字节（8位）存储器membyte </span></span><br><span class="line">membyte[<span class="number">511</span>]<span class="comment">//取出存储器membyte中地址511处所存的字节</span></span><br></pre></td></tr></table></figure></li><li><p>参数</p><p>Verilog允许使用关键字parameter在模块内定义常数。参数代表常数，不能像变量那样赋值，但是每个模块实例的参数值可以在编译阶段被重载。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">parameter</span> port_id=<span class="number">5</span>;<span class="comment">//定义常数portid为5</span></span><br><span class="line"><span class="keyword">parameter</span> cache_1ine_width=<span class="number">256</span>;<span class="comment">//定义高速缓冲器总线宽度为常数256</span></span><br><span class="line"><span class="keyword">parameter</span> <span class="keyword">signed</span>[<span class="number">15</span>:<span class="number">0</span>] WIDTH;<span class="comment">//把参数WIDTH规定为有正负号，宽度为16位</span></span><br></pre></td></tr></table></figure><p>Verilog中的局部参数使用关键字localparam来定义，其作用等同于参数，区别在于它的值不能改变。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">localparam</span>  state1 = <span class="number">4&#x27;b0001</span>,</span><br><span class="line">state2 = <span class="number">4&#x27;b0010</span>,</span><br><span class="line">state3 = <span class="number">4&#x27;b0100</span>,</span><br><span class="line">state4 = <span class="number">4&#x27;b1000</span>;</span><br></pre></td></tr></table></figure></li><li><p>字符串</p><ol><li><p>字符串保存在reg类型的变量中，每个字符占用8位（一个字节），因此寄存器变量的宽度应足够大。</p></li><li><p>如果寄存器变量的宽度大于字符串的大小，则Verilog使用0来填充左边的空余位；如果寄存器变量的宽度小于字符串的大小，则Verilog截去字符串最左边的位。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span>[<span class="number">8</span>*<span class="number">18</span>:<span class="number">1</span>] string_value;<span class="comment">//声明变量string_vaiue，其宽度为18个字节</span></span><br><span class="line"><span class="keyword">initial</span></span><br><span class="line">string_value = <span class="string">&quot;Hello Verilog World&quot;</span>;<span class="comment">//字符串可以存储在变量中</span></span><br></pre></td></tr></table></figure></li><li><p>有一些特殊字符在显示字符串时有特定的意义，例如换行符，制表符和显示参数值。如果需要在字符串中显示这些特殊字符，则必须加前缀转义字符。</p></li></ol></li></ol><table><thead><tr><th>转义字符</th><th>显示的字符</th></tr></thead><tbody><tr><td>\n</td><td>换行</td></tr><tr><td>\t</td><td>tab（制表空格）</td></tr><tr><td>%%</td><td>%</td></tr><tr><td>\\</td><td>\</td></tr><tr><td>\&quot;</td><td>&quot;</td></tr><tr><td>\000</td><td>1到3个八进制数字字符</td></tr></tbody></table><p> </p><p> </p><h2 id="系统任务和编译指令">系统任务和编译指令</h2><h3 id="系统任务">系统任务</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 课程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电子信息科学与技术攻略</title>
      <link href="/posts/69d7a7f9.html"/>
      <url>/posts/69d7a7f9.html</url>
      
        <content type="html"><![CDATA[<h1>电子信息科学与技术攻略</h1><p>亲爱的学弟学妹们：</p><p>首先，我要热烈欢迎你们加入电子信息科学与技术专业！恭喜你们顺利踏上了大学的征程，这将是一个充满挑战和成长的旅程。我是电子信息科学与技术专业的一名本科生，非常高兴能在这里与你们分享一些有关入学和大学生活的经验。</p><p>在你们即将开始的学术和生活冒险中，我相信你们会遇到各种新的机会和挑战。作为学长，我们愿意与你们分享我们的经验，帮助你们更快地适应大学生活。不管你们面临什么问题，都请放心来寻求帮助，我们将竭尽全力支持你们。</p><p>接下来，让我们一起探讨一些入学后关于学习的一些建议。无论你们有什么疑问或需要，都可以随时私信我。</p><h2 id="关于电子信息科学信息与技术">关于电子信息科学信息与技术</h2><p>在刚入学时我也对这个专业充满疑问，根本不知道这个专业是什么，要学什么，可以用来干什么。</p><p>简单来说，电子信息科学与技术是一门涵盖电子工程、计算机科学和信息技术的跨学科领域。它关注的是如何处理、传输和管理信息，以及如何使用电子设备和计算机系统来解决实际问题。</p><p>具体来说，这个领域包括了以下重要方面：</p><ol><li><strong>电子工程：</strong> 电子信息科学与技术涉及设计、开发和维护各种电子设备和系统，如电路、通信设备、传感器和嵌入式系统。这些技术在现代社会中无处不在，用于各种应用，从智能手机到医疗设备。</li><li><strong>计算机科学：</strong> 这个领域强调计算机系统的设计、编程和软件开发。学生将学习如何编写代码、开发应用程序，并理解计算机硬件和软件之间的相互作用。</li><li><strong>通信技术：</strong> 电子信息科学与技术还涉及到数据通信和网络技术，包括互联网、移动通信和无线传感器网络。这是现代社会中信息传递的关键组成部分。</li><li><strong>信息处理：</strong> 学生将学习如何处理和分析数据，以从中提取有用的信息。这包括数据挖掘、人工智能和机器学习等技术，这些技术在商业、科学和许多其他领域中都有广泛的应用。</li></ol><p>当然如果只这么说的话还是会有些抽象，不过不用担心，接下来的文章里我会对我们的专业做更加详细的解释。</p><p>​这是一门涉及知识很广的学科，但你不得不说也是一门非常有趣的学科。我最开始知道这个专业并且对此感兴趣是在B站上看到的一个视频。是<strong>稚晖君</strong>做的一个小电视，我当时就被深深得吸引了，如此小的一个小电视上个怎么可以实现这么多功能，完全都可以当作一个电脑来使用。</p><p><a href="https://www.bilibili.com/video/BV1jE41137eu/?spm_id_from=333.999.0.0&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">【自制】技术宅UP耗时三个月，自制B站最强小电视！【硬核】【3分钟从草图到实物】_哔哩哔哩_bilibili</a></p><p>​随后，我又在B站发现了更多电子信息专业可以做的很多东西。</p><p><a href="https://www.bilibili.com/video/BV1BW41147kC/?spm_id_from=333.337.search-card.all.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">基于Arduino的十个可以DIY的炫酷项目_哔哩哔哩_bilibili</a></p><p>​这对还没有开始学习大学知识的你来说可能就像魔法一样，我最开始刚进入大学的时候也是感觉这一切都是那么迷茫，不知道怎办开始，怎么学习才能做出来像这些视频里一样的diy项目。</p><p>​但是经过一个学期的学习，我在大一上学期结束的那个寒假也用自己所学的东西，做了一个很简易的流水灯，虽然现在看起来是很简单的一个小制作，但是在当时把流水灯点亮的那一刻，心里的成就感是很强烈得，足够开心很久很久。</p><p><a href="https://www.bilibili.com/video/BV1uR4y1u7z5/?spm_id_from=333.999.0.0">做了个流水灯_哔哩哔哩_bilibili</a></p><p>希望你也可以在之后的学习中，做出一些很有趣的小制作。</p><p> </p><h2 id="电子信息科学与技术课程设置及其相关资料">电子信息科学与技术课程设置及其相关资料</h2><h3 id="大一（Freshman-Year）"><strong>大一（Freshman Year）</strong></h3><h4 id="第一学期课程（Curriculum-in-First-Semester）：">第一学期课程（Curriculum in First Semester）：</h4><p>l 英语（English）</p><p>l 思政课（Ideological and Political courses）</p><p>l 大学体育（一）College Physical Education I</p><p>l 工程微积分Ⅰ（Calculus Ⅰ for Engineers）</p><p>l 线性代数导论（Introduction to Linear Algebra）</p><p>l 大学物理Ⅰ（University Physics Ⅰ）</p><p>l 工程学导论Ⅰ（Introduction to Engineering Ⅰ）</p><p>l 编程导论（Introduction to Programming）</p><h4 id="第二学期课程（Curriculum-in-Second-Semester）："><strong>第二学期课程（Curriculum in Second Semester）：</strong></h4><p>l 英语（English）</p><p>l 思政课（Ideological and Political courses）</p><p>l 大学体育（二）College Physical Education II</p><p>l 微积分Ⅱ和III（Calculus Ⅱ and III）</p><p>l 大学物理Ⅱ及实验（University Physics Ⅱ and Lab）</p><p>l 工程学导论Ⅱ（Introduction to Engineering Ⅱ）</p><p>l 电路原理及实验（Electrical Circuit Theory and Lab）</p><h3 id="大二（Sophomore-Year）"><strong>大二（Sophomore Year）</strong></h3><h4 id="第三学期课程（Curriculum-in-Third-Semester）："><strong>第三学期课程（Curriculum in Third Semester）：</strong></h4><p>l 英语（English）</p><p>l 思政课（Ideological and Political courses）</p><p>l 大学体育（三）College Physical Education III</p><p>l 常微分方程导论（Introduction to Ordinary Differential）</p><p>l 大学物理III及实验（University Physics III and Lab）</p><p>l 数据结构（Data Structures）</p><p>l 电子学Ⅰ及实验（Electronics Ⅰ and Lab）</p><h4 id="第四学期课程（Curriculum-in-Forth-Semester）"><strong>第四学期课程（Curriculum in Forth Semester）</strong></h4><p>l 大学体育（四）（College Physical Education IV）</p><p>l 工程概率基础（Introduction to Engineering Probability）</p><p>l 信号与系统（Circuits，Signals and System）</p><p>l 逻辑设计（Logic Design）</p><p>l 数字设计实验（Digital Design Lab）</p><p>l 电子学Ⅱ和实验（Electronics Ⅱ and Lab）</p><p>l 微机原理和接口技术（Processors：Hardware, Software，and Interfacing）</p><p>l 电子电路CAD （Electronic Circuit CAD）</p><h3 id="大三（Junior-Year）"><strong>大三（Junior Year）</strong></h3><h4 id="第五学期课程（Curriculum-in-Fifth-Semester）"><strong>第五学期课程（Curriculum in Fifth Semester）</strong></h4><p>l 离散时间信号与系统（Discrete-Time Signals and Systems）</p><p>l 电磁场原理（Electromagnetic Field Theory）</p><p>l 固态电子学（Solid-State Electronics）</p><p>l 单片机原理（MCU Principle）</p><p>l 结构化数字设计（含FPGA）Structured Digital Design</p><p>l 创新项目实践（一）Practice of Innovation Project I</p><h4 id="第六学期课程（Curriculum-in-Sixth-Semester）"><strong>第六学期课程（Curriculum in Sixth Semester）</strong></h4><p>l 嵌入式微处理系统设计（Embedded Microprocessor System Design）</p><p>l 通信系统（Communication Systems）</p><p>l 线性控制系统（Linear Control Systems）</p><p>l 电力电子（Power Electronics）</p><p>l VLSI 大规模集成电路系统（Large-scale Integrated Circuit System）</p><p>l 模拟集成电路（Analog Integrated Circuit）</p><p>l 创新项目实践（二）Practice of Innovation Project II</p><h3 id="大四（Senior-Year）"><strong>大四（Senior Year）</strong></h3><h4 id="第七学期课程（Curriculum-in-Seventh-Semester）"><strong>第七学期课程（Curriculum</strong> <strong>in Seventh Semester）</strong></h4><p>l 数字图像处理（Introduction to Digital Image Processing）</p><p>l 现场可编程逻辑阵列（Field programmable logic array）</p><p>l 高级项目设计（Advanced project design）</p><p>l 集成电路EDA（Integrated circuit EDA）</p><p>l 版图设计（Layout design）</p><p>l 专业实习（Internship）</p><h4 id="第八学期课程（Curriculum-in-Eighth-Semester）"><strong>第八学期课程（Curriculum in Eighth Semester）</strong></h4><p>l 毕业设计（Senior Project）</p><p> </p><p>关于大学期间所有能用到得课本已经全部整理出来，链接就放到下面。</p><p>链接：<a href="https://pan.baidu.com/s/1JEZYkR3-MfOQYS646UjtBg">https://pan.baidu.com/s/1JEZYkR3-MfOQYS646UjtBg</a> 提取码：2038</p><p>​这一部分要感谢一名学长，将我们所有的文档归纳起来并且分享给大家，我也把这位学长的原博客链接放到下面。这篇博客里还有所有对于我们课程的相关资料的推荐，我个人也是这篇博客的受益者。</p><p><a href="https://y006.github.io/2022/03/23/15-24-59/">电子专业资料共享计划 | Blog (y006.github.io)</a></p><p>​如果打不开上面的博客，可能是因为博客的地址在GitHub，而你的电脑又没有开vpn。</p><p>关于vpn是什么，怎么使用，你可以去看这个视频。</p><p><a href="https://www.bilibili.com/video/BV1LX4y1E7AS/?spm_id_from=333.337.search-card.all.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">【科普】VPN到底是什么，你还敢用吗_哔哩哔哩_bilibili</a></p><p> </p><h2 id="课程部分">课程部分</h2><p>​大家最关心的莫过于自己将要学习的课程以及如何去学好他们，接下来我将对此讲一些自己的看法，如果你有更好的建议或者发现了错误也希望你及时联系我。</p><p>​但是大学的知识学习不等同于高中，高中的一贯学习套路是：</p><ol><li>先学会基础知识，了解最基本的概念</li><li>反复练习简单题，中档题及压轴题</li><li>将练习后的题目分类总结，总结成一套自己的方法，直到考试碰到此类问题可以立即有思路，很快地解出题目。</li></ol><p>​但是在大学如果你仍然按高中的学习方法明显是很吃力的，因为对于三年学习六门科目的学习方法去应对一学期学十几门课的实际情况，明显是不可能的。</p><p>​我就对大一第一学期的课程做一些简单的介绍。我把课程分为三类，<code>基础类</code>，<code>导论类</code>，<code>应用类</code></p><h3 id="基础类：工程微积分，线性代数导论，大学物理"><em>基础类</em>：工程微积分，线性代数导论，大学物理</h3><p>​基础类的课程设计了很多的基础概念，公式，和思想。学习这类课程需要你对自己学习过的知识有一个清晰的框架，以至于自己学习完这门课后知道自己都学习了什么内容。</p><p>​例如你想去做一个平衡车，你学习完这些知识之后你要很清楚知道，微积分中的PID算法可以用来解决调节平衡角度的问题，大学物理的角动量可以让你更加了解平衡的机械部分是如何实现的。</p><h3 id="导论类：工程学导论，编程导论"><em>导论类</em>：工程学导论，编程导论</h3><p>​导论类课程一般会带你们使用一种新的技术解决一个问题，这类课程不需要你像基础列课程学习得那么细致，对概念那么精通，你只需要知道这么课大概都讲了什么，用到了什么工具。</p><p>​例如现在需要你在图纸上画出一个很标准的心形，或者一个零件。这时候你知道，自己在工程学导论中使用CAD可以用来解决这个问题，这个过程中，你不知道软件的工具在哪里，怎么使用，或者使用什么方案，这些都不要紧，你只需要知道有这些工具，并且这些工具可以解决什么问题就可以了。</p><p>​当然，这也并不代表你就可以只是听故事一样听完整门课程就可以了，上课的例题，或者作业题也需要你去实践一下。</p><p>​在编程导论中你知道用编程可以解决很多实际问题，它可以帮你计算，管理系统，等等。那你知道这些功能以后去自己写一个学生成绩管理系统是不是也是一个比较有趣的事情</p><p> </p><h3 id="实践类：编程导论"><em>实践类</em>：编程导论</h3><p>​大多的实践类课程就是在你有一定的学习基础后，可以用这些基础的知识结合硬件去做一些项目。我们学习的编程导论虽然是一门导论课，但是编程在我们之后的学习生活中是不可或缺的一部分，这门课重要到即使它是一门导论课，也值得我们去把他当作一门实践类课程去学习。</p><p>​你可以在学习了解完基础知识以后，写一个简单的猜数字游戏，学生成绩管理系统等等。</p><p>​ </p><p>​或许对于还没有开始上课的你来说看这些内容还有些懵，但是在之后的学习生活中你会对此有更加深刻的体会。</p><h3 id="大一">大一</h3><p>​大一的课程是整个大学的基础，十分重要，其中的微积分，线性代数，大学物理，编程导论等也是之后很多课程的基础。</p><p>​比如：大二你们要学习的常微分的基础就是微积分与线性代数，如果这两门你在最开始就没有学好，那在之后的学习中是很头疼的一件事情，你仍然要返回去学习这些基础课程。所以，希望同学们在最开始的时候就好好学习这些课程。</p><h4 id="l-工程微积分Ⅰ（Calculus-Ⅰ-for-Engineers）">l 工程微积分Ⅰ（Calculus Ⅰ for Engineers）</h4><p>微积分一中，主要的大方面学习分几部分</p><ol><li><p>对极限的理解</p></li><li><p>导数的进阶应用</p></li><li><p>微积分中重要思想------积分</p></li><li><p>积分方法的学习</p></li></ol><h5 id="极限">极限</h5><p>在第二章极限的学习中，相较于初等数学，了解到了极限与无穷的概念，在图形中分析计算垂直与水平渐近线可以加深对与极限的理解。</p><p>要学会对连续性进行判断，从而判断出任意点的类型（如可去间断点，跳跃间断点等）</p><p>其次，在极限式子的计算中，多数较难的式子均可以最终化简为两个重要极限的形式。<br>$$<br>\lim _{x \rightarrow 0} \frac{\sin x}{x}=1 \quad \lim _{x \rightarrow \infty}\left(1+\frac{1}{x}\right)^{x}=e<br>$$<br>由此，对于两个总要的极限的应用就显得及其重要，当然在极限中，熟练运用洛必达法则也是必不可少的</p><p> </p><h5 id="导数">导数</h5><p>在高数开始接触导数便移入了很多新的概念，在导数中，很重要的一点就是加深对链法则的理解，这个对以后学习各类积分微分知识都是帮助很大的。</p><p>如果对链法则的理解加深了，关于隐函数求导，符合函数求导，三角函数求导中的一系列问题都可以迎刃而解。</p><p>如果可以，多用导数的概念定义式进行积分的运算，会加深对于极限的理解。</p><p>在导数中有一系列相关的应用问题</p><ol><li><p>求最大最小值</p></li><li><p>求极大极小值</p></li><li><p>凹度与拐点</p></li></ol><p>这些问题无非都是通过1.函数的一阶导2.函数的二阶导3.临界点进行求值</p><p>三个方面进行分析，从而就可以对上诉三个问题进行求解</p><p>熟练理解中值定理，并可以对简单的式子进行推导</p><p> </p><h5 id="积分">积分</h5><p>在积分的学习中我也认为是本书中最重要的一个概念，对积分的理解不应该只是会算出各种各样的积分形式，我们当然会学习很多各种各样的积分方法，不限于:<code>分部积分法</code>，<code>三角积分法</code>，<code>三角换元法</code>，<code>分布分式法</code>…这些方法在大量的练习中我们可以熟练地去解出各种类型的式子，配合506页的公式表，当然效果肯定会更棒。</p><p>对<code>反函数</code>，<code>对数指数</code>模型，<code>反三角函数</code>，在推导过一遍可以对公式进行记背。</p><p>在微积分的应用中，我们不应该仅仅停留在解出图形的<code>面积</code>，<code>体积</code>。</p><p>深刻理解微积分，把整个要计算的图形，分为极限趋向0的无数个点，由点去积分成线，再将由无数的线与一定区间进行积分，可以得到面，对面再积分可以得到体积。这是从一维到三维，我们都是很容易理解的。</p><p>但到四维呢？如果我们对于每个点再赋予一个维度的含义，那么这个式子就可以表达整个图形的质量。</p><p>这样去深刻理解每个维度之间的积分关系，就显得非常奇妙。</p><p>对于中间一些题型呢，如下</p><ol><li><p>求面积</p></li><li><p>求体积</p></li><li><p>求弧长</p></li></ol><p> </p><p>但是总得来说，上述只是对基础知识点的一个概述，微积分在我们的生活中可谓是应用广泛，比如在音乐播放器使用微积分来调整音频信号的音量和频率，以确保音乐听起来和谐而流畅；在电梯系统使用微积分来计算电梯的速度和位置，以便顺利地将你从一楼带到其他楼层；在电子游戏中的物理引擎使用微积分来模拟物体的运动和碰撞，以使游戏更加真实。</p><p>对于微积分，在你学完相关内容后你可以去看这些内容，可以更加加深你对知识的理解。</p><p><a href="https://www.bilibili.com/video/BV1qW411N7FU/?spm_id_from=333.337.search-card.all.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">【官方双语/合集】微积分的本质 - 系列合集_哔哩哔哩_bilibili</a></p><p>宋浩老师的视频也很适合你去进行预习或者打基础</p><p><a href="https://www.bilibili.com/video/BV1UW411k7Jv/?spm_id_from=333.337.search-card.all.click">《微积分》《高等数学》全程教学视频–宋浩老师_哔哩哔哩_bilibili</a></p><p> </p><h4 id="l-线性代数导论（Introduction-to-Linear-Algebra）">l 线性代数导论（Introduction to Linear Algebra）</h4><p>​线性代数是一门数学分支，它主要研究向量、向量空间和线性变换等概念。它在电子信息科学与技术领域中具有关键作用，因为它提供了处理多维数据和解决复杂问题的数学工具。</p><p>​注意，这门线性代数是一个数学工具，就好比你学习了方程以后就可以用使用方程来解决一些数学问题，而同样的，当你学习过线性代数以后，你也可以通过线性代数来解决一些数学或者工程上的问题。</p><ol><li><strong>向量和向量空间：</strong> 线性代数的核心概念之一是向量。向量可以用来表示多维数据，如在图像处理、信号处理和数据分析中常见的数据结构。线性代数还研究了向量空间，这是一组满足特定性质的向量的集合。向量空间理论为我们提供了处理和分析数据的框架。</li><li><strong>线性变换：</strong> 另一个重要的概念是线性变换，它描述了如何将一个向量空间映射到另一个向量空间。线性变换在图像处理、信号处理和控制系统等领域中广泛应用。例如，在通信系统中，线性变换可以用来描述信号的传输和变换。</li><li><strong>矩阵：</strong> 矩阵是线性代数中的另一个核心概念，它用于表示线性变换和解决线性方程组。在电子信息科学与技术中，矩阵常常用于描述电路、信号处理滤波器和数据转换等。</li></ol><p>​我也在知乎上发现了一篇十分详细的知识点，链接在下方。</p><p><a href="https://zhuanlan.zhihu.com/p/453305373">【数学】线性代数知识点总结（精炼版） - 知乎 (zhihu.com)</a></p><p>​宋浩老师的视频也是相当经典。</p><p><a href="https://www.bilibili.com/video/BV1aW411Q7x1/?spm_id_from=333.337.search-card.all.click">《线性代数》高清教学视频 “惊叹号”系列 宋浩老师_哔哩哔哩_bilibili</a></p><p>​如果在学习完基础内容，会解一些基本题型后，你可以去看3Blue1Brown的视频，相信你在看完之后会对线性代数有更加深刻的认识。</p><p><a href="https://www.bilibili.com/video/BV1ib411t7YR/?spm_id_from=333.337.search-card.all.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">-UP主汉语配音-【线性代数的本质】合集-转载于3Blue1Brown官方双语】_哔哩哔哩_bilibili</a></p><p> </p><h4 id="l-大学物理Ⅰ（University-Physics-Ⅰ）">l 大学物理Ⅰ（University Physics Ⅰ）</h4><p>​大学物理Ⅰ的大部分内容其实我们已经在高中学习过了，但要注意的是，大学的物理相较与初中的物理更贴合实际，更具有普遍性。解决这部分实际问题就需要结合微积分知识和大学物理把很多过程微分成很多很小的过程，然后在把这很多很小的过程累积在一起。</p><p>​例如下面这个图片</p><p>​在小球从O到A的过程中，弹簧的力一直在发生变化，如果我们需要求在原点O到A点弹簧的弹性势能，用中学的知识，我们可以用图像法分析出<br>$$<br>E = \frac{1}{2} k x ^2<br>$$<br>​在大学学习了微积分以后我们就可以将每一个微小过程中的做的功微分后积分在一起，结果是一样的<br>$$<br>E = \int_{0}^{x} kx dx<br>$$<br>​</p><p>​但是假设k的值不是恒定的，用高中的知识就无法解决了，但是我们可以用二重积分来解决这个问题，这也就是为什么大学里解决的问题更具有普遍性的例子。也希望大家在学习物理的过程不要只局限与写题，而是多去思考这个过程。</p><p>​学习大学物理你可以去看东北大学马文蔚老师的物理课。</p><p><a href="https://www.bilibili.com/video/BV1qW411H7UX/?spm_id_from=333.337.search-card.all.click">【大学物理】东北大学-马文蔚_哔哩哔哩_bilibili</a></p><p> </p><h4 id="l-工程学导论Ⅰ（Introduction-to-Engineering-Ⅰ）">l 工程学导论Ⅰ（Introduction to Engineering Ⅰ）</h4><p>​工程学导论的主要目标是引导你们进入电子信息科学与技术领域。它将帮助你们了解电子技术、通信系统、计算机科学和信息处理等方面的基本概念。</p><p>​我们将介绍CAD（计算机辅助设计）工具、MATLAB和C++编程，这些工具在电子信息科学与技术领域中非常重要。</p><p>​大家在课上认真听讲，积极完成老师布置的课下作业，如果你还有精力，那你可以去B站，谷歌，GitHub去了解更多的内容，这门课不是重点也不是难点，你们只需要知道了解我们上课学习的内容即可。</p><p> </p><h4 id="l-编程导论（Introduction-to-Programming）">l 编程导论（Introduction to Programming）</h4><p>​最开始我对编程的感觉就是黑客在都是黑色的屏幕上敲命令行，感觉就像是拥有魔法一样，敲几行代码就可以实现一些不可思议的功能。后来我开始接触编程，还很清楚得记得我在学习完if和for语句做出一个猜数字的游戏后激动的心情。</p><p>​包括我之前做的那款心形流水灯也是用c语言进行编程的，学会了编程语言就好比你有了一把利器，解决之前不敢想象的问题。</p><p>​如果你是刚刚入门，我希望你去看翁恺老师的c语言程序设计，这可谓是大家编程梦开始的地方。</p><p><a href="https://www.bilibili.com/video/BV1dr4y1n7vA/?spm_id_from=333.337.search-card.all.click">浙江大学翁恺教你C语言程序设计！C语言基础入门！_哔哩哔哩_bilibili</a></p><p>​如果你已经开始了c++语言的学习，那我推荐你去看黑马程序员的视频，这个视频用很简单的语言就可以解释清楚复杂的知识点，也希望你尽可能得把所有视频上的程序都自己敲写一遍。</p><p><a href="https://www.bilibili.com/video/BV1et411b73Z/?spm_id_from=333.337.search-card.all.click">黑马程序员匠心之作|C++教程从0到1入门编程,学习编程不再难_哔哩哔哩_bilibili</a></p><p>​工欲善其事必先利其器，当然学习编程你就需要一款好的编译器，我推荐编程小白使用Visual Studio，这一款编译软件不要配置复杂的编译环境，可谓是上手即用，而且关于其的学习资料还比较多。下载方式如下。</p><p><a href="https://www.bilibili.com/video/BV1Xt411g7jT/?spm_id_from=333.337.search-card.all.click">vs2022(Visual Studio 2022)权威指南&amp;&amp;C语言&amp;&amp;软件工程开发的方向&amp;&amp;技巧要领_哔哩哔哩_bilibili</a></p><p> </p><h2 id="实践部分">实践部分</h2><p>​很明显，如果我们只学习课堂上教授的这部分内容，我们并没有办法去完成自己的diy项目或者小制作。我在最开始也有着这个疑问，不知道怎么样去动手实践，但是在之后摸索了很多方法之后，我认为初学者去学习arduino入门是很可行的一个道路。</p><p>​Arduino是一款便捷灵活、方便上手的开源电子原型平台。很多重来没有接触过电子知识的创客也可用通过arduino来制作自己的小发明，更不用说我们这些科班出身的大学生。</p><p>​你完全可用自己去淘宝买一套arduino的学习套件，跟着<code>太极创客</code>中的视频模仿，一步一步体会自己动手去做出来一个实物的快乐。</p><p><a href="https://www.bilibili.com/video/BV164411J7GE/?spm_id_from=333.337.search-card.all.click">【太极创客】零基础入门学用Arduino 第一部分 合辑_哔哩哔哩_bilibili</a></p><p>​希望你一定不要把这作为自己的学习任务，自己去制作小发明就好比自己在拼乐高，去给玩偶涂色等等。是激动人心的一件事。我曾寒假在家就碰到了一个问题，屋子的灯只有一个开关，而我每次睡觉前关灯都需要爬下床去关灯然后抹黑爬回床上。于是我就花了一个下午的时间用蓝牙加舵机使用arduino的开发板制作了一个简易的智能开关。</p><p><a href="https://www.bilibili.com/video/BV1JF411r78p/?spm_id_from=333.999.0.0&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">arduino➕舵机➕蓝牙智能灯_哔哩哔哩_bilibili</a></p><p> </p><p> </p><h2 id="竞赛部分">竞赛部分</h2><p>​我非常建议大一的新生去参加蓝桥杯的单片机赛道，虽然正常情况下大家在大三才会学到单片机的使用，可能在学习中你们并不知道138译码器，与非门等等这些概念，甚至设计功能都不知道这其中的原理是什么，但是这并不妨碍我们先去学习，去接触。</p><p>​推荐你先去看江科大的单片机以后再去针对比赛看小蜜蜂的比赛视频，蓝桥杯在每年年末报名，次年的四五月份进行比赛。无论如何，只要付出了，这对你绝对是一段很宝贵的学习经历，而且这个比赛的获奖率也是很高的，每年的大一小白参加最后也是有很多获得了省奖。</p><p><a href="https://www.bilibili.com/video/BV1Mb411e7re/?spm_id_from=333.337.search-card.all.click">51单片机入门教程-2020版 程序全程纯手打 从零开始入门_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1Bt41187hw/?spm_id_from=333.337.search-card.all.click">【小蜜蜂笔记】蓝桥杯大赛-单片机设计与开发基础技能与进阶强化教程_哔哩哔哩_bilibili</a></p><p>​</p><p> </p><h2 id="寻找资源">寻找资源</h2><p>​大学的学习不同于高中，在高中针对固定的学科学校会统一给同学们发很多教辅，卷子，资料。</p><p>​但是大学中并不会这样，甚至有些学科你甚至没有课本，电子版课本老师没有发给你的话，你可能上课连课本都没有了。这就需要你有一定的资源检索能力，对于想要学习的内容可以找到对应的学习资料或者网站。</p><p>​下面会向大家介绍一些资源和网站。</p><h3 id="Chatgpt">Chatgpt</h3><p>​我把这个重量级的大模型放在第一位，是因为chatgpt是2022年底发布的，是人类最新技术的应用，强大到令人惊叹。</p><p>​我曾经在2021年入学的时候遇到过很多问题，我想参加竞赛，想要在有限的时间内学好十几门课程，当了解到单片机，微处理器想去学习，但是会发现很难很难找到老师，去给你解答各种各样的问题，为你答疑解惑制定具体的学习方案。</p><p>​直到Chatgpt的出现，我发现这个大模型就好像是一个无所不知的老师，你可以去问他任何你已有的疑问，甚至不限于学习，生活，情感，等等等。关于Chatgpt具体是什么，你可以看下面这个视频。</p><img src="/posts/69d7a7f9.htm/image-20230916201601406.png" alt="image-20230916201601406" style="zoom:100%;"><p><a href="https://www.bilibili.com/video/BV11m4y1B7ur/?spm_id_from=333.337.search-card.all.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">ChatGPT是什么？两分钟带你了解! （中英熟肉字幕）_哔哩哔哩_bilibili</a></p><p>​当然你也需要找到正确使用它的方式，以至他可以更好理解你的问题并且为你回答，你可以看下面这个网站总结了如何对Chatgpt进行有效提问。</p><p><a href="https://flowus.cn/flowus101/share/f0601ddc-72e5-4b4e-ab17-0af2cce98732">GitHub - PlexPt/awesome-chatgpt-prompts-zh: ChatGPT 中文调教指南 (flowus.cn)</a></p><p>Chatgpt的网址放在下方，你可以去某宝购买一个账号，开vpn登录即可使用（vpn的地址最好是非亚州区，挂在美国更好）</p><p><a href="https://chat.openai.com/auth/login">ChatGPT (openai.com)</a></p><h3 id="bilibili">bilibili</h3><p>​bilibili大家号称B站大学，B站上可谓是有着无数的学习资源，通常找一个课程，一个编程项目，去B站搜索这些资源链接都会出现在评论区的第一条或者视频的介绍中，点击链接下载即可。</p><p>​B站也有着更种各样的优秀课程，宋浩老师的高数系列，3blue1brown等等，上课没听懂不用去担心，B站大学为你兜底。</p><p>​你同样也可以在B站学习如何去寻找资源。</p><p><a href="https://www.bilibili.com/video/BV17P4y187Kw/?spm_id_from=333.999.0.0&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">99%的人不知道这些渠道能帮你找到所有想要资源！！！第2期_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1Db4y1a7sa/?vd_source=db4533a45f532ba6c1133faafbf7f171">收藏血赚！3分钟大学逆袭，各专业最有用资源大合集！_哔哩哔哩_bilibili</a></p><p><a href="https://www.bilibili.com/video/BV1TN411d7FL/?spm_id_from=333.999.0.0&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">99%的人不知道这些渠道，能帮你找到所有想要资源！第1期_哔哩哔哩_bilibili</a></p><h3 id="知乎">知乎</h3><p>​如果你想参加一个比赛，一个项目，去知乎搜索相关内容，它会给到你更加客观的答案（现在可能会对各种事情的看法会更加现实和消极）</p><p>​如果你是想听听大家对一个事件，一个学科或者是各种各样问题的看法或者意见，那欢迎你来到知乎。</p><p> </p><h3 id="CDSN">CDSN</h3><p>​<em>CSDN</em>是全球知名中文IT技术交流平台，如果你是在学习编程语言，机器学习，各种各样的技术知识，这绝对是你绕不开的一个平台，去互联网上去寻找响应的代码，你很有可能就是在csdn上找到答案。</p><p>​比如你正在学习数据结构的链表，但是你上课有没有太听懂，你就可以去csdn搜索链表，会出现各种各样关于链表的总结，其中可能就会点进我的主页（悄悄安利自己一波）</p><p><a href="https://blog.csdn.net/u011146203/article/details/127587997?spm=1001.2014.3001.5501">（数据结构）链表_指针怎么取数据域_江江江江江江江江江的博客-CSDN博客</a></p><h3 id="百度">百度</h3><p>​在开始学习编程的时候，经常会遇到编译错误的问题，但是这也可能是之前别人学习时也碰到的问题，把错误复制下来输入到搜索引擎，一般情况下你也会在其中找到你想要的答案。</p><p><a href="https://www.baidu.com/">百度一下，你就知道 (baidu.com)</a></p><p> </p><h3 id="小红书">小红书</h3><p>​去旅游想知道那里有什么好吃的，生了xx要怎么处理，想要去学习做个什么饭等等这些生活中的问题小红书会给你答案，（我也经常会去小红书上大家安利的美食店）。但毕竟是社交平台，还有微博，知乎这些，关于大家对事情都有自己的看法，保持正确三观，遵从内心的想法，不要别人说风就是雨。有时候看太多一些社会，工作还是情感上的内容会平添很多焦虑。希望大家可以自由愉快地享受大学生活。</p><p> </p><p> </p><p> </p><p>因为我目前也只是一名刚进入大三的本科生，很多想法见解可能在之后的学习过程中也会有不同的体验，如果你有更好的建议或者发现了一些错误请及时私信我，本文档将持续进行更新…</p>]]></content>
      
      
      
        <tags>
            
            <tag> 学习攻略 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cpu制作</title>
      <link href="/posts/68d8d011.html"/>
      <url>/posts/68d8d011.html</url>
      
        <content type="html"><![CDATA[<h1>cpu的制作</h1><p>cpu制作在最开始听起来是一个非常复杂的项目，但其实其所需要的基础非常简单，只需要一些简单的数字电路基础即可完成搭建。</p><p>而且自己制作cpu是一件非常有趣的一件事情，去理解身边的电脑，手机等等的一些运作的底层原理。</p><p>那么现在，我们就从最开始最简单的电路开始搭建吧。</p><h2 id="电路搭建">电路搭建</h2><h3 id="与或非门，同或异或门">与或非门，同或异或门</h3><img src="/posts/68d8d011.htm/image-20231010180429855.png" alt="image-20231010180429855" style="zoom:67%;"><p>与或非是计算机逻辑门的最基础的部件，其他任意的部件都可以通过与或非三种门来表示。</p><h3 id="八位加法器">八位加法器</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> eight_bit_full_adder  (</span><br><span class="line">  <span class="keyword">input</span> A,</span><br><span class="line">  <span class="keyword">input</span> B,</span><br><span class="line">  <span class="keyword">output</span> S,</span><br><span class="line">  <span class="keyword">output</span> C</span><br><span class="line">);</span><br><span class="line">  <span class="keyword">assign</span> S = (A ^ B);</span><br><span class="line">  <span class="keyword">assign</span> C = (A &amp; B);</span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"><span class="keyword">module</span> DIG_Add</span><br><span class="line">#(</span><br><span class="line">    <span class="keyword">parameter</span> Bits = <span class="number">1</span></span><br><span class="line">)</span><br><span class="line">(</span><br><span class="line">    <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] a,</span><br><span class="line">    <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] b,</span><br><span class="line">    <span class="keyword">input</span> c_i,</span><br><span class="line">    <span class="keyword">output</span> [(Bits - <span class="number">1</span>):<span class="number">0</span>] s,</span><br><span class="line">    <span class="keyword">output</span> c_o</span><br><span class="line">);</span><br><span class="line">   <span class="keyword">wire</span> [Bits:<span class="number">0</span>] temp;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">assign</span> temp = a + b + c_i;</span><br><span class="line">   <span class="keyword">assign</span> s = temp [(Bits-<span class="number">1</span>):<span class="number">0</span>];</span><br><span class="line">   <span class="keyword">assign</span> c_o = temp[Bits];</span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span>   (</span><br><span class="line">  <span class="keyword">input</span> A1,</span><br><span class="line">  <span class="keyword">input</span> B1,</span><br><span class="line">  <span class="keyword">input</span> A2,</span><br><span class="line">  <span class="keyword">input</span> B2,</span><br><span class="line">  <span class="keyword">input</span> A3,</span><br><span class="line">  <span class="keyword">input</span> B3,</span><br><span class="line">  <span class="keyword">input</span> A4,</span><br><span class="line">  <span class="keyword">input</span> B4,</span><br><span class="line">  <span class="keyword">input</span> A5,</span><br><span class="line">  <span class="keyword">input</span> B5,</span><br><span class="line">  <span class="keyword">input</span> A6,</span><br><span class="line">  <span class="keyword">input</span> B6,</span><br><span class="line">  <span class="keyword">input</span> A7,</span><br><span class="line">  <span class="keyword">input</span> B7,</span><br><span class="line">  <span class="keyword">input</span> A0,</span><br><span class="line">  <span class="keyword">input</span> B0,</span><br><span class="line">  <span class="keyword">output</span> S0,</span><br><span class="line">  <span class="keyword">output</span> S1,</span><br><span class="line">  <span class="keyword">output</span> S2,</span><br><span class="line">  <span class="keyword">output</span> S3,</span><br><span class="line">  <span class="keyword">output</span> S4,</span><br><span class="line">  <span class="keyword">output</span> S5,</span><br><span class="line">  <span class="keyword">output</span> S6,</span><br><span class="line">  <span class="keyword">output</span> S7,</span><br><span class="line">  <span class="keyword">output</span> C</span><br><span class="line">);</span><br><span class="line">  <span class="keyword">wire</span> s8;</span><br><span class="line">  <span class="keyword">wire</span> s9;</span><br><span class="line">  <span class="keyword">wire</span> s10;</span><br><span class="line">  <span class="keyword">wire</span> s11;</span><br><span class="line">  <span class="keyword">wire</span> s12;</span><br><span class="line">  <span class="keyword">wire</span> s13;</span><br><span class="line">  <span class="keyword">wire</span> s14;</span><br><span class="line">  \???  \???_i0 (</span><br><span class="line">    <span class="variable">.A</span>( A0 ),</span><br><span class="line">    <span class="variable">.B</span>( B0 ),</span><br><span class="line">    <span class="variable">.S</span>( S0 ),</span><br><span class="line">    <span class="variable">.C</span>( s8 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i1 (</span><br><span class="line">    <span class="variable">.a</span>( s8 ),</span><br><span class="line">    <span class="variable">.b</span>( A1 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B1 ),</span><br><span class="line">    <span class="variable">.s</span>( S1 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s9 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i2 (</span><br><span class="line">    <span class="variable">.a</span>( A2 ),</span><br><span class="line">    <span class="variable">.b</span>( s9 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B2 ),</span><br><span class="line">    <span class="variable">.s</span>( S2 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s10 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i3 (</span><br><span class="line">    <span class="variable">.a</span>( s10 ),</span><br><span class="line">    <span class="variable">.b</span>( A3 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B3 ),</span><br><span class="line">    <span class="variable">.s</span>( S3 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s11 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i4 (</span><br><span class="line">    <span class="variable">.a</span>( s11 ),</span><br><span class="line">    <span class="variable">.b</span>( A4 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B4 ),</span><br><span class="line">    <span class="variable">.s</span>( S4 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s12 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i5 (</span><br><span class="line">    <span class="variable">.a</span>( s12 ),</span><br><span class="line">    <span class="variable">.b</span>( A5 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B5 ),</span><br><span class="line">    <span class="variable">.s</span>( S5 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s13 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i6 (</span><br><span class="line">    <span class="variable">.a</span>( s13 ),</span><br><span class="line">    <span class="variable">.b</span>( A6 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B6 ),</span><br><span class="line">    <span class="variable">.s</span>( S6 ),</span><br><span class="line">    <span class="variable">.c_o</span>( s14 )</span><br><span class="line">  );</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">1</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i7 (</span><br><span class="line">    <span class="variable">.a</span>( s14 ),</span><br><span class="line">    <span class="variable">.b</span>( A7 ),</span><br><span class="line">    <span class="variable">.c_i</span>( B7 ),</span><br><span class="line">    <span class="variable">.s</span>( S7 ),</span><br><span class="line">    <span class="variable">.c_o</span>( C )</span><br><span class="line">  );</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="锁存器">锁存器</h3><p>与门可以存储下来0，或门可以存储下来1，我们把与门和或门进行一个组合，就能做出来第一个有用的电路结构。</p><table><thead><tr><th>引脚</th><th>解释</th></tr></thead><tbody><tr><td>Dindatain</td><td>数据输入</td></tr><tr><td>WE</td><td>write enable</td></tr></tbody></table><p>当WE为高电平的时候，Din的数据可以被存储起来当WE为低电平的时候，out的值不发生变化。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> latch  (</span><br><span class="line">  <span class="keyword">input</span> Din,</span><br><span class="line">  <span class="keyword">input</span> WE,</span><br><span class="line">  <span class="keyword">output</span> Out</span><br><span class="line">);</span><br><span class="line">  <span class="keyword">wire</span> Out_temp;</span><br><span class="line">  <span class="keyword">assign</span> Out_temp = ((Out_temp | (Din &amp; WE)) &amp; ~ (~ Din &amp; WE));</span><br><span class="line">  <span class="keyword">assign</span> Out = Out_temp;</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="寄存器">寄存器</h3><p>寄存器=8位锁存器/16/32位</p><p>一次可以存储8位数据。</p><table><thead><tr><th>引脚</th><th>解释</th></tr></thead><tbody><tr><td>Dindatain</td><td>数据输入</td></tr><tr><td>WE</td><td>write enable</td></tr></tbody></table><p>当WE为高电平的时候，Din的数据可以被存储起来当WE为低电平的时候，out的值不发生变化。</p><img src="/posts/68d8d011.htm/image-20231011105654618.png" alt="image-20231011105654618" style="zoom:80%;"><p> </p><h3 id="带边缘触发的锁存器">带边缘触发的锁存器</h3><h4 id="为什么需要时钟">为什么需要时钟</h4><p>大家都见过划船的，划船需要一个喊口号的主要原因是为了保证协调。通过喊口号，船员们可以同步动作，确保船在平稳且有效率地前进。<br>CPU需要clock来同步内部操作，如执行指令、进行数据传输等。Clock提供了精确的时间控制，确保每个内部操作在正确的顺序与速度内执行，从而确保CPU的正常工作。另外，Clock还与CPU的频率相关，通过控制Clock频率，可以控制CPU的速度。</p><h4 id="时钟信号是什么">时钟信号是什么</h4><p>时钟信号就是周期性的高低电平变化的信号<br>我们可以用两个普通的寄存器加上一个非门，组成一个带有边缘触发的寄存器。<br>在按钮按下的一瞬间，电压从低电平到高电平的一瞬间，Din的数据被存储起来。</p><p> </p><h3 id="寄存器REG">寄存器REG</h3><table><thead><tr><th>引脚</th><th>解释</th><th></th></tr></thead><tbody><tr><td>D</td><td>数据输入</td><td></td></tr><tr><td>C</td><td>时钟信号</td><td></td></tr><tr><td>en</td><td>使能端口，高电平工作</td><td></td></tr></tbody></table><p>存储器-寄存器</p><blockquote><p>可以做的扩展，增加输入使能WE和输出使能OE<br>寄存器访问速度快，因为寄存器的每一条数据线都是直接接出来的。</p></blockquote><p> </p><h3 id="十六位的内存">十六位的内存</h3><p>内存地址：从并行到串行<br>内存单元格要自己自己在哪一行和哪一列，需要有row和column<br>内存单元要有ld（load）读的控制<br>内存单元要有str（store）有存的控制<br>内存单元要有数据的输入</p><table><thead><tr><th>引脚</th><th>解释</th></tr></thead><tbody><tr><td>row&amp;column</td><td>确定需要储存的地址</td></tr><tr><td>ld（load）</td><td>读的控制</td></tr><tr><td>str（store）</td><td>存的控制</td></tr></tbody></table><p>内存地址：从并行到串行<br>内存地址的作用主要是为了节省数据线，简化电路数量有了内存地址的概念后，输入和输出只需要1条数据线了先选中需要读写的内存单元，再输入输出</p><p> </p><h3 id="8位的寄存器">8位的寄存器</h3><p>设计8位（bit）的寄存器，用于CPU存储的临时计算的数据</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> DIG_Register_BUS #(</span><br><span class="line">    <span class="keyword">parameter</span> Bits = <span class="number">1</span></span><br><span class="line">)</span><br><span class="line">(</span><br><span class="line">    <span class="keyword">input</span> C,</span><br><span class="line">    <span class="keyword">input</span> en,</span><br><span class="line">    <span class="keyword">input</span> [(Bits - <span class="number">1</span>):<span class="number">0</span>]D,</span><br><span class="line">    <span class="keyword">output</span> [(Bits - <span class="number">1</span>):<span class="number">0</span>]Q</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">reg</span> [(Bits - <span class="number">1</span>):<span class="number">0</span>] state = <span class="number">&#x27;h0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">assign</span> Q = state;</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> C) <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">if</span> (en)</span><br><span class="line">        state &lt;= D;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">end</span></span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> DriverBus#(</span><br><span class="line">    <span class="keyword">parameter</span> Bits = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line">(</span><br><span class="line">    <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] in,</span><br><span class="line">    <span class="keyword">input</span> sel,</span><br><span class="line">    <span class="keyword">output</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] out</span><br><span class="line">);</span><br><span class="line">    <span class="keyword">assign</span> out = (sel == <span class="number">1&#x27;b1</span>)? in : &#123;Bits&#123;<span class="number">1&#x27;bz</span>&#125;&#125;;</span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> <span class="number">8_</span>REG  (</span><br><span class="line">  <span class="keyword">input</span> Clock,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">7</span>:<span class="number">0</span>] Din,</span><br><span class="line">  <span class="keyword">input</span> WE,</span><br><span class="line">  <span class="keyword">input</span> OE,</span><br><span class="line">  <span class="keyword">output</span> [<span class="number">7</span>:<span class="number">0</span>] Stored_Data,</span><br><span class="line">  <span class="keyword">output</span> [<span class="number">7</span>:<span class="number">0</span>] Dout</span><br><span class="line">);</span><br><span class="line">  <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] Stored_Data_temp;</span><br><span class="line">  DIG_Register_BUS #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">8</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Register_BUS_i0 (</span><br><span class="line">    <span class="variable">.D</span>( Din ),</span><br><span class="line">    <span class="variable">.C</span>( Clock ),</span><br><span class="line">    <span class="variable">.en</span>( WE ),</span><br><span class="line">    <span class="variable">.Q</span>( Stored_Data_temp )</span><br><span class="line">  );</span><br><span class="line">  DriverBus #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">8</span>)</span><br><span class="line">  )</span><br><span class="line">  DriverBus_i1 (</span><br><span class="line">    <span class="variable">.in</span>( Stored_Data_temp ),</span><br><span class="line">    <span class="variable">.sel</span>( OE ),</span><br><span class="line">    <span class="variable">.out</span>( Dout )</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">assign</span> Stored_Data = Stored_Data_temp;</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p>基于上面的原理图，我们分别设计4位和8位的寄存器4位的寄存器用于程序计数器（PC）和MAR（内存地址寄存器）<br>8位的寄存器用于指令寄存器（IR），CPU通用临时寄存器（RegA）（RegB），内存缓存寄存器（MBR）等。分别测试4位和8位的寄存器。</p><img src="/posts/68d8d011.htm/image-20231011154050156.png" alt="image-20231011154050156" style="zoom:80%;"><p> </p><h3 id="逻辑和算数运算单元（ALU）">逻辑和算数运算单元（ALU）</h3><table><thead><tr><th>引脚</th><th>解释</th></tr></thead><tbody><tr><td>RegA</td><td>8位的寄存器数据</td></tr><tr><td>RegB</td><td>8位的寄存器数据</td></tr><tr><td>OE</td><td>输出允许</td></tr><tr><td>ALUResult</td><td>ALU内部计算结果，方便观察调试</td></tr><tr><td>Carry</td><td>溢出位引出1位信号线</td></tr><tr><td>Dout</td><td>输出数据8位，默认高阻态</td></tr></tbody></table><img src="/posts/68d8d011.htm/image-20231011155356141.png" alt="image-20231011155356141" style="zoom:80%;"><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">* <span class="keyword">module</span> DIG_Add</span><br><span class="line">  #(</span><br><span class="line">  <span class="keyword">parameter</span> Bits = <span class="number">1</span></span><br><span class="line">  )</span><br><span class="line">  (</span><br><span class="line">  <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] a,</span><br><span class="line">  <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] b,</span><br><span class="line">  <span class="keyword">input</span> c_i,</span><br><span class="line">  <span class="keyword">output</span> [(Bits - <span class="number">1</span>):<span class="number">0</span>] s,</span><br><span class="line">  <span class="keyword">output</span> c_o</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">wire</span> [Bits:<span class="number">0</span>] temp;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">assign</span> temp = a + b + c_i;</span><br><span class="line">  <span class="keyword">assign</span> s = temp [(Bits-<span class="number">1</span>):<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">assign</span> c_o = temp[Bits];</span><br><span class="line">  <span class="keyword">endmodule</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> DriverBus#(</span><br><span class="line">    <span class="keyword">parameter</span> Bits = <span class="number">2</span></span><br><span class="line">)</span><br><span class="line">(</span><br><span class="line">    <span class="keyword">input</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] in,</span><br><span class="line">    <span class="keyword">input</span> sel,</span><br><span class="line">    <span class="keyword">output</span> [(Bits-<span class="number">1</span>):<span class="number">0</span>] out</span><br><span class="line">);</span><br><span class="line">    <span class="keyword">assign</span> out = (sel == <span class="number">1&#x27;b1</span>)? in : &#123;Bits&#123;<span class="number">1&#x27;bz</span>&#125;&#125;;</span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> ALU (</span><br><span class="line">  <span class="keyword">input</span> OE,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">7</span>:<span class="number">0</span>] RegA,</span><br><span class="line">  <span class="keyword">input</span> [<span class="number">7</span>:<span class="number">0</span>] RegB,</span><br><span class="line">  <span class="keyword">output</span> [<span class="number">7</span>:<span class="number">0</span>] Dout,</span><br><span class="line">  <span class="keyword">output</span> [<span class="number">7</span>:<span class="number">0</span>] ALU_Result,</span><br><span class="line">  <span class="keyword">output</span> Carry</span><br><span class="line">);</span><br><span class="line">  <span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>] ALU_Result_temp;</span><br><span class="line">  DIG_Add #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">8</span>)</span><br><span class="line">  )</span><br><span class="line">  DIG_Add_i0 (</span><br><span class="line">    <span class="variable">.a</span>( RegA ),</span><br><span class="line">    <span class="variable">.b</span>( RegB ),</span><br><span class="line">    <span class="variable">.c_i</span>( <span class="number">1&#x27;b0</span> ),</span><br><span class="line">    <span class="variable">.s</span>( ALU_Result_temp ),</span><br><span class="line">    <span class="variable">.c_o</span>( Carry )</span><br><span class="line">  );</span><br><span class="line">  DriverBus #(</span><br><span class="line">    <span class="variable">.Bits</span>(<span class="number">8</span>)</span><br><span class="line">  )</span><br><span class="line">  DriverBus_i1 (</span><br><span class="line">    <span class="variable">.in</span>( ALU_Result_temp ),</span><br><span class="line">    <span class="variable">.sel</span>( OE ),</span><br><span class="line">    <span class="variable">.out</span>( Dout )</span><br><span class="line">  );</span><br><span class="line">  <span class="keyword">assign</span> ALU_Result = ALU_Result_temp;</span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="CPU框架搭建">CPU框架搭建</h3><img src="/posts/68d8d011.htm/image-20231011161355384.png" alt="image-20231011161355384" style="zoom:80%;"><img src="/posts/68d8d011.htm/image-20231011165424214.png" alt="image-20231011165424214" style="zoom:80%;">]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>简单cpu的内部结构</title>
      <link href="/posts/dee20e4.html"/>
      <url>/posts/dee20e4.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>verilog基础语法</title>
      <link href="/posts/20b3f144.html"/>
      <url>/posts/20b3f144.html</url>
      
        <content type="html"><![CDATA[<h1>verilog基础语法</h1><h2 id="格式">格式</h2><p>Verilog 是区分大小写的。</p><h3 id="标识符与关键字">标识符与关键字</h3><p>标识符（identifier）可以是任意一组字母、数字、<strong>$</strong> 符号和 <strong>_</strong>(下划线)符号的合，但标识符的第一个字符必须是字母或者下划线，不能以数字或者美元符开始。</p><p>关键字是 Verilog 中预留的用于定义语言结构的特殊标识符。</p><p>Verilog 中关键字全部为小写。</p><h3 id="实例">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] counter ; <span class="comment">//reg 为关键字， counter 为标识符</span></span><br><span class="line"><span class="keyword">input</span> clk; <span class="comment">//input 为关键字，clk 为标识符</span></span><br><span class="line"><span class="keyword">input</span> CLK; <span class="comment">//CLK 与 clk是 2 个不同的标识符</span></span><br></pre></td></tr></table></figure><p>Verilog HDL 有下列四种基本的值来表示硬件电路中的电平逻辑：</p><ul><li>0：逻辑 0 或 “假”</li><li>1：逻辑 1 或 “真”</li><li>x 或 X：未知</li><li>z 或 Z：高阻</li></ul><p><strong>x</strong> 意味着信号数值的不确定，即在实际电路里，信号可能为 1，也可能为 0。</p><p><strong>z</strong> 意味着信号处于高阻状态，常见于信号（input, reg）没有驱动时的逻辑结果。例如一个 pad 的 input 呈现高阻状态时，其逻辑值和上下拉的状态有关系。上拉则逻辑值为 1，下拉则为 0 。</p><h3 id="整数数值表示方法">整数数值表示方法</h3><p>数字声明时，合法的基数格式有 4 种，包括：十进制('d 或 'D)，十六进制('h 或 'H)，二进制（'b 或 'B），八进制（'o 或 'O）。数值可指明位宽，也可不指明位宽。</p><p><strong>指明位宽：</strong></p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4&#x27;b1011</span>         <span class="comment">// 4bit 数值</span></span><br><span class="line"><span class="number">32&#x27;h3022_c0de</span>   <span class="comment">// 32bit 的数值</span></span><br></pre></td></tr></table></figure><p><strong>不指明位宽:</strong></p><p>一般直接写数字时，默认为十进制表示，例如下面的 3 种写法是等效的：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="number">&#x27;d100</span> ; <span class="comment">//一般会根据编译器自动分频位宽，常见的为32bit</span></span><br><span class="line">counter = <span class="number">100</span> ;</span><br><span class="line">counter = <span class="number">32&#x27;h64</span> ;</span><br></pre></td></tr></table></figure><p><code>位宽就是**内存或显存一次能传输的数据量**。 简单地讲就是一次能传递的数据宽度，就像公路的车道宽度，双向四车道、双向六车道，当然车道越多一次能通过的汽车就越大，所以位宽越大，一次性能舆的数据就越多,对显卡来说对性能的提高很明显。</code></p><p><strong>负数表示</strong></p><p>通常在表示位宽的数字前面加一个减号来表示负数。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-<span class="number">6&#x27;d15</span>  </span><br><span class="line">-<span class="number">15</span></span><br></pre></td></tr></table></figure><h3 id="实数表示方法">实数表示方法</h3><p>实数表示方法主要有两种方式：</p><p><strong>科学计数法：</strong></p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="variable">.2e4</span>         <span class="comment">//大小为12000</span></span><br><span class="line"><span class="number">1_0001</span>e4      <span class="comment">//大小为100010000</span></span><br><span class="line"><span class="number">1</span>E-<span class="number">3</span>          <span class="comment">//大小为0.001</span></span><br></pre></td></tr></table></figure><h3 id="字符串表示方法">字符串表示方法</h3><p>字符串是由双引号包起来的字符队列。字符串不能多行书写，即字符串中不能包含<code>回车符</code>。Verilog 将字符串当做一系列的单字节 ASCII 字符队列。例如，为存储字符串 “<a href="http://www.runoob.com">www.runoob.com</a>”, 需要 14*8bit 的存储单元。例如：</p><h3 id="实例-2">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">0</span>: <span class="number">14</span>*<span class="number">8</span>-<span class="number">1</span>]       str ;<span class="comment">//先定义字符串的大小14*8bit </span></span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">    str = <span class="string">&quot;www.runoob.com&quot;</span>;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p> </p><h2 id="Verilog的数据类型">Verilog的数据类型</h2><p>Verilog 最常用的 2 种数据类型就是线网（wire）与寄存器（reg），其余类型可以理解为这两种数据类型的扩展或辅助。</p><h3 id="线网（wire）">线网（wire）</h3><p>wire 类型表示硬件单元之间的<code>物理连线</code>，由其连接的器件输出端连续驱动。如果没有驱动元件连接到 wire 型变量，缺省值一般为 “Z”。举例如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span>   interrupt ;</span><br><span class="line"><span class="keyword">wire</span>   flag1, flag2 ;</span><br><span class="line"><span class="keyword">wire</span>   gnd = <span class="number">1&#x27;b0</span> ;</span><br></pre></td></tr></table></figure><p>线网型还有其他数据类型，包括 wand，wor，wri，triand，trior，trireg 等。这些数据类型用的频率不是很高，这里不做介绍。</p><h3 id="寄存器（reg）">寄存器（reg）</h3><p>寄存器（reg）用来表示存储单元，它会保持数据原有的值，直到被改写。声明举例如下：</p><h3 id="实例-3">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span>    clk_temp;</span><br><span class="line"><span class="keyword">reg</span>    flag1, flag2 ;</span><br></pre></td></tr></table></figure><p>例如在 always 块中，寄存器可能被综合成边沿触发器，在组合逻辑中可能被综合成 wire 型变量。寄存器不需要驱动源，也不一定需要时钟信号。在仿真时，寄存器的值可在任意时刻通过赋值操作进行改写。例如：</p><h3 id="实例-4">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> rstn ;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">    rstn = <span class="number">1&#x27;b0</span> ;</span><br><span class="line">    #<span class="number">100</span> ;</span><br><span class="line">    rstn = <span class="number">1&#x27;b1</span> ;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><h3 id="向量">向量</h3><p>当位宽大于 1 时，wire 或 reg 即可声明为向量的形式。例如：</p><h3 id="实例-5">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>]      counter ;    <span class="comment">//声明4bit位宽的寄存器counter</span></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">32</span>-<span class="number">1</span>:<span class="number">0</span>]  gpio_data;   <span class="comment">//声明32bit位宽的线型变量gpio_data</span></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">8</span>:<span class="number">2</span>]     addr ;       <span class="comment">//声明7bit位宽的线型变量addr，位宽范围为8:2</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">0</span>:<span class="number">31</span>]     data ;       <span class="comment">//声明32bit位宽的寄存器变量data, 最高有效位为0</span></span><br></pre></td></tr></table></figure><p>对于上面的向量，我们可以指定某一位或若干相邻位，作为其他逻辑使用。例如：</p><h3 id="实例-6">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span> [<span class="number">9</span>:<span class="number">0</span>]     data_low = data[<span class="number">0</span>:<span class="number">9</span>] ;</span><br><span class="line">addr_temp[<span class="number">3</span>:<span class="number">2</span>] = addr[<span class="number">8</span>:<span class="number">7</span>] + <span class="number">1&#x27;b1</span> ;</span><br></pre></td></tr></table></figure><p>Verilog 支持可变的向量域选择，例如：</p><h3 id="实例-7">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>]     data1 ;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">7</span>:<span class="number">0</span>]      byte1 [<span class="number">3</span>:<span class="number">0</span>];</span><br><span class="line"><span class="keyword">integer</span> j ;</span><br><span class="line"><span class="keyword">always</span>@* <span class="keyword">begin</span></span><br><span class="line">    <span class="keyword">for</span> (j=<span class="number">0</span>; j&lt;=<span class="number">3</span>;j=j+<span class="number">1</span>) <span class="keyword">begin</span></span><br><span class="line">        byte1[j] = data1[(j+<span class="number">1</span>)*<span class="number">8</span>-<span class="number">1</span> : j*<span class="number">8</span>]; </span><br><span class="line">        <span class="comment">//把data1[7:0]…data1[31:24]依次赋值给byte1[0][7:0]…byte[3][7:0]</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>Verillog 还支持指定 bit 位后固定位宽的向量域选择访问。</strong></p><ul><li><strong>[bit+: width]</strong> : 从起始 bit 位开始递增，位宽为 width。</li><li><strong>[bit-: width]</strong> : 从起始 bit 位开始递减，位宽为 width。</li></ul><h3 id="实例-8">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//下面 2 种赋值是等效的</span></span><br><span class="line">A = data1[<span class="number">31</span>-: <span class="number">8</span>] ;</span><br><span class="line">A = data1[<span class="number">31</span>:<span class="number">24</span>] ;</span><br><span class="line"></span><br><span class="line"><span class="comment">//下面 2 种赋值是等效的</span></span><br><span class="line">B = data1[<span class="number">0</span>+ : <span class="number">8</span>] ;</span><br><span class="line">B = data1[<span class="number">0</span>:<span class="number">7</span>] ;</span><br></pre></td></tr></table></figure><p><strong>对信号重新进行组合成新的向量时，需要借助大括号。例如：</strong></p><h3 id="实例-9">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">wire</span> [<span class="number">31</span>:<span class="number">0</span>]    temp1, temp2 ;</span><br><span class="line"><span class="keyword">assign</span> temp1 = &#123;byte1[<span class="number">0</span>][<span class="number">7</span>:<span class="number">0</span>], data1[<span class="number">31</span>:<span class="number">8</span>]&#125;;  <span class="comment">//数据拼接</span></span><br><span class="line"><span class="keyword">assign</span> temp2 = &#123;<span class="number">32</span>&#123;<span class="number">1&#x27;b0</span>&#125;&#125;;  <span class="comment">//赋值32位的数值0</span></span><br></pre></td></tr></table></figure><h2 id="整数，实数，时间寄存器变量">整数，实数，时间寄存器变量</h2><p>整数，实数，时间等数据类型实际也属于寄存器类型。</p><p><strong>整数（integer）</strong>(相当于int)</p><p>整数类型用关键字 integer 来声明。声明时不用指明位宽，位宽和编译器有关，一般为32 bit。reg 型变量为无符号数，而 integer 型变量为有符号数。例如：</p><h3 id="实例-10">实例</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">reg [31:0]      data1 ;</span><br><span class="line">reg [3:0]       byte1 [7:0]; //数组变量，后续介绍</span><br><span class="line">integer j ;  //整型变量，用来辅助生成数字电路</span><br><span class="line">always@* begin</span><br><span class="line">    for (j=0; j&lt;=3;j=j+1) begin</span><br><span class="line">        byte1[j] = data1[(j+1)*8-1 : j*8]; </span><br><span class="line">        //把data1[7:0]…data1[31:24]依次赋值给byte1[0][7:0]…byte[3][7:0]</span><br><span class="line">        end</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>此例中，integer 信号 j 作为辅助信号，将 data1 的数据依次赋值给数组 byte1。综合后实际电路里并没有 j 这个信号，j 只是辅助生成相应的硬件电路。</p><p><code>always@* begin</code>：</p><ul><li>这是一个组合逻辑块的定义，<code>always@*</code>表示该组合逻辑块会在任何输入变化时执行。</li></ul><p><strong>时序逻辑</strong>：</p><ul><li><code>always @ (posedge clk)</code> 表示在时钟上升沿触发的时序逻辑。</li><li>在时钟上升沿触发时，将执行<code>begin</code>和<code>end</code>之间的代码块。</li></ul><p><strong>实数（real）</strong></p><p>实数用关键字 real 来声明，可用十进制或科学计数法来表示。实数声明不能带有范围，默认值为 0。如果将一个实数赋值给一个整数，则只有实数的整数部分会赋值给整数。例如：</p><h3 id="实例-11">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">real</span>        data1 ;</span><br><span class="line"><span class="keyword">integer</span>     temp ;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">    data1 = <span class="number">2</span>e3 ;</span><br><span class="line">    data1 = <span class="number">3</span><span class="variable">.75</span> ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">    temp = data1 ; <span class="comment">//temp 值的大小为3</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p><strong>时间（time）</strong></p><p>Verilog 使用特殊的时间寄存器 time 型变量，对仿真时间进行保存。其宽度一般为 64 bit，通过调用系统函数 $time$ 获取当前仿真时间。例如：</p><h3 id="实例-12">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">time</span>       current_time ;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">       #<span class="number">100</span> ;</span><br><span class="line">       current_time = <span class="built_in">$time</span> ; <span class="comment">//current_time 的大小为 100</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p> </p><h2 id="数组">数组</h2><p>在 Verilog 中允许声明 reg, wire, integer, time, real 及其向量类型的数组。</p><p>数组维数没有限制。线网数组也可以用于连接实例模块的端口。数组中的每个元素都可以作为一个标量或者向量，以同样的方式来使用，形如：<strong>&lt;数组名&gt;[&lt;下标&gt;]</strong>。对于多维数组来讲，用户需要说明其每一维的索引。例如：</p><h3 id="实例-13">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">integer</span>          flag [<span class="number">7</span>:<span class="number">0</span>] ; <span class="comment">//8个整数组成的数组</span></span><br><span class="line"><span class="keyword">reg</span>  [<span class="number">3</span>:<span class="number">0</span>]       counter [<span class="number">3</span>:<span class="number">0</span>] ; <span class="comment">//由4个4bit计数器组成的数组</span></span><br><span class="line"><span class="keyword">wire</span> [<span class="number">7</span>:<span class="number">0</span>]       addr_bus [<span class="number">3</span>:<span class="number">0</span>] ; <span class="comment">//由4个8bit wire型变量组成的数组</span></span><br><span class="line"><span class="keyword">wire</span>             data_bit[<span class="number">7</span>:<span class="number">0</span>][<span class="number">5</span>:<span class="number">0</span>] ; <span class="comment">//声明1bit wire型变量的二维数组</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">31</span>:<span class="number">0</span>]       data_4d[<span class="number">11</span>:<span class="number">0</span>][<span class="number">3</span>:<span class="number">0</span>][<span class="number">3</span>:<span class="number">0</span>][<span class="number">255</span>:<span class="number">0</span>] ; <span class="comment">//声明4维的32bit数据变量数组</span></span><br></pre></td></tr></table></figure><p>下面显示了对数组元素的赋值操作：</p><h3 id="实例-14">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">flag [<span class="number">1</span>]   = <span class="number">32&#x27;d0</span> ; <span class="comment">//将flag数组中第二个元素赋值为32bit的0值</span></span><br><span class="line">counter[<span class="number">3</span>] = <span class="number">4&#x27;hF</span> ;  <span class="comment">//将数组counter中第4个元素的值赋值为4bit 十六进制数F，等效于counter[3][3:0] = 4&#x27;hF，即可省略宽度; </span></span><br><span class="line"><span class="keyword">assign</span> addr_bus[<span class="number">0</span>]        = <span class="number">8&#x27;b0</span> ; <span class="comment">//将数组addr_bus中第一个元素的值赋值为0</span></span><br><span class="line"><span class="keyword">assign</span> data_bit[<span class="number">0</span>][<span class="number">1</span>]     = <span class="number">1&#x27;b1</span>;  <span class="comment">//将数组data_bit的第1行第2列的元素赋值为1，这里不能省略第二个访问标号，即 assign data_bit[0] = 1&#x27;b1; 是非法的。</span></span><br><span class="line">data_4d[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="number">15</span>:<span class="number">0</span>] = <span class="number">15&#x27;d3</span> ;  <span class="comment">//将数组data_4d中标号为[0][0][0][0]的寄存器单元的15~0bit赋值为3</span></span><br></pre></td></tr></table></figure><p>虽然数组与向量的访问方式在一定程度上类似，但不要将向量和数组混淆。向量是一个单独的元件，位宽为 n；数组由多个元件组成，其中每个元件的位宽为 n 或 1。它们在结构的定义上就有所区别。</p><h2 id="存储器">存储器</h2><p>存储器变量就是一种寄存器数组，可用来描述 RAM 或 ROM 的行为。例如：</p><h3 id="实例-15">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span>               membit[<span class="number">0</span>:<span class="number">255</span>] ;  <span class="comment">//256bit的1bit存储器</span></span><br><span class="line"><span class="keyword">reg</span>  [<span class="number">7</span>:<span class="number">0</span>]        mem[<span class="number">0</span>:<span class="number">1023</span>] ;    <span class="comment">//1Kbyte存储器，位宽8bit</span></span><br><span class="line">mem[<span class="number">511</span>] = <span class="number">8&#x27;b0</span> ;                  <span class="comment">//令第512个8bit的存储单元值为0</span></span><br></pre></td></tr></table></figure><h2 id="参数">参数</h2><p>参数用来表示常量，用关键字 parameter 声明，只能赋值一次。例如：</p><h3 id="实例-16">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">parameter</span>      data_width = <span class="number">10&#x27;d32</span> ;</span><br><span class="line"><span class="keyword">parameter</span>      i=<span class="number">1</span>, j=<span class="number">2</span>, k=<span class="number">3</span> ;</span><br><span class="line"><span class="keyword">parameter</span>      mem_size = data_width * <span class="number">10</span> ;</span><br></pre></td></tr></table></figure><p>但是，通过实例化的方式，可以更改参数在模块中的值。此部分以后会介绍。</p><p>局部参数用 localparam 来声明，其作用和用法与 parameter 相同，区别在于它的值不能被改变。所以当参数只在本模块中调用时，可用 localparam 来说明。</p><h2 id="字符串">字符串</h2><p>字符串保存在 reg 类型的变量中，每个字符占用一个字节（8bit）。因此寄存器变量的宽度应该足够大，以保证不会溢出。</p><p>字符串不能多行书写，即字符串中不能包含回车符。如果寄存器变量的宽度大于字符串的大小，则使用 0 来填充左边的空余位；如果寄存器变量的宽度小于字符串大小，则会截去字符串左边多余的数据。例如，为存储字符串 “<a href="http://run.runoob.com">run.runoob.com</a>”, 需要 14*8bit 的存储单元：</p><h3 id="实例-17">实例</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">0</span>: <span class="number">14</span>*<span class="number">8</span>-<span class="number">1</span>]       str ;</span><br><span class="line"><span class="keyword">initial</span> <span class="keyword">begin</span></span><br><span class="line">    str = <span class="string">&quot;run.runoob.com&quot;</span>; </span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>有一些特殊字符在显示字符串中有特殊意义，例如换行符，制表符等。如果需要在字符串中显示这些特殊的字符，则需要在前面加前缀转义字符 *<em>*</em> 。例如下表所示：</p><table><thead><tr><th style="text-align:left">转义字符</th><th style="text-align:left">显示字符</th></tr></thead><tbody><tr><td style="text-align:left">\n</td><td style="text-align:left">换行</td></tr><tr><td style="text-align:left">\t</td><td style="text-align:left">制表符</td></tr><tr><td style="text-align:left">%%</td><td style="text-align:left">%</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left">\</td></tr><tr><td style="text-align:left">&quot;</td><td style="text-align:left">&quot;</td></tr><tr><td style="text-align:left">\ooo</td><td style="text-align:left">1到3个8进制数字字符</td></tr></tbody></table><p>其实，在 SystemVerilog（主要用于 Verilog 仿真的编程语言）语言中，已经可以直接用关键字 string 来表示字符串变量类型，这为 Verilog 的仿真带来了极大的便利。有兴趣的学者可以简单学习下 SystemVerilog。</p><p> </p><p> </p><h2 id="表达式">表达式</h2><p>表达式由操作符和操作数构成，其目的是根据操作符的意义得到一个计算结果。表达式可以在出现数值的任何地方使用。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a^b ;          <span class="comment">//a与b进行异或操作</span></span><br><span class="line">address[<span class="number">9</span>:<span class="number">0</span>] + <span class="number">10&#x27;b1</span> ;  <span class="comment">//地址累加</span></span><br><span class="line">flag1 &amp;&amp; flag2 ;  <span class="comment">//逻辑与操作</span></span><br></pre></td></tr></table></figure><h2 id="操作数">操作数</h2><p>操作数可以是任意的数据类型，只是某些特定的语法结构要求使用特定类型的操作数。</p><p>操作数可以为常数，整数，实数，线网，寄存器，时间，位选，域选，存储器及函数调用等。</p><h2 id="实例-18">实例</h2><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">module</span> test;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//实数</span></span><br><span class="line"><span class="keyword">real</span> a, b, c;</span><br><span class="line">c = a + b ;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//寄存器</span></span><br><span class="line"><span class="keyword">reg</span>  [<span class="number">3</span>:<span class="number">0</span>]       cprmu_1, cprmu_2 ;</span><br><span class="line"><span class="keyword">always</span> @(<span class="keyword">posedge</span> clk) <span class="keyword">begin</span></span><br><span class="line">        cprmu_2 = cprmu_1 ^ cprmu_2 ;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">         </span><br><span class="line"><span class="comment">//函数</span></span><br><span class="line"><span class="keyword">reg</span>  flag1 ;</span><br><span class="line">flag = calculate_result(A, B);</span><br><span class="line"> </span><br><span class="line"><span class="comment">//非法操作数</span></span><br><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>]         res;</span><br><span class="line"><span class="keyword">wire</span> [<span class="number">3</span>:<span class="number">0</span>]        temp;</span><br><span class="line"><span class="keyword">always</span>@ （*）<span class="keyword">begin</span></span><br><span class="line">    res    = cprmu_2 – cprmu_1 ;</span><br><span class="line">    <span class="comment">//temp = cprmu_2 – cprmu_1 ; //不合法，always块里赋值对象不能是wire型</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br></pre></td></tr></table></figure><h3 id="操作符">操作符</h3><p>Verilog 中提供了大约 9 种操作符，分别是算术、关系、等价、逻辑、按位、归约、移位、拼接、条件操作符。</p><p>大部分操作符与 C 语言中类似。同类型操作符之间，除条件操作符从右往左关联，其余操作符都是自左向右关联。圆括号内表达式优先执行。例如下面每组的 2 种写法都是等价的。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自右向左关联，两种写法等价</span></span><br><span class="line">A+B-C ;</span><br><span class="line">(A+B）-C ;</span><br><span class="line"></span><br><span class="line"><span class="comment">//自右向左关联，两种写法等价，结果为 B、D 或 F</span></span><br><span class="line">A ? B : C ? D : F ;</span><br><span class="line">A ? B : (C ? D : F) ;</span><br><span class="line"></span><br><span class="line"><span class="comment">//自右向左关联，两种写法不等价</span></span><br><span class="line">(A ? B : C) ? D : F ;  <span class="comment">//结果 D 或 F</span></span><br><span class="line">A ? B : C ? D : F ; <span class="comment">//结果为 B、D 或 F</span></span><br></pre></td></tr></table></figure><p>不同操作符之间，优先级是不同的。下表列出了操作符优先级从高至低的排列顺序。当没有圆括号时，Verilog 会根据操作符优先级对表达式进行计算。为了避免由操作符优先级导致的计算混乱，在不确定优先级时，建议用圆括号将表达式区分开来。</p><table><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">操作符号</th><th style="text-align:left">优先级</th></tr></thead><tbody><tr><td style="text-align:left">单目运算</td><td style="text-align:left">+ - ! ~</td><td style="text-align:left">最高</td></tr><tr><td style="text-align:left">乘、除、取模</td><td style="text-align:left">* / %</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">加减</td><td style="text-align:left">+ -</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">移位</td><td style="text-align:left">&lt;&lt;  &gt;&gt;</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">关系</td><td style="text-align:left">&lt; &lt;= &gt; &gt;=</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">等价</td><td style="text-align:left">== != === !===</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">归约</td><td style="text-align:left">&amp; ~&amp;</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left">^ ~^</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left">| ~|</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">逻辑</td><td style="text-align:left">&amp;&amp;</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"></td><td style="text-align:left">||</td><td style="text-align:left"></td></tr><tr><td style="text-align:left">条件</td><td style="text-align:left">?:</td><td style="text-align:left">最低</td></tr></tbody></table><h3 id="算术操作符">算术操作符</h3><p>算术操作符包括单目操作符和双目操作符。</p><p>双目操作符对 2 个操作数进行算术运算，包括乘（*）、除（/）、加（+）、减（-）、求幂（**）、取模（%）。</p><h2 id="实例-19">实例</h2><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>]  a, b;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">4</span>:<span class="number">0</span>]  c ;</span><br><span class="line">a = <span class="number">4&#x27;b0010</span> ;</span><br><span class="line">b = <span class="number">4&#x27;b1001</span> ;</span><br><span class="line">c = a+b;        <span class="comment">//结果为c=b&#x27;b1011</span></span><br><span class="line">c = a/b;          <span class="comment">//结果为c=4，取整</span></span><br></pre></td></tr></table></figure><p>如果操作数某一位为 X，则计算结果也会全部出现 X。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">b = <span class="number">4&#x27;b100x</span> ;</span><br><span class="line">c = a+b ;       <span class="comment">//结果为c=4&#x27;bxxxx</span></span><br></pre></td></tr></table></figure><p>对变量进行声明时，要根据变量的操作符对变量的位宽进行合理声明，不要让结果溢出。上述例子中，相加的 2 个变量位宽为 4bit，那么结果寄存器变量位宽最少为 5bit。否则，高位将被截断，导致结果高位丢失。无符号数乘法时，结果变量位宽应该为 2 个操作数位宽之和。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>]        mula ;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>]        mulb;</span><br><span class="line"><span class="keyword">reg</span> [<span class="number">5</span>:<span class="number">0</span>]        res ;</span><br><span class="line">mula = <span class="number">4&#x27;he</span>   ;</span><br><span class="line">mulb = <span class="number">2&#x27;h3</span>   ;</span><br><span class="line">res  = mula * mulb ; <span class="comment">//结果为res=6&#x27;h2a, 数据结果没有丢失位数</span></span><br></pre></td></tr></table></figure><p>+ 和 - 也可以作为单目操作符来使用，表示操作数的正负性。此类操作符优先级最高。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-<span class="number">4</span>  <span class="comment">//表示负4</span></span><br><span class="line">+<span class="number">3</span>  <span class="comment">//表示正3</span></span><br></pre></td></tr></table></figure><p>负数表示时，可以直接在十进制数字前面增加一个减号 <strong>-</strong>，也可以指定位宽。因为负数使用二进制补码来表示，不指定位宽来表示负数，编译器在转换时，会自动分配位宽，从而导致意想不到的结果。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mula = -<span class="number">4&#x27;d4</span> ;</span><br><span class="line">mulb = <span class="number">2</span> ;</span><br><span class="line">res = mula * mulb ;      <span class="comment">//计算结果为res=-6&#x27;d8, 即res=6&#x27;h38，正常</span></span><br><span class="line">res = mula * (-<span class="number">&#x27;d4</span>) ;    <span class="comment">//(4的32次幂-4) * 2, 结果异常</span></span><br></pre></td></tr></table></figure><h3 id="关系操作符">关系操作符</h3><p>关系操作符有大于（&gt;），小于（&lt;），大于等于（&gt;=），小于等于（&lt;=）。</p><p>关系操作符的正常结果有 2 种，真（1）或假（0）。</p><p>如果操作数中有一位为 x 或 z，则关系表达式的结果为 x。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4</span> ;</span><br><span class="line">B = <span class="number">3</span> ;</span><br><span class="line">X = <span class="number">3&#x27;b1xx</span> ;</span><br><span class="line">    </span><br><span class="line">A &gt; B     <span class="comment">//为真</span></span><br><span class="line">A &lt;= B    <span class="comment">//为假</span></span><br><span class="line">A &gt;= Z    <span class="comment">//为X，不确定</span></span><br></pre></td></tr></table></figure><h3 id="等价操作符">等价操作符</h3><p>等价操作符包括逻辑相等（ == ） ，逻辑不等（!=），全等（ ===  ），非全等（  !  ）。</p><p>等价操作符的正常结果有 2 种：为真（1）或假（0）。</p><p>逻辑相等/不等操作符不能比较 x 或 z，当操作数包含一个 x 或 z，则结果为不确定值。</p><p>全等比较时，如果按位比较有相同的 x 或 z，返回结果也可以为 1，即全等比较可比较 x 或 z。所以，全等比较的结果一定不包含 x。举例如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4</span> ;</span><br><span class="line">B = <span class="number">8&#x27;h04</span> ;</span><br><span class="line">C = <span class="number">4&#x27;bxxxx</span> ;</span><br><span class="line">D = <span class="number">4&#x27;hx</span> ;</span><br><span class="line">A == B        <span class="comment">//为真</span></span><br><span class="line">A == (B + <span class="number">1</span>)  <span class="comment">//为假</span></span><br><span class="line">A == C        <span class="comment">//为X，不确定</span></span><br><span class="line">A === C       <span class="comment">//为假，返回值为0</span></span><br><span class="line">C === D       <span class="comment">//为真，返回值为1</span></span><br></pre></td></tr></table></figure><h3 id="逻辑操作符">逻辑操作符</h3><p>逻辑操作符主要有 3 个：&amp;&amp;（逻辑与）, ||（逻辑或），!（逻辑非）。</p><p>逻辑操作符的计算结果是一个 1bit 的值，0 表示假，1 表示真，x 表示不确定。</p><p>如果一个操作数不为 0，它等价于逻辑 1；如果一个操作数等于 0，它等价于逻辑 0。如果它任意一位为 x 或 z，它等价于 x。</p><p>如果任意一个操作数包含 x，逻辑操作符运算结果不一定为 x。</p><p>逻辑操作符的操作数可以为变量，也可以为表达式。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">3</span>; </span><br><span class="line">B = <span class="number">0</span>; </span><br><span class="line">C = <span class="number">2&#x27;b1x</span> ;</span><br><span class="line">    </span><br><span class="line">A &amp;&amp; B    <span class="comment">//     为假</span></span><br><span class="line">A || B    <span class="comment">//     为真</span></span><br><span class="line">! A       <span class="comment">//     为假</span></span><br><span class="line">! B       <span class="comment">//     为真</span></span><br><span class="line">A &amp;&amp; C    <span class="comment">//     为X，不确定</span></span><br><span class="line">A || C    <span class="comment">//     为真，因为A为真</span></span><br><span class="line">(A==<span class="number">2</span>) &amp;&amp; (! B)  <span class="comment">//为真，此时第一个操作数为表达式</span></span><br></pre></td></tr></table></figure><h3 id="按位操作符">按位操作符</h3><p>按位操作符包括：取反（<sub>），与（&amp;），或（|），异或（^），同或（</sub>^）。</p><p>按位操作符对 2 个操作数的每 1bit 数据进行按位操作。</p><p>如果 2 个操作数位宽不相等，则用 0 向左扩展补充较短的操作数。</p><p>取反操作符只有一个操作数，它对操作数的每 1bit 数据进行取反操作。</p><p>下图给出了按位操作符的逻辑规则。</p><table><thead><tr><th style="text-align:left">&amp;(与）</th><th style="text-align:left">0</th><th style="text-align:left">1</th><th style="text-align:left">x</th><th style="text-align:left"></th><th style="text-align:left">|(或)</th><th style="text-align:left">0</th><th style="text-align:left">1</th><th style="text-align:left">x</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left"></td><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">x</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">x</td><td style="text-align:left"></td><td style="text-align:left">1</td><td style="text-align:left">1</td><td style="text-align:left">1</td><td style="text-align:left">1</td></tr><tr><td style="text-align:left">x</td><td style="text-align:left">0</td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left"></td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left">1</td><td style="text-align:left">x</td></tr></tbody></table><table><thead><tr><th style="text-align:left">^(异或)</th><th style="text-align:left">0</th><th style="text-align:left">1</th><th style="text-align:left">x</th><th style="text-align:left"></th><th style="text-align:left">~^(同或)</th><th style="text-align:left">0</th><th style="text-align:left">1</th><th style="text-align:left">x</th></tr></thead><tbody><tr><td style="text-align:left">0</td><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">x</td><td style="text-align:left"></td><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">x</td></tr><tr><td style="text-align:left">1</td><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">x</td><td style="text-align:left"></td><td style="text-align:left">1</td><td style="text-align:left">0</td><td style="text-align:left">1</td><td style="text-align:left">x</td></tr><tr><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left"></td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left">x</td><td style="text-align:left">x</td></tr></tbody></table><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4&#x27;b0101</span> ;</span><br><span class="line">B = <span class="number">4&#x27;b1001</span> ;</span><br><span class="line">C = <span class="number">4&#x27;bx010</span> ;</span><br><span class="line">    </span><br><span class="line">~A        <span class="comment">//4&#x27;b1010</span></span><br><span class="line">A &amp; B     <span class="comment">//4&#x27;b0001</span></span><br><span class="line">A | B     <span class="comment">//4&#x27;b1101</span></span><br><span class="line">A^B       <span class="comment">//4&#x27;b1100</span></span><br><span class="line">A ~^ B    <span class="comment">//4&#x27;b0011</span></span><br><span class="line">B | C     <span class="comment">//4&#x27;b1011</span></span><br><span class="line">B&amp;C       <span class="comment">//4&#x27;bx000</span></span><br></pre></td></tr></table></figure><h3 id="归约操作符">归约操作符</h3><p>归约操作符包括：归约与（&amp;），归约与非（<sub>&amp;），归约或（|），归约或非（</sub>|），归约异或（<sup>），归约同或（~</sup>）。</p><p>归约操作符只有一个操作数，它对这个向量操作数逐位进行操作，最终产生一个 1bit 结果。</p><p>逻辑操作符、按位操作符和归约操作符都使用相同的符号表示，因此有时候容易混淆。区分这些操作符的关键是分清操作数的数目，和计算结果的规则。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4&#x27;b1010</span> ;</span><br><span class="line">&amp;A ;      <span class="comment">//结果为 1 &amp; 0 &amp; 1 &amp; 0 = 1&#x27;b0，可用来判断变量A是否全1</span></span><br><span class="line">~|A ;     <span class="comment">//结果为 ~(1 | 0 | 1 | 0) = 1&#x27;b0, 可用来判断变量A是否为全0</span></span><br><span class="line">^A ;      <span class="comment">//结果为 1 ^ 0 ^ 1 ^ 0 = 1&#x27;b0</span></span><br></pre></td></tr></table></figure><h3 id="移位操作符">移位操作符</h3><p>移位操作符包括左移（&lt;&lt;），右移（&gt;&gt;），算术左移（&lt;&lt;&lt;），算术右移（&gt;&gt;&gt;）。</p><p>移位操作符是双目操作符，两个操作数分别表示要进行移位的向量信号（操作符左侧）与移动的位数（操作符右侧）。</p><p>算术左移和逻辑左移时，右边低位会补 0。</p><p>逻辑右移时，左边高位会补 0；而算术右移时，左边高位会补充符号位，以保证数据缩小后值的正确性。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4&#x27;b1100</span> ;</span><br><span class="line">B = <span class="number">4&#x27;b0010</span> ;</span><br><span class="line">A = A &gt;&gt; <span class="number">2</span> ;        <span class="comment">//结果为 4&#x27;b0011</span></span><br><span class="line">A = A &lt;&lt; <span class="number">1</span>;         <span class="comment">//结果为 4&#x27;b1000</span></span><br><span class="line">A = A &lt;&lt;&lt; <span class="number">1</span> ;       <span class="comment">//结果为 4&#x27;b1000</span></span><br><span class="line">C = B + (A&gt;&gt;&gt;<span class="number">2</span>);    <span class="comment">//结果为 2 + (-4/4) = 1, 4&#x27;b0001</span></span><br></pre></td></tr></table></figure><h3 id="拼接操作符">拼接操作符</h3><p>拼接操作符用大括号 <strong>{，}</strong> 来表示，用于将多个操作数（向量）拼接成新的操作数（向量），信号间用逗号隔开。</p><p>拼接符操作数必须指定位宽，常数的话也需要指定位宽。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">A = <span class="number">4&#x27;b1010</span> ;</span><br><span class="line">B = <span class="number">1&#x27;b1</span> ;</span><br><span class="line">Y1 = &#123;B, A[<span class="number">3</span>:<span class="number">2</span>], A[<span class="number">0</span>], <span class="number">4&#x27;h3</span> &#125;;  <span class="comment">//结果为Y1=&#x27;b1100_0011</span></span><br><span class="line">Y2 = &#123;<span class="number">4</span>&#123;B&#125;, <span class="number">3&#x27;d4</span>&#125;;  <span class="comment">//结果为 Y2=7&#x27;b111_1100</span></span><br><span class="line">Y3 = &#123;<span class="number">32</span>&#123;<span class="number">1&#x27;b0</span>&#125;&#125;;  <span class="comment">//结果为 Y3=32h0，常用作寄存器初始化时匹配位宽的赋初值</span></span><br></pre></td></tr></table></figure><h3 id="条件操作符">条件操作符</h3><p>条件表达式有 3 个操作符，结构描述如下：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">condition_expression ? true_expression : false_expression</span><br></pre></td></tr></table></figure><p>计算时，如果 condition_expression 为真（逻辑值为 1），则运算结果为 true_expression；如果 condition_expression 为假（逻辑值为 0），则计算结果为 false_expression。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assign</span> hsel    = (addr[<span class="number">9</span>:<span class="number">8</span>] == <span class="number">2&#x27;b0</span>) ? hsel_p1 : hsel_p2 ;</span><br><span class="line"><span class="comment">//当信号 addr 高 2bit 为 0 时，hsel 赋值为 hsel_p1; 否则，将 hsel_p2 赋值给 hsel。</span></span><br></pre></td></tr></table></figure><p>其实，条件表达式类似于 2 路（或多路）选择器，其描述方式完全可以用 if-else 语句代替。</p><p>当然条件操作符也能进行嵌套，完成一个多次选择的逻辑。例如：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assign</span>   hsel = (addr[<span class="number">9</span>:<span class="number">8</span>] == <span class="number">2&#x27;b00</span>) ? hsel_p1 : </span><br><span class="line">                (addr[<span class="number">9</span>:<span class="number">8</span>] == <span class="number">2&#x27;b01</span>) ? hsel_p2 :</span><br><span class="line">                (addr[<span class="number">9</span>:<span class="number">8</span>] == <span class="number">2&#x27;b10</span>) ? hsel_p3 :</span><br><span class="line">                (addr[<span class="number">9</span>:<span class="number">8</span>] == <span class="number">2&#x27;b11</span>) ? hsel_p4 ;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> verilog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>verilog</title>
      <link href="/posts/ffaf1e77.html"/>
      <url>/posts/ffaf1e77.html</url>
      
        <content type="html"><![CDATA[<h1>Quartus</h1><h3 id="使用–全加器">使用–全加器</h3><h3 id="原理图方式（而输入或门）">原理图方式（而输入或门）</h3><img src="/posts/ffaf1e77.htm/image-20230807180738812.png" alt="image-20230807180738812" style="zoom:50%;"><img src="/posts/ffaf1e77.htm/image-20230807181223960.png" alt="image-20230807181223960" style="zoom:50%;"><img src="/posts/ffaf1e77.htm/image-20230807181408224.png" alt="image-20230807181408224" style="zoom:50%;"><p>然后完成一个2选1的原理图</p><img src="/posts/ffaf1e77.htm/image-20230807181746258.png" alt="image-20230807181746258" style="zoom:50%;"><p>然后点击new选择University Program VWF</p><img src="/posts/ffaf1e77.htm/image-20230807181829430.png" alt="image-20230807181829430" style="zoom:50%;"><img src="/posts/ffaf1e77.htm/image-20230807181944693.png" alt="image-20230807181944693" style="zoom:50%;"><img src="/posts/ffaf1e77.htm/image-20230807182059221.png" alt="image-20230807182059221" style="zoom:50%;"><p>将其全部移入</p><img src="/posts/ffaf1e77.htm/image-20230807182228594.png" alt="image-20230807182228594" style="zoom:50%;"><p>选择器件然后点击设置时间。</p><img src="/posts/ffaf1e77.htm/image-20230807182426708.png" alt="image-20230807182426708" style="zoom:50%;"><h3 id="用verilog进行电路设计">用verilog进行电路设计</h3><img src="/posts/ffaf1e77.htm/image-20230807183308472.png" alt="image-20230807183308472" style="zoom:50%;"><p>右击选择Insert Template</p><img src="/posts/ffaf1e77.htm/image-20230807183728558.png" alt="image-20230807183728558" style="zoom:50%;"><p>！！Verilog HDL要求module描述的实例名称必须与储存文件名一致，我们将程序性稍做修改</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Quartus II Verilog Template</span></span><br><span class="line"><span class="comment">// Signed adder/subtractor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">module</span> adder_sub</span><br><span class="line">#(<span class="keyword">parameter</span> WIDTH=<span class="number">16</span>)</span><br><span class="line">(</span><br><span class="line"><span class="keyword">input</span> <span class="keyword">signed</span> [WIDTH-<span class="number">1</span>:<span class="number">0</span>] dataa,</span><br><span class="line"><span class="keyword">input</span> <span class="keyword">signed</span> [WIDTH-<span class="number">1</span>:<span class="number">0</span>] datab,</span><br><span class="line"><span class="keyword">input</span> add_sub,  <span class="comment">// if this is 1, add; else subtract</span></span><br><span class="line"><span class="keyword">input</span> clk,</span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH:<span class="number">0</span>] result</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">always</span> @ (<span class="keyword">posedge</span> clk)</span><br><span class="line"><span class="keyword">begin</span></span><br><span class="line"><span class="keyword">if</span> (add_sub)</span><br><span class="line">result &lt;= dataa + datab;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">result &lt;= dataa - datab;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">endmodule</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol><li><p>Verilog HDL程序是以module为基本单位的，形式上以$module<name>$开头,以$endmodule$结尾，模块名称$name$可以由设计者自定，并要求和文件存储名称一致。</name></p></li><li><p>$module<name>$和$endmodule$之间成为<code>模块实体</code>，其包括输入输出端口及数据类型描述，接下来是实际语句体描述。输入输出端口数据名称和类型的描述，要放在模块名称后面，并且用括号括起来。</name></p></li><li><p>输入/输出/双向端口变量描述一般以如下形式，不同端口之间要用逗号<code>，</code>隔开</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//input 变量宽度 变量名称</span></span><br><span class="line"><span class="keyword">input</span> <span class="keyword">signed</span> [WIDTH-<span class="number">1</span>:<span class="number">0</span>] dataa,</span><br><span class="line"><span class="comment">//output 变量宽度 变量名称</span></span><br><span class="line"><span class="keyword">output</span> <span class="keyword">reg</span> [WIDTH:<span class="number">0</span>] result</span><br><span class="line"><span class="comment">//bidir 变量宽度 变量名称</span></span><br></pre></td></tr></table></figure></li><li><p>Verilog HDL中主要有两种类型<code>导线型</code>$wire$和<code>寄存器型</code>$reg$。在端口变量描述中$wire$可以省略。</p><p>各种类型容纳变量都是容纳的二进制数，他们能够纳二进制数的位数称之为<code>线宽</code></p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//例如[7:0],表示有8位宽度的向量，内部的二进制数或存放二进制数的位置编号是7，6，5，4，3，2，1，0</span></span><br></pre></td></tr></table></figure></li><li><p>形参要用parameter保留字来定义，形式为：$parameter 形参名称 = 常数$，大多数情况下形参都用大写字母来表示</p></li><li><p>$lways @ (posedge clk)$是一个结构体语句的头，有多个语句时要用$begin … end$语句括起来，其代表只要clk上升沿到来，该$begin … end$语句体的内容就会被执行一遍。always语句括号内的变量成为敏感变量，多个敏感变量同时存在，用<code>or</code>或者<code>，</code>分开。$posedge$和$negedge$必须在每个敏感变量之前修饰，如果下降沿有效则用$negedge$修饰。</p></li><li><p>$always$中的语句都是按顺序执行的。</p></li><li><p>这个Add_Sub程序中设计了一个16位的加减法运算器，输入输出端口有两个16位的数据导线$dataa$和$datab$一个时钟输入导线$clk$，一个控制选择加减法运算的导线Sub，输出端口是一个16位的寄存器$result$。每当时钟上升沿到来的时刻，依据Sub为0还是1进行加法或者减法运算，并且将结果送到$result$寄存器。</p></li></ol><p> </p><img src="/posts/ffaf1e77.htm/image-20230807220923070.png" alt="image-20230807220923070" style="zoom:50%;">]]></content>
      
      
      
        <tags>
            
            <tag> verilog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>acfly飞控</title>
      <link href="/posts/a4e8942.html"/>
      <url>/posts/a4e8942.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>立创eda专业版</title>
      <link href="/posts/9c8613dc.html"/>
      <url>/posts/9c8613dc.html</url>
      
        <content type="html"><![CDATA[<h1>立创eda专业版</h1><h2 id="1-新建文档">1.新建文档</h2><p>创建工程，命名规则如下</p><p>文件名-版本-日期</p><p>例如：GD32F230C8T6-V1.0.0-20230725</p><p> </p><h2 id="2-原理图设计环境设置">2.原理图设计环境设置</h2><p>设置–&gt;常规–&gt;设置原理图尺寸为0.1</p><p>保存–&gt;自动保存</p><img src="/posts/9c8613dc.htm/image-20230725180844637.png" alt="image-20230725180844637" style="zoom: 50%;"><img src="/posts/9c8613dc.htm/image-20230725181110414.png" alt="image-20230725181110414" style="zoom:50%;"><p>右方图页中可以更改相关信息，例如图纸尺寸，以及右下角的各种信息。</p><img src="/posts/9c8613dc.htm/image-20230725182334274.png" alt="image-20230725182334274" style="zoom:50%;"><p> </p><h2 id="3-电源转换电路">3.电源转换电路</h2><p>在库中，选择器件进行原理图绘制，同时在绘制原理图时要注意对应的封装。</p><p>寻找元器件不仅可以通过==元器件的名称==去找，还可以通过==供应商编号==去找。</p><img src="/posts/9c8613dc.htm/image-20230725184044652.png" alt="image-20230725184044652" style="zoom:50%;"><p>并且通过折线和文本进行模块化的标注。</p><h2 id="4-查找元器件">4.查找元器件</h2><p>当供应商编号查找不到元器件时，假如是0.1uf的电容，我们可以在立创商城中找到响应的替代品，复制其的器件型号，在专业版的库中进行查找。</p><p> </p><h2 id="5-更改网络标签">5.更改网络标签</h2><p>点击网络标签出现预览按钮以后按住tab键即可</p><p> </p><h2 id="原理图转pcb">原理图转pcb</h2><h3 id="1-设置板框">1.设置板框</h3><p>放置–&gt;板框–&gt;矩形</p><img src="/posts/9c8613dc.htm/image-20230725203709836.png" alt="image-20230725203709836" style="zoom:50%;"><p>当然我们也可用通过右侧的矩形轮廓，修改板框的大小。</p><p>单击板框右键–&gt;添加–&gt;添加圆角，即可设置板框为圆角</p><p> </p><h3 id="2-规则设置">2.规则设置</h3><p>设计–&gt;设计规则–&gt;导线设置为8mil–&gt;全部设置为8mil</p><p>设置导线，最小，默认，最大分别为10，10，30</p><img src="/posts/9c8613dc.htm/image-20230725205824273.png" alt="image-20230725205824273" style="zoom:50%;"><p>添加一个导线规则，最小，默认，最大分别设为10，30，30</p><img src="/posts/9c8613dc.htm/image-20230725210044705.png" alt="image-20230725210044705" style="zoom:50%;"><p>过孔尺寸按如下设置即可</p><img src="/posts/9c8613dc.htm/image-20230725210222093.png" alt="image-20230725210222093" style="zoom:50%;"><p>铺铜规则—&gt;网络间隔和到边框均改为20</p><img src="/posts/9c8613dc.htm/image-20230725211405979.png" alt="image-20230725211405979" style="zoom:50%;"><p>之后，在网络规则中进行设置</p><p> </p><h3 id="3-绘制定位孔">3.绘制定位孔</h3><p><code>放置</code>——&gt;<code>挖槽区域</code>——&gt;<code>圆孔</code></p><img src="/posts/9c8613dc.htm/image-20230811190718746.png" alt="image-20230811190718746" style="zoom:50%;"><p>在右侧可以设置相关参数</p><img src="/posts/9c8613dc.htm/image-20230811190950371.png" alt="image-20230811190950371" style="zoom:50%;"><p> </p><p> </p><h3 id="4-绘制OLED模块定位孔">4.绘制OLED模块定位孔</h3><h4 id="丝印边框">丝印边框</h4><img src="/posts/9c8613dc.htm/image-20230811191917326.png" alt="image-20230811191917326" style="zoom:67%;"><p>1.选择顶层丝印层–&gt;2.网格类型选用正方形–&gt;3.选择为矩形</p><p> </p><h3 id="5-布局">5.布局</h3><p>在原理图中选择<code>对应元器件</code>—&gt;<code>设计</code>–&gt;<code>布局传递</code></p><p>这样回到pcb图就会自动选择相关元器件</p><img src="/posts/9c8613dc.htm/image-20230811192421560.png" alt="image-20230811192421560" style="zoom:67%;"><p>ps：丝印放置规则，横着为从左到右，竖着为从上到下</p><p> </p><p> </p><h3 id="6-布线">6.布线</h3><p>常用<code>焊盘</code>，<code>过孔</code>,<code>单路布线</code></p><p> </p><p> </p><h3 id="7-修改位号丝印大小">7.修改位号丝印大小</h3><p>右键丝印点击查找</p><img src="/posts/9c8613dc.htm/image-20230811201254714.png" alt="image-20230811201254714" style="zoom:50%;"><p>查找—&gt;查找全部–&gt;线宽8mil–&gt;线高70mil</p><p> </p><h3 id="8-添加丝印">8.添加丝印</h3><img src="/posts/9c8613dc.htm/image-20230811201619036.png" alt="image-20230811201619036" style="zoom:67%;"><img src="/posts/9c8613dc.htm/image-20230811201740095.png" alt="image-20230811201740095" style="zoom:67%;"><p> </p><p> </p><h3 id="9-泪滴">9.泪滴</h3><img src="/posts/9c8613dc.htm/image-20230811201848466.png" alt="image-20230811201848466" style="zoom:67%;"><p> </p><h3 id="10-铺铜">10.铺铜</h3><p>点击选择矩形</p><img src="/posts/9c8613dc.htm/image-20230811202050096.png" alt="image-20230811202050096" style="zoom:67%;"><p>网络选择GND</p><p>图层顶层和底层分别进行铺铜，如果顶层有大面积没有铺铜，在此区域添加过孔然后继续铺铜。</p>]]></content>
      
      
      
        <tags>
            
            <tag> eda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210与esp32串口通信</title>
      <link href="/posts/bfa0354e.html"/>
      <url>/posts/bfa0354e.html</url>
      
        <content type="html"><![CDATA[<h1>k210与esp32串口通信</h1><h3 id="构造函数">构造函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fm.register(pin,function,force=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>【pin】芯片外部 IO，<strong>外部I对应上图K210的IO而非Maxiduino</strong></p><p>【function】芯片功能</p><p>【force】=True 则强制注册，清除之前的注册记录；</p><p>例：fm.register(12, fm.fpioa.GPIO0,force=True)</p><p>表示将外部 IO12 注册到内部 GPIO0</p><p> </p><h2 id="maxiduino与电脑串口进行通信">maxiduino与电脑串口进行通信</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> UART,Timer</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="comment">#映射串口引脚</span></span><br><span class="line">fm.register(<span class="number">11</span>, fm.fpioa.UART1_RX, force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">10</span>, fm.fpioa.UART1_TX, force=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#初始化串口</span></span><br><span class="line">uart = UART(UART.UART1, <span class="number">115200</span>, read_buf_len=<span class="number">4096</span>)</span><br><span class="line">uart.write(<span class="string">&#x27;Hello word!&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> text=uart.read() <span class="comment">#读取数据</span></span><br><span class="line"> <span class="keyword">if</span> text: <span class="comment">#如果读取到了数据</span></span><br><span class="line">  <span class="built_in">print</span>(text.decode(<span class="string">&#x27;utf-8&#x27;</span>)) <span class="comment">#REPL 打印</span></span><br><span class="line">  uart.write(<span class="string">&#x27;I got&#x27;</span>+text.decode(<span class="string">&#x27;utf-8&#x27;</span>)) <span class="comment">#数据回传</span></span><br></pre></td></tr></table></figure><p> </p><h2 id="esp32-s3与电脑串口进行通信">esp32_s3与电脑串口进行通信</h2><h3 id="相关资料">相关资料</h3><p><a href="https://blog.csdn.net/Naisu_kun/article/details/86004049">(8条消息) 使用Arduino开发ESP32（02）：串口（Serial port）使用说明_arduino esp32 serial_Naisu Xu的博客-CSDN博客</a></p><p><a href="https://blog.csdn.net/m0_50064262/article/details/119006749">(8条消息) ESP32 之 ESP-IDF 教学（九）—— 串口通信（UART）_esp32 idf 串口_Augtons正(单片机)的博客-CSDN博客</a></p><p><a href="https://www.bilibili.com/video/BV1A3411Z7gd/?spm_id_from=333.880.my_history.page.click&amp;vd_source=db4533a45f532ba6c1133faafbf7f171">40 ESP32之UART串口简介 - 基于Arduino_哔哩哔哩_bilibili</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32_s3多任务处理</title>
      <link href="/posts/a1417d5c.html"/>
      <url>/posts/a1417d5c.html</url>
      
        <content type="html"><![CDATA[<h1>esp32_S3多任务处理</h1><h2 id="多任务介绍">多任务介绍</h2><ul><li>多任务的概念：同一时间内执行多个任务，它充分利用CPU资源，提高程序的执行效率。</li><li>对于单核CPU处理多任务，操作系统会给每个运行的任务一小段运行的时间，时间一到，然后立马切换任务，由于交替切换的速度过快，以人的眼光去看感觉每个程序都是同时执行的错觉。</li><li>相对于多核CPU，操作系统会给每个内核安排一个执行的软件同时运行，从而达到同一个时间内执行多任务的效果。</li><li>ESP32的任务和操作系统的进程的概念是一样的</li></ul><ul><li>ESP32有两颗CPU，包含ProtocolcPU（称为CPUO或PRO_CPU）和ApplicationcPu（称为CPU1或APP_CPU）。这两个核实际上是相同的，并且共享相同的内存</li><li>我们之前用的setup和loop方法都是在CPU1上执行的CPUO一直不干活，我们要使用多任务让它动起来。</li><li>保证所有的任务都以合理正确的速率推进，不被其它任务所阻塞。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void1oop（）&#123;</span><br><span class="line">task1（）<span class="comment">//这个需要较长的操作，比如59oms</span></span><br><span class="line">task2（）；<span class="comment">//这个需要50ms执行一次</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有如上代码，任务一的时间较长，但任务二时间较短，就会有一定冲突。此时就适合双线程来完成任务。</p><h3 id="时间片轮转调度">时间片轮转调度</h3><p>参考：<a href="https://blog.csdn.net/a568713197/article/details/81542772">(8条消息) UCOS学习笔记（四）时间片轮转调度_ucosii时间片轮转调度_爱吃肉的大高个的博客-CSDN博客</a></p><h3 id="多任务处理相关函数">多任务处理相关函数</h3><h4 id="头文件">头文件</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;freertos/FreeRTOS.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;freertos/task.h&quot;</span></span></span><br></pre></td></tr></table></figure><h4 id="创建任务">创建任务</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BaseType_t <span class="title function_">tXTaskCreatePinnedToCore</span><span class="params">(TaskFunctiont_t pvTaskcode,</span></span><br><span class="line"><span class="params"><span class="type">const</span> <span class="type">char</span> * <span class="type">const</span> pcName,<span class="type">const</span> <span class="type">uint32_t</span> usstackDepth,</span></span><br><span class="line"><span class="params"><span class="type">void</span>* <span class="type">const</span> pvParameters,UBaseType_t uxPriority,TaskHandle_t <span class="type">const</span> pvCreatedTask,<span class="type">const</span> BaseType_t xCoreID)</span>；</span><br></pre></td></tr></table></figure><ul><li>pvTaskCode：指向任务输入函数的指针。任务必须被实现为永不Return（如：死循环），或者应该使用</li><li>vtTaskDelete:函数终止</li><li>pcName：该任务的描述性名称，最大长度16字节</li><li>usStackDepth：指定为字节数的任务堆栈的大小</li><li>pvParameters：将用作所创建的任务的参数的指针，在创建任务的时候可以向任务传递参数。</li><li>uxPriority：任务运行的优先级。目前ESP32的优先级有25级，0-24，数字越大优先级越高，Idle为0，loop任务的优先级是1</li><li>pvCreatedTask：用于传递回所创建任务的句柄</li><li>xCoreID：如果值为tskNOAFFINITY，则创建的任务不会固定到任何CPU，调度程序可以在任何可用的核心上运行。值0或1表示任务应固定到的CPU的索引编号。指定大于（portNUMPROCESSORS-1）的值将导致函数失败</li><li>函数成功返回pdPASS，其它值都是失败。</li></ul><h4 id="任务函数原型">任务函数原型</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> task（<span class="type">void</span>* param）;</span><br></pre></td></tr></table></figure><h4 id="获取任务的优先级">获取任务的优先级</h4><p>如果在任务函数里获取本任务的优先级可以使用uxTaskPriorityGet（NULL）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UBaseType_t <span class="title function_">uxTaskPriorityGet</span><span class="params">(<span class="type">const</span> TaskHandle_t xTask)</span>;</span><br></pre></td></tr></table></figure><h4 id="获取本任务在哪个CPU上运行">获取本任务在哪个CPU上运行</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BaseType_t IRAM_ATTR <span class="title function_">xPortGetcoreID</span><span class="params">(<span class="type">void</span>)</span>;</span><br></pre></td></tr></table></figure><h4 id="删除任务">删除任务</h4><p>如果在任务函数体内使用vTaskDelete（NULL）来结束本任务</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">vTaskDelete</span><span class="params">(TaskHandle_t xTaskToDelete)</span></span><br></pre></td></tr></table></figure><p> </p><p> </p><h3 id="互斤量（xSemaphoreHandle）">互斤量（xSemaphoreHandle）</h3><p>互压量又称互床信号量（本质是信号量），是一种特殊的二值信号量，它用于实现对临界资源的独占式处理（它不会屏蔽CPU的中断处理）任意时刻互压量的状态只有两种，开锁或闭锁。当互斤量被任务持有时，该互压量处于闭锁状态，这个任务获得互压量的所有权。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xSemaphoreHandle<span class="comment">//互斤锁，也算是一种信号量</span></span><br></pre></td></tr></table></figure><p>创建一个互斤锁</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xSemaphoreHandle xMutex = xSemaphoreCreateMutex()</span><br></pre></td></tr></table></figure><p>获取互斤锁</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xSemaphoreTake (xSemaphore,xBlockTime)</span><br></pre></td></tr></table></figure><p>功能：在普通任务中获取信号量<br>参数：xSemaphore信号量句柄<br>xBlockTime等待的节拍数，立即返回，portMAX_DELAY等待到信号到来<br>ESP32默认的一节拍是1ms<br>返回值：pdTRUE：获取成功1pdFALSE：获取失败</p><p>释放互压锁</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xSemaphoreGive（xSemaphore）</span><br></pre></td></tr></table></figure><p>功能：在普通任务中释放信号量，也就是将信号量设为有信号的状态返回值：pdTRUE：设置成功 ，pdFALSE：设置失败</p><p> </p><p>使用方法</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if (xSemaphoreTake(xMutex,portMAX_DELAY))</span><br><span class="line">//临界资源处理</span><br><span class="line">xSemaphoreGive(xMutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="综合例子">综合例子</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FreeRTOSConfig.h&gt;</span></span></span><br><span class="line">xSemaphoreHandle xMutex; <span class="comment">//互斥量</span></span><br><span class="line"><span class="type">int</span> number = <span class="number">0</span>;          <span class="comment">//互斥资源</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">task1</span><span class="params">(<span class="type">void</span>* param)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">static</span> <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">  <span class="type">int</span> p = *((<span class="type">int</span>*)param);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span>(count++ &lt; <span class="number">200</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> core = xPortGetCoreID();  <span class="comment">//获取当前核</span></span><br><span class="line">    Serial.<span class="built_in">printf</span>(<span class="string">&quot;Core %d -&gt; &quot;</span>, core);</span><br><span class="line">    Serial.print(<span class="string">&quot;I am task1, Param: &quot;</span>);</span><br><span class="line">    Serial.print(p);</span><br><span class="line">    <span class="keyword">if</span>(xSemaphoreTake(xMutex, portMAX_DELAY))</span><br><span class="line">    &#123;</span><br><span class="line">      Serial.<span class="built_in">printf</span>(<span class="string">&quot; number: %d&quot;</span>, number);</span><br><span class="line">      xSemaphoreGive(xMutex);</span><br><span class="line">    &#125;</span><br><span class="line">    Serial.println();</span><br><span class="line">    delay(<span class="number">2000</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  vTaskDelete(<span class="literal">NULL</span>);  <span class="comment">//结束任务</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">task2</span><span class="params">(<span class="type">void</span>* param)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">static</span> <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span>(count++ &lt; <span class="number">200</span>)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="type">int</span> core = xPortGetCoreID();  <span class="comment">//获取当前核</span></span><br><span class="line">    Serial.<span class="built_in">printf</span>(<span class="string">&quot;Core %d -&gt; &quot;</span>, core);</span><br><span class="line">    Serial.println(<span class="string">&quot;I am task2&quot;</span>);</span><br><span class="line">    <span class="keyword">if</span>(xSemaphoreTake(xMutex, portMAX_DELAY))</span><br><span class="line">    &#123;</span><br><span class="line">      number++;</span><br><span class="line">      xSemaphoreGive(xMutex);</span><br><span class="line">    &#125;</span><br><span class="line">    delay(<span class="number">2000</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  vTaskDelete(<span class="literal">NULL</span>);  <span class="comment">//结束任务</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">115200</span>);</span><br><span class="line">  </span><br><span class="line">  TaskHandle_t handle1;</span><br><span class="line">  <span class="type">int</span> param = <span class="number">30</span>;</span><br><span class="line">  xMutex = xSemaphoreCreateMutex();</span><br><span class="line">  xTaskCreatePinnedToCore(task1, <span class="string">&quot;task1&quot;</span>, <span class="number">2048</span>, (<span class="type">void</span>*)&amp;param, <span class="number">15</span>, &amp;handle1, <span class="number">0</span>);</span><br><span class="line">  xTaskCreatePinnedToCore(task2, <span class="string">&quot;task2&quot;</span>, <span class="number">2048</span>, <span class="literal">NULL</span>, <span class="number">15</span>, <span class="literal">NULL</span>, <span class="number">1</span>);  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="type">int</span> core = xPortGetCoreID();  <span class="comment">//获取当前核</span></span><br><span class="line">  Serial.<span class="built_in">printf</span>(<span class="string">&quot;Core %d -&gt; I am loop &quot;</span>, core);</span><br><span class="line">  <span class="keyword">auto</span> pri = uxTaskPriorityGet(<span class="literal">NULL</span>);</span><br><span class="line">  Serial.<span class="built_in">printf</span>(<span class="string">&quot; priority: %d&quot;</span>, pri);</span><br><span class="line">  Serial.println();</span><br><span class="line">  delay(<span class="number">2000</span>);</span><br><span class="line">  <span class="comment">//一个任务的delay不会影响到其它任务的运行</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="使用方法">使用方法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (xSemaphoreTake(xMutex, portMAX_DELAY))&#123; </span><br><span class="line"><span class="comment">//临界资源处理</span></span><br><span class="line">xSemaphoreGive（xMutex）；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="多并行任务创建">多并行任务创建</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> CONFIG_FREERTOS_UNICORE</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ARDUINO_RUNNING_CORE 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ARDUINO_RUNNING_CORE 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">FreeRTOS任务优先级：任务优先级数值越小，任务优先级越低。</span></span><br><span class="line"><span class="comment">一、 FreeRTOS 中任务的最高优先级是通过 FreeRTOSConfig.h 文件中的 configMAX_PRIORITIES 进行</span></span><br><span class="line"><span class="comment">配置的，用户实际可以使用的优先级范围是 0 到 configMAX_PRIORITIES – 1。比如我们配置此宏定</span></span><br><span class="line"><span class="comment">义为 5，那么用户可以使用的优先级号是 0,1,2,3,4，不包含 5。</span></span><br><span class="line"><span class="comment">二、用户配置任务的优先级数值越小，那么此任务的优先级越低，空闲任务的优先级是 0。</span></span><br><span class="line"><span class="comment">三、用户配置宏定义 configMAX_PRIORITIES 的最大值不要超过 32，即用户任务可以使用的优先级</span></span><br><span class="line"><span class="comment">范围是0到31</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="comment">// define two tasks for Blink &amp; AnalogRead</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">TaskBlink</span><span class="params">( <span class="type">void</span> *pvParameters )</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">TaskAnalogReadA3</span><span class="params">( <span class="type">void</span> *pvParameters )</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the setup function runs once when you press reset or power the board</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// initialize serial communication at 115200 bits per second:</span></span><br><span class="line">  USBSerial.begin(<span class="number">115200</span>); </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Now set up two tasks to run independently.</span></span><br><span class="line">  xTaskCreatePinnedToCore(</span><br><span class="line">    TaskBlink</span><br><span class="line">    ,  <span class="string">&quot;TaskBlink&quot;</span>   <span class="comment">// A name just for humans</span></span><br><span class="line">    ,  <span class="number">1024</span>  <span class="comment">// This stack size can be checked &amp; adjusted by reading the Stack Highwater</span></span><br><span class="line">    ,  <span class="literal">NULL</span></span><br><span class="line">    ,  <span class="number">2</span>  <span class="comment">// Priority, with 3 (configMAX_PRIORITIES - 1) being the highest, and 0 being the lowest.</span></span><br><span class="line">    ,  <span class="literal">NULL</span> </span><br><span class="line">    ,  ARDUINO_RUNNING_CORE);</span><br><span class="line"></span><br><span class="line">  xTaskCreatePinnedToCore(</span><br><span class="line">    TaskAnalogReadA3</span><br><span class="line">    ,  <span class="string">&quot;AnalogReadA3&quot;</span></span><br><span class="line">    ,  <span class="number">1024</span>  <span class="comment">// Stack size</span></span><br><span class="line">    ,  <span class="literal">NULL</span></span><br><span class="line">    ,  <span class="number">1</span>  <span class="comment">// Priority</span></span><br><span class="line">    ,  <span class="literal">NULL</span> </span><br><span class="line">    ,  ARDUINO_RUNNING_CORE);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Now the task scheduler, which takes over control of scheduling individual tasks, is automatically started.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// Empty. Things are done in Tasks.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*--------------------------------------------------*/</span></span><br><span class="line"><span class="comment">/*---------------------- Tasks ---------------------*/</span></span><br><span class="line"><span class="comment">/*--------------------------------------------------*/</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TaskBlink</span><span class="params">(<span class="type">void</span> *pvParameters)</span>  <span class="comment">// This is a task.</span></span><br><span class="line">&#123;</span><br><span class="line">  (<span class="type">void</span>) pvParameters;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  Blink</span></span><br><span class="line"><span class="comment">  Turns on an LED on for one second, then off for one second, repeatedly.</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">  If you want to know what pin the on-board LED is connected to on your ESP32 model, check</span></span><br><span class="line"><span class="comment">  the Technical Specs of your board.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// initialize digital LED_BUILTIN on pin 13 as an output.</span></span><br><span class="line">  pinMode(<span class="number">45</span>, OUTPUT);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (;;) <span class="comment">// A Task shall never return or exit.</span></span><br><span class="line">  &#123;</span><br><span class="line">    digitalWrite(<span class="number">45</span>, HIGH);   <span class="comment">// turn the LED on (HIGH is the voltage level)</span></span><br><span class="line">    vTaskDelay(<span class="number">100</span>);  <span class="comment">// one tick delay (15ms) in between reads for stability</span></span><br><span class="line">    digitalWrite(<span class="number">45</span>, LOW);    <span class="comment">// turn the LED off by making the voltage LOW</span></span><br><span class="line">    vTaskDelay(<span class="number">100</span>);  <span class="comment">// one tick delay (15ms) in between reads for stability</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">TaskAnalogReadA3</span><span class="params">(<span class="type">void</span> *pvParameters)</span>  <span class="comment">// This is a task.</span></span><br><span class="line">&#123;</span><br><span class="line">  (<span class="type">void</span>) pvParameters;</span><br><span class="line">  </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">  AnalogReadSerial</span></span><br><span class="line"><span class="comment">  Reads an analog input on pin A3, prints the result to the serial monitor.</span></span><br><span class="line"><span class="comment">  Graphical representation is available using serial plotter (Tools &gt; Serial Plotter menu)</span></span><br><span class="line"><span class="comment">  Attach the center pin of a potentiometer to pin A3, and the outside pins to +5V and ground.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  This example code is in the public domain.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (;;)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// read the input on analog pin A3:</span></span><br><span class="line">    <span class="type">int</span> sensorValueA3 = analogRead(A3);</span><br><span class="line">    <span class="comment">// print out the value you read:</span></span><br><span class="line">    USBSerial.print(<span class="string">&quot;A3-&gt;&quot;</span>);</span><br><span class="line">    USBSerial.println(sensorValueA3);</span><br><span class="line">    vTaskDelay(<span class="number">100</span>);  <span class="comment">// one tick delay (15ms) in between reads for stability</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="基于多核并行任务创建">基于多核并行任务创建</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">//  多线程基于FreeRTOS，可以多个任务并行处理；</span></span><br><span class="line"><span class="comment">//  ESP32具有两个32位Tensilica Xtensa LX6微处理器；</span></span><br><span class="line"><span class="comment">//  实际上我们用Arduino进行编程时只使用到了第一个核（大核），第0核并没有使用</span></span><br><span class="line"><span class="comment">//  多线程可以指定在那个核运行；</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Arduino.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> USE_MULTCORE 1</span></span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">xTaskOne</span><span class="params">(<span class="type">void</span> *xTask1)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        USBSerial.<span class="built_in">printf</span>(<span class="string">&quot;Task1 \r\n&quot;</span>);</span><br><span class="line">        delay(<span class="number">500</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">xTaskTwo</span><span class="params">(<span class="type">void</span> *xTask2)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        USBSerial.<span class="built_in">printf</span>(<span class="string">&quot;Task2 \r\n&quot;</span>);</span><br><span class="line">        delay(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    USBSerial.begin(<span class="number">115200</span>);</span><br><span class="line">    delay(<span class="number">10</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> !USE_MULTCORE</span></span><br><span class="line"></span><br><span class="line">    xTaskCreate(</span><br><span class="line">        xTaskOne,  <span class="comment">/* Task function. */</span></span><br><span class="line">        <span class="string">&quot;TaskOne&quot;</span>, <span class="comment">/* String with name of task. */</span></span><br><span class="line">        <span class="number">4096</span>,      <span class="comment">/* Stack size in bytes. */</span></span><br><span class="line">        <span class="literal">NULL</span>,      <span class="comment">/* Parameter passed as input of the task */</span></span><br><span class="line">        <span class="number">1</span>,         <span class="comment">/* Priority of the task.(configMAX_PRIORITIES - 1 being the highest, and 0 being the lowest.) */</span></span><br><span class="line">        <span class="literal">NULL</span>);     <span class="comment">/* Task handle. */</span></span><br><span class="line"></span><br><span class="line">    xTaskCreate(</span><br><span class="line">        xTaskTwo,  <span class="comment">/* Task function. */</span></span><br><span class="line">        <span class="string">&quot;TaskTwo&quot;</span>, <span class="comment">/* String with name of task. */</span></span><br><span class="line">        <span class="number">4096</span>,      <span class="comment">/* Stack size in bytes. */</span></span><br><span class="line">        <span class="literal">NULL</span>,      <span class="comment">/* Parameter passed as input of the task */</span></span><br><span class="line">        <span class="number">2</span>,         <span class="comment">/* Priority of the task.(configMAX_PRIORITIES - 1 being the highest, and 0 being the lowest.) */</span></span><br><span class="line">        <span class="literal">NULL</span>);     <span class="comment">/* Task handle. */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//最后一个参数至关重要，决定这个任务创建在哪个核上.PRO_CPU 为 0, APP_CPU 为 1,或者 tskNO_AFFINITY 允许任务在两者上运行.</span></span><br><span class="line">    xTaskCreatePinnedToCore(xTaskOne, <span class="string">&quot;TaskOne&quot;</span>, <span class="number">4096</span>, <span class="literal">NULL</span>, <span class="number">1</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">    xTaskCreatePinnedToCore(xTaskTwo, <span class="string">&quot;TaskTwo&quot;</span>, <span class="number">4096</span>, <span class="literal">NULL</span>, <span class="number">2</span>, <span class="literal">NULL</span>, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        Serial.<span class="built_in">printf</span>(<span class="string">&quot;XTask is running\r\n&quot;</span>);</span><br><span class="line">        delay(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32开发环境搭建（arduino）</title>
      <link href="/posts/ec4b5731.html"/>
      <url>/posts/ec4b5731.html</url>
      
        <content type="html"><![CDATA[<h1>esp32开发环境搭建（arduino）</h1><h2 id="首先下载arduino-IDE最新版">首先下载arduino IDE最新版</h2><p>网址：<a href="https://www.arduino.cc/en/software">Software | Arduino</a></p><img src="https://i.imgtg.com/2023/07/05/Oxe1Rb.png" alt="Oxe1Rb.png" border="0"><p>点击windows win10</p><img src="https://i.imgtg.com/2023/07/05/Oxehu6.png" alt="Oxehu6.png" border="0"><p>点击just download</p><p>此时即可下载到电脑。</p><h3 id="方法二（github）">方法二（github）</h3><p>打开网址<a href="https://github.com/arduino/arduino-ide">arduino/arduino-ide: Arduino IDE 2.x (github.com)</a></p><p>点击code<img src="/posts/ec4b5731.htm/OxenFP.png" alt="OxenFP.png" border="0"></p><p>点击Download ZIP下载压缩包，下载完压缩即可。</p><p><a href="https://imgtg.com/image/Oxe79l"><img src="/posts/ec4b5731.htm/Oxe79l.png" alt="Oxe79l.png" border="0"></a></p><p> </p><p> </p><h2 id="安装esp32开发环境">安装esp32开发环境</h2><p>你需要向 Arduino IDE 板管理器添加一个额外的源，然后安装 ESP32。</p><p>打开<code>文件</code> 菜单下的 <code>首选项</code>。</p><img src="https://i.imgtg.com/2023/07/05/OxeFEF.png" alt="OxeFEF.png" border="0"><p>把下面的链接复制粘贴到 <code>附加开发板管理网址</code> 中：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://raw.githubusercontent.com/espressif/arduino-esp32/gh-pages/package_esp32_index.json</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2023/07/05/OxeeUg.png" alt="OxeeUg.png" border="0"><p>再安装 ESP32 开发板，选择 <code>工具</code> 菜单中的 <code>开发板</code> -&gt; <code>开发板管理器...</code></p><img src="https://i.imgtg.com/2023/07/05/OxeryB.png" alt="OxeryB.png" border="0"><p>在搜索栏搜索esp32，点击安装即可</p><img src="https://i.imgtg.com/2023/07/05/OxeAds.png" alt="OxeAds.png" border="0"><p>完成安装后即可在 工具—&gt;开发板中发现esp32</p><img src="https://i.imgtg.com/2023/07/05/OxeZaK.png" alt="OxeZaK.png" border="0"><p> </p><h2 id="下载驱动">下载驱动</h2><p>如果在连接esp32后没有反应则需要下载驱动</p><p>链接：<a href="https://pan.baidu.com/s/1IJa40kU_MtdsdDK8BgEnHg?pwd=m1bc">https://pan.baidu.com/s/1IJa40kU_MtdsdDK8BgEnHg?pwd=m1bc</a><br>提取码：m1bc</p><p>下在完可以在<strong>设备管理器</strong>中查看到设备</p><img src="https://i.imgtg.com/2023/07/05/Oxevea.png" alt="Oxevea.png" border="0">]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32WIFI</title>
      <link href="/posts/e7f7981b.html"/>
      <url>/posts/e7f7981b.html</url>
      
        <content type="html"><![CDATA[<h1><strong>WiFi</strong> <strong>应用</strong></h1><p>通过前面的实验，我们已经对 ESP32-S2 有了一定的了解。从本章开始，将迎来非常重要实用的内容，那就是 WIFI 应用。ESP32-S2 就是为 WIFI 无线连接而生的。通过本章内容，我们可以看到基于 MicroPython 的 WIFI 开发是多么的简单而美妙。物联网的学习变得非常简单有趣！事不宜迟，马上开始学习。</p><h2 id="连接无线路由器"><strong>连接无线路由器</strong></h2><p>⚫ <strong>前言：</strong></p><p>WIFI 是物联网中非常重要的角色，现在基本上家家户户都有 WIFI 网络了，通过 WIFI 接入到互联网，成了智能家居产品普遍的选择。而要想上网，首先需要连接上无线路由器。这一节我们就来学习如何通过 MicroPython 编程连上路由器。</p><p>⚫ <strong>实验目的：</strong></p><p>编程实现连接路由器，将 IP 地址等相关信息通过 OLED 显示（只支持 2.4G网络）。</p><p>⚫ <strong>实验讲解：</strong></p><p>连接路由器上网是我们每天都做的事情，日常生活中我们只需要知道路由器的账号和密码，就能使用电脑或者手机连接到无线路由器，然后上网冲浪。</p><p>MicroPython 已经集成了 network 模块，开发者使用内置的 network 模块函数可以非常方便地连接上路由器。但往往也有各种连接失败的情况，如密码不正确等。这时候我们只需要再加上一些简单的判断机制，避免陷入连接失败的死循环即可！</p><p>我们先来看看 network 基于 WiFi（WLAN 模块）的构造函数和使用方法。</p><p> </p><p><strong>构造函数</strong></p><p>wlan = network.WLAN(interface_id)</p><p>构建 WIFI 连接对象。interface_id:分为热点 network.AP_IF 和客户端</p><p>network.STA_IF 模式。</p><p><strong>使用方法</strong></p><p>wlan.active([is_active])</p><p>激活 wlan 接口。Ture：激活；False:关闭。</p><p>wlan.scan ()</p><p>扫描允许访问的 SSID。</p><p>wlan.isconnected()</p><p>检查设备是否已经连接上。返回 Ture:已连接；False：未连接。</p><p>wlan.connected(ssid,passwork)</p><p>WIFI 连接。ssid:账号；passwork：密码。</p><p>wlan.ifconfig([ip,subnet,gateway,dns])</p><p>设备信息配置。ip：IP 地址；subnet:子网掩码；gateway:网关地址；dns:DNS</p><p>信息。<strong>（如果参数为空，则返回当前连接信息。）</strong></p><p>wlan.disconnected()</p><p>断开连接。</p><p> </p><p>从上表可以看到 MicroPython 通过模块封装，让 WIFI 联网变得非常简单。模块包含热点 AP 模块和客户端 STA 模式，热点 AP 是指电脑端直接连接 ESP32-S2发出的热点实现连接，但这样你的电脑就不能上网了，因此我们一般情况下都是使用 STA 模式。也就是电脑和设备同时连接到相同网段的路由器上。模块上电后可以先判断是否已经连接到网络，如果是则无需再次连接，否的话则进入 WIFI 连接状态，指示灯闪烁，连接成功后指示灯常亮，IP 等相关信息通过 OLED 显示和串口打印。另外需要配置超时 15 秒还没连接成功时执行取消连接，避免因无法连接而陷入死循环。代码编写流程如下：</p><img src="/posts/e7f7981b.htm/image-20230702142321217.png" alt="image-20230702142321217" style="zoom:80%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：连接无线路由器</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2021.8</span></span><br><span class="line"><span class="string">作者：01Studio</span></span><br><span class="line"><span class="string">说明：编程实现连接路由器，将IP地址等相关信息通过OLED显示（只支持2.4G网络）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> network,time</span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> SoftI2C,Pin</span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化相关模块</span></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>))</span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#WIFI连接函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">WIFI_Connect</span>():</span><br><span class="line"></span><br><span class="line">    WIFI_LED=Pin(<span class="number">2</span>, Pin.OUT) <span class="comment">#初始化WIFI指示灯</span></span><br><span class="line"></span><br><span class="line">    wlan = network.WLAN(network.STA_IF) <span class="comment">#STA模式</span></span><br><span class="line">    wlan.active(<span class="literal">True</span>)                   <span class="comment">#激活接口</span></span><br><span class="line">    start_time=time.time()              <span class="comment">#记录时间做超时判断</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> wlan.isconnected():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;connecting to network...&#x27;</span>)</span><br><span class="line">        wlan.connect(<span class="string">&#x27;01Studio&#x27;</span>, <span class="string">&#x27;88888888&#x27;</span>) <span class="comment">#输入WIFI账号密码</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> wlan.isconnected():</span><br><span class="line"></span><br><span class="line">            <span class="comment">#LED闪烁提示</span></span><br><span class="line">            WIFI_LED.value(<span class="number">1</span>)</span><br><span class="line">            time.sleep_ms(<span class="number">300</span>)</span><br><span class="line">            WIFI_LED.value(<span class="number">0</span>)</span><br><span class="line">            time.sleep_ms(<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#超时判断,15秒没连接成功判定为超时</span></span><br><span class="line">            <span class="keyword">if</span> time.time()-start_time &gt; <span class="number">15</span> :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;WIFI Connected Timeout!&#x27;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> wlan.isconnected():</span><br><span class="line">        <span class="comment">#LED点亮</span></span><br><span class="line">        WIFI_LED.value(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#串口打印信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;network information:&#x27;</span>, wlan.ifconfig())</span><br><span class="line"></span><br><span class="line">        <span class="comment">#OLED数据显示</span></span><br><span class="line">        oled.fill(<span class="number">0</span>)   <span class="comment">#清屏背景黑色</span></span><br><span class="line">        oled.text(<span class="string">&#x27;IP/Subnet/GW:&#x27;</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">0</span>], <span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">1</span>],<span class="number">0</span>,<span class="number">38</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">2</span>],<span class="number">0</span>,<span class="number">56</span>)</span><br><span class="line">        oled.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行WIFI连接函数</span></span><br><span class="line">WIFI_Connect()</span><br></pre></td></tr></table></figure><p>⚫ <strong>总结：</strong></p><p>本节是 WIFI 应用的基础，成功连接到无线路由器的实验后，后面就可以做socket 等相关网络通信的应用了。</p><p> </p><h2 id="Socket-通信"><strong>Socket</strong> <strong>通信</strong></h2><p>⚫ <strong>前言：</strong></p><p>上一节我们学习了如何通过 MicroPython 编程实现 pyWiFi-ESP32-S2 模块连接到无线路由器。这一节我们则来学习一下 Socket 通信实验。Socket 几乎是整个互联网通信的基础。</p><p>⚫ <strong>实验目的：</strong></p><p>通过 Socket 编程实现 pyWiFi-ESP32-S2 与电脑服务器助手建立连接，相互收发数据。</p><p>⚫ <strong>实验讲解：</strong></p><p>Socket 我们听得非常多了，但由于网络工程是一门系统工程，涉及的知识非常广，概念也很多，任何一个知识点都能找出一堆厚厚的的书，因此我们经常会混淆。在这里，我们尝试以最容易理解的方式来讲述 Socket，如果需要全面了解，可以自行查阅相关资料学习。</p><p>我们先来看看网络层级模型图，这是构成网络通信的基础：</p><p>我们看看 TCP/IP 模型的传输层和应用层，传输层比较熟悉的概念是 TCP 和UDP，UPD 协议基本就没有对 IP 层的数据进行任何的处理了。而 TCP 协议还加入了更加复杂的传输控制，比如滑动的数据发送窗口（Slice Window），以及接收确认和重发机制，以达到数据的可靠传送。应用层中网页常用的则是 HTTP。那么我们先来解析一下这 TCP 和 HTTP 两者的关系。我们知道网络通信是最基础是依赖于 IP 和端口的，HTTP 一般情况下默认使用端口 80。举个简单的例子：我们逛淘宝，浏览器会向淘宝网的网址（本质是IP）和端口发起请求，而淘宝网收到请求后响应，向我们手机返回相关网页数据信息，实现了网页交互的过程。而这里就会引出一个多人连接的问题，很多人访问淘宝网，实际上接收到网页信息后就断开连接，否则淘宝网的服务器是无法支撑这么多人长时间的连接的，哪怕能支持，也非常占资源。</p><p>也就是应用层的 HTTP 通过传输层进行数据通信时，TCP 会遇到同时为多个应用程序进程提供并发服务的问题。多个 TCP 连接或多个应用程序进程可能需要通过同一个 TCP 协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与 TCP／IP 协议交互提供了套接字(Socket)接口。应用层可以和传输层通过 Socket 接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。简单来说，Socket 抽象层介于传输层和应用层之间，跟 TCP/IP 并没有必然的联系。Socket 编程接口在设计的时候，就希望也能适应其他的网络协议。</p><p>套接字（socket）是通信的基石，是支持 TCP/IP 协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议（通常是 <strong>TCP</strong> <strong>或</strong> <strong>UDP</strong>），本地主机的 <strong>IP</strong> <strong>地址，本地进程的协议端****口，远地主机的</strong>IP** <strong>地址，远地进程的协议端口。</strong></p><p>所以，socket 的出现只是可以更方便的使用 TCP/IP 协议栈而已，简单理解就是其对 TCP/IP 进行了抽象，形成了几个最基本的函数接口。比如 create，listen，accept，connect，read 和 write 等等。以下是通讯流程：</p><img src="/posts/e7f7981b.htm/image-20230702143005669.png" alt="image-20230702143005669" style="zoom:70%;"><p>从上图可以看到，建了 Socket 通信需要一个服务器端和一个客户端，以本实验为例，pyWiFi-ESP32-S2 作为客户端，电脑使用网络调试助手作为服务器端，双方使用 TCP 协议传输。对于客户端，则需要知道电脑端的 IP 和端口即可建立连接。（端口可以自定义，范围在 0~65535，注意不占用常用的 80 等端口即可。）以上的内容，简单来说就是如果用户面向应用来说，那么 ESP32-S2 只需要知道<strong>通讯协议是</strong> <strong>TCP</strong> <strong>或</strong> <strong>UDP</strong>**、服务器的** <strong>IP</strong> <strong>和端口号</strong>这 3 个信息，即可向服务器发起连接和发送信息。就这么简单。</p><p>MicroPython 已经封装好相关模块 usocket,跟传统的 socket 大部分兼容，两者均可使用，本实验使用 usocket，对象如下介绍：</p><p><strong>构造函数</strong></p><p>s=usocket.socekt(af=AF_INET, type=SOCK_STREAM,proto=IPPROTO_TCP)</p><p>构建 usocket 对象。</p><p>af: AF_INET→IPV4，AF_INET6 → IPV6；</p><p>type: SCOK_STREAM→TCP，SOCK_DGRAM→UDP；</p><p>proto: IPPROTO_TCP→TCP 协议，IPPROTO_UDP→UDP 协议。</p><p>（如果要构建 TCP 连接，可以使用默认参数配置，即不输入任何参数。）</p><p><strong>使用方法</strong></p><p>addr=usocket.getaddrinfo(‘<a href="http://www.01studio.org">www.01studio.org</a>’, 80)[0][-1]</p><p>获取 Socket 通信格式地址。返回：(‘47.91.208.161’,80)</p><p>s.connect(address)</p><p>创建连接。address:地址格式为 IP+端口。例：(‘192.168.1.115’,10000)</p><p>s.send(bytes)</p><p>发送。bytes：发送内容格式为字节</p><p>s.recv(bufsize)</p><p>接收数据。bufsize：单次最大接收字节个数。</p><p>s.bind(address)</p><p>绑定，用于服务器角色</p><p>s.listen([backlog])</p><p>监听，用于服务器角色。backlog:允许连接个数，必须大于 0。</p><p>s.accept()</p><p>接受连接，用于服务器角色。</p><p> </p><p>本实验中 pyWiFi-ESP32-S2 属于客户端，因此只用到客户端的函数即可。实验代码编写流程如下：</p><img src="/posts/e7f7981b.htm/image-20230702143126631.png" alt="image-20230702143126631" style="zoom:80%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：连接无线路由器</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2021.8</span></span><br><span class="line"><span class="string">作者：01Studio</span></span><br><span class="line"><span class="string">说明：通过Socket编程实现pyWiFi-ESP32与电脑服务器助手建立TCP连接，相互收发数据。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导入相关模块</span></span><br><span class="line"><span class="keyword">import</span> network,usocket,time</span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> SoftI2C,Pin,Timer</span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化相关模块</span></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>))</span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#WIFI连接函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">WIFI_Connect</span>():</span><br><span class="line"></span><br><span class="line">    WIFI_LED=Pin(<span class="number">2</span>, Pin.OUT) <span class="comment">#初始化WIFI指示灯</span></span><br><span class="line"></span><br><span class="line">    wlan = network.WLAN(network.STA_IF) <span class="comment">#STA模式</span></span><br><span class="line">    wlan.active(<span class="literal">True</span>)                   <span class="comment">#激活接口</span></span><br><span class="line">    start_time=time.time()              <span class="comment">#记录时间做超时判断</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> wlan.isconnected():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Connecting to network...&#x27;</span>)</span><br><span class="line">        wlan.connect(<span class="string">&#x27;henu-student&#x27;</span>, <span class="string">&#x27;hbwz12138&#x27;</span>) <span class="comment">#输入WIFI账号密码</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> wlan.isconnected():</span><br><span class="line"></span><br><span class="line">            <span class="comment">#LED闪烁提示</span></span><br><span class="line">            WIFI_LED.value(<span class="number">1</span>)</span><br><span class="line">            time.sleep_ms(<span class="number">300</span>)</span><br><span class="line">            WIFI_LED.value(<span class="number">0</span>)</span><br><span class="line">            time.sleep_ms(<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#超时判断,15秒没连接成功判定为超时</span></span><br><span class="line">            <span class="keyword">if</span> time.time()-start_time &gt; <span class="number">15</span> :</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;WIFI Connected Timeout!&#x27;</span>)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> wlan.isconnected():</span><br><span class="line">        <span class="comment">#LED点亮</span></span><br><span class="line">        WIFI_LED.value(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#串口打印信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;network information:&#x27;</span>, wlan.ifconfig())</span><br><span class="line"></span><br><span class="line">        <span class="comment">#OLED数据显示</span></span><br><span class="line">        oled.fill(<span class="number">0</span>)   <span class="comment">#清屏背景黑色</span></span><br><span class="line">        oled.text(<span class="string">&#x27;IP/Subnet/GW:&#x27;</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">0</span>], <span class="number">0</span>, <span class="number">20</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">1</span>],<span class="number">0</span>,<span class="number">38</span>)</span><br><span class="line">        oled.text(wlan.ifconfig()[<span class="number">2</span>],<span class="number">0</span>,<span class="number">56</span>)</span><br><span class="line">        oled.show()</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#判断WIFI是否连接成功</span></span><br><span class="line"><span class="keyword">if</span> WIFI_Connect():</span><br><span class="line"></span><br><span class="line">    <span class="comment">#创建socket连接TCP类似，连接成功后发送“Hello 01Studio！”给服务器。</span></span><br><span class="line">    s=usocket.socket()</span><br><span class="line">    addr=(<span class="string">&#x27;192.168.1.115&#x27;</span>,<span class="number">10000</span>) <span class="comment">#服务器IP和端口</span></span><br><span class="line">    s.connect(addr)</span><br><span class="line">    s.send(<span class="string">&#x27;Hello 01Studio!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    </span><br><span class="line">    text=s.recv(<span class="number">128</span>) <span class="comment">#单次最多接收128字节</span></span><br><span class="line">    <span class="keyword">if</span> text == <span class="string">&#x27;&#x27;</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>: <span class="comment">#打印接收到的信息为字节，可以通过decode(&#x27;utf-8&#x27;)转成字符串</span></span><br><span class="line">        <span class="built_in">print</span>(text)</span><br><span class="line">        s.send(<span class="string">&#x27;I got:&#x27;</span>+text.decode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">    </span><br><span class="line">    time.sleep_ms(<span class="number">300</span>)</span><br></pre></td></tr></table></figure><p>WIFI 连接代码在上一节已经讲解，这里不再重复，WIFI 连接成功后返回 True，否则返回 False。程序在返回连接成功后建了 Socket 连接，连接成功发送‘Hello 01Studio!’信息到服务器。另外 RTOS 定时器设定了了每 300ms 处理从服务器接收到的数据。将接收到数据通过串口打印和发送给服务器。</p><p>⚫ <strong>实验结果：</strong></p><p>先在电脑端打开网络调试助手并建立服务器，软件在 零一科技（01Studio）MicroPython 开发套件配套资料_latest\01-开发工具\01-Windows\网络调试助手下的 NetAssist.exe ，直接双击打开即可！</p><img src="/posts/e7f7981b.htm/image-20230702143433653.png" alt="image-20230702143433653" style="zoom:67%;"><p>以下是新建服务器的方法，打开网络调试助手后在左上角协议类型选择 TCP Server；中间的本地 IP 地址是自动识别的，不要修改，这个就是服务器的 IP 地址。然后端口写 10000（0-65535 都可以。），点击连接，成功后红点亮。如下图：</p><img src="/posts/e7f7981b.htm/image-20230702143452690.png" alt="image-20230702143452690" style="zoom:80%;"><p>在时候服务器已经在监听状态！用户需要根据自己的实际情况自己输入 WIFI信息和服务器 IP 地址+端口。即修改上面的代码以下部分内容。（服务器 IP 和端口可以在网络调试助手找到。）</p><p>WiFi 网络信息：</p><p>wlan.connect(‘01Studio’, ‘88888888’) #输入 WIFI 账号密码</p><p>服务器信息：</p><p>addr=(‘192.168.1.115’,10000) #服务器 IP 和端口</p><p>下载程序，开发板成功连接 WIFI 后，发起了 socket 连接，连接成功可以可以看到网络调试助手收到了开发板发来的信息。在下方列表多了一个连接对象，点击选中</p><p>选中后我们在发送框输入信息“Hi”，点击发送，可以看到开发板的 REPL 打印出来信息 Hi。为字节数据。另外由于程序将收到的信息发回给服务器，所以在网络调试助手中也接收到开发板返回的信息：I got:Hi。</p><img src="/posts/e7f7981b.htm/image-20230702143554343.png" alt="image-20230702143554343" style="zoom:60%;"><img src="/posts/e7f7981b.htm/image-20230702143618314.png" alt="image-20230702143618314" style="zoom:80%;"><p>⚫ <strong>总结：</strong></p><p>通过本节学习，我们了解了socket通信原理以及使用MicroPython进行socket编程并且通信的实验。得益于优秀的封装，让我们可以直接面向 socket 对象编程就可以快速实现 socket 通信，从而开发更多的网络应用，例如将前面采集到的传感器数据发送到服务器。</p>]]></content>
      
      
      
        <tags>
            
            <tag> espe32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32传感器</title>
      <link href="/posts/30e8a1b9.html"/>
      <url>/posts/30e8a1b9.html</url>
      
        <content type="html"><![CDATA[<h1><strong>传感器实验</strong></h1><p>日常生活中我们会用到各式各样的外设或者传感器，还是那句，一个有经验的嵌入式开发工程师驱动一款未接触过的传感器的一般流程是：了解传感器原理、设计电路图、信号时序分析和编程。没个几天折腾不出来。生活中有很多传感器已经是非常通用了，前人已经做好封装函数模块，我们直接调用函数即可。我们不需要将时间花在“怎么用”上，而更多的是考虑“用到什么地方”！</p><h3 id="温度传感器-DS18B20"><strong>温度传感器</strong> <strong>DS18B20</strong></h3><p>⚫ <strong>前言：</strong></p><p>相信没有电子爱好者不知道 DS18B20 的，DS18B20 是常用的数字温度传感器，其输出的是数字信号，具有体积小，硬件开销低，抗干扰能力强，精度高的特点。DS18B20 数字温度传感器接线方便，封装成后可应用于多种场合，如管道式，螺纹式，磁铁吸附式，不锈钢封装式，型号多种多样。主要根据应用场合的不同而改变其外观。封装后的 DS18B20 可用于电缆沟测温，高炉水循环测温，锅炉测温，机房测温，农业大棚测温，洁净室测温，弹药库测温等各种非极限温度场合。耐磨耐碰，体积小，使用方便，封装形式多样，适用于各种狭小空间设备数字测温和控制领域。</p><p>⚫ <strong>实验目的：</strong></p><p>通过编程采集温度数据，并在 OLED 上显示。</p><p>⚫ <strong>实验讲解：</strong></p><p>DS18B20 是单总线驱动（onewire）传感器，也就是说只占用 1 个 IO 口。我，们来看看原理图：</p><p>⚫ <strong>实验目的：</strong></p><p>通过编程采集温度数据，并在 OLED 上显示。</p><p>⚫ <strong>实验讲解：</strong></p><p>DS18B20 是单总线驱动（onewire）传感器，也就是说只占用 1 个 IO 口。我们来看看原理图：</p><img src="/posts/30e8a1b9.htm/image-20230702140646041.png" alt="image-20230702140646041" style="zoom:50%;"><p>可以看到 DS18B20 传感器连接到了 pyBase 的 X11 引脚上。也就是连接到pyWiFi-ESP32-S2 的引脚 41，如下图所示：</p><img src="/posts/30e8a1b9.htm/image-20230702140747976.png" alt="image-20230702140747976" style="zoom:50%;"><p>也就是说我们需要针对引脚 41 编写程序来驱动 DS18B20。那么我们需要自己来编写驱动么？如果你有兴趣的可以自己尝试一下。这部分我们 01Studio 已经收集整理和编写好了，单总线模块文件是：<a href="http://onewire.py">onewire.py</a>，DS18B20 模块的文件是 <a href="http://ds18x20.py">ds18x20.py</a>。如果你学习过前面基于 STM32 平台应该不陌生。而对于 ESP32-S2,这两个模块已经集成到了初始化固件中，也就是说我们可以直接在 <a href="http://main.py">main.py</a> 导入模块并调用即可！单总线模块（onewire）和 ds18x20 模块说明如下：</p><p><strong>构造函数</strong></p><p>ow=onewire.OneWire(machine.Pin(id))</p><p>构建单总线对象。id:引脚编号；</p><p><strong>使用方法</strong></p><p>ow.scan()</p><p>扫描总线上的设备。返回设备地址，支持多设备同时挂载。</p><p>ow.reset()</p><p>总线设备复位。</p><p>ow.readbyte()</p><p>读 1 个字节。</p><p>ow.writebyte(0x12)</p><p>写入 1 个字节。</p><p>ow.write(‘123’)</p><p>写入多个字节。</p><p>ow.select_rom(b’12345678’)</p><p>根据 ROM 编号选择总线上指定设备</p><p> </p><p><strong>构造函数</strong></p><p>ds=ds18x20.DS18X20(ow)</p><p>构建 DS18B20 传感器对象。ow:定义好的单总线对象；</p><p><strong>使用方法</strong></p><p>ds.scan()</p><p>扫描总线上的设备。返回设备地址，支持多设备同时挂载。</p><p>ds.convert_temp()</p><p>温度转换。</p><p>ds.read_temp(rom)</p><p>获取温度值。rom：表示对应的设备号。</p><p> </p><p>大部分场景下温度的变化不会太频繁，我们可以每隔 1 秒采集一次，显示精度为小数点后 2 位，基本满足大部分应用需求。编程逻辑如下：</p><img src="/posts/30e8a1b9.htm/image-20230702140853444.png" alt="image-20230702140853444" style="zoom:80%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：温度传感器DS18B20</span></span><br><span class="line"><span class="string">说明：通过编程采集温度数据，并在OLED上显示。。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#引用相关模块</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin,SoftI2C,Timer</span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C</span><br><span class="line"><span class="keyword">import</span> onewire,ds18x20,time</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化相关模块</span></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>))</span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化DS18B20</span></span><br><span class="line">ow= onewire.OneWire(Pin(<span class="number">41</span>)) <span class="comment">#使能单总线</span></span><br><span class="line">ds = ds18x20.DS18X20(ow)        <span class="comment">#传感器是DS18B20</span></span><br><span class="line">rom = ds.scan()         <span class="comment">#扫描单总线上的传感器地址，支持多个传感器同时连接</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">temp_get</span>(<span class="params">tim</span>):</span><br><span class="line">    ds.convert_temp()</span><br><span class="line">    temp = ds.read_temp(rom[<span class="number">0</span>]) <span class="comment">#温度显示,rom[0]为第1个DS18B20</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#OLED数据显示</span></span><br><span class="line">    oled.fill(<span class="number">0</span>)   <span class="comment">#清屏背景黑色</span></span><br><span class="line">    oled.text(<span class="string">&#x27;MicroPython&#x27;</span>, <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">    oled.text(<span class="string">&#x27;Temp test:&#x27;</span>,<span class="number">0</span>,<span class="number">20</span>)</span><br><span class="line">    oled.text(<span class="built_in">str</span>(<span class="string">&#x27;%.2f&#x27;</span>%temp)+<span class="string">&#x27; C&#x27;</span>,<span class="number">0</span>,<span class="number">40</span>) <span class="comment">#显示temp,保留2位小数</span></span><br><span class="line">    oled.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启RTOS定时器，编号为-1</span></span><br><span class="line">tim = Timer(-<span class="number">1</span>)</span><br><span class="line">tim.init(period=<span class="number">1000</span>, mode=Timer.PERIODIC,callback=temp_get) <span class="comment">#周期为1000ms</span></span><br></pre></td></tr></table></figure><p>⚫ <strong>实验拓展：</strong></p><p>pyBase 开发底板预留了外界传感器接口，只要接线正确就可以进行更多的传感器实验。我们将带金属探头的 DS18B20 传感器接到 pyBase 右侧上面的传感器母座，其连接到 pyBase 的“Y11”引脚,也就是对应 pyWiFi-ESP32-S2 的引脚 10。</p><p>所以只要将原程序代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ow= onewire.OneWire(Pin(<span class="number">41</span>)) </span><br></pre></td></tr></table></figure><p>改成 ：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ow= onewire.OneWire(Pin(<span class="number">10</span>))，</span><br></pre></td></tr></table></figure><p>即可驱动外接的 DS18B20。</p><p>⚫ <strong>总结</strong></p><p>DS18B20 作为我们第一个实验传感器，使用 MicroPython 编程非常容易就用起来了，而且精度和稳定性丝毫没有影响。温度传感器只是一个敲门砖，接下来我们将会学习更多的传感器应用。</p><p> </p><h3 id="温湿度传感器-DHT11"><strong>温湿度传感器</strong> <strong>DHT11</strong></h3><p>⚫ <strong>前言：</strong></p><p>温湿度也是我们日常非常常见的指标，我们使用的是 DHT11 数字温湿度传感器。这是一款含有已校准数字信号输出的温湿度复合传感器，它应用专用的数字模块采集技术和温湿度传感技术，确保产品具有极高的可靠性和卓越的长期稳定性。</p><p>DHT11 具有小体积、极低的功耗，信号传输距离可达 20 米以上，使其成为给类应用甚至最为苛刻的应用场合的最佳选择。产品为 4 针单排引脚封装，连接方便。</p><p>⚫ <strong>实验目的：</strong></p><p>通过编程采集温湿度数据，并在 OLED 上显示。</p><p>⚫ <strong>实验讲解：</strong></p><p>DHT11 虽然有 4 个引脚，但其中第 3 个引脚是悬空的，也就是说 DHT11 也是单总线的传感器，只占用 1 个 IO 口。</p><img src="/posts/30e8a1b9.htm/image-20230702141333793.png" alt="image-20230702141333793" style="zoom:80%;"><p>我们来看看 DHT11 在开发板上的接线图：</p><img src="/posts/30e8a1b9.htm/image-20230702141347945.png" alt="image-20230702141347945" style="zoom:67%;"><p>可以看到 DHT11 连接到 pyBase 的‘X12’引脚，也就是连接到 pyWiFi-ESP32-S2 的引脚 42，如下图所示：</p><p>因此可以针对引脚 42 编程来驱动 DHT11 传感器，模块文件是 <a href="http://dht.py">dht.py</a>。而对于 pyWiFi-ESP32-S2,这个模块已经集成到了初始化固件中，也就是说我们可以直接在 <a href="http://main.py">main.py</a> 导入模块并调用即可。函数模块说明如下</p><p> </p><p><strong>构造函数</strong></p><p>d = dht.DHT11(machine.Pin(id))</p><p>构建 DHT11 传感器对象。id:传感器所连接的引脚；</p><p><strong>使用方法</strong></p><p>d.measure()</p><p>测量温湿度。</p><p>d.temperature()</p><p>获取温度值。</p><p>d.humidity()</p><p>获取湿度值</p><p>建议上电先延时 1 秒，让 DHT11 稳定后再开始读取。代码编写流程如下：</p><img src="/posts/30e8a1b9.htm/image-20230702141458320.png" alt="image-20230702141458320" style="zoom:80%;"><p> </p><h3 id="人体感应传感器"><strong>人体感应传感器</strong></h3><p>⚫ <strong>前言：</strong></p><p>人体感应传感器，在室内安防应用非常普遍，其原理是由探测元件将探测到人体的红外辐射转变成微弱的电压信号，经过放大后输出。为了提高探测器的探测灵敏度以增大探测距离，一般在探测器的前方装设一个塑料的菲涅尔透镜，它和放大电路相配合，可将信号放大 70dB 以上，这样就可以测出 5~10 米范围内人的行动。</p><p>⚫ <strong>实验目的：</strong></p><p>通过外部中断编程来检测人体感应模块，当有人出现时候 OLED 通过“GetPeople!！！”闪烁提示。</p>]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32基础实验</title>
      <link href="/posts/7fbb683d.html"/>
      <url>/posts/7fbb683d.html</url>
      
        <content type="html"><![CDATA[<h1><strong>基础实验</strong></h1><p>MicroPython 更强调的是针对应用的学习，强大的底层库函数让我们可以直接关心功能的实现，也就是说我们只要理解和熟练相关的函数用法，就可以很好</p><p>的玩转 MicroPython。它让我们可以做到不关心硬件和底层原理（当然有兴趣和能力的小伙伴可以深入研究）而直接跑起硬件。</p><h2 id="点亮第一个-LED"><strong>点亮第一个</strong> <strong>LED</strong></h2><p>⚫ <strong>实验讲解：</strong></p><p>pyWiFi-ESP32-S2 上有 1 个 LED（蓝色），控制 LED 使用 machine 中的 Pin 对</p><p>象，其构造函数和使用方法如下：</p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>led=machine.Pin(id,mode,pull)</td></tr><tr><td>构建 led 对象。id:引脚编号；mode:输入输出方式；pull:上下拉电阻配置。</td></tr><tr><td><strong>使用方法</strong></td></tr><tr><td>led.value([x])</td></tr><tr><td>引脚电平值。输出状态：x=0 表示低电平，x=1 表示高电平；输入状态：无须</td></tr><tr><td>参数，返回当前引脚值。</td></tr><tr><td>led.on()</td></tr><tr><td>使引脚输出高电平“1”。</td></tr><tr><td>led.off()</td></tr><tr><td>使引脚输出低电平“0”。</td></tr><tr><td>更详细内容，请查看 micropython 库文档：<a href="https://docs.01studio.cc/">https://docs.01studio.cc/</a></td></tr></tbody></table><p>上表对 MicroPython 的 machine 中 Pin 对象做了详细的说明，machine 是大</p><p>模块，Pin 是 machine 下面的其中一个小模块，在 python 编程里有两种方式引用</p><p>相关模块:</p><p><strong>方式</strong> <strong>1</strong> <strong>是</strong>：import machine，然后通过 machine.Pin 来操作；</p><p><strong>方式</strong> <strong>2</strong> <strong>是</strong>：from machine import Pin,意思是直接从 machine 中引入 Pin 模块，</p><p>然后直接通过构建 led 对象来操作。显然方式 2 会显得更直观和方便，本实验也</p><p>是使用方式 2 来编程。代码编写流程如下：</p><p>从原理图可以看到 LED 跟模块引脚 2 相连，通过输出高电平方式点亮</p><img src="/posts/7fbb683d.htm/image-20230701223726651.png" alt="image-20230701223726651" style="zoom:50%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：点亮 LED 蓝灯</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin <span class="comment">#导入 Pin 模块</span></span><br><span class="line">led=Pin(<span class="number">2</span>,Pin.OUT) <span class="comment">#构建 led 对象，GPIO2,输出</span></span><br><span class="line">led.value(<span class="number">1</span>) <span class="comment">#点亮 LED，也可以使用 led.on()</span></span><br></pre></td></tr></table></figure><p>⚫ <strong>总结：</strong></p><p>从第一个实验我们可以看到，使用 MicroPython 来开发关键是要学会构造函</p><p>数和其使用方法，便可完成对相关对象的操作，在强大的模块函数支持下，实验</p><p>只用了简单的两行代码便实现了点亮 LED 灯。</p><p> </p><p> </p><h2 id="按键"><strong>按键</strong></h2><p>⚫ <strong>前言：</strong></p><p>按键是最简单也最常见的输入设备，很多产品都离不开按键，包括早期的iPhone。有了按键输入功能，我们就可以做很多好玩的东西了。</p><p>⚫ <strong>实验目的：</strong></p><p>使用按键功能，通过检测按键被按下后，改变 LED（蓝灯）的亮灭状态。</p><p>⚫ <strong>实验讲解：</strong></p><p>pyWiFi-ESP32-S2 开发板上有 2 个按键，RST 和 KEY，RST 顾名思义是复位用的，所以真正自带可以用的就只有 1 个按键 KEY。</p><p>让我们先来搞清楚 MicroPython 里面 Pin 模块实现按键的构造函数和使用方法。</p><p> </p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>KEY=machine.Pin(id,mode,pull)</td></tr><tr><td>构建按键对象。id:引脚编号；mode:输入输出方式；pull:上下拉电阻配置。</td></tr><tr><td><strong>使用方法</strong></td></tr><tr><td>KEY.value()</td></tr><tr><td>引脚电平值。输入状态：无须参数，返回当前引脚值 0 或者 1。</td></tr></tbody></table><p>可以看到跟上一节 LED 一样，只是输入/输出状态的一个改变。从下面原理图可以看到，我们只需要在开发板上电后判断 KEY 引脚的电平，当被按下时候引</p><p>脚为低电平“0</p><p>按键被按下时候可能会发生抖动，抖动如下图，有可能造成误判，因此我们</p><p>需要使用延时函数来进行消抖：</p><img src="/posts/7fbb683d.htm/image-20230701224121294.png" alt="image-20230701224121294" style="zoom:67%;"><p>常用的方法就是当检测按键值为 0 时，延时一段时间，大约 10ms，再判断按键引脚值仍然是 0，是的话说明按键被按下。延时使用 time 模块，使用方法如</p><p>下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">1</span>) <span class="comment"># 睡眠 1 秒</span></span><br><span class="line">time.sleep_ms(<span class="number">500</span>) <span class="comment"># 睡眠 500 毫秒</span></span><br><span class="line">time.sleep_us(<span class="number">10</span>) <span class="comment"># 睡眠 10 微妙</span></span><br><span class="line">start = time.ticks_ms() <span class="comment"># 获取毫秒计时器开始值</span></span><br><span class="line">delta = time.ticks_diff(time.ticks_ms(), start) <span class="comment"># 计算从上电开始到当前时间</span></span><br><span class="line">的差值</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：按键</span></span><br><span class="line"><span class="string">说明：通过按键改变 LED 的亮灭状态</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">LED=Pin(<span class="number">2</span>,Pin.OUT) <span class="comment">#构建 LED 对象,开始熄灭</span></span><br><span class="line">KEY=Pin(<span class="number">0</span>,Pin.IN,Pin.PULL_UP) <span class="comment">#构建 KEY 对象</span></span><br><span class="line">state=<span class="number">0</span> <span class="comment">#LED 引脚状态</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#按键被按下</span></span><br><span class="line"> time.sleep_ms(<span class="number">10</span>) <span class="comment">#消除抖动</span></span><br><span class="line"> <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#确认按键被按下</span></span><br><span class="line">        state=<span class="keyword">not</span> state <span class="comment">#使用 not 语句而非~语句</span></span><br><span class="line"> LED.value(state) <span class="comment">#LED 状态翻转</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&#x27;KEY&#x27;</span>)</span><br><span class="line"> <span class="keyword">while</span> <span class="keyword">not</span> KEY.value(): <span class="comment">#检测按键是否松开</span></span><br><span class="line"> <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>从上面代码可以看到，初始化各个对象后，进入循环，当检测到 KEY 的值为0（按键被按下）时候，先做了 10ms 的延时，再次判断；</p><p>state 为 LED 状态的值，每次按键按下后通过使用 not 来改变。这里注意的是在 python 里使用‘not’而不是‘~’的方式。not 返回的是 True 和 False，即</p><p>0,1。而~ 是取反操作，会导致出错。</p><p> </p><h2 id="外部中断"><strong>外部中断</strong></h2><p>⚫ <strong>前言：</strong></p><p>前面我们在做普通的 GPIO 时候，虽然能实现 IO 口输入输出功能，但代码是一直在检测 IO 输入口的变化，因此效率不高，特别是在一些特定的场合，比如</p><p>某个按键，可能 1 天才按下一次去执行相关功能，这样我们就浪费大量时间来实时检测按键的情况。</p><p>为了解决这样的问题，我们引入外部中断概念，顾名思义，就是当按键被按下(产生中断)时，我们才去执行相关功能。这大大节省了 CPU 的资源，因此中断</p><p>的在实际项目的应用非常普遍.</p><p>⚫ <strong>实验目的：</strong></p><p>利用中断方式来检查按键 KEY 状态，被按键被按下（产生外部中断）后使 LED</p><p>的亮灭状态翻转</p><p>⚫ <strong>实验讲解：</strong></p><p>外部中断也是通过 machine 模块的 Pin 子模块来配置，我们先来看看其配构</p><p>造函数和使用方法</p><table><thead><tr><th><strong>构造函数</strong></th><th></th></tr></thead><tbody><tr><td>KEY=machine.Pin(id,mode,pull)</td><td></td></tr><tr><td>构建按键对象。id:引脚编号；mode:输入输出方式；pull:上下拉电阻配置。</td><td></td></tr><tr><td><strong>使用方法</strong></td><td></td></tr><tr><td>KEY.irq(handler,trigger)</td><td></td></tr><tr><td>配置中断模式。</td><td></td></tr><tr><td>handler:中断执行的回调函数；</td><td></td></tr><tr><td>trigger: 触发中断的方式，共 4 种，分别是 Pin.IRQ_FALLING（下降沿触发）、</td><td></td></tr><tr><td>Pin.IRQ_RISING（上升沿触发）、Pin.IRQ_LOW_LEVEL（低电平触发）、</td><td></td></tr><tr><td>Pin.IRQ_HIGH_LEVEL（高电平触发）</td><td></td></tr></tbody></table><p>上升沿和下降沿触发统称边沿触发。从上一节按键可以看到，按键被按下时一个引脚值从 1 到 0 变化的过程，边沿触发就是指这个过程。</p><img src="/posts/7fbb683d.htm/image-20230701224921935.png" alt="image-20230701224921935" style="zoom:50%;"><p>由此可见，我们可以选择下降沿方式触发外部中断，也就是当按键被按下的时候立即产生中断。</p><p>编程思路中断跟按键章节类似，在初始化中断后，当系统检测到外部终端时候，执行 LED 亮灭状态反转的代码即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：外部中断</span></span><br><span class="line"><span class="string">说明：通过按键改变LED的亮灭状态（外部中断方式）</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">LED=Pin(<span class="number">2</span>,Pin.OUT) <span class="comment">#构建LED对象,开始熄灭</span></span><br><span class="line">KEY=Pin(<span class="number">0</span>,Pin.IN,Pin.PULL_UP) <span class="comment">#构建KEY对象</span></span><br><span class="line">state=<span class="number">0</span>  <span class="comment">#LED引脚状态</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#LED状态翻转函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">KEY</span>):</span><br><span class="line">    <span class="keyword">global</span> state</span><br><span class="line">    time.sleep_ms(<span class="number">10</span>) <span class="comment">#消除抖动</span></span><br><span class="line">    <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#确认按键被按下</span></span><br><span class="line">        state = <span class="keyword">not</span> state</span><br><span class="line">        LED.value(state)</span><br><span class="line"></span><br><span class="line">KEY.irq(fun,Pin.IRQ_FALLING) <span class="comment">#定义中断，下降沿触发</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以上代码中需要注意的地方：</p><p>1、state 是全局变量，因此在 fun 函数里面用该变量必须添加 globalstate 代码，否则会在函数里面新建一个样的变量造成冲突。</p><p>2、在定义回调函数 fun 的时候，需要将 Pin 对象 KEY 传递进去。</p><p>⚫ <strong>总结：</strong></p><p>从参考代码来看，只是用了几行代码就实现了实验功能，而且相对于使用while True 实时检测函数来看，代码的效率大大增强。外部中断的应用非常广，</p><p>出来普通的按键输入和电平检测外，很大一部分输入设备，比如传感器也是通过外部中断方式来实时检测.</p><p> </p><h3 id="定时器"><strong>定时器</strong></h3><p>⚫ <strong>前言：</strong></p><p>定时器，顾名思义就是用来计时的，我们常常会设定计时或闹钟，然后时间到了就告诉我们要做什么了。单片机也是这样，通过定时器可以完成各种预设好</p><p>的任务。</p><p>⚫ <strong>实验目的：</strong></p><p>通过定时器让 LED 周期性每秒闪烁 1 次。</p><p>⚫ <strong>实验讲解：</strong></p><p>ESP32-S2 内置 RTOS（实时操作系统）定时器，在 machine 的 Timer 模块中。通过 MicroPython 可以轻松编程使用。我们也是只需要了解其构造对象函数和使</p><p>用方法即可！</p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>tim=machine.Timer(id)</td></tr><tr><td>构建定时器对象。</td></tr><tr><td>【id】ESP32-S2 有 2 路硬件定时器，id=0~1，也可以定义成-1，即RTOS 虚拟定时器</td></tr><tr><td></td></tr><tr><td><strong>使用方法</strong></td></tr><tr><td>tim.init(period,mode,callback)</td></tr><tr><td>定时器初始化。</td></tr><tr><td>period:单位为 ms；</td></tr><tr><td>mode：2 种工作模式，Timer.ONE_SHOT（执行一次）、Timer.PERIODIC（周期性）；callback:定时器中断后的回调函数。</td></tr></tbody></table><p>定时器到了预设指定时间后，也会产生中断，因此跟外部中断的编程方式类似，代码编程流程图如下：</p><img src="/posts/7fbb683d.htm/image-20230701225642158.png" alt="image-20230701225642158" style="zoom:75%;"><p>参考代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：定时器</span></span><br><span class="line"><span class="string">说明：通过定时器让LED周期性每秒闪烁1次</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin,Timer</span><br><span class="line"></span><br><span class="line">led=Pin(<span class="number">2</span>,Pin.OUT)</span><br><span class="line">Counter = <span class="number">0</span></span><br><span class="line">Fun_Num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">tim</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> Counter</span><br><span class="line">    Counter = Counter + <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(Counter)</span><br><span class="line">    led.value(Counter%<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启RTOS定时器，编号为-1</span></span><br><span class="line">tim = Timer(<span class="number">1</span>)</span><br><span class="line">tim.init(period=<span class="number">1000</span>, mode=Timer.PERIODIC,callback=fun) <span class="comment">#周期为1000ms</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="I2C-总线（-OLED-显示屏）"><strong>I2C</strong> **总线（**OLED <strong>显示屏）</strong></h3><p>前面学习了按键输入设备后，这一节我们来学习输出设备 OLED 显示屏，其实之前的 LED 灯也算是输出设备，因为它们确切地告诉了我们硬件的状态。只是</p><p>相对于只有亮灭的 LED 而言，显示屏可以显示更多的信息，体验更好。</p><p>⚫ <strong>实验讲解：</strong></p><p><strong>什么是</strong> <strong>I2C</strong>**？**</p><p>I2C 是用于设备之间通信的双线协议，在物理层面，它由 2 条线组成：SCL 和SDA，分别是时钟线和数据线。也就是说不通设备间通过这两根线就可以进行通</p><p>信。</p><p><strong>什么是</strong> <strong>OLED</strong> <strong>显示屏？</strong></p><p>OLED 的特性是自己发光，不像 TFT LCD 需要背光，因此可视度和亮度均高，其次是电压需求低且省电效率高，加上反应快、重量轻、厚度薄，构造简单，成</p><p>本低等特点。简单来说跟传统液晶的区别就是里面像素的材料是由一个个发光二极管组成，因为密度不高导致像素分辨率低，所以早期一般用作户外 LED 广告</p><p>牌。随着技术的成熟，使得集成度越来越高。小屏也可以制作出较高的分辨率。</p><img src="/posts/7fbb683d.htm/image-20230701230249879.png" alt="image-20230701230249879" style="zoom:50%;"><p>在了解完 I2C 和 OLED 显示屏后，我们先来看看 pyBase 开发板的原理图，也就是上面的 OLED 接口是如何连线的。</p><img src="/posts/7fbb683d.htm/image-20230701230306218.png" alt="image-20230701230306218" style="zoom:50%;"><p>我们从 pyWiFi-ESP32-S2 和 pyBase 相结合的原理图可以看到 GPIO38—Y6—SCL, GPIO40—Y8—SDA 的连接关系：</p><img src="/posts/7fbb683d.htm/image-20230701230321167.png" alt="image-20230701230321167" style="zoom:50%;"><p>本实验将使用 MicroPython 的 Machine 模块来定义 Pin 口和 I2C 初始化。具体如下：</p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>i2c = machine.I2C(scl,sda)i2c = machine.I2C(scl,sda)</td></tr><tr><td>构建 I2C 对象。scl:时钟引脚；sda:数据引脚。构建 I2C 对象。scl:时钟引脚；sda:数据引脚。</td></tr><tr><td><strong>使用方法****使用方法</strong></td></tr><tr><td>i2c.scan()i2c.scan()</td></tr><tr><td>扫描 I2C 总线的设备。返回地址，如：0x3c；扫描 I2C 总线的设备。返回地址，如：0x3c；</td></tr><tr><td>i2c.readfrom(addr,nbytes)i2c.readfrom(addr,nbytes)</td></tr><tr><td>从指定地址读数据。addr:指定设备地址；nbytes:读取字节数；从指定地址读数据。addr:指定设备地址；nbytes:读取字节数；</td></tr><tr><td>i2c.write(buf)</td></tr><tr><td>写数据。buf:数据内容；</td></tr></tbody></table><p>定义好 I2C 后，还需要驱动一下 OLED。这里我们已经写好了 OLED 的库函数，在 <a href="http://ssd1306.py">ssd1306.py</a> 文件里面。开发者只需要拷贝到 pyBoard 文件系统里面，然后在 <a href="http://main.py">main.py</a> 里面调用函数即可。人生苦短，我们学会调用函数即可，也就是注重顶层的应用，想深入的小伙伴也可以自行研究 <a href="http://ssd1306.py">ssd1306.py</a> 文件代码。OLED 显示屏对象介绍如下：</p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>oled = SSD1306_I2C(width, height, i2c, addr)</td></tr><tr><td>构 OLED 显示屏对象。width:屏幕宽像素；height: 屏幕高像素；i2c:定义好的</td></tr><tr><td>I2C 对象; addr:显示屏设备地址。</td></tr><tr><td><strong>使用方法</strong></td></tr><tr><td>oled.text(string,x,y)</td></tr><tr><td>将 string 字符写在指定为位置。string：字符；x:横坐标；y:纵坐标。</td></tr><tr><td>oled.show()</td></tr><tr><td>执行显示。</td></tr><tr><td>oled.fill(RGB)</td></tr><tr><td>清屏。RGB：0 表示黑色，1 表示白色。</td></tr></tbody></table><p>学习了 I2C、OLED 对象用法后我们通过编程流程图来理顺一下思路：</p><img src="/posts/7fbb683d.htm/image-20230701231539182.png" alt="image-20230701231539182" style="zoom:80%;"><h4 id="mian函数">mian函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：I2C总线(OLED显示屏)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> SoftI2C,Pin         <span class="comment">#从machine模块导入I2C、Pin子模块</span></span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C     <span class="comment">#从ssd1306模块中导入SSD1306_I2C子模块</span></span><br><span class="line"></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>))   <span class="comment">#I2C初始化：sda--&gt;40, scl --&gt;38</span></span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>) <span class="comment">#OLED显示屏初始化：128*64分辨率,OLED的I2C地址是0x3c</span></span><br><span class="line"></span><br><span class="line">oled.text(<span class="string">&quot;Hello World!&quot;</span>, <span class="number">0</span>,  <span class="number">0</span>)      <span class="comment">#写入第1行内容</span></span><br><span class="line">oled.text(<span class="string">&quot;MicroPython&quot;</span>,  <span class="number">0</span>, <span class="number">20</span>)      <span class="comment">#写入第2行内容</span></span><br><span class="line">oled.text(<span class="string">&quot;By 01Studio&quot;</span>,  <span class="number">0</span>, <span class="number">50</span>)      <span class="comment">#写入第3行内容</span></span><br><span class="line"></span><br><span class="line">oled.show()   <span class="comment">#OLED执行显示</span></span><br></pre></td></tr></table></figure><p>上述代码中 OLED 的 I2C 地址是 0x3C,不同厂家的产品地址可能预设不一样，具体参考厂家的说明书。或者也可以通过 I2C.scan()来获取设备地址。另外记得将我们提供的示例代码中的 <a href="http://ssd1306.py">ssd1306.py</a> 驱动文件拷贝到 pyWiFiESP32-S2 的文件系统下，跟 <a href="http://main.py">main.py</a> 保持同一个路径。</p><img src="/posts/7fbb683d.htm/image-20230701231632416.png" alt="image-20230701231632416" style="zoom:50%;"><p>⚫ <strong>总结：</strong></p><p>这一节我们学会了驱动 OLED 显示屏，换着以往如果从使用单片机从 0 开发的话你需要了解 I2C 总线原理，了解 OLED 显示屏的使用手册，编程 I2C 代码，有经验的嵌入式工程师搞不好也要弄个几天。现在基本半个小时解决问题。当然前提是别人已经给你搭好桥了，有了强大的底层驱动代码支持，我们只做好应用就好。</p><p> </p><p> </p><h3 id="RTC-实时时钟"><strong>RTC</strong> <strong>实时时钟</strong></h3><p>⚫ <strong>前言：</strong></p><p>时钟可以说我们日常最常用的东西了，手表、电脑、手机等等无时无刻不显示当前的时间。可以说每一个电子爱好者心中都希望拥有属于自己制作的一个电子时钟，接下来我们就用 MicroPython 开发板来制作一个属于自己的电子时钟。</p><p>⚫ <strong>实验讲解：</strong></p><p>实验的原理是读取 RTC 数据，然后通过 OLED 显示。毫无疑问，强大的MicroPython 已经集成了内置时钟函数模块。位于 machine 的 RTC 模块中，具体介绍如下：</p><table><thead><tr><th><strong>构造函数</strong></th></tr></thead><tbody><tr><td>rtc=machine.RTC()</td></tr><tr><td>构建 RTC 对象。</td></tr><tr><td><strong>使用方法</strong></td></tr><tr><td>rtc.datetime((2019, 4, 1, 0, 0, 0, 0, 0))</td></tr><tr><td>设置日期和时间。按顺序分别是：（年，月，日，星期，时，分，秒，微秒），</td></tr><tr><td>其中星期使用 0-6 表示周一至周日。</td></tr><tr><td>rtc.datetime()</td></tr><tr><td>获取当前日期和时间</td></tr></tbody></table><p>从上表可以看到 RTC()的使用方法，我们需要做的就是先设定时间，然后再获取当前芯片里的时间，通过 OLED 显示屏显示，如此循环。在循环里，如果一直获取日期时间数据会造成资源浪费，所以可以每隔第一段时间获取一次数据，又由于肉眼需要看到至少每秒刷新一次即可，这里每隔 300ms 获取一次数据，使用前面学习过的 RTOS 定时器来计时，具体编程流程如下：</p><img src="/posts/7fbb683d.htm/image-20230701232806658.png" alt="image-20230701232806658" style="zoom:67%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：RTC实时时钟</span></span><br><span class="line"><span class="string">说明：使用Thonny连接开发板会自动更新RTC时间</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入相关模块</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin, SoftI2C, RTC,Timer</span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义星期和时间（时分秒）显示字符列表</span></span><br><span class="line">week = [<span class="string">&#x27;Mon&#x27;</span>, <span class="string">&#x27;Tues&#x27;</span>, <span class="string">&#x27;Wed&#x27;</span>, <span class="string">&#x27;Thur&#x27;</span>, <span class="string">&#x27;Fri&#x27;</span>, <span class="string">&#x27;Sat&#x27;</span>, <span class="string">&#x27;Sun&#x27;</span>]</span><br><span class="line">time_list = [<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化所有相关对象</span></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>)) <span class="comment">#I2C初始化：sda--&gt;40, scl--&gt;38</span></span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line">rtc = RTC()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首次上电配置时间，按顺序分别是：年，月，日，星期，时，分，秒，次秒级；这里做了</span></span><br><span class="line"><span class="comment"># 一个简单的判断，检查到当前年份不对就修改当前时间，开发者可以根据自己实际情况来</span></span><br><span class="line"><span class="comment"># 修改。</span></span><br><span class="line"><span class="keyword">if</span> rtc.datetime()[<span class="number">0</span>] != <span class="number">2023</span>:</span><br><span class="line">    rtc.datetime((<span class="number">2021</span>, <span class="number">7</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">RTC_Run</span>(<span class="params">tim</span>):</span><br><span class="line"></span><br><span class="line">    datetime = rtc.datetime()  <span class="comment"># 获取当前时间</span></span><br><span class="line"></span><br><span class="line">    oled.fill(<span class="number">0</span>)  <span class="comment"># 清屏显示黑色背景</span></span><br><span class="line">    oled.text(<span class="string">&#x27;01Studio&#x27;</span>, <span class="number">0</span>, <span class="number">0</span>)    <span class="comment"># 首行显示01Studio</span></span><br><span class="line">    oled.text(<span class="string">&#x27;RTC Clock&#x27;</span>, <span class="number">0</span>, <span class="number">15</span>)  <span class="comment"># 次行显示实验名称</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示日期，字符串可以直接用“+”来连接</span></span><br><span class="line">    oled.text(<span class="built_in">str</span>(datetime[<span class="number">0</span>]) + <span class="string">&#x27;-&#x27;</span> + <span class="built_in">str</span>(datetime[<span class="number">1</span>]) + <span class="string">&#x27;-&#x27;</span> + <span class="built_in">str</span>(datetime[<span class="number">2</span>]) + <span class="string">&#x27; &#x27;</span> + week[datetime[<span class="number">3</span>]], <span class="number">0</span>, <span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示时间需要判断时、分、秒的值否小于10，如果小于10，则在显示前面补“0”以达</span></span><br><span class="line">    <span class="comment"># 到较佳的显示效果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>, <span class="number">7</span>):</span><br><span class="line">        <span class="keyword">if</span> datetime[i] &lt; <span class="number">10</span>:</span><br><span class="line">            time_list[i - <span class="number">4</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            time_list[i - <span class="number">4</span>] = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示时间</span></span><br><span class="line">    oled.text(time_list[<span class="number">0</span>] + <span class="built_in">str</span>(datetime[<span class="number">4</span>]) + <span class="string">&#x27;:&#x27;</span> + time_list[<span class="number">1</span>] + <span class="built_in">str</span>(datetime[<span class="number">5</span>]) + <span class="string">&#x27;:&#x27;</span> + time_list[<span class="number">2</span>] + <span class="built_in">str</span>(datetime[<span class="number">6</span>]), <span class="number">0</span>, <span class="number">55</span>)</span><br><span class="line">    oled.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启RTOS定时器</span></span><br><span class="line">tim = Timer(<span class="number">0</span>)</span><br><span class="line">tim.init(period=<span class="number">300</span>, mode=Timer.PERIODIC, callback=RTC_Run) <span class="comment">#周期300ms</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>由于实验要用到 OLED 显示屏，所以同样别忘了将示例代码该实验文件夹下的 <a href="http://ssd1306.py">ssd1306.py</a> 文件复制到 pyWiFi-ESP32-S2 的文件系统里面。</p><p>由于 ESP32-S2 没有后备电池引脚，所以不支持掉电保存。因此 pybase 上面的纽扣电池是不起作用的。</p><p>⚫ <strong>总结：</strong></p><p>细心的用户或许已经发现运行程序后 RTC 时间自动更新，那是因为 thonny每次连接 MicroPython 开发板会自动更新开发板的 RTC 时间。</p><p>RTC 实时时钟的可玩性很强，我们还可以根据自己的风格来设定数字显示位置，以及加上一些属于自己的字符标识。打造自己的电子时钟。</p><p> </p><h3 id="ADC（电位器）"><strong>ADC</strong>（电位器）</h3><p>⚫ <strong>前言：</strong></p><p>ADC(analog to digital conversion) 模拟数字转换。意思就是将模拟信号转化成数字信号，由于单片机只能识别二级制数字，所以外界模拟信号常常会通过 ADC转换成其可以识别的数字信息。常见的应用就是将变化的电压转成数字信号。</p><p>⚫ <strong>实验目的：</strong></p><p>通过编程调用 MicroPython 的内置 ADC 函数，实现测量输入电压，并显示到屏幕上。</p><p>⚫ <strong>实验讲解：</strong></p><p>pyBase 开发底板的 X7 引脚连接到了电位器，通过电位器的调节可以使得 X7引脚上的电压变化范围实现从 0-3.3V。</p><img src="/posts/7fbb683d.htm/image-20230701233122746.png" alt="image-20230701233122746" style="zoom:50%;"><img src="/posts/7fbb683d.htm/image-20230701233132565.png" alt="image-20230701233132565" style="zoom:50%;"><p>从上图可以看到，电位器引脚对应 pyBase 的 X7,实际是跟 pyWiFi-ESP32-S2</p><p>的‘</p><p>6’引脚 ADC 输入引脚相连。ESP32-S2 的 ADC 默认只能测量 0-1V 的量程，</p><p>但 ESP32-S2 内部集成了衰减器，最大支持 11dB 衰减，通过配置衰减器最多能测</p><p>量 3V 左右的电压。我们来看看 ADC 模块的构造函数和使用方法。</p><p><strong>构造函数</strong></p><p>adc=machine.ADC(Pin(id))</p><p>构建 ADC 对象。</p><p>【id】目前仅支持 ESP32-S2 的 ADC1，共 10 个通道：</p><p>GPIO1: ADC1_0</p><p>GPIO2: ADC1_1</p><p>GPIO3: ADC1_2</p><p>GPIO4: ADC1_3</p><p>GPIO5: ADC1_4</p><p>GPIO6: ADC1_5</p><p>GPIO7: ADC1_6</p><p>GPIO8: ADC1_7</p><p>GPIO9: ADC1_8</p><p>GPIO10: ADC1_9</p><p><strong>使用方法</strong></p><p>adc.read()</p><p>获取 ADC 值。测量精度是 13 位，返回 0- 8191（表示 0-1V）。</p><p>adc.atten(attenuation)</p><p>配置衰减器。配置衰减器能增加电压测量范围，但是以精度为代价的。</p><p>attenuation:衰减设置</p><p>ADC.ATTN_0DB： 0dB 衰减, 最大输入电压为 1.00v - 这是默认配置；</p><p>ADC.ATTN_2_5DB： 2.5dB 衰减, 最大输入电压约为 1.34v；</p><p>ADC.ATTN_6DB：6dB 衰减, 最大输入电压约为 2.00v；</p><p>ADC.ATTN_11DB：11dB 衰减, 最大输入电压约为 3.3v。</p><p>你没看错，就这么简单，两句函数就可以获得 ADC 数值。我们将在本实验中以默认的量程 0-1V 来测试。让我们来理顺一下编程逻辑。先导入相关模块，然后初始化模块。在循环中不断读取 ADC 的值，转化成电压值后在 OLED 上面显示，每隔 300 毫秒读取一次，具体如下：</p><img src="/posts/7fbb683d.htm/image-20230701233235973.png" alt="image-20230701233235973" style="zoom:75%;"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：ADC-电压测量</span></span><br><span class="line"><span class="string">说明：通过对ADC数据采集，转化成电压在显示屏上显示。ADC精度13位（0~8191），默认电压0-1V。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导入相关模块</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin,SoftI2C,ADC,Timer</span><br><span class="line"><span class="keyword">from</span> ssd1306 <span class="keyword">import</span> SSD1306_I2C</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化相关模块</span></span><br><span class="line">i2c = SoftI2C(sda=Pin(<span class="number">40</span>), scl=Pin(<span class="number">38</span>))  <span class="comment">#I2C初始化：sda--&gt;40, scl --&gt;38</span></span><br><span class="line">oled = SSD1306_I2C(<span class="number">128</span>, <span class="number">64</span>, i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line">adc = ADC(Pin(<span class="number">6</span>)) <span class="comment">#6引脚跟pyBase的电位器相连接</span></span><br><span class="line">adc.atten(ADC.ATTN_11DB) <span class="comment">#开启衰减，测量量程增大到3.3V</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ADC_Test</span>(<span class="params">tim</span>):</span><br><span class="line"></span><br><span class="line">    oled.fill(<span class="number">0</span>)  <span class="comment"># 清屏显示黑色背景</span></span><br><span class="line">    oled.text(<span class="string">&#x27;01Studio&#x27;</span>, <span class="number">0</span>, <span class="number">0</span>)  <span class="comment"># 首行显示01Studio</span></span><br><span class="line">    oled.text(<span class="string">&#x27;ADC&#x27;</span>, <span class="number">0</span>, <span class="number">15</span>)      <span class="comment"># 次行显示实验名称</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#获取ADC数值</span></span><br><span class="line">    oled.text(<span class="built_in">str</span>(adc.read()),<span class="number">0</span>,<span class="number">40</span>)</span><br><span class="line">    oled.text(<span class="string">&#x27;(8191)&#x27;</span>,<span class="number">60</span>,<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算电压值，获得的数据0-4095相当于0-1V，（&#x27;%.2f&#x27;%）表示保留2位小数</span></span><br><span class="line">    oled.text(<span class="built_in">str</span>(<span class="string">&#x27;%.2f&#x27;</span>%(adc.read()/<span class="number">8191</span>*<span class="number">3.3</span>)),<span class="number">0</span>,<span class="number">55</span>)</span><br><span class="line">    oled.text(<span class="string">&#x27;V&#x27;</span>,<span class="number">40</span>,<span class="number">55</span>)</span><br><span class="line"></span><br><span class="line">    oled.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启定时器</span></span><br><span class="line">tim = Timer(<span class="number">1</span>)</span><br><span class="line">tim.init(period=<span class="number">300</span>, mode=Timer.PERIODIC, callback=ADC_Test) <span class="comment">#周期300ms</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>⚫ <strong>总结：</strong></p><p>这一节我们学习了 ADC 的应用，主要用于电压的检测。有兴趣的用户可以尝试使用其衰减器测试，可以扩充电压量程，但精度会有所下降。</p><p> </p><p> </p><h3 id="PWM（无源蜂鸣器）"><strong>PWM</strong>（无源蜂鸣器）</h3><p>⚫ <strong>前言：</strong></p><p>上一节的 ADC 是信号输入，这节的 PWM 就是一个信号输出。PWM（脉冲宽度调制），主要用于输出不同频率、占空比（一个周期内高电平出现时间占总时间比例）的方波。以实现固定频率或平均电压输出。</p><p>⚫ <strong>实验目的：</strong></p><p>通过不同频率的 PWM 信号输出，驱动无源蜂鸣器发出不同频率的声音。</p><p>⚫ <strong>实验讲解：</strong></p><p>蜂鸣器分有源蜂鸣器和无源蜂鸣器，有源蜂鸣器的使用方式非常简单，只需要接上电源，蜂鸣器就发声，断开电源就停止发声。而本实验用到的无源蜂鸣器，是需要给定指定的频率，才能发声的，而且可以通过改变频率来改变蜂鸣器的发声音色，以此来判定 pyWiFi-ESP32-S2 的 PWM 输出频率是在变化的。pyBase 开发底板上的无源蜂鸣器连接到 pyBase 引脚 X5。如下图所示：</p><img src="/posts/7fbb683d.htm/image-20230702110722346.png" alt="image-20230702110722346" style="zoom:50%;"><p>从 pyWiFi-ESP32-S2 原理图可以看到由底板蜂鸣器 X5 连接到 ESP32-S2 的引脚 4。</p><img src="/posts/7fbb683d.htm/image-20230702110739134.png" alt="image-20230702110739134" style="zoom:50%;"><p>PWM 可以通过 ESP32-S2 所有 GPIO 引脚输出. 所有通道都有 1 个特定的频率，从 0 到 40M 之间（单位是 Hz）。占空比的值为 0 至 1023 之间。在本实验中我们用到引脚 4。</p><p>先看看 PWM 模块对象：</p><p><strong>构造函数</strong></p><p>pwm=machine.PWM(machine.Pin(id),freq,duty)</p><p>构建 PWM 对象。id:引脚编号；freq:频率值；duty:占空比；配置完后 PWM 自</p><p>动生效。</p><p><strong>使用方法</strong></p><p>pwm.freq(freq)</p><p>设置频率。freq:频率值在 1-1000 之间，freq 为空时表示获取当前频率值。</p><p>pwm.duty(duty)</p><p>设置占空比。duty:占空比在 0-1023 之间，duty 为空时表示获取当前占空比值。</p><p>pwm.deinit()</p><p>关闭 PWM。</p><p>无源蜂鸣器我们可以用特定频率的方波来驱动，方波的原理很简单，就是一定频率的高低电平转换，可以简单理解成占空比为 50%的 PWM 输出。</p><p>结合上述讲解，总结出代码编写流程图如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：PWM</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2021.8</span></span><br><span class="line"><span class="string">作者：01Studio</span></span><br><span class="line"><span class="string">说明：通过不同频率的PWM信号输出，驱动无源蜂鸣器发出不同频率的声音。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin, PWM</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">Beep = PWM(Pin(<span class="number">4</span>), freq=<span class="number">0</span>, duty=<span class="number">512</span>) <span class="comment"># 在同一语句下创建和配置PWM,占空比50%</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#蜂鸣器发出频率200Hz响声</span></span><br><span class="line">Beep.freq(<span class="number">200</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#蜂鸣器发出频率400Hz响声</span></span><br><span class="line">Beep.freq(<span class="number">400</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#蜂鸣器发出频率600Hz响声</span></span><br><span class="line">Beep.freq(<span class="number">600</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#蜂鸣器发出频率800Hz响声</span></span><br><span class="line">Beep.freq(<span class="number">800</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#蜂鸣器发出频率1000Hz响声</span></span><br><span class="line">Beep.freq(<span class="number">1000</span>)</span><br><span class="line">time.sleep(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#停止</span></span><br><span class="line">Beep.deinit()</span><br></pre></td></tr></table></figure><p> </p><h3 id="UART（串口通信）"><strong>UART</strong>（串口通信）</h3><p>⚫ <strong>前言：</strong></p><p>串口是非常常用的通信接口，有很多工控产品、无线透传模块都是使用串口来收发指令和传输数据，这样用户就可以在无须考虑底层实现原理的前提下将各类串口功能模块灵活应用起来。</p><p>⚫ <strong>实验讲解：</strong></p><p>pyWiFi-ESP32-S2 开发板一共有 2 个串口，编号是 0-1，如下表：</p><table><thead><tr><th>UART(0)</th><th>TX</th><th>43</th></tr></thead><tbody><tr><td></td><td>RT</td><td>44</td></tr><tr><td>UART(1)</td><td>TX</td><td>任意映射IO</td></tr><tr><td></td><td>RX</td><td>任意映射IO</td></tr></tbody></table><p>由于 UART0 用于下载和 REPL 调试，因此我们使用 UART1 来进行本节实验。</p><p>我们先来了解一下串口对象的构造函数和使用方法</p><p> </p><p><strong>构造函数</strong></p><p>uart=machine.UART(id,baudrate,tx=None,rx=None bits=8, parity=None, stop=1,…)</p><p>创建 UART 对象。</p><p>【id】0-1</p><p>【baudrate】波特率，常用 115200、9600</p><p>【tx】自定义 IO</p><p>【rx】自定义 IO</p><p>【bits】数据位</p><p>【parity】校验；默认 None, 0(偶校验)，1(奇校验)</p><p>【stop】停止位，默认 1</p><p>…</p><p>特别说明： ESP32-S2 的 UART 引脚映射到其它 IO 来使用，用户可以通过构造</p><p>函数时候指定如 tx=8,rx=9 的方式来改变串口引脚，实现更灵活的应用。</p><p><strong>使用方法</strong></p><p>uart.deinit()</p><p>关闭串口</p><p>uart.any()</p><p>返回等待读取的字节数据，0 表示没有</p><p>uart.read([<em>nbytes</em>])</p><p>【nbytes】读取字节数</p><p>UART.readline()</p><p>读行</p><p>UART.write(<em>buf</em>)</p><p>【buf】串口 TX 写数据</p><p> </p><p>我们可以用一个USB转TTL工具，配合电脑上位机串口助手来跟MicroPython</p><p>开发板模拟通信。</p><img src="/posts/7fbb683d.htm/image-20230702111650095.png" alt="image-20230702111650095" style="zoom:50%;"><p>注意要使用 3.3V 电平的 USB 转串口 TTL 工具，本实验我们使用串口 2，也就是 8（TX）和 9（RX），接线示意图如下：</p><p>在本实验中我们可以先初始化串口，然后给串口发去一条信息，这样 PC 机的串口助手就会在接收区显示出来，然后进入循环，当检测到有数据可以接收时候就将数据接收并打印，并通过 REPL 打印显示。代码编写流程图如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：串口通信</span></span><br><span class="line"><span class="string">说明：通过编程实现串口通信，跟电脑串口助手实现数据收发。</span></span><br><span class="line"><span class="string">平台：pyWiFi-ESP32</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导入串口模块</span></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> UART</span><br><span class="line"></span><br><span class="line">uart=UART(<span class="number">1</span>,<span class="number">115200</span>,rx=<span class="number">9</span>,tx=<span class="number">8</span>) <span class="comment">#设置串口号1和波特率</span></span><br><span class="line"></span><br><span class="line">uart.write(<span class="string">&#x27;Hello 01Studio!&#x27;</span>)<span class="comment">#发送一条数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断有无收到信息</span></span><br><span class="line">    <span class="keyword">if</span> uart.<span class="built_in">any</span>():</span><br><span class="line"></span><br><span class="line">        text=uart.read(<span class="number">128</span>) <span class="comment">#接收128个字符</span></span><br><span class="line">        <span class="built_in">print</span>(text) <span class="comment">#通过REPL打印串口3接收的数据</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>⚫ <strong>实验结果：</strong></p><p>我们按照上述方式将 USB 转 TTL 的 TX 接到开发板的 RX（</p><p>9），USB 转 TTL 的</p><p>RX 接到开发板的 TX（</p><p>8）。GND 接一起，3.3V 可以选择接或不接。</p><p>根据上图设备管理器里面的信息，将串口工具配置成 COM14，REPL 串口配置成 COM27（根据自己的串口号调整）。波特率 115200。运行程序，可以看到一开始串口助手收到开发板上电发来的信息“Hello 01Studio!”。我们在串口助手的发送端输入“<a href="http://www.01studio.org">http://www.01studio.org</a>”， 点击发送，可以看到 pyWiFi-ESP32-S2 在接收到该信息后在 REPL 里面打印了出来。如下图所示：</p><img src="/posts/7fbb683d.htm/image-20230702111909798.png" alt="image-20230702111909798" style="zoom:67%;"><p> </p><p> </p><h3 id="LCD-显示屏"><strong>LCD</strong> <strong>显示屏</strong></h3><p>⚫ <strong>前言：</strong></p><p>前面用到的 OLED 显示屏虽然能显示信息，但是颜色只有黑白，而且分辨率也比较低 128x64，本节我们来学习 3.2 寸 TFT_LCD 彩色显示屏的使用方法。</p><p>⚫ <strong>实验目的：</strong></p><p>通过 MicorPython 编程方式实现 LCD 的各种显示功能，包括画点、线、矩形、圆形、显示英文、显示图片等</p><p> </p><p>实验用的 LCD 是 3.2 寸，驱动是的 ILI9341，使用 SPI 方式跟 ESP32-S2 通信，按以往嵌入式 C 语言开发，我们需要对 ILI9341 进行编程实现驱动，然后再建立各种描点、划线、以及显示图片函数。</p><p>使用 MicroPython 其实也需要做以上工作，但由于可读性和移植性强的特点我们只需要搞清各个对象函数使如何使用即可。总的来说和前面实验一样，有构造函数和功能函数。构造函数解决的是初始化问题，告诉开发板该外设是怎么接线，初始化参数如何，而功能函数解决的则是使用问题，我们基于自己的需求直接调用相关功能函数，实现自己的功能即可！</p><p>我们管这些函数的集合叫<strong>驱动</strong>，驱动可以是预先在固件里面，也可以通过.py文件存放在开发板文件系统。也就是说工程师已经将复杂的底层代码封装好，我们顶层直接使用 python 开发即可，人生苦短。我们来看看 pyWiFi-ESP32-S2P 开发板 3.2 寸 LCD 的构造函数和使用方法</p><p> </p><p><strong>构造函数</strong></p><p>tftlcd.LCD32(portrait=1)</p><p>构建 3.2 寸 LCD 对象。</p><p>【portrait】 设置屏幕方向：</p><p>⚫ 1 - 竖屏，240*320 ，默认</p><p>⚫ 2 - 横屏，320*240 ，1 基础上顺时针旋转 90°</p><p>⚫ 3 - 竖屏，240*320 ，1 基础上顺时针旋转 180°</p><p>⚫ 4 - 横屏，320*240 ，1 基础上顺时针旋转 270°</p><p><strong>使用方法</strong></p><p>LCD32.fill(color)</p><p>【color】RGB 颜色数据；如(255,0,0)表示红色。</p><p>LCD32.drawPixel(x,y,color)</p><p>画点。</p><p>【x】:横坐标，</p><p>【y】:纵坐标，</p><p>【color】:颜色。</p><p>LCD32.drawLine(x0,y0,x1,y1,color)</p><p>画线段。</p><p>【x0,y0】:起始坐标，</p><p>【x1,y1】:终点坐标，</p><p>【color】:颜色</p><p>LCD32.drawRect(x,y,width,height,color,border=1,fillcolor=None)</p><p>画矩形。</p><p>【</p><p>x,y】:起始坐标，</p><p>【width】:宽度，</p><p>【height】:高度，</p><p>【color】:颜色，</p><p>【border】:边宽，</p><p>【fillcolor】:填充颜色，默认 None 为不填充</p><p>LCD32.drawCircle(x,y,radius,color,border=1,fillcolor=None)</p><p>画圆。</p><p>【x, y】:圆心，</p><p>【radius】:半径，</p><p>【color】:颜色，</p><p>【border】:边宽，</p><p>【fillcolor】:填充颜色，默认 None 为不填充</p><p>LCD32.printStr(text,x,y,color,backcolor=None,size=2)</p><p>写字符。</p><p>【text】:字符，</p><p>【x,y】:起始坐标,</p><p>【color】:字体颜色；</p><p>【backcolor】:字体背景颜色；</p><p>【size】:字体尺寸（1-小号，2-标准，3-中号，4-大号）</p><p>LCD32.Picture(x,y,filename)</p><p>显示图片。支持图片格式类型：jpg、bmp</p><p>【x,y】:起始坐标。</p><p>【filename】: 图片路径+名称，如：“/cat.jpg”</p><p><strong>（‘</strong>/<strong>’表示开发板的板载</strong> <strong>flash</strong> <strong>的根目录。）</strong></p><p>有了上面的对象构造函数和使用说明，编程可以说是信手拈来了，我们在使用中将以上功能都跑一遍先看看编程流程图：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：3.2寸LCD液晶显示屏</span></span><br><span class="line"><span class="string">说明：通过编程实现LCD的各种显示功能，包括填充、画点、线、矩形、圆形、显示英文、显示图片等。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#导入相关模块</span></span><br><span class="line"><span class="keyword">from</span> tftlcd <span class="keyword">import</span> LCD32</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义常用颜色</span></span><br><span class="line">RED = (<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">GREEN = (<span class="number">0</span>,<span class="number">255</span>,<span class="number">0</span>)</span><br><span class="line">BLUE = (<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>)</span><br><span class="line">BLACK = (<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">WHITE = (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line"><span class="comment"># 构建3.2寸LCD对象并初始化</span></span><br><span class="line"><span class="comment">########################</span></span><br><span class="line">d = LCD32(portrait=<span class="number">1</span>) <span class="comment">#默认方向竖屏</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#填充白色</span></span><br><span class="line">d.fill(WHITE)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画点</span></span><br><span class="line">d.drawPixel(<span class="number">5</span>, <span class="number">5</span>, RED)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#画线段</span></span><br><span class="line">d.drawLine(<span class="number">5</span>, <span class="number">10</span>, <span class="number">200</span>, <span class="number">10</span>, RED)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#画矩形</span></span><br><span class="line">d.drawRect(<span class="number">5</span>, <span class="number">30</span>, <span class="number">200</span>, <span class="number">40</span>, RED, border=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画圆</span></span><br><span class="line">d.drawCircle(<span class="number">100</span>, <span class="number">120</span>, <span class="number">30</span>, RED, border=<span class="number">5</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#写字符,4种尺寸</span></span><br><span class="line">d.printStr(<span class="string">&#x27;Hello 01Studio&#x27;</span>, <span class="number">10</span>, <span class="number">200</span>, RED, size=<span class="number">1</span>)</span><br><span class="line">d.printStr(<span class="string">&#x27;Hello 01Studio&#x27;</span>, <span class="number">10</span>, <span class="number">230</span>, GREEN, size=<span class="number">2</span>)</span><br><span class="line">d.printStr(<span class="string">&#x27;Hello 01Studio&#x27;</span>, <span class="number">10</span>, <span class="number">270</span>, BLUE, size=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">time.sleep(<span class="number">5</span>) <span class="comment">#等待5秒</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#显示图片</span></span><br><span class="line">d.Picture(<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;/picture/1.jpg&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">d.Picture(<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;/picture/2.jpg&quot;</span>)</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br><span class="line">d.Picture(<span class="number">0</span>,<span class="number">0</span>,<span class="string">&quot;/picture/01studio.jpg&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>⚫ <strong>实验结果：</strong></p><p>将示例程序的素材文件上传到 pyWiFi-ESP32-S2P 开发板。<strong>（也可以只上传单</strong>张图片，注意修改代码中文件的路径即可。）</p><p> </p><h3 id="电阻触摸屏"><strong>电阻触摸屏</strong></h3><p>⚫ <strong>前言：</strong></p><p>上一节我们学习了 LCD 实验，但 LCD 只能显示相关内容，跟人是缺乏交互的。好比我们的智能手机，如果只有显示不能触碰，那么就没有可玩性了。因此本节学习一下 3.2 寸 LCD 的电阻触摸屏使用方法。</p><p>⚫ <strong>实验讲解：</strong></p><p>01Studio 配套的 3.2 寸 LCD 上带电阻触摸屏,驱动芯片为 XPT2046。当手指按下时候，通过简单的编程即可返回一个坐标，我们来看看其 micropython 构造函数和使用方法：</p><p><strong>构造函数</strong></p><p><strong>touch.XPT2046(portrait=1)</strong></p><p>构建触摸屏对象。<strong>XPT2046</strong> 表示驱动芯片型号。</p><p>【portrait】 设置屏幕方向：</p><p>⚫ 1 - 竖屏，240*320 ，默认</p><p>⚫ 2 - 横屏，320*240 ，1 基础上顺时针旋转 90°</p><p>⚫ 3 - 竖屏，240*320 ，1 基础上顺时针旋转 180°</p><p>⚫ 4 - 横屏，320*240 ，1 基础上顺时针旋转 270°</p><p><strong>使用方法</strong></p><p><strong>XPT2046.tick_inc()</strong></p><p>手动刷新触摸。</p><p><strong>XPT2046.read()</strong></p><p>读取触摸屏数据，返回（states,x,y）</p><p>【states】-当前触摸状态：0：按下；1：移动；2：松开。</p><p>【x】:触摸横坐标</p><p>【y】:触摸纵坐标</p><p> </p><p>学会了触摸对象用法后，我们可以编程实现触摸后屏幕打点表示，然后左上角显示当前触摸的坐标。另外再加入一个按键，按下清空屏幕。编程流程图如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：电阻触摸屏</span></span><br><span class="line"><span class="string">说明：电阻触摸屏采集触摸信息</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> touch <span class="keyword">import</span> XPT2046</span><br><span class="line"><span class="keyword">from</span> tftlcd <span class="keyword">import</span> LCD32</span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义颜色</span></span><br><span class="line">BLACK = (<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line">WHITE = (<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>)</span><br><span class="line">RED=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#LCD初始化</span></span><br><span class="line">d = LCD32(portrait=<span class="number">1</span>) <span class="comment">#默认竖屏</span></span><br><span class="line">d.fill(WHITE) <span class="comment">#填充白色</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#电阻触摸屏初始化，方向和LCD一致</span></span><br><span class="line">t = XPT2046(portrait=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">KEY</span>):</span><br><span class="line">    </span><br><span class="line">    d.fill(WHITE) <span class="comment">#清屏</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#USR按键初始化</span></span><br><span class="line">KEY=Pin(<span class="number">0</span>,Pin.IN,Pin.PULL_UP) <span class="comment">#构建KEY对象</span></span><br><span class="line">KEY.irq(fun,Pin.IRQ_FALLING) <span class="comment">#定义中断，下降沿触发</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line">    data = t.read() <span class="comment">#获取触摸屏坐标</span></span><br><span class="line">    <span class="built_in">print</span>(data) <span class="comment">#REPL打印</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#当产生触摸时</span></span><br><span class="line">    <span class="keyword">if</span> data[<span class="number">0</span>]!=<span class="number">2</span>: <span class="comment">#0：按下； 1：移动； 2：松开</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#触摸坐标画圆</span></span><br><span class="line">        d.drawCircle(data[<span class="number">1</span>], data[<span class="number">2</span>], <span class="number">5</span>, BLACK, fillcolor=BLACK)</span><br><span class="line">        d.printStr(<span class="string">&#x27;(X:&#x27;</span>+<span class="built_in">str</span>(<span class="string">&#x27;%03d&#x27;</span>%data[<span class="number">1</span>])+<span class="string">&#x27; Y:&#x27;</span>+<span class="built_in">str</span>(<span class="string">&#x27;%03d&#x27;</span>%data[<span class="number">2</span>])+<span class="string">&#x27;)&#x27;</span>,<span class="number">10</span>,<span class="number">10</span>,RED,size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    time.sleep_ms(<span class="number">20</span>) <span class="comment">#触摸响应间隔</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>⚫ <strong>实验结果：</strong></p><p>运行程序，首次运行会自动提示进行触摸校准（电阻屏需要校准），按提示分别点击四个角落进行校准，如校准失败会自动重复。校准成功会自动保存一个“touch.cail”文件到开发板 flash，下次无须再校准。</p><p>成功后出现空白画面，用手指触摸屏幕或者在屏幕上滑动，可以看到描点并在 LCD 左上角显示当前坐标。</p><p>重启开发板，可以看到文件系统多了一个“touch.cail”，在运行电阻屏初始化时候会检测这个文件，如果存在则不进行校准，若想重新校准的用户可以把这个文件删除即可！</p><p>⚫ <strong>总结：</strong></p><p>没有触摸屏的 LCD 就失去了灵魂，有了触摸屏，跟开发板的交互就变得有意思了。</p>]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp32</title>
      <link href="/posts/86375cb2.html"/>
      <url>/posts/86375cb2.html</url>
      
        <content type="html"><![CDATA[<h1>esp32</h1><h2 id="ESP32-S2-平台"><strong>ESP32-S2</strong> <strong>平台</strong></h2><h3 id="pyWiFi-ESP32-S2"><strong>pyWiFi-ESP32-S2</strong></h3><p>pyWiFi-ESP32-S2 是由 01Studio 设计研发，基于 ESP32-S2 平台的 MicroPython</p><p>开发板，主要特点如下：</p><p> 自动下载电路</p><p> 板载锂电池输入接口和充电电路</p><p> 标准 24P 摄像头接口</p><p> USB OTG 接口</p><p> 全 IO 引出</p><p> 按键和 LED 排列整齐，丝印清晰</p><p> 兼容 pyBoard 接口</p><img src="/posts/86375cb2.htm/86375cb2/image-20230701220231747.png" class title="image-20230701220231747"><img src="/posts/86375cb2.htm/86375cb2/image-20230701220244595.png" class title="image-20230701220244595"><h3 id="开发环境快速建立"><strong>开发环境快速建立</strong></h3><p>ESP32-S2 是基于是继 ESP32 普遍板后推出的一个版本，主要特点是引脚数量非常多。还支持标准 USB HOST。</p><h4 id="安装开发软件-Thonny"><strong>安装开发软件</strong> <strong>Thonny</strong></h4><p>Thonny Python IDE 是一款开源软件，以极简方式设计，对 MicroPython 的兼容性非常友善。而且支持 Windows、Mac OS、Linux、树莓派。由于开源，所以软</p><p>件迭代速度非常快，功能日趋成熟。具体安装方法如下：在 <a href="https://thonny.org/">https://thonny.org/</a> 下载最新版，选择自己的开发平台进行下载安装即可(这里选择 Windows！)：</p><p> </p><h3 id="REPL-串口交互调试"><strong>REPL</strong> <strong>串口交互调试</strong></h3><p>yWiFi-ESP32-S2 的 MicroPython 固件集成了交互解释器 REPL 【读取(Read)-运算(Eval)-输出(Print)-循环(Loop) 】，开发者可以直接通过串口终端来调试开发板。我们打开 Thonny，将开发板连接到电脑。点击右下角：</p><img src="/posts/86375cb2.htm/image-20230701221427314.png" alt="image-20230701221427314" style="zoom:50%;"><p>在弹出的列表选择：<strong>Configure interpreter</strong></p><img src="/posts/86375cb2.htm/86375cb2/image-20230701221436676.png" class title="image-20230701221436676"><p>选择“MicroPython（ESP32）”和开发板对应的串口号，点击确认。</p><img src="/posts/86375cb2.htm/image-20230701221656057.png" alt="image-20230701221656057" style="zoom:50%;"><p>连接成功后可以在 shell（串口终端）看到固件的相关信息：</p><img src="/posts/86375cb2.htm/image-20230701221713389.png" alt="image-20230701221713389" style="zoom:50%;"><p>我们在 Shell 里面输入 print(“Hello 01Studio!”) , 按回车，可以看到打印出Hello 01Studio 字符：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin</span><br><span class="line">LED = Pin(<span class="number">2</span>, Pin.OUT) </span><br><span class="line">LED.value(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><img src="/posts/86375cb2.htm/image-20230701221806760.png" alt="image-20230701221806760" style="zoom:50%;"><p>接下来我们将上一节的三行代码逐行输入和逐行按回车，可以看到 LED 灯也被点亮：</p><img src="/posts/86375cb2.htm/image-20230701222057224.png" alt="image-20230701222057224" style="zoom:50%;"><p>REPL 还有一个强大的功能就是打印错误的代码来调试程序，在后面代码运行时候，如果程序出错，出错信息将通过 REPL 打印。</p><img src="/posts/86375cb2.htm/image-20230701222115947.png" alt="image-20230701222115947" style="zoom:50%;"><p><strong>REPL</strong> <strong>终端常用键盘按键：</strong></p><p>Ctrl + C : 打断正在运行的程序（特别是含 While True: 的代码）；</p><p>Ctrl + D : 软件复位开发板</p><p> </p><h3 id="文件系统"><strong>文件系统</strong></h3><p>pyWiFi-ESP32-S2 里面内置了文件系统，可以简单理解成上电后运行的 python文件，这个可以通过 Thonny 非常方便地读写。</p><p>点击 <strong>视图</strong>–<strong>文件</strong> ：</p><img src="/posts/86375cb2.htm/image-20230701222203009.png" style="zoom:50%;"><p>可以看到左边出现本地和开发板的实时文件浏览窗口：</p><img src="/posts/86375cb2.htm/image-20230701222237796.png" alt="image-20230701222237796" style="zoom:50%;"><p>在本地文件点击右键—上传到即可将相关文件发送到开发板，也可以将开发板上的文件发送到本地，非常方便。</p><h3 id="代码测试"><strong>代码测试</strong></h3><p>前面已经安装好了 Thonny IDE 和配置，接下来使用最简单的方式来做一个点亮 LED 蓝灯的实验。具体如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：点亮LED蓝灯</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Pin <span class="comment">#导入Pin模块</span></span><br><span class="line"></span><br><span class="line">led=Pin(<span class="number">2</span>,Pin.OUT) <span class="comment">#构建led对象，GPIO2,输出</span></span><br><span class="line">led.value(<span class="number">1</span>) <span class="comment">#点亮LED，也可以使用led.on()</span></span><br></pre></td></tr></table></figure><p>运行功能代码是保存在开发板的 RAM（内存）里面，断电后丢失，那么如何实现开发板上电运行我们的代码呢？方法如下：</p><p>Micropython 上电默认先运行名字为 <a href="http://boot.py">boot.py</a> 文件，然后在运行 <a href="http://main.py">main.py</a> 文件，如果没有 <a href="http://boot.py">boot.py</a> 那么直接运行 <a href="http://main.py">main.py</a>。</p><p><strong><a href="http://boot.py">boot.py</a>:</strong> <strong>一般用于配置初始化参数；</strong></p><p><strong><a href="http://main.py">main.py</a></strong>**：主程序**</p><p>也就是我们只需要将代码以 <a href="http://main.py">main.py</a> 文件发送到开发板，那么开发板就可以实现上电运行相关程序。</p><p>我们将 LED 例程的 <a href="http://main.py">main.py</a> 发送到开发板</p><img src="/posts/86375cb2.htm/image-20230701222956537.png" alt="image-20230701222956537" style="zoom:50%;"><p>按下开发板的复位键，可以看到 LED 蓝灯被点亮：</p><img src="/posts/86375cb2.htm/image-20230701223032307.png" alt="image-20230701223032307" style="zoom:50%;"><h3 id="固件更新"><strong>固件更新</strong></h3><p>固件更新是指重新烧写开发板的出厂文件或者是升级的固件，使用上海乐鑫提供的官方软件烧录：</p><img src="/posts/86375cb2.htm/image-20230701223127927.png" alt="image-20230701223127927" style="zoom:50%;"><p>芯片这里选择 ESP32-S2，develop 开发者模式，然后点击 OK :</p><img src="/posts/86375cb2.htm/image-20230701223146766.png" alt="image-20230701223146766" style="zoom:50%;"><p>选择 SPIDownload，在下图箭头位置点击，选择要烧录固件。</p><p>其它配置选项也请参考下图，注意下载地址是 <strong>0x1000</strong>。（COM 串口是选择自己的串口，在设备管理器查询。）</p><img src="/posts/86375cb2.htm/image-20230701223234252.png" alt="image-20230701223234252" style="zoom:50%;"><p>配置好后，先点击“ERASE”按钮刷除模块里面内容。点击软件下方“ERASE”按钮，刷除成功后，左边绿色框出现完成字样</p><img src="/posts/86375cb2.htm/86375cb2/image-20230701223253705.png" class title="image-20230701223253705"><p>刷除成功后，点击“START”按钮开始烧录，烧录完成有左边绿色框出现“完成”字样。完成后记得点”stop”按钮或者关闭软件释放串口。</p><img src="/posts/86375cb2.htm/86375cb2/image-20230701223316527.png" class title="image-20230701223316527">]]></content>
      
      
      
        <tags>
            
            <tag> esp32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210项目</title>
      <link href="/posts/384e6f73.html"/>
      <url>/posts/384e6f73.html</url>
      
        <content type="html"><![CDATA[<h2 id="照相机">照相机</h2><p>本项目主要是按键应用和拍照的相结合，这些内容可以在前面的实验找到，这里不再重复</p><p>外部中断按键实验：请参阅 <strong>4.4</strong> <strong>外部中断</strong> 章节内容；</p><p>拍摄照片实验：请参阅 <strong>5.9</strong> <strong>图片拍摄</strong> 章节内容。</p><p>拍照后我们应该让图片停留一段时间，让用户观察照片的拍摄情况，然后再进行继续拍摄。代码编写流程如下：</p><h3 id="代码如下">代码如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor, lcd, utime</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"></span><br><span class="line"><span class="comment">#注册 KEY 的外部 IO</span></span><br><span class="line">fm.register(<span class="number">16</span>, fm.fpioa.GPIOHS0, force=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#构建 KEY 对象</span></span><br><span class="line">KEY=GPIO(GPIO.GPIOHS0, GPIO.IN, GPIO.PULL_UP)</span><br><span class="line"></span><br><span class="line"><span class="comment">#摄像头初始化</span></span><br><span class="line"></span><br><span class="line">sensor.reset() <span class="comment"># Initialize the camera sensor.</span></span><br><span class="line">sensor.set_pixformat(sensor.RGB565) <span class="comment"># or sensor.GRAYSCALE</span></span><br><span class="line">sensor.set_framesize(sensor.QVGA) <span class="comment"># or sensor.QVGA (or others)</span></span><br><span class="line">sensor.skip_frames(<span class="number">30</span>) <span class="comment"># Let new settings take affect.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#sensor.set_vflip(1) #摄像头后置模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#LCD 初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line"></span><br><span class="line">key_node = <span class="number">0</span> <span class="comment">#按键标志位</span></span><br><span class="line">name_num = <span class="number">0</span> <span class="comment">#照片名字</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line"><span class="comment"># 按键和其回调函数</span></span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">KEY</span>):</span><br><span class="line"></span><br><span class="line"> <span class="keyword">global</span> key_node</span><br><span class="line"> utime.sleep_ms(<span class="number">10</span>) <span class="comment">#消除抖动</span></span><br><span class="line"> <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#确认按键被按下</span></span><br><span class="line">  key_node = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#开启中断，下降沿触发</span></span><br><span class="line"></span><br><span class="line">KEY.irq(fun, GPIO.IRQ_FALLING)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line"> lcd.display(sensor.snapshot()) <span class="comment"># LCD 实时显示</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> key_node==<span class="number">1</span>: <span class="comment">#按键被按下</span></span><br><span class="line">  key_node = <span class="number">0</span> <span class="comment">#清空按键标志位</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">#拍照并保存，保存文件用时间来命名。</span></span><br><span class="line">  lcd.display(sensor.snapshot().save(<span class="built_in">str</span>(name_num)+<span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line"></span><br><span class="line">  name_num=name_num+<span class="number">1</span> <span class="comment">#名字编码加 1</span></span><br><span class="line"></span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;Done! Reset the camera to see the saved image.&quot;</span>)</span><br><span class="line"></span><br><span class="line"> <span class="comment">#延时 3 秒，观看拍摄图片</span></span><br><span class="line"></span><br><span class="line">  utime.sleep_ms(<span class="number">3000</span>)</span><br></pre></td></tr></table></figure><p> </p><p> </p><h2 id="视频播放器"><strong>视频播放器</strong></h2><p>音视频解码是一个复杂的过程，但 K210 底层 MicroPython 库写好后，着重应用来编程就变得非常简单了。和以往一样，我们只需要熟悉模块用法即可。</p><p>本实验实验 01Studio 音频模块，基于 PAM8403 的一款 D 类功放 IC，和麦克风一样使用 I2S 接口通信，这里不再重复 I2S 内容。</p><p>而视频播放被封装成 video 模块，在前面视频录制章节内容已经介绍过，这里重温一下，模块说明如下</p><p> </p><p><strong>构造函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> video</span><br><span class="line"></span><br><span class="line">v=vedio.<span class="built_in">open</span>((path, record=<span class="literal">False</span>, interval=<span class="number">100000</span>, quality=<span class="number">50</span>,width=<span class="number">320</span>, height=<span class="number">240</span>, audio=<span class="literal">False</span>, sample_rate=<span class="number">44100</span>, channels=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>播放或录制视频文件。</p><p>【path】文件路径，比如：/sd/badapple.avi；</p><p>【record】=True 表示视频录制，=False 表示视频播放；</p><p>【interval】录制帧间隔，单位是微妙；FPS=1000000/interval，默认值</p><p>是 100000，即 FPS 默认是 10（每秒 10 帧）；</p><p>【quality】jpeg 压缩质量（%），默认 50；</p><p>【width】录制屏幕宽度，默认 320；</p><p>【height】录制屏幕高度，默认 240；</p><p>【audio】是否录制音频，默认 False;</p><p>【sample_rate】录制音频采样率，默认 44100（44.1k）;</p><p>【channels】录制音频声道数，默认 1，即单声道。</p><h3 id="使用方法"><strong>使用方法</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.play()</span><br></pre></td></tr></table></figure><p>播放视频；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.volume([value])</span><br></pre></td></tr></table></figure><p>设置音量值。</p><p>【value】0-100;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.revord ()</span><br></pre></td></tr></table></figure><p>录制音视频；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.revord_finish ()</span><br></pre></td></tr></table></figure><p>停止录制；</p><p>*更多使用说明请阅读官方文档：</p><p><a href="https://maixpy.sipeed.com/zh/libs/machine_vision/video.html">https://maixpy.sipeed.com/zh/libs/machine_vision/video.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：视频播放器</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2019.12</span></span><br><span class="line"><span class="string">翻译和注释：01Studio</span></span><br><span class="line"><span class="string">说明：AVI视频播放。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> video,time</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> board <span class="keyword">import</span> board_info</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">import</span> lcd</span><br><span class="line"></span><br><span class="line">lcd.init()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 音频使能IO</span></span><br><span class="line">AUDIO_PA_EN_PIN = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#注册音频使能IO</span></span><br><span class="line"><span class="keyword">if</span> AUDIO_PA_EN_PIN:</span><br><span class="line">    fm.register(AUDIO_PA_EN_PIN, fm.fpioa.GPIO1, force=<span class="literal">True</span>)</span><br><span class="line">    audio_en=GPIO(GPIO.GPIO1, GPIO.OUT,value=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#注册音频控制IO</span></span><br><span class="line">fm.register(<span class="number">34</span>,  fm.fpioa.I2S0_OUT_D1, force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">35</span>,  fm.fpioa.I2S0_SCLK, force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">33</span>,  fm.fpioa.I2S0_WS, force=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#播放avi文件</span></span><br><span class="line">v = video.<span class="built_in">open</span>(<span class="string">&quot;/sd/badapple.avi&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印视频文件信息</span></span><br><span class="line"><span class="built_in">print</span>(v)</span><br><span class="line"></span><br><span class="line"><span class="comment">#音量调节</span></span><br><span class="line">v.volume(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">if</span> v.play() == <span class="number">0</span>: <span class="comment">#播放完毕</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;play end&quot;</span>)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">v.__del__() <span class="comment">#销毁对象，释放内存</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>本实验播放的视频是 badapple.avi，文件在本例程文件夹中，先将该文件拷贝到 sd 卡。然后将 sd 卡插到 pyAI-K210。</p><p>接上 01Studio 音频模块，运行本实验程序代码，可以见到串口终端打印了avi 视频信息后，开发板便开始播放视频。</p><p> </p><p> </p><h2 id="NES-游戏机"><strong>NES</strong> <strong>游戏机</strong></h2><p>MaixPy 集成了 NES 的 MicroPython 模块,用户通过几行代码就可以实现游戏的加载，已经使用键盘或者标准游戏手柄来操控。NES 对象如下：</p><h3 id="构造函数"><strong>构造函数</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> nes</span><br></pre></td></tr></table></figure><p>导入 nes 模块；</p><h3 id="使用方法-2"><strong>使用方法</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nes.init(rc_type=nes.KEYBOARD, cs, mosi, miso, clk, repeat=<span class="number">16</span>,vol=<span class="number">5</span>)</span><br></pre></td></tr></table></figure><p>初始化 nes 游戏模拟器；</p><p>【rc_type】遥控类型。nes.KEYBOARD:REPL 中使用键盘；nes.JOYSTICK:PS2 手柄。</p><p>【cs,mosi,miso,clk】使用 PS2 手柄时的引脚配置；</p><p>【repeat】键盘按键重复率；</p><p>【vol】音量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nes.run(xx.nes)</span><br></pre></td></tr></table></figure><p>运行 nes 文件。</p><p>*更多使用说明请阅读官方文档：</p><p> </p><p>键盘和手柄的快捷键如下：</p><h4 id="键盘（串口）">键盘（串口）</h4><p>【移动】：WSAD(上下左右)</p><p>【A】：J</p><p>【B】：K</p><p>【start】：M 或 Enter</p><p>【option】：N 或\</p><p>【退出】：ESC</p><p>【音量-】：-</p><p>【音量+】：=</p><p>【运行速度-】：R</p><p>【运行速度+】：F</p><h4 id="PS2-手柄">PS2 手柄</h4><p>【移动】：方向键(上下左右)</p><p>【A】：口</p><p>【B】：X</p><p>【start】：START</p><p>【option】：SELECT</p><p>【退出】：暂无</p><p>【音量-】：R2</p><p>【音量+】：R1</p><p>【运行速度-】：L1</p><p>【运行速度+】：L2</p><p>从上表 NES 对象看到，只需要简单的初始化和运行语句，即可运行 NES 游戏模拟器，编程思路如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> nes, lcd</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 音频使能IO</span></span><br><span class="line">AUDIO_PA_EN_PIN = <span class="number">32</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#注册音频使能IO</span></span><br><span class="line"><span class="keyword">if</span> AUDIO_PA_EN_PIN:</span><br><span class="line">    fm.register(AUDIO_PA_EN_PIN, fm.fpioa.GPIO1, force=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#LCD初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化nes，配置为键盘控制</span></span><br><span class="line">nes.init(nes.KEYBOARD)</span><br><span class="line"></span><br><span class="line"><span class="comment">#运行游戏</span></span><br><span class="line">nes.run(<span class="string">&quot;/sd/Bomberman.nes&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210拓展模块</title>
      <link href="/posts/a4696bae.html"/>
      <url>/posts/a4696bae.html</url>
      
        <content type="html"><![CDATA[<h2 id="拓展模块"><strong>拓展模块</strong></h2><h3 id="电阻触摸屏"><strong>电阻触摸屏</strong></h3><p>本实验 LCD 触摸屏上使用 NS2009 芯片，将电阻触摸屏信号转化为 I2C 信号跟 K210 通信，而 MaixPy 已经集成了触摸屏应用的相关函数模块，具体介绍如下：</p><h4 id="构造函数"><strong>构造函数</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> touchscreen <span class="keyword">as</span> ts</span><br></pre></td></tr></table></figure><p>导入 touchscreen 模块;</p><h4 id="使用方法"><strong>使用方法</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ts.init(i2c=<span class="literal">None</span>,cal=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p>初始化触摸屏。</p><p>【i2c】I2C 总线；</p><p>【cal】一个 7 个整型值的元组，触摸校准数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ts.calibrate()</span><br></pre></td></tr></table></figure><p>触摸校准。返回一个 7 个整型值的元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ts.read()</span><br></pre></td></tr></table></figure><p>读取屏幕状态和坐标信息。返回（status,x,y）</p><p>【status】: 触摸状态，取值有如下</p><p>touchscreen.STATUS_RELEASE,值为 1，触摸屏没动作；</p><p>touchscreen.STATUS_PRESS,值为 2，触摸屏被按下；</p><p>touchscreen.STATUS_MOVE,值为 3，触摸屏在滑动；</p><p>【x】x 轴坐标</p><p>【y】y 轴坐标</p><h4 id="代码如下">代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> I2C</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">import</span> lcd, image</span><br><span class="line"><span class="keyword">import</span> touchscreen <span class="keyword">as</span> ts</span><br><span class="line"></span><br><span class="line"><span class="comment">#按键 KEY 用于清屏</span></span><br><span class="line">fm.register(<span class="number">16</span>, fm.fpioa.GPIO1, force=<span class="literal">True</span>)</span><br><span class="line">btn_clear = GPIO(GPIO.GPIO1, GPIO.IN)</span><br><span class="line"></span><br><span class="line"><span class="comment">#触摸使用 I2C 控制（NS2009）</span></span><br><span class="line">i2c = I2C(I2C.I2C0, freq=<span class="number">400000</span>, scl=<span class="number">30</span>, sda=<span class="number">31</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#触摸屏初始化</span></span><br><span class="line">ts.init(i2c)</span><br><span class="line"><span class="comment">#ts.calibrate() #触摸校准</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#LCD 初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line">lcd.clear()</span><br><span class="line"></span><br><span class="line"><span class="comment">#新建图像和触摸屏相关参数变量</span></span><br><span class="line">img = image.Image()</span><br><span class="line">status_last = ts.STATUS_IDLE</span><br><span class="line">x_last = <span class="number">0</span></span><br><span class="line">y_last = <span class="number">0</span></span><br><span class="line">draw = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line"> <span class="comment">#获取触摸屏状态</span></span><br><span class="line"> (status,x,y) = ts.read()</span><br><span class="line"> <span class="built_in">print</span>(status, x, y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line"> <span class="keyword">if</span> draw:</span><br><span class="line">  img.draw_line((x_last, y_last, x, y))</span><br><span class="line"></span><br><span class="line"> <span class="comment">#更新最后坐标</span></span><br><span class="line"> x_last = x</span><br><span class="line"> y_last = y</span><br><span class="line"></span><br><span class="line"> <span class="comment">#根据触摸屏状态判断是否继续执行画图功能</span></span><br><span class="line"> <span class="keyword">if</span> status_last!=status:</span><br><span class="line">  <span class="keyword">if</span> (status==ts.STATUS_PRESS <span class="keyword">or</span> status == ts.STATUS_MOVE):</span><br><span class="line">   draw = <span class="literal">True</span></span><br><span class="line">  <span class="keyword">else</span>: <span class="comment">#松开</span></span><br><span class="line">   draw = <span class="literal">False</span></span><br><span class="line">  status_last = status</span><br><span class="line">    </span><br><span class="line"> <span class="comment">#LCD 显示</span></span><br><span class="line"> lcd.display(img)</span><br><span class="line">    </span><br><span class="line"> <span class="comment">#按键 KEY 按下清屏</span></span><br><span class="line"> <span class="keyword">if</span> btn_clear.value() == <span class="number">0</span>:</span><br><span class="line">  img.clear()</span><br></pre></td></tr></table></figure><p>固件用如下所示固件，其中含有touchscreen库</p><p> </p><p> </p><h3 id="舵机"><strong>舵机</strong></h3><p>伺服电机对象通过 3 线（信号，电源，地）控制，pyBase 上有 4 个位置可以插这些电机，分别是 X1-X4 引脚。对应 pyAI-K210 的 17、35、34、33 脚。</p><p>180°舵机的控制一般需要一个 20ms 左右的时基脉冲，该脉冲的高电平部分一般为 0.5ms-2.5ms 范围内的角度控制脉冲部分，总间隔为 2ms。以 180 度角度伺服为例，在 MicroPython 编程对应的控制关系是从-90°至 90°，示例图如下</p><p>而对于 360°连续旋转舵机，上面的脉冲表则对应从正向最大速度旋转到反向最大速度旋转的过程。</p><p>如果过你学习过前面基于 STM32 平台的舵机实验，那就知道在 STM32 平台集成了舵机模块，使用起来非常方便。当前的 ESP32 平台并没有集成 Servo 模块，但从上面可以看到上面是通过 PWM 来控制的，我们可以直接写 PWM 函数驱动即可。代码编程流程图如下：</p><h4 id="代码如下-2">代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Timer,PWM</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment">#PWM 通过定时器配置，接到 IO17 引脚</span></span><br><span class="line">tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)</span><br><span class="line">S1 = PWM(tim, freq=<span class="number">50</span>, duty=<span class="number">0</span>, pin=<span class="number">17</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">说明：舵机控制函数</span></span><br><span class="line"><span class="string">功能：180 度舵机：angle:-90 至 90 表示相应的角度</span></span><br><span class="line"><span class="string"> 360 连续旋转度舵机：angle:-90 至 90 旋转方向和速度值。</span></span><br><span class="line"><span class="string"> 【duty】占空比值：0-100</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Servo</span>(<span class="params">servo,angle</span>):</span><br><span class="line"> S1.duty((angle+<span class="number">90</span>)/<span class="number">180</span>*<span class="number">10</span>+<span class="number">2.5</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"></span><br><span class="line"> <span class="comment">#-90 度</span></span><br><span class="line"> Servo(S1,-<span class="number">90</span>)</span><br><span class="line"> time.sleep(<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#-45 度</span></span><br><span class="line"> Servo(S1,-<span class="number">45</span>)</span><br><span class="line"> time.sleep(<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#0 度</span></span><br><span class="line"> Servo(S1,<span class="number">0</span>)</span><br><span class="line"> time.sleep(<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#45 度</span></span><br><span class="line"> Servo(S1,<span class="number">45</span>)</span><br><span class="line"> time.sleep(<span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#90 度</span></span><br><span class="line"> Servo(S1,<span class="number">90</span>)</span><br><span class="line"> time.sleep(<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>将 180°舵机插到 pyBase 的 X1 的三线接口，运行程序。可以看到舵机依次旋转至不同角度。</p><p>⚫ <strong>实验拓展：</strong></p><p>我们刚刚实现了 180°舵机的角度控制，现在来做一下 360°连续旋转舵机的实验，360°连续旋转舵机可以实现直流减速电机功能，用在小车或者航模上。</p><p>实验的代码不变，参数【-90 至 90】代表旋转方向和速度值大小。插上 360°连续旋转舵机。可以看到舵机的旋转速度和方向逐渐变变化。</p>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器听觉</title>
      <link href="/posts/e06f755d.html"/>
      <url>/posts/e06f755d.html</url>
      
        <content type="html"><![CDATA[<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.email &quot;1273339296@qq.com&quot;</span><br><span class="line">git config --global user.name &quot;Rozen12123&quot;</span><br><span class="line"></span><br><span class="line">ssh-keygen -t rsa -C &quot;1273339296@qq.com&quot; </span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210机器视觉</title>
      <link href="/posts/210a3ee2.html"/>
      <url>/posts/210a3ee2.html</url>
      
        <content type="html"><![CDATA[<h2 id="机器视觉">机器视觉</h2><h3 id="LCD"><strong>LCD</strong></h3><p>LCD 液晶显示屏是非常常见的一个外接显示设备，跟前面的 OLED 显示屏相比，LCD 会更常用一些，我们看到的手持设备、小型电器，很多都用到 LCD，部分配合触摸屏应用，能实现非常多的功能。</p><p>除此之外，LCD 还是 pyAI-K210 机器视觉应用中显示的重要工具。</p><p>本实验用的 LCD 是 2.8 寸，驱动是常见的 ST7789V，使用 8 位接口跟 pyAIK210 通信，按以往嵌入式 C 语言开发，我们需要对 ST7789 进行编程实现驱动，然后再建立各种字符显示及显示图片等函数。使用 MicroPython 其实也需要做以上工作，但由于可读性和移植性强的特点，我们只需要搞清各个对象函数使如何使用即可。总的来说和之前一样，有构造函数和功能函数。构造函数解决的是初始化问题，告诉 pyAI-K210 外设是怎么接线，是什么样的；而功能函数解决的则是使用问题，我们基于自己的需求直接调用相关功能函数，实现自己的功能即可！我们管这些函数的集合叫驱动，MaixPy 已经将这 <a href="http://LCD.py">LCD.py</a> 驱动写好了，我们学会如何使用即可。其构造函数和使用方法如下：</p><p> </p><h4 id="构造函数">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.init(<span class="built_in">type</span>=<span class="number">1</span>,freq=<span class="number">15000000</span>,color=lcd.BLACK)</span><br></pre></td></tr></table></figure><p>初始化 LCD。</p><p>【type】LCD 类型；</p><p>【freq】通信频率；</p><p>【color】LCD 初始化的颜色。</p><h4 id="使用方法">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.deinit()</span><br></pre></td></tr></table></figure><p>注销 LCD 驱动，释放 IO 引脚。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.clear(color)</span><br></pre></td></tr></table></figure><p>填充指定颜色。默认是黑色</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.draw_string(x,y,<span class="built_in">str</span>,color,bg_color)</span><br></pre></td></tr></table></figure><p>写字符</p><p>【x,y】起始坐标；</p><p>【str】字符内容</p><p>【color】字体颜色</p><p>【bg_color】字体背景颜色</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.display(image,roi=Auto)</span><br></pre></td></tr></table></figure><p>显示图片。</p><p>【image】RGB565 或 GRAYSCALE 图片。</p><p>【ROI】显示的感兴趣区域，未指定则为图像大小。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.rotation(<span class="built_in">dir</span>)</span><br></pre></td></tr></table></figure><p>LCD 屏幕方向设定。</p><p>【dir】取值范围[0-3]，从 0 到 3 依顺时钟旋转。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lcd.mirror(invert)</span><br></pre></td></tr></table></figure><p>镜面显示。</p><p>【invert】=True 则为镜面显示；=False 则否。</p><p>更多 LCD 模块说明请看 MaxiPy 官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/lcd.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/lcd.html</a></p><p>有了上面的对象构造函数和使用说明，编程可以说是信手拈来了，我们来跑</p><p>一下其主要功能显示字符和图像，代码编写流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lcd,image,utime</span><br><span class="line">lcd.init() <span class="comment">#初始化 LCD</span></span><br><span class="line">lcd.clear(lcd.WHITE) <span class="comment">#清屏白色</span></span><br><span class="line"><span class="comment">#显示字符</span></span><br><span class="line">lcd.draw_string(<span class="number">110</span>, <span class="number">120</span>, <span class="string">&quot;Hello 01Studio!&quot;</span>,lcd.BLACK, lcd.WHITE) <span class="comment">#显示字符</span></span><br><span class="line">utime.sleep(<span class="number">2</span>) <span class="comment">#延时 2 秒</span></span><br><span class="line">lcd.rotation(<span class="number">1</span>) <span class="comment">#由于图像默认是 240*320，因此顺时钟旋转 90°。</span></span><br><span class="line"><span class="comment">#显示图像，必须先将 01Studio.bmp 文件发送到开发板才能正常运行</span></span><br><span class="line">lcd.display(image.Image(<span class="string">&quot;01Studio.bmp&quot;</span>))</span><br></pre></td></tr></table></figure><p> </p><h3 id="摄像头应用"><strong>摄像头应用</strong></h3><p>从前面的基础实验我们熟悉了 K210 基于 MicroPython 的编程方法，但那可以说是只发挥了 K210 冰山一角的性能应用，摄像头是整个机器视觉应用的基础。今天我们就通过示例代码来看看 pyAI-K210 是如何使用摄像头的。</p><p> </p><p>MaixPy 机器视觉库代码大部分都是参考 OpenMV 移植过来，其已经将所有的摄像头功能封装到 sersor 模块中，用户可以通过调用轻松使用。这也是使用MicroPython 编程的魅力所在。</p><p> </p><h4 id="构造函数-2">构造函数</h4><p>sensor</p><p>摄像头对象，通过 import 直接调用</p><h4 id="使用方法-2">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.reset()</span><br></pre></td></tr></table></figure><p>初始化摄像头</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.set_pixformat(*pixformat*)</span><br></pre></td></tr></table></figure><p>设置像素格式。pixformat 有 3 个参数。</p><p>sensor.GRAYSCAL：灰度图像，每像素 8 位（1 字节），处理速度快；</p><p>sensor.RGB565: 每像素为 16 位（2 字节），5 位用于红色，6 位用于绿色，5 位用于蓝色，处理速度比灰度图像要慢。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.set_framesize(*framesize*)</span><br></pre></td></tr></table></figure><p>设置每帧大小（即图像尺寸）。常用的 <em>framesize</em> 参数有下面这些：</p><p>sensor.QQVGA: 160*120;</p><p>sensor.QVGA: 320*240;</p><p>sensor.VGA: 640*480;</p><p>sensor.skip_frames([<em>n</em>, <em>time</em>])</p><p>摄像头配置后跳过 n 帧或者等待时间 time 让其变稳定。n:跳过帧数；time：等待</p><p>时间,单位 ms。</p><p>（如果 n 和 time 均没指定，则默认跳过 300 毫秒的帧。）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.snapshot()</span><br></pre></td></tr></table></figure><p>使用相机拍摄一张照片，并返回 image 对象。</p><p>*其它更多用法请阅读 MaixPy 官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_visio">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_visio</a></p><p>n/sensor.html</p><p> </p><p>我们再来看看本例程用于计算 FPS（每秒帧数）的 clock 模块。</p><h4 id="构造函数-3">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clock=time.clock()</span><br></pre></td></tr></table></figure><p>创建一个时钟。</p><h4 id="使用方法-3">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clock.tick()</span><br></pre></td></tr></table></figure><p>开始追踪运行时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clock.fps ()</span><br></pre></td></tr></table></figure><p>停止追踪运行时间，并返回当前 FPS（每秒帧数）。</p><p>在调用该函数前始终首先调用 tick 。</p><p>*其它更多用法请阅读 Maixpy 官方文档：</p><p>文档链接：<a href="http://docs.openmv.io/library/omv.time.html">http://docs.openmv.io/library/omv.time.html</a></p><p> </p><p> </p><p>我们来看看 helloword 代码的编写流程图：</p><p>这个实验运行的就是编辑框里面的 helloworld 代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor, image, time, lcd</span><br><span class="line">lcd.init(freq=<span class="number">15000000</span>) <span class="comment">#初始化 LCD</span></span><br><span class="line">sensor.reset() <span class="comment">#复位和初始化摄像头，执行 sensor.run(0)停止。</span></span><br><span class="line"><span class="comment">#sensor.set_vflip(1) #将摄像头设置成后置方式（所见即所得）</span></span><br><span class="line">sensor.set_pixformat(sensor.RGB565) <span class="comment"># 设置像素格式为彩色 RGB565 (或灰色)</span></span><br><span class="line">sensor.set_framesize(sensor.QVGA) <span class="comment"># 设置帧大小为 QVGA (320x240)</span></span><br><span class="line">sensor.skip_frames(time = <span class="number">2000</span>) <span class="comment"># 等待设置生效.</span></span><br><span class="line">clock = time.clock() <span class="comment"># 创建一个时钟来追踪 FPS（每秒拍摄帧数）</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line"> clock.tick() <span class="comment"># 更新 FPS 时钟.</span></span><br><span class="line"> img = sensor.snapshot() <span class="comment"># 拍摄一个图片并保存.</span></span><br><span class="line"> lcd.display(img) <span class="comment"># 在 LCD 上显示</span></span><br><span class="line"> <span class="built_in">print</span>(clock.fps()) <span class="comment"># 注意: 当 K210 连接到 IDE 时候，运行速度减</span></span><br><span class="line"> <span class="comment">#半，因此当断开 IDE 时 FPS 会提升。</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="画图"><strong>画图</strong></h3><p>通过摄像头采集到照片后，我们会进行一些处理，而这时候往往需要一些图形来指示，比如在图片某个位置标记箭头、人脸识别后用矩形框提示等。本节就是学习在图形上画图的使用功能。</p><h4 id="构造函数-4">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img=sensor.snapshot() 或 img=image.Image(path[, copy_to_fb=<span class="literal">False</span>])</span><br></pre></td></tr></table></figure><p>创建图像，通过拍摄或者读取文件路径获取。</p><p><em>copy_to_fb=True</em>*：可以加载大图片；*</p><p>copy_to_fb=False：不可以加载大图片。</p><p>示例：img = image.Image(“01Studio.bmp”, copy_to_fb=True),表示加载根</p><p>目录下的 01Studio.bmp 图片。</p><h4 id="使用方法-4">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_line(*x0*, *y0*, *x1*, *y1*[, *color*[, *thickness=<span class="number">1</span>*]])</span><br></pre></td></tr></table></figure><p>画线段。（x0,y0）:起始坐标；（x1,y1）:终点坐标；color:颜色，如</p><p>（255,0,0）表示红色；thickness：粗细。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_rectangle(*x*, *y*, *w*, *h*[, *color*[, thickness*=<span class="number">1</span>*[, *fill=<span class="literal">False</span>*]]])</span><br></pre></td></tr></table></figure><p>画矩形。（x,y）:起始坐标；w:宽度；h:长度；color：颜色；thickness：边框粗细；fill:是否填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_circle(*x*, *y*, *radius*[, *color*[, thickness*=<span class="number">1</span>*[, *fill=<span class="literal">False</span>*]]])</span><br></pre></td></tr></table></figure><p>画圆。（x,y）:圆心； radius:半径； color：颜色；thickness:线条粗细；</p><p>fill：是否填充。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_arrow(*x0*, *y0*, *x1*, *y1*[, *color*[, size,[thickness*=<span class="number">1</span>]*]])</span><br></pre></td></tr></table></figure><p>画箭头。（x0,y0）:起始坐标；（x1,y1）:终点坐标；color:颜色；size:箭头位置大小。thickness：线粗细。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_cross(*x*, *y*[, *color*[, *size=<span class="number">5</span>*[, *thickness=<span class="number">1</span>*]]])</span><br></pre></td></tr></table></figure><p>画十字交叉。（x,y）:交叉坐标；color:颜色；size:尺寸；thickness：线粗细。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.draw_string(*x*, *y*, *text*[, *color*[, *scale=*<span class="number">1</span>[,*mono_space=<span class="literal">True</span>*…]]]])</span><br></pre></td></tr></table></figure><p>写字符。(x,y): 起始坐标；text:字符内容；color：颜色；scale：字体大小；</p><p>mono_space:强制间距。</p><p>*其它更多用法请阅读 MaixPy 官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html</a></p><p> </p><p>熟悉了 image 对象的画图功能后，我们尝试在摄像头采集到的画面依次画出线段、矩形、圆形、箭头、十字交叉和字符。具体编程思路如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor, image, time, lcd</span><br><span class="line">lcd.init(freq=<span class="number">15000000</span>)</span><br><span class="line">sensor.reset() <span class="comment">#复位摄像头</span></span><br><span class="line"><span class="comment">#sensor.set_vflip(1) #将摄像头设置成后置方式（所见即所得）</span></span><br><span class="line">sensor.set_pixformat(sensor.RGB565) <span class="comment"># 设置像素格式 RGB565 (or GRAYSCALE)</span></span><br><span class="line">sensor.set_framesize(sensor.QVGA) <span class="comment"># 设置帧尺寸 QVGA (320x240)</span></span><br><span class="line">sensor.skip_frames(time = <span class="number">2000</span>) <span class="comment"># 灯带设置响应.</span></span><br><span class="line">clock = time.clock() <span class="comment"># 新建一个时钟对象计算 FPS.</span></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line"> clock.tick() </span><br><span class="line"> img = sensor.snapshot() </span><br><span class="line"> </span><br><span class="line"> <span class="comment"># 画线段：从 x0, y0 到 x1, y1 坐标的线段，颜色红色，线宽度 2。</span></span><br><span class="line"> img.draw_line(<span class="number">20</span>, <span class="number">20</span>, <span class="number">100</span>, <span class="number">20</span>, color = (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), thickness = <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#画矩形：绿色不填充。</span></span><br><span class="line"> img.draw_rectangle(<span class="number">150</span>, <span class="number">20</span>, <span class="number">100</span>, <span class="number">30</span>, color = (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>),</span><br><span class="line"> thickness = <span class="number">2</span>, fill = <span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#画圆：蓝色不填充。</span></span><br><span class="line"> img.draw_circle(<span class="number">60</span>, <span class="number">120</span>, <span class="number">30</span>, color = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">255</span>), thickness = <span class="number">2</span>,</span><br><span class="line"> fill = <span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#画箭头：白色。</span></span><br><span class="line"> img.draw_arrow(<span class="number">150</span>, <span class="number">120</span>, <span class="number">250</span>, <span class="number">120</span>, color = (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), size =</span><br><span class="line"> <span class="number">20</span>, thickness = <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#画十字交叉。</span></span><br><span class="line"> img.draw_cross(<span class="number">60</span>, <span class="number">200</span>, color = (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>), size = <span class="number">20</span>,</span><br><span class="line"> thickness = <span class="number">2</span>)</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#写字符。</span></span><br><span class="line"> img.draw_string(<span class="number">150</span>, <span class="number">200</span>, <span class="string">&quot;Hello 01Studio!&quot;</span>, color = (<span class="number">255</span>, <span class="number">255</span>,</span><br><span class="line"> <span class="number">255</span>), scale = <span class="number">2</span>,mono_space = <span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line"> lcd.display(img) <span class="comment"># Display on LCD</span></span><br><span class="line"> <span class="built_in">print</span>(clock.fps()) <span class="comment"># Note: MaixPy&#x27;s Cam runs about half as fast when connected</span></span><br><span class="line"> <span class="comment"># to the IDE. The FPS should increase once disconnected</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="颜色识别"><strong>颜色识别</strong></h3><p>我们活在一个色彩斑斓的世界里。本节我们来学习机器视觉中的颜色识别。我们会预先设定颜色阈值，如红、绿、蓝。这样 K210 摄像头采集图像后就能自动识别了。</p><p> </p><p>通过编程实现 pyAI-K210 识别程序预先设定的颜色色块，分别是红、绿、蓝三种颜色。</p><p>MaixPy 集成了 RGB565 颜色块识别 find_blobs 函数，主要是基于 LAB 颜色模型（每个颜色都是用一组 LAB 阈值表示，有兴趣的用户可以自行查阅相关模型资料）。其位于 image 模块下，因此我们直接将拍摄到的图片进行处理即可，那么我们像以往一样像看一下本实验相关对象和函数说明，具体如下：</p><h4 id="构造函数-5">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.find_blobs(thresholds[,invert=<span class="literal">False</span>[,roi[,x_stride=<span class="number">2</span>[,y_stride=<span class="number">1</span>[,area_threshold=<span class="number">10</span>[,pixels_threshold=<span class="number">10</span>[,merge=<span class="literal">False</span>[,margin=<span class="number">0</span>[, threshold_cb=<span class="literal">None</span>[, merge_cb=<span class="literal">None</span>]]]]]]]]]])</span><br></pre></td></tr></table></figure><p>查找图像中指定的色块。返回 image.blog 对象列表；</p><p>【thresholds】 必须是元组列表。 [(lo, hi), (lo, hi), …, (lo, hi)] 定义你想追踪的颜</p><p>色范围。 对于灰度图像，每个元组需要包含两个值 - 最小灰度值和最大灰</p><p>度值。 仅考虑落在这些阈值之间的像素区域。 对于 RGB565 图像，每个元</p><p>组需要有六个值(l_lo，l_hi，a_lo，a_hi，b_lo，b_hi) - 分别是 LAB L，A 和 B</p><p>通道的最小值和最大值。</p><p>【area_threshold】若色块的边界框区域小于此参数值，则会被过滤掉；</p><p>【pixels_threshold】若色块的像素数量小于此参数值，则会被过滤掉；</p><p>【merge】若为 True,则合并所有没有被过滤的色块；</p><p>【margin】调整合并色块的边缘。</p><h4 id="使用方法-5">使用方法</h4><p>以上函数返回 image.blob。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blob.rect()</span><br></pre></td></tr></table></figure><p>返回一个矩形元组（x,y,w,h）,如色块边界。可以通过索引[0-3]来获得这些值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blob.cx()</span><br></pre></td></tr></table></figure><p>返回色块(int)的中心 x 位置。可以通过索引[5]来获得这个值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blob.cy()</span><br></pre></td></tr></table></figure><p>返回色块(int)的中心 y 位置。可以通过索引[6]来获得这个值。</p><p>*更多使用说明请阅读官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html</a></p><p>了解了找色块函数应用方法后，我们可以理清一下编程思路，代码编写流程如下：</p><p>参考代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor,lcd,time</span><br><span class="line"><span class="comment">#摄像头初始化</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_vflip(<span class="number">1</span>) <span class="comment">#后置模式，所见即所得</span></span><br><span class="line"><span class="comment">#lcd 初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line">clock=time.clock()</span><br><span class="line"><span class="comment"># 颜色识别阈值 (L Min, L Max, A Min, A Max, B Min, B Max) LAB 模型</span></span><br><span class="line"><span class="comment"># 下面的阈值元组是用来识别 红、绿、蓝三种颜色，当然你也可以调整让识别变得更好。</span></span><br><span class="line">thresholds = [(<span class="number">30</span>, <span class="number">100</span>, <span class="number">15</span>, <span class="number">127</span>, <span class="number">15</span>, <span class="number">127</span>), <span class="comment"># 红色阈值</span></span><br><span class="line"> (<span class="number">30</span>, <span class="number">100</span>, -<span class="number">64</span>, -<span class="number">8</span>, -<span class="number">32</span>, <span class="number">32</span>), <span class="comment"># 绿色阈值</span></span><br><span class="line"> (<span class="number">0</span>, <span class="number">30</span>, <span class="number">0</span>, <span class="number">64</span>, -<span class="number">128</span>, -<span class="number">20</span>)] <span class="comment"># 蓝色阈值</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> </span><br><span class="line"> clock.tick()</span><br><span class="line"> </span><br><span class="line"> img=sensor.snapshot()</span><br><span class="line"> </span><br><span class="line"> blobs = img.find_blobs([thresholds[<span class="number">2</span>]]) <span class="comment"># 0,1,2 分别表示红，绿，蓝色。</span></span><br><span class="line"> <span class="keyword">if</span> blobs:</span><br><span class="line">  <span class="keyword">for</span> b <span class="keyword">in</span> blobs:</span><br><span class="line">   tmp=img.draw_rectangle(b[<span class="number">0</span>:<span class="number">4</span>])</span><br><span class="line">   tmp=img.draw_cross(b[<span class="number">5</span>], b[<span class="number">6</span>])</span><br><span class="line"> </span><br><span class="line"> lcd.display(img) <span class="comment">#LCD 显示图片</span></span><br><span class="line"> <span class="built_in">print</span>(clock.fps()) <span class="comment">#打印 FPS</span></span><br></pre></td></tr></table></figure><p>在 IDE 中运行代码，代码默认检测的是蓝色，用户可以自行修改 find_blobs()参数的阈值数组编号来切换识别颜色</p><p> </p><h3 id="二维码识别"><strong>二维码识别</strong></h3><p>相信大家都知道二维码了，特别是在扫描支付越来越流行的今天，二维码的应用非常广泛。今天我们就来学习如何使用 pyAI-K210 开发套件实现二维码信息识别</p><p>而对于 pyAI-K210 而言，直接使用 MicroPython 中的 find_qrcodes()即可获取摄像头采集图像中二维码的相关信息。具体说明如下：</p><h4 id="构造函数-6">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.find_qrcodes([roi])</span><br></pre></td></tr></table></figure><p>查找 roi 区域内的所有二维码并返回一个 image.qrcode 的对象列表。</p><h4 id="使用方法-6">使用方法</h4><p>以上函数返回 image.qrcode 对象列表。</p><p>qrcode.rect()</p><p>返回一个矩形元组（</p><p>x,y,w,h）;</p><p>qrcode.payload()</p><p>返回二维码字符串信息。可以通过索引[4]来获得这个值。</p><p>qrcode.verison()</p><p>返回二维码版本号。</p><p>*更多使用说明请阅读官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html#image.find_qrcodes%28%5Broi%5D%29">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine_vision/image/image.html#image.find_qrcodes([roi])</a></p><p> </p><p>从上表可以看到，使用 MicroPython 编程我们只需要简单地调find_qrcodes()函数，对得到的结果再进行处理即可，非常方便。代码编写流程如下图所示:</p><p>参考代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor,lcd,time</span><br><span class="line"><span class="comment">#摄像头模块初始化</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_vflip(<span class="number">1</span>) <span class="comment">#后置模式</span></span><br><span class="line">sensor.skip_frames(<span class="number">30</span>)</span><br><span class="line"><span class="comment">#lcd 初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line">clock = time.clock()</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> clock.tick()</span><br><span class="line"> img = sensor.snapshot()</span><br><span class="line"> res = img.find_qrcodes() <span class="comment">#寻找二维码</span></span><br><span class="line"> <span class="keyword">if</span> <span class="built_in">len</span>(res) &gt; <span class="number">0</span>: <span class="comment">#在图片和终端显示二维码信息</span></span><br><span class="line">  img.draw_rectangle(res[<span class="number">0</span>].rect())</span><br><span class="line">  img.draw_string(<span class="number">2</span>,<span class="number">2</span>, res[<span class="number">0</span>].payload(), color=(<span class="number">0</span>,<span class="number">128</span>,<span class="number">0</span>), scale=<span class="number">2</span>)</span><br><span class="line">  <span class="built_in">print</span>(res[<span class="number">0</span>].payload())</span><br><span class="line"> lcd.display(img)</span><br><span class="line"> <span class="built_in">print</span>(clock.fps())</span><br></pre></td></tr></table></figure><h3 id="人脸识别">人脸识别</h3><p>pyAI-K210 开发套件，配 SD 卡放模型文件。</p><p>我们来简单介绍一下 K210 的 KPU。KPU 是 K210 内部一个神经网络处理器，它可以在低功耗的情况下实现卷积神经网络计算，实时获取被检测目标的大小、坐标和种类，对人脸或者物体进行检测和分类。</p><p>KPU 具备以下几个特点：</p><p>➢ 支持主流训练框架按照特定限制规则训练出来的定点化模型</p><p>➢ 对网络层数无直接限制，支持每层卷积神经网络参数单独配置，包括输</p><p>入输出通道数目、输入输 出行宽列高</p><p>➢ 支持两种卷积内核 1x1 和 3x3</p><p>➢ 支持任意形式的激活函数</p><p>➢ 实时工作时最大支持神经网络参数大小为 5.5MiB 到 5.9MiB</p><p>➢ 非实时工作时最大支持网络参数大小为（Flash 容量-软件体积）</p><p>简单来说就是 KPU 能加载和运行各种现成的 AI 算法模型，实现各种机器视</p><p>觉等功能。</p><p>MaixPy 中人脸识别本质是目标检测，主要通过在 K210 的 KPU 上跑 YOLO（You Only Look Once）目标检测算法来实现。我们来看一下 KPU 在 MaixPy 下的用法</p><h4 id="构造函数-7">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br></pre></td></tr></table></figure><p>常用的 KPU 模块导入方法。</p><h4 id="使用方法-7">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.load(offset <span class="keyword">or</span> file_path)</span><br></pre></td></tr></table></figure><p>加载模型。</p><p>【offset】模型存放在 flash 的偏移量，如 0x300000;</p><p>【file_path】模型在文件系统为文件名，如“xxx.kmodel”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.init_yolo2(kpu_net,threshold,nms_value,anchor_num,anchor)</span><br></pre></td></tr></table></figure><p>初始化 yolo2 网络；</p><p>【kpu_net】kpu 网络对象；</p><p>【threshold】概率阈值；</p><p>【nms_value】box_iou 门限；</p><p>【anchor_num】描点数；</p><p>【anchor】描点参数与模型参数一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.run_yolo2(kpu_net,image)</span><br></pre></td></tr></table></figure><p>运行 yolo2 网络；</p><p>【kpu_net】从 kpu_load()中返回的网络对象；</p><p>【image】从 sensor 中采集到的图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.deinit(kpu_net)</span><br></pre></td></tr></table></figure><p>反初始化。</p><p>【kpu_net】kpu 网络对象；</p><p> </p><p>从上表可以看到通过 KPU 模块直接加载 YOLO2 网络，再结合人脸检测模型</p><p>来实现人脸识别。具体编程思路如下：</p><h4 id="代码如下">代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor,lcd,time</span><br><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br><span class="line"><span class="comment">#设置摄像头</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line"><span class="comment">#sensor.set_vflip(1) #设置摄像头后置</span></span><br><span class="line">lcd.init() <span class="comment">#LCD 初始化</span></span><br><span class="line">clock = time.clock()</span><br><span class="line"><span class="comment">#需要将模型（face.kfpkg）烧写到 flash 的 0x300000 位置</span></span><br><span class="line"><span class="comment">#task = kpu.load(0x300000) </span></span><br><span class="line"><span class="comment">#将模型放在 SD 卡中。</span></span><br><span class="line">task = kpu.load(<span class="string">&quot;/sd/facedetect.kmodel&quot;</span>) <span class="comment">#模型 SD 卡上</span></span><br><span class="line"><span class="comment">#模型描参数</span></span><br><span class="line">anchor = (<span class="number">1.889</span>, <span class="number">2.5245</span>, <span class="number">2.9465</span>, <span class="number">3.94056</span>, <span class="number">3.99987</span>, <span class="number">5.3658</span>, <span class="number">5.155437</span>, </span><br><span class="line"><span class="number">6.92275</span>, <span class="number">6.718375</span>, <span class="number">9.01025</span>)</span><br><span class="line"><span class="comment">#初始化 yolo2 网络</span></span><br><span class="line">a = kpu.init_yolo2(task, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">5</span>, anchor)</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line"> clock.tick()</span><br><span class="line"> img = sensor.snapshot()</span><br><span class="line"> code = kpu.run_yolo2(task, img) <span class="comment">#运行 yolo2 网络</span></span><br><span class="line"> <span class="comment">#识别到人脸就画矩形表示</span></span><br><span class="line"> <span class="keyword">if</span> code:</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> code:</span><br><span class="line">   <span class="built_in">print</span>(i)</span><br><span class="line">   b = img.draw_rectangle(i.rect())</span><br><span class="line"> <span class="comment">#LCD 显示</span></span><br><span class="line"> lcd.display(img)</span><br><span class="line"> </span><br><span class="line"> <span class="built_in">print</span>(clock.fps()) <span class="comment">#打印 FPS</span></span><br></pre></td></tr></table></figure><p>有了代码后我们还需要将模型放在文件系统中。这里介绍 2 个方法：</p><p><strong>方法一：将模型放在</strong> <strong>SD</strong> <strong>卡中。</strong></p><p>在本节示例程序路径中可以看到有 1 个件夹 <strong>face_model_at_0x300000</strong>将里面的 <strong>facedetect.kmodel</strong> 文件移动到 SD 卡，运行上述代码即可。</p><p><strong>方法二：将模型烧录到</strong> <strong>K210</strong> <strong>的</strong> <strong>Flash</strong> <strong>中。</strong></p><p>打开本节示例程序路径的件夹<strong>face_model_at_0x300000</strong>里面的<strong>flash-list.json</strong>文件，内容如下（告诉烧录软件烧写地址和文件名）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> &quot;version&quot;: &quot;0.1.0&quot;,</span><br><span class="line"> &quot;files&quot;: [</span><br><span class="line"> &#123;</span><br><span class="line"> &quot;address&quot;: 0x00300000,</span><br><span class="line"> &quot;bin&quot;: &quot;facedetect.kmodel&quot;,</span><br><span class="line"> &quot;sha256Prefix&quot;: false</span><br><span class="line"> &#125;</span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>接下来直接将</strong> <strong>kmodel</strong> <strong>和</strong> <strong>json</strong> <strong>这两个文件用</strong> <strong>zip</strong> <strong>方式压缩（不要用文件夹）</strong>，然后将 zip 后缀名改成 kfpkg，得到一个可以用 K210 固件烧录工具烧录的文件。</p><p>再使用 K210 固件烧录工具烧录直接烧录该文件即可，烧录软件会根据上述的 json 文件自动调整烧录地址，无需再次填写。</p><p>当我们去识别图片时候，可以将摄像头设置成后置，sensor 初始化时增加以</p><p>下代码：(LCD 装在 pyAI-K210 核心板背面，横屏测试。)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sensor.set_vflip(<span class="number">1</span>) <span class="comment">#设置摄像头后置</span></span><br></pre></td></tr></table></figure><p> </p><p> </p><h3 id="物体识别"><strong>物体识别</strong></h3><p>在上一节人脸检测章节我们已经介绍过 KPU 的用法，这里不再重复。本实验还是使用到 YOLO2 网络，结合 20class 模型（20 种物体分类模型）来识别图像中的物体。下面重温一下 KPU 的用法</p><h4 id="构造函数-8">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br></pre></td></tr></table></figure><p>常用的 KPU 模块导入方法。</p><h4 id="使用方法-8">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.load(offset <span class="keyword">or</span> file_path)</span><br></pre></td></tr></table></figure><p>加载模型。</p><p>【offset】模型存放在 flash 的偏移量，如 0x300000;</p><p>【file_path】模型在文件系统为文件名，如“xxx.kmodel”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.init_yolo2(kpu_net,threshold,nms_value,anchor_num,anchor)</span><br></pre></td></tr></table></figure><p>初始化 yolo2 网络；</p><p>【kpu_net】kpu 网络对象；</p><p>【threshold】概率阈值；</p><p>【nms_value】box_iou 门限；</p><p>【anchor_num】描点数；</p><p>【anchor】描点参数与模型参数一致。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.run_yolo2(kpu_net,image)</span><br></pre></td></tr></table></figure><p>运行 yolo2 网络；</p><p>【kpu_net】从 kpu_load()中返回的网络对象；</p><p>【image】从 sensor 中采集到的图像</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kpu.deinit(kpu_net)</span><br></pre></td></tr></table></figure><p>反初始化。</p><p>【kpu_net】kpu 网络对象；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor,image,lcd,time</span><br><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br><span class="line"><span class="comment">#摄像头初始化</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_vflip(<span class="number">1</span>) <span class="comment">#摄像头后置方式</span></span><br><span class="line">lcd.init() <span class="comment">#LCD 初始化</span></span><br><span class="line">clock = time.clock()</span><br><span class="line"><span class="comment">#模型分类，按照 20class 顺序</span></span><br><span class="line">classes = [<span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, <span class="string">&#x27;bus&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;diningtable&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;pottedplant&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tvmonitor&#x27;</span>]</span><br><span class="line"><span class="comment">#下面语句需要将模型（20class.kfpkg）烧写到 flash 的 0x500000 位置</span></span><br><span class="line"><span class="comment">#task = kpu.load(0x500000)</span></span><br><span class="line"><span class="comment">#将模型放在 SD 卡中。</span></span><br><span class="line">task = kpu.load(<span class="string">&quot;/sd/20class.kmodel&quot;</span>) <span class="comment">#模型 SD 卡上</span></span><br><span class="line"><span class="comment">#网络参数</span></span><br><span class="line">anchor = (<span class="number">1.889</span>, <span class="number">2.5245</span>, <span class="number">2.9465</span>, <span class="number">3.94056</span>, <span class="number">3.99987</span>, <span class="number">5.3658</span>, <span class="number">5.155437</span>, </span><br><span class="line"><span class="number">6.92275</span>, <span class="number">6.718375</span>, <span class="number">9.01025</span>)</span><br><span class="line"><span class="comment">#初始化 yolo2 网络，识别可信概率为 0.7（70%）</span></span><br><span class="line">a = kpu.init_yolo2(task, <span class="number">0.7</span>, <span class="number">0.3</span>, <span class="number">5</span>, anchor)</span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line"> clock.tick()</span><br><span class="line"> img = sensor.snapshot()</span><br><span class="line"> code = kpu.run_yolo2(task, img) <span class="comment">#运行 yolo2 网络</span></span><br><span class="line"> <span class="keyword">if</span> code:</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> code:</span><br><span class="line">   a=img.draw_rectangle(i.rect())</span><br><span class="line">   a = lcd.display(img)</span><br><span class="line">   lcd.draw_string(i.x(), i.y(),classes[i.classid()],lcd.RED, lcd.WHITE)</span><br><span class="line">   lcd.draw_string(i.x(), i.y()+<span class="number">12</span>,<span class="string">&#x27;%f1.3&#x27;</span>%i.value(),lcd.RED,lcd.WHITE)</span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">  a = lcd.display(img)</span><br><span class="line"><span class="built_in">print</span>(clock.fps()) <span class="comment">#打印 FPS</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="在线训练模型"><strong>在线训练模型</strong></h3><p>当我们想自己学习识别自</p><p>己的东西（比如键盘和鼠标的区分），就可以通过在线训练平台训练自己的模型。</p><p>在线训练上有完整的教程，这里不再重复</p><p>MaixHub 在线训练链接：<a href="https://maixhub.com/">https://maixhub.com/</a></p><p>当然上面也有很多现成别人训练好的模型可以直接使用，在模型库中选择</p><p>nncase 即可以看到适合 K210 使用的模型</p><p> </p><h3 id="图片拍摄"><strong>图片拍摄</strong></h3><p>我们在前面摄像头应用章节已经学习过拍摄是使用 image=sensor.snapshot()函数模块，那么我们只需要学会将图片保存即可。保存也是可以直接使用 image下的 save 模块，具体如下：</p><h4 id="构造函数-9">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img=sensor.snapshot()</span><br></pre></td></tr></table></figure><p>通过拍摄创建图像 img</p><h4 id="使用方法-9"><strong>使用方法</strong></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">image.save(*path*[, *roi*[, *quality=<span class="number">50</span>*]])</span><br></pre></td></tr></table></figure><p>保存图片。</p><p>path：保存路径；</p><p>roi:指定保存区域(x, y, w, h)，默认全图保存；</p><p>quality:仅针对 JPEG 格式的质量控制，有效值为 0-100。</p><p> </p><p>掌握了拍照和保存功能，我们就可以编程实现了，例程编程代码流程图如下：</p><h4 id="代码如下-2">代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor, lcd, image</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="comment">#配置 LED 蓝、红引脚</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0,force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">14</span>, fm.fpioa.GPIO1,force=<span class="literal">True</span>)</span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT,value=<span class="number">1</span>) <span class="comment">#构建 LED 对象</span></span><br><span class="line">LED_R = GPIO(GPIO.GPIO1, GPIO.OUT,value=<span class="number">1</span>) <span class="comment">#构建 LED 对象</span></span><br><span class="line"><span class="comment">#摄像头初始化</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.skip_frames(<span class="number">40</span>)</span><br><span class="line">lcd.init() <span class="comment">#LCD 初始化</span></span><br><span class="line"><span class="comment">#红灯亮提示拍照开始</span></span><br><span class="line">LED_R.value(<span class="number">0</span>)</span><br><span class="line">sensor.skip_frames(time = <span class="number">2000</span>) <span class="comment"># 给 2 秒时间用户准备.</span></span><br><span class="line">LED_R.value(<span class="number">1</span>)</span><br><span class="line"><span class="comment">#蓝灯亮提示正在拍照</span></span><br><span class="line">LED_B.value(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;You&#x27;re on camera!&quot;</span>)</span><br><span class="line"><span class="comment"># 拍摄并保存相关文件，也可以用&quot;example.bmp&quot;或其它文件方式。</span></span><br><span class="line">sensor.snapshot().save(<span class="string">&quot;/sd/example.jpg&quot;</span>)</span><br><span class="line">LED_B.value(<span class="number">1</span>) <span class="comment">#l 蓝灯灭提示拍照完成</span></span><br><span class="line">lcd.display(image.Image(<span class="string">&quot;/sd/example.jpg&quot;</span>)) <span class="comment">#LCD 显示照片</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="视频录制"><strong>视频录制</strong></h3><p>pyAI-K210 使用的 MaixPy 集成了 vedio 视频模块，也就是通过 MicroPython编程可以轻松实现录制视频功能，我们来看看 vedio 对象：</p><p><strong>构造函数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> vedio</span><br><span class="line"></span><br><span class="line">v=vedio.<span class="built_in">open</span>((path, record=<span class="literal">False</span>, interval=<span class="number">100000</span>, quality=<span class="number">50</span>,width=<span class="number">320</span>, height=<span class="number">240</span>, audio=<span class="literal">False</span>, sample_rate=<span class="number">44100</span>, channels=<span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>播放或录制视频文件。</p><p>【path】文件路径，比如：/sd/badapple.avi；</p><p>【record】=True 表示视频录制，=False 表示视频播放；</p><p>【interval】录制帧间隔，单位是微妙；FPS=1000000/interval，默认值</p><p>是 100000，即 FPS 默认是 10（每秒 10 帧）；</p><p>【quality】jpeg 压缩质量（%），默认 50；</p><p>【width】录制屏幕宽度，默认 320；</p><p>【height】录制屏幕高度，默认 240；</p><p>【audio】是否录制音频，默认 False;</p><p>【sample_rate】录制音频采样率，默认 44100（44.1k）;</p><p>【channels】录制音频声道数，默认 1，即单声道。</p><h4 id="使用方法-10"><strong>使用方法</strong></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.play()</span><br></pre></td></tr></table></figure><p>播放视频；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.volume([value])</span><br></pre></td></tr></table></figure><p>设置音量值。</p><p>【value】0-100;</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.revord ()</span><br></pre></td></tr></table></figure><p>录制音视频；</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v.revord_finish ()</span><br></pre></td></tr></table></figure><p>停止录制；</p><p>*更多使用说明请阅读官方文档：</p><p><a href="https://maixpy.sipeed.com/zh/libs/machine_vision/video.html">https://maixpy.sipeed.com/zh/libs/machine_vision/video.html</a></p><p> </p><p>学习了 vedio 的相关用法后，我们整理思路，代码编写流程如下：</p><h4 id="参考代码">参考代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> video, sensor, image, lcd, time</span><br><span class="line"><span class="comment">#摄像头初始化</span></span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_vflip(<span class="number">1</span>) <span class="comment">#后置拍摄模式</span></span><br><span class="line">sensor.skip_frames(<span class="number">30</span>)</span><br><span class="line"><span class="comment">#LCD 初始化</span></span><br><span class="line">lcd.init()</span><br><span class="line"><span class="comment">#指定录制文件路径和文件名</span></span><br><span class="line">v = video.<span class="built_in">open</span>(<span class="string">&quot;/sd/example.avi&quot;</span>, record=<span class="number">1</span>)</span><br><span class="line">i = <span class="number">0</span> <span class="comment">#计算录制帧数</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> tim = time.ticks_ms()</span><br><span class="line"> img = sensor.snapshot()</span><br><span class="line"> lcd.display(img)</span><br><span class="line"> img_len = v.record(img) <span class="comment">#img_len 为返回的录制帧长度。</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&quot;record&quot;</span>,time.ticks_ms() - tim) <span class="comment">#打印录制的每帧间隔</span></span><br><span class="line"> <span class="comment">#录制 100 帧,每帧默认 100ms，即 10 秒视频。</span></span><br><span class="line"> i += <span class="number">1</span></span><br><span class="line"> <span class="keyword">if</span> i &gt; <span class="number">100</span>:</span><br><span class="line">  <span class="keyword">break</span></span><br><span class="line">v.record_finish() <span class="comment">#停止录制</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finish&quot;</span>) <span class="comment">#录制完成提示</span></span><br></pre></td></tr></table></figure><h3 id="人脸识别-2">人脸识别</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"><span class="keyword">import</span> sensor</span><br><span class="line"><span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">import</span> lcd</span><br><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> FPIOA, GPIO</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">from</span> board <span class="keyword">import</span> board_info</span><br><span class="line"><span class="keyword">import</span> utime</span><br><span class="line"></span><br><span class="line"><span class="comment"># task_fd = kpu.load(0x300000)</span></span><br><span class="line"><span class="comment"># task_ld = kpu.load(0x400000)</span></span><br><span class="line"><span class="comment"># task_fe = kpu.load(0x500000)</span></span><br><span class="line"></span><br><span class="line">task_fd = kpu.load(<span class="string">&quot;/sd/FaceDetection.smodel&quot;</span>)</span><br><span class="line">task_ld = kpu.load(<span class="string">&quot;/sd/FaceLandmarkDetection.smodel&quot;</span>)</span><br><span class="line">task_fe = kpu.load(<span class="string">&quot;/sd/FeatureExtraction.smodel&quot;</span>)</span><br><span class="line"></span><br><span class="line">clock = time.clock()</span><br><span class="line"></span><br><span class="line">fm.register(board_info.BOOT_KEY, fm.fpioa.GPIOHS0)</span><br><span class="line">key_gpio = GPIO(GPIO.GPIOHS0, GPIO.IN)</span><br><span class="line">start_processing = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">BOUNCE_PROTECTION = <span class="number">50</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_key_state</span>(<span class="params">*_</span>):</span><br><span class="line">    <span class="keyword">global</span> start_processing</span><br><span class="line">    start_processing = <span class="literal">True</span></span><br><span class="line">    utime.sleep_ms(BOUNCE_PROTECTION)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">key_gpio.irq(set_key_state, GPIO.IRQ_RISING, GPIO.WAKEUP_NOT_SUPPORT)</span><br><span class="line"></span><br><span class="line">lcd.init()</span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_hmirror(<span class="number">1</span>)</span><br><span class="line">sensor.set_vflip(<span class="number">1</span>)</span><br><span class="line">sensor.run(<span class="number">1</span>)</span><br><span class="line">anchor = (<span class="number">1.889</span>, <span class="number">2.5245</span>, <span class="number">2.9465</span>, <span class="number">3.94056</span>, <span class="number">3.99987</span>, <span class="number">5.3658</span>, <span class="number">5.155437</span>,</span><br><span class="line">          <span class="number">6.92275</span>, <span class="number">6.718375</span>, <span class="number">9.01025</span>)  <span class="comment"># anchor for face detect</span></span><br><span class="line">dst_point = [(<span class="number">44</span>, <span class="number">59</span>), (<span class="number">84</span>, <span class="number">59</span>), (<span class="number">64</span>, <span class="number">82</span>), (<span class="number">47</span>, <span class="number">105</span>),</span><br><span class="line">             (<span class="number">81</span>, <span class="number">105</span>)]  <span class="comment"># standard face key point position</span></span><br><span class="line">a = kpu.init_yolo2(task_fd, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">5</span>, anchor)</span><br><span class="line">img_lcd = image.Image()</span><br><span class="line">img_face = image.Image(size=(<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">a = img_face.pix_to_ai()</span><br><span class="line">record_ftr = []</span><br><span class="line">record_ftrs = []</span><br><span class="line">names = [<span class="string">&#x27;Mr.1&#x27;</span>, <span class="string">&#x27;Mr.2&#x27;</span>, <span class="string">&#x27;Mr.3&#x27;</span>, <span class="string">&#x27;Mr.4&#x27;</span>, <span class="string">&#x27;Mr.5&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;Mr.6&#x27;</span>, <span class="string">&#x27;Mr.7&#x27;</span>, <span class="string">&#x27;Mr.8&#x27;</span>, <span class="string">&#x27;Mr.9&#x27;</span>, <span class="string">&#x27;Mr.10&#x27;</span>]</span><br><span class="line"></span><br><span class="line">ACCURACY = <span class="number">85</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>):</span><br><span class="line">    img = sensor.snapshot()</span><br><span class="line">    clock.tick()</span><br><span class="line">    code = kpu.run_yolo2(task_fd, img)</span><br><span class="line">    <span class="keyword">if</span> code:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> code:</span><br><span class="line">            <span class="comment"># Cut face and resize to 128x128</span></span><br><span class="line">            a = img.draw_rectangle(i.rect())</span><br><span class="line">            face_cut = img.cut(i.x(), i.y(), i.w(), i.h())</span><br><span class="line">            face_cut_128 = face_cut.resize(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">            a = face_cut_128.pix_to_ai()</span><br><span class="line">            <span class="comment"># a = img.draw_image(face_cut_128, (0,0))</span></span><br><span class="line">            <span class="comment"># Landmark for face 5 points</span></span><br><span class="line">            fmap = kpu.forward(task_ld, face_cut_128)</span><br><span class="line">            plist = fmap[:]</span><br><span class="line">            le = (i.x() + <span class="built_in">int</span>(plist[<span class="number">0</span>] * i.w() - <span class="number">10</span>), i.y() + <span class="built_in">int</span>(plist[<span class="number">1</span>] * i.h()))</span><br><span class="line">            re = (i.x() + <span class="built_in">int</span>(plist[<span class="number">2</span>] * i.w()), i.y() + <span class="built_in">int</span>(plist[<span class="number">3</span>] * i.h()))</span><br><span class="line">            nose = (i.x() + <span class="built_in">int</span>(plist[<span class="number">4</span>] * i.w()), i.y() + <span class="built_in">int</span>(plist[<span class="number">5</span>] * i.h()))</span><br><span class="line">            lm = (i.x() + <span class="built_in">int</span>(plist[<span class="number">6</span>] * i.w()), i.y() + <span class="built_in">int</span>(plist[<span class="number">7</span>] * i.h()))</span><br><span class="line">            rm = (i.x() + <span class="built_in">int</span>(plist[<span class="number">8</span>] * i.w()), i.y() + <span class="built_in">int</span>(plist[<span class="number">9</span>] * i.h()))</span><br><span class="line">            a = img.draw_circle(le[<span class="number">0</span>], le[<span class="number">1</span>], <span class="number">4</span>)</span><br><span class="line">            a = img.draw_circle(re[<span class="number">0</span>], re[<span class="number">1</span>], <span class="number">4</span>)</span><br><span class="line">            a = img.draw_circle(nose[<span class="number">0</span>], nose[<span class="number">1</span>], <span class="number">4</span>)</span><br><span class="line">            a = img.draw_circle(lm[<span class="number">0</span>], lm[<span class="number">1</span>], <span class="number">4</span>)</span><br><span class="line">            a = img.draw_circle(rm[<span class="number">0</span>], rm[<span class="number">1</span>], <span class="number">4</span>)</span><br><span class="line">            <span class="comment"># align face to standard position</span></span><br><span class="line">            src_point = [le, re, nose, lm, rm]</span><br><span class="line">            T = image.get_affine_transform(src_point, dst_point)</span><br><span class="line">            a = image.warp_affine_ai(img, img_face, T)</span><br><span class="line">            a = img_face.ai_to_pix()</span><br><span class="line">            <span class="comment"># a = img.draw_image(img_face, (128,0))</span></span><br><span class="line">            <span class="keyword">del</span> (face_cut_128)</span><br><span class="line">            <span class="comment"># calculate face feature vector</span></span><br><span class="line">            fmap = kpu.forward(task_fe, img_face)</span><br><span class="line">            feature = kpu.face_encode(fmap[:])</span><br><span class="line">            reg_flag = <span class="literal">False</span></span><br><span class="line">            scores = []</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(record_ftrs)):</span><br><span class="line">                score = kpu.face_compare(record_ftrs[j], feature)</span><br><span class="line">                scores.append(score)</span><br><span class="line">            max_score = <span class="number">0</span></span><br><span class="line">            index = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(scores)):</span><br><span class="line">                <span class="keyword">if</span> max_score &lt; scores[k]:</span><br><span class="line">                    max_score = scores[k]</span><br><span class="line">                    index = k</span><br><span class="line">            <span class="keyword">if</span> max_score &gt; ACCURACY:</span><br><span class="line">                a = img.draw_string(i.x(), i.y(), (<span class="string">&quot;%s :%2.1f&quot;</span> % (</span><br><span class="line">                    names[index], max_score)), color=(<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), scale=<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                a = img.draw_string(i.x(), i.y(), (<span class="string">&quot;X :%2.1f&quot;</span> % (</span><br><span class="line">                    max_score)), color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), scale=<span class="number">2</span>)</span><br><span class="line">            <span class="keyword">if</span> start_processing:</span><br><span class="line">                record_ftr = feature</span><br><span class="line">                record_ftrs.append(record_ftr)</span><br><span class="line">                start_processing = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    fps = clock.fps()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%2.1f fps&quot;</span> % fps)</span><br><span class="line">    a = lcd.display(img)</span><br><span class="line">    gc.collect()</span><br><span class="line">    <span class="comment"># kpu.memtest()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># a = kpu.deinit(task_fe)</span></span><br><span class="line"><span class="comment"># a = kpu.deinit(task_ld)</span></span><br><span class="line"><span class="comment"># a = kpu.deinit(task_fd)</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210基础实验</title>
      <link href="/posts/abdf738c.html"/>
      <url>/posts/abdf738c.html</url>
      
        <content type="html"><![CDATA[<h2 id="点亮第一个-LED"><strong>点亮第一个</strong> <strong>LED</strong></h2><p>其连接到 pyAI-K210 的外部 IO 引脚如下（可以看开发板原理图），LED 蓝灯对应的外部 IO 为 IO12，从电路可以看到当 IO12 为低电平时，蓝灯被点亮。</p><p>K210 为外部 IO 和内部 IO，其片上外设（比如 GPIO、I2C 等）对应的引脚是可以任意设置的，而传统大部分 MCU 片上外设和引脚对应关系已经固定了， 只有部分引脚可以复用， 相比之下 K210 自由度更大。</p><p>因此我们在编程使用 GPIO 的时候需要注册一下硬件 IO 和 K210 内部 IO 的对应关系。注册方式使用 fpioa_manager：简称 fm，该模块用于注册芯片内部功能和引脚，帮助用户管理内部功能和引脚。</p><h3 id="构造函数">构造函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fm.register(pin,function,force=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>【pin】芯片外部 IO</p><p>【function】芯片功能</p><p>【force】=True 则强制注册，清除之前的注册记录；</p><p>例：fm.register(12, fm.fpioa.GPIO0,force=True)</p><p>表示将外部 IO12 注册到内部 GPIO0</p><p>更多有关引脚和功能注册信息请看官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/Maix/gpio.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/Maix/gpio.html</a></p><p>注册成功后我们就可以通过 GPIO 对象模块来控制外部 IO，从而控制 LED。</p><p>GPIO 对象说明如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO(ID,MODE,PULL,VALUE)</span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">GPIO 对象。</span><br><span class="line"></span><br><span class="line">【ID】内部 GPIO 编号;</span><br><span class="line"></span><br><span class="line">【MODE】GPIO 模式；</span><br><span class="line"></span><br><span class="line">GPIO.IN ：输入模式</span><br><span class="line"></span><br><span class="line">GPIO.OUT ：输出模式</span><br><span class="line"></span><br><span class="line">【PULL】</span><br><span class="line"></span><br><span class="line">GPIO.PULL<span class="emphasis">_UP ：上拉</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">GPIO.PULL_</span>DOWN ：下拉</span><br><span class="line"></span><br><span class="line">GPIO.PULL<span class="emphasis">_NONE ：无</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">【value】GPIO 初始化电平</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">1：高电平</span></span><br><span class="line"><span class="emphasis"></span></span><br><span class="line"><span class="emphasis">0：低电平</span></span><br></pre></td></tr></table></figure><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO.value([value])</span><br></pre></td></tr></table></figure><p>【value】GPIO 输出电平值；</p><p>1：高电平</p><p>0：低电平</p><p>方式 1 是：import Maix，然后通过 Maix.GPIO 来操作；</p><p>方式 2 是：from Maix import GPIO，意思是直接从 Maix 中引入 GPIO 模块，然后直接通过 GPIO 来操作。显然方式 2 会显得更直观和方便，本实验也是使用</p><p>方式 2 来编程。代码编写流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="string">实验名称：点亮 LED_B 蓝灯</span></span><br><span class="line"><span class="string">实验目的：学习 led 点亮。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="comment">#将蓝灯引脚 IO12 配置到 GPIO0，K210 引脚支持任意配置</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0,force=<span class="literal">True</span>)</span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT) <span class="comment">#构建 LED 对象</span></span><br><span class="line">LED_B.value(<span class="number">0</span>) <span class="comment">#点亮 LED</span></span><br></pre></td></tr></table></figure><p>关于python中from和import</p><p><a href="https://www.cnblogs.com/keenajiao/p/15336312.html">Python的from和import用法 - keena_jiao - 博客园 (cnblogs.com)</a></p><h3 id="流水灯">流水灯</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">utime()</span><br><span class="line"><span class="comment">#时间模块</span></span><br></pre></td></tr></table></figure><h4 id="使用方法">使用方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">utime.sleep(seconds)</span><br><span class="line">秒级颜色。seconds:延时秒数</span><br><span class="line">utime.sleep_ms(ms)</span><br><span class="line">毫秒级延时。ms：延时毫秒数。</span><br><span class="line">utime.sleep_us(us)</span><br><span class="line">微秒级延时。us：延时微秒数。</span><br></pre></td></tr></table></figure><p>*更多用法请阅读 MaixPy 官方文档：</p><p><a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/standard/utime.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/standard/utime.html</a></p><p>知道了延时函数的使用方法后，我们可以简单的梳理一下流程，首先导入LED 和 utime 模块，程序开始先让 RGB LED 灭掉，开启循环，依次点亮每个 LED，延时 1 秒，关闭 LED。流程如下：</p><p>代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：流水灯</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2019.12</span></span><br><span class="line"><span class="string">作者：01Studio</span></span><br><span class="line"><span class="string">实验目的：让 RGB 灯循环闪烁。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">import</span> utime</span><br><span class="line"><span class="comment">#将将 LED 外部 IO 注册到内部 GPIO，K210 引脚支持任意配置</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0)</span><br><span class="line">fm.register(<span class="number">13</span>, fm.fpioa.GPIO1)</span><br><span class="line">fm.register(<span class="number">14</span>, fm.fpioa.GPIO2)</span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT,value=<span class="number">1</span>) <span class="comment">#构建 LED 对象</span></span><br><span class="line">LED_G = GPIO(GPIO.GPIO1, GPIO.OUT,value=<span class="number">1</span>) <span class="comment">#构建 LED 对象</span></span><br><span class="line">LED_R = GPIO(GPIO.GPIO2, GPIO.OUT,value=<span class="number">1</span>) <span class="comment">#构建 LED 对象</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> </span><br><span class="line"> <span class="comment">#蓝灯亮 1 秒</span></span><br><span class="line"> LED_B.value(<span class="number">0</span>) <span class="comment">#点亮 LED</span></span><br><span class="line"> utime.sleep(<span class="number">1</span>)</span><br><span class="line"> LED_B.value(<span class="number">1</span>) <span class="comment">#关闭 LED</span></span><br><span class="line"> </span><br><span class="line"> <span class="comment">#绿灯亮 1 秒</span></span><br><span class="line"> LED_G.value(<span class="number">0</span>) <span class="comment">#点亮 LED</span></span><br><span class="line">    utime.sleep(<span class="number">1</span>)</span><br><span class="line"> LED_G.value(<span class="number">1</span>) <span class="comment">#关闭 LED</span></span><br><span class="line"> <span class="comment">#红灯亮 1 秒</span></span><br><span class="line"> LED_R.value(<span class="number">0</span>) <span class="comment">#点亮 LED</span></span><br><span class="line"> utime.sleep(<span class="number">1</span>)</span><br><span class="line">LED_R.value(<span class="number">1</span>) <span class="comment">#关闭 LED</span></span><br></pre></td></tr></table></figure><p>上述代码没错是完整地按照编程思路来编写，但可以见到有很多格式相似的地方，这显得代码非常冗余。我们可以通过 for 函数来编写程序，由于是对 3 个LED 的操作，因此我们可以用 for i in range(0,3): 语句来修改，参考代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">实验名称：流水灯</span></span><br><span class="line"><span class="string">版本：v1.0</span></span><br><span class="line"><span class="string">日期：2019.12</span></span><br><span class="line"><span class="string">作者：01Studio</span></span><br><span class="line"><span class="string">实验目的：让 RGB 灯循环闪烁。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">import</span> utime</span><br><span class="line"><span class="comment">#将将 LED 外部 IO 注册到内部 GPIO，K210 引脚支持任意配置</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0)</span><br><span class="line">fm.register(<span class="number">13</span>, fm.fpioa.GPIO1)</span><br><span class="line">fm.register(<span class="number">14</span>, fm.fpioa.GPIO2)</span><br><span class="line"><span class="comment">#构建 LED 对象，并初始化输出高电平，关闭 LED</span></span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT,value=<span class="number">1</span>)</span><br><span class="line">LED_G = GPIO(GPIO.GPIO1, GPIO.OUT,value=<span class="number">1</span>)</span><br><span class="line">LED_R = GPIO(GPIO.GPIO2, GPIO.OUT,value=<span class="number">1</span>)</span><br><span class="line"><span class="comment">#定义数组方便循环语句调用</span></span><br><span class="line">LED=[LED_B, LED_G, LED_R]</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">3</span>):</span><br><span class="line">  LED[i].value(<span class="number">0</span>) <span class="comment">#点亮 LED</span></span><br><span class="line"> utime.sleep(<span class="number">1</span>)</span><br><span class="line"> LED[i].value(<span class="number">1</span>) <span class="comment">#关闭 LED</span></span><br></pre></td></tr></table></figure><h3 id="按键"><strong>按键</strong></h3><p>从原理图可以看到，按键 KEY 的一端连接到 K210 的外部 IO16，另一端连接到 GND。所以按键在没按下时候输入高电平（1），按下时候输入低电平（0）。和 LED 一样，按键的输入检测也是用到 GPIO 对象模块，具体如下：</p><h4 id="构造函数-2">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO(ID,MODE,PULL,VALUE)</span><br></pre></td></tr></table></figure><p>GPIO 对象。</p><p>【ID】内部 GPIO 编号;</p><p>【MODE】GPIO 模式；</p><p><a href="http://GPIO.IN">GPIO.IN</a> ：输入模式</p><p>GPIO.OUT ：输出模式</p><p>【PULL】</p><p>GPIO.PULL_UP ：上拉</p><p>GPIO.PULL_DOWN ：下拉</p><p>GPIO.PULL_NONE ：无</p><p>【value】GPIO 初始化电平</p><p>1：高电平</p><p>0：低电平</p><h4 id="使用">使用</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO.value([value])</span><br></pre></td></tr></table></figure><p>【value】GPIO 输出电平值；</p><p>1：高电平</p><p>0：低电平</p><p>*输入模式时候参数为空，表示获取当前 IO 输入电平值。</p><p>GPIO 对象使用非常简单，我们将按键即外部“IO16”引脚配置成输入，实现当检测到按键被按下时候点亮 LED 蓝灯，松开时关闭 LED 蓝灯来做指示。代码编写流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="comment">#注册 IO，蓝灯--&gt;IO12,KEY--&gt;IO16</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0)</span><br><span class="line">fm.register(<span class="number">16</span>, fm.fpioa.GPIO1)</span><br><span class="line"><span class="comment">#初始化 IO</span></span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT)</span><br><span class="line">KEY = GPIO(GPIO.GPIO1, GPIO.IN)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#按键被按下接地</span></span><br><span class="line">  LED_B.value(<span class="number">0</span>) <span class="comment">#点亮 LED_B,蓝灯</span></span><br><span class="line"> <span class="keyword">else</span>:</span><br><span class="line">  LED_B.value(<span class="number">1</span>) <span class="comment">#熄灭 LED</span></span><br></pre></td></tr></table></figure><h3 id="外部中断"><strong>外部中断</strong></h3><p>前面我们在做普通的按键（GPIO）时候，虽然能实现 IO 口输入输出功能，但代码是一直在检测 IO 输入口的变化，因此效率不高，特别是在一些特定的场合，比如某个按键，可能 1 天才按下一次去执行相关功能，这样我们就浪费大量时间来实时检测按键的情况。</p><p>为了解决这样的问题，我们引入外部中断概念，顾名思义，就是当按键被按下(产生中断)时，我们才去执行相关功能。这大大节省了 CPU 的资源，因此中断的在实际项目的应用非常普遍。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO.irq(CALLBACK_FUNC,TRIGGER_CONDITION)</span><br></pre></td></tr></table></figure><p>配置中断。</p><p>【CALLBACK_FUNC】中断执行的回调函数；</p><p>【TRIGGER_CONDITION】中断触发方式；</p><p>GPIO.IRQ_RISING：上升沿触发</p><p>GPIO.IRQ_FALLING：下降沿沿触发</p><p>GPIO.IRQ_BOTH：都触发</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPIO.disirq()</span><br></pre></td></tr></table></figure><p>关闭中断。</p><p>我们先来了解一下上升沿和下降沿的概念，由于按键 KEY 引脚是通过按键接到 GND，也就是我们所说的低电平“0”，所以当按键被按下再松开时，引脚先获得下降沿，再获得上升沿，如下图所示：</p><p>按键被按下时候可能会发生抖动，抖动如下图，有可能造成误判，因此我们</p><p>需要使用延时函数来进行消抖：</p><p>我们可以选择下降沿方式触发外部中断，也就是当按键被按下的时候立即产</p><p>生中断。</p><p>需要注意的是 K210 只有高速 GPIO 才有外部中断，GPIO 常量表如下：</p><table><thead><tr><th><strong>K210 - GPIO</strong></th></tr></thead><tbody><tr><td>普通 GPIO</td></tr><tr><td>GPIO0 - GPIO7</td></tr><tr><td>高速 GPIO</td></tr><tr><td>GPIOHS0 – GPIOHS31</td></tr></tbody></table><p>编程思路中断跟 GPIO 按键章节类似，在初始化中断后，当系统检测到外部</p><p>中断时候，执行 LED 状态反转的代码即可。流程图如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">import</span> utime</span><br><span class="line"></span><br><span class="line"><span class="comment">#注册 IO，注意高速 GPIO 口才有中断</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0)</span><br><span class="line">fm.register(<span class="number">16</span>, fm.fpioa.GPIOHS0)</span><br><span class="line"><span class="comment">#构建 lED 和 KEY 对象</span></span><br><span class="line"></span><br><span class="line">LED_B=GPIO(GPIO.GPIO0,GPIO.OUT,value=<span class="number">1</span>)</span><br><span class="line">KEY=GPIO(GPIO.GPIOHS0, GPIO.IN, GPIO.PULL_UP)</span><br><span class="line"></span><br><span class="line"><span class="comment">#LED 状态表示</span></span><br><span class="line">state = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#中断回调函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">KEY</span>):</span><br><span class="line"> <span class="keyword">global</span> state</span><br><span class="line"> utime.sleep_ms(<span class="number">10</span>) <span class="comment">#消除抖动</span></span><br><span class="line"> <span class="keyword">if</span> KEY.value()==<span class="number">0</span>: <span class="comment">#确认按键被按下</span></span><br><span class="line"> state = <span class="keyword">not</span> state</span><br><span class="line"> LED_B.value(state)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#开启中断，下降沿触发</span></span><br><span class="line">KEY.irq(fun, GPIO.IRQ_FALLING)</span><br></pre></td></tr></table></figure><h3 id="定时器"><strong>定时器</strong></h3><h4 id="构造函数-3">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">machine.Timer(<span class="built_in">id</span>,channel,mode=Timer.MODE_ONE_SHOT,period=<span class="number">1000</span>,unit=Timer.UNIT_MS, callback=<span class="literal">None</span>, arg=<span class="literal">None</span>, start=<span class="literal">True</span>,</span><br><span class="line">priority=<span class="number">1</span>, div=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>定时器对象 Timer 对象在 machine 模块下。</p><p>【id】定时器编号, [Timer.TIMER0~TIMER2] 定时器 0-2;</p><p>【channel】Timer 通道，[Timer.CHANNEL0~Timer.CHANNEL3]</p><p>【mode】定时器模式</p><p>MODE_ONE_SHOT: 一次性</p><p>MODE_PERIODIC: 周期性</p><p>MODE_PWM</p><p>【period】定时器为周期性模块时每个周期时间值</p><p>【unit】周期的单位</p><p>Timer.UNIT_S：秒</p><p>Timer.UNIT_MS：毫秒</p><p>Timer.UNIT_US：微妙</p><p>Timer.UNIT_NS：纳秒</p><p>【callback】定时器中断执行的回调函数；<strong>注意：回调函数是在中断中调用</strong></p><p><strong>的，所以在回调函数中请不要占用太长时间以及做动态内存分配开关中断等</strong></p><p><strong>动作。</strong></p><p>【arg】回调函数第 2 个参数</p><p>【start】是否在构建对象后立即开始定时器，</p><p>=True: 立即开始；</p><p>=False: 不立即开始，需要调用 start()来开启。</p><p>【priority】硬件中断优先级，在 K210 中，取值范围是[1,7],值越小优先级越高</p><p>【div】硬件分频器。</p><h4 id="使用方法-2">使用方法</h4><table><thead><tr><th>Timer.callback(fun)</th></tr></thead><tbody><tr><td>定义回调函数。</td></tr><tr><td>Timer.period([value])</td></tr><tr><td>配置周期。</td></tr><tr><td>Timer.start()</td></tr><tr><td>启动定时器。</td></tr><tr><td>Timer.stop()</td></tr><tr><td>停止定时器。</td></tr><tr><td>Timer.deinit()</td></tr><tr><td>注销定时器。</td></tr><tr><td>*更多用法请阅读 MaixPy 官方文档：<a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine/timer.html">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine/timer.html</a></td></tr></tbody></table><p>定时器到了预设指定时间后，也会产生中断，因此跟外部中断的编程方式类</p><p>似，代码编程流程图如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Maix <span class="keyword">import</span> GPIO</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Timer</span><br><span class="line"></span><br><span class="line"><span class="comment">#注册 IO 和构建 LED 对象</span></span><br><span class="line">fm.register(<span class="number">12</span>, fm.fpioa.GPIO0)</span><br><span class="line">LED_B = GPIO(GPIO.GPIO0, GPIO.OUT)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计数变量</span></span><br><span class="line">Counter=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定时器回调函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">tim</span>):</span><br><span class="line"> <span class="keyword">global</span> Counter</span><br><span class="line"> Counter = Counter + <span class="number">1</span></span><br><span class="line"> <span class="built_in">print</span>(Counter)</span><br><span class="line"> LED_B.value(Counter%<span class="number">2</span>)<span class="comment">#LED 循环亮灭。</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#定时器 0 初始化，周期 1 秒</span></span><br><span class="line">tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PERIODIC, </span><br><span class="line">period=<span class="number">1000</span>, callback=fun)</span><br></pre></td></tr></table></figure><p> </p><p> </p><h3 id="PWM"><strong>PWM</strong></h3><p>蜂鸣器分有源蜂鸣器和无源蜂鸣器，有源蜂鸣器的使用方式非常简单，只需</p><p>要接上电源，蜂鸣器就发声，断开电源就停止发声。而本实验用到的无源蜂鸣器，是需要给定指定的频率，才能发声的，而且可以通过改变频率来改变蜂鸣器的发声音色，以此来判定 pyAI-K210 的 PWM 输出频率是在变化的。</p><p>pyBase 开发底板上的无源蜂鸣器连接到引脚 X5。如下图所示：</p><p>而 pyAI-K210 并没有引脚直接连接到 pyBase 的 X5（主要避免影响 IO 复用。）而 IO15 连接到 pyBase 开发底板的 X6 引脚，因此我们可以用跳线帽或者跳线来连接 pyBase 的 X5 和 X6 引脚。相当于将无源蜂鸣器接到 pyAI-K210 的外部 IO15引脚。</p><h4 id="构造函数-4">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">machine.PWM(tim, freq, duty, pin, enable=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>PWM 对象在 machine 模块下。</p><p>【tim】K210 的 PWM 依赖于定时器来产生波形</p><p>【freq】PWM 频率</p><p>【duty】PWM 占空比</p><p>【pin】PWM 输出引脚</p><p>【enable】是否在构建对象后立即产生波形，默认 True。</p><h4 id="使用方法-3">使用方法</h4><table><thead><tr><th>PWM.freq(freq)</th></tr></thead><tbody><tr><td>设置频率。不传参数返回当前频率值。</td></tr><tr><td>PWM.duty(duty)</td></tr><tr><td>设置占空比。不传参数返回当前占空比值。[0-100]表示占空比百分比<strong>107</strong></td></tr><tr><td>PWM.enable()</td></tr><tr><td>使能 PWM 输出。</td></tr><tr><td>PWM.disable()</td></tr><tr><td>暂停 PWM 输出。</td></tr><tr><td>PWM.deinit()</td></tr><tr><td>注销 PWM。</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> Timer,PWM</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#PWM 通过定时器配置，接到 IO15 引脚</span></span><br><span class="line">tim = Timer(Timer.TIMER0, Timer.CHANNEL0, mode=Timer.MODE_PWM)</span><br><span class="line">beep = PWM(tim, freq=<span class="number">1</span>, duty=<span class="number">50</span>, pin=<span class="number">15</span>)</span><br><span class="line"><span class="comment">#循环发出不同频率响声。</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> beep.freq(<span class="number">200</span>)</span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br><span class="line"> beep.freq(<span class="number">400</span>)</span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br><span class="line"> beep.freq(<span class="number">600</span>)</span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br><span class="line"> beep.freq(<span class="number">800</span>)</span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br><span class="line"> beep.freq(<span class="number">1000</span>)</span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>有条件的朋友可以使用示波器测量 pyAI-K210 的 IO15 引脚或 pyBase 的 X5 引脚，观察信号波形的变化：</p><p> </p><h3 id="I2C-总线（OLED显示屏）"><strong>I2C</strong> <strong>总线（OLED显示屏）</strong></h3><p>我们先来看看开发板的原理图，也就是MicroPython 上的 OLED 接口是如何连线的。下图是 pyBase 开发底板的原理图。</p><p>我们再来看看 pyAI-K210 转接板的原理图接口部分。</p><p>结合以上可以得知 pyBase 底板连接到 OLED 的对应关系是 Y6→SCL 和Y8→SDA。对应 pyAI-K210 的关系是：IO27→Y6→SCL，IO28→Y8→SDA。本例程将使用 MicroPython 的 Machine 模块的 I2C 来定义 Pin 口和 I2C 初始化。具体如下：</p><p> </p><h4 id="构造函数-5">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">machine.I2C(<span class="built_in">id</span>, mode=I2C.MODE_MASTER, scl=<span class="literal">None</span>, sda=<span class="literal">None</span>,</span><br><span class="line">freq=<span class="number">400000</span>, timeout=<span class="number">1000</span>, addr=<span class="number">0</span>, addr_size=<span class="number">7</span>)</span><br></pre></td></tr></table></figure><p>构建 I2C 对象。</p><p>【id】I2C ID,[ I2C.I2C0~I2C.I2C2 ]</p><p>【scl】时钟引脚；直接传引脚编号；</p><p>【sda】数据引脚; 直接传引脚编号；</p><p>【freq】通信频率，即速度；</p><p>【timeout】参数保留，设置无效；</p><p>【addr】从机地址；</p><p>【addr_size】地址长度， 支持 7 位寻址和 10 位寻址， 取值 7 或者 10。</p><table><thead><tr><th><strong>使用方法</strong></th></tr></thead><tbody><tr><td>i2c.scan()</td></tr><tr><td>扫描 I2C 总线的设备。返回地址，如：0x3c；</td></tr><tr><td>i2c.readfrom(addr,len)</td></tr><tr><td>从指定地址读数据。addr:指定设备地址；len:读取字节数；</td></tr><tr><td>i2c.writeto(addr,buf)</td></tr><tr><td>写数据。addr:从机地址；buf:数据内容；</td></tr><tr><td>i2c.deinit()</td></tr><tr><td>注销 I2C。</td></tr><tr><td>*其它更多用法请阅读官方文档：<a href="https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine/i2c.h">https://wiki.sipeed.com/soft/maixpy/zh/api_reference/machine/i2c.h</a></td></tr></tbody></table><p>定义好 I2C 后，还需要驱动一下 OLED。这里我们已经写好了 OLED 的库函数，在 <a href="http://ssd1306k.py">ssd1306k.py</a> 文件里面。开发者只需要将改 py 文件拷贝到 pyAI-K210 文件系统里面，然后在 <a href="http://main.py">main.py</a> 里面调用函数即可。人生苦短，我们学会调用函数即可，也就是注重顶层的应用，想深入的小伙伴也可以自行研究 <a href="http://ssd1306k.py">ssd1306k.py</a> 文件代码。OLED 显示屏对象介绍如下：</p><h4 id="构造函数-6">构造函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">oled = SSD1306_I2C(i2c, addr)</span><br></pre></td></tr></table></figure><p>构 OLED 显示屏对象。默认分辨率 128*64；</p><p>【i2c】定义好的 I2C 对象;</p><p>【addr】显示屏设备地址。</p><h4 id="使用方法-4">使用方法</h4><p>oled.fill([value])</p><p>清屏</p><p>value=0x00 (黑屏)；value=0xFF(白屏)</p><p>oled.text(string,x,y)</p><p>将 string 字符写在指定为位置。</p><p>【string】：字符；</p><p>【x】横坐标；[0-127]；</p><p>【y】纵坐标。[0-7] 共 8 行</p><p>学习了 I2C、OLED 对象用法后我们通过编程流程图来理顺一下思路：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> I2C</span><br><span class="line"><span class="keyword">from</span> ssd1306k <span class="keyword">import</span> SSD1306</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义 I2C 接口和 OLED 对象</span></span><br><span class="line">i2c = I2C(I2C.I2C0, mode=I2C.MODE_MASTER,scl=<span class="number">27</span>, sda=<span class="number">28</span>)</span><br><span class="line">oled = SSD1306(i2c, addr=<span class="number">0x3c</span>)</span><br><span class="line"><span class="comment">#清屏,0x00(白屏)，0xff(黑屏)</span></span><br><span class="line">oled.fill(<span class="number">0</span>)</span><br><span class="line"><span class="comment">#显示字符。参数格式为（str,x,y）,其中 x 范围是 0-127，y 范围是 0-7（共 8 行）</span></span><br><span class="line">oled.text(<span class="string">&quot;Hello World!&quot;</span>, <span class="number">0</span>, <span class="number">0</span>) <span class="comment">#写入第 0 行内容</span></span><br><span class="line">oled.text(<span class="string">&quot;MicroPython&quot;</span>, <span class="number">0</span>, <span class="number">2</span>) <span class="comment">#写入第 2 行内容</span></span><br><span class="line">oled.text(<span class="string">&quot;By 01Studio&quot;</span>, <span class="number">0</span>, <span class="number">5</span>) <span class="comment">#写入第 5 行内容</span></span><br></pre></td></tr></table></figure><p> </p><p> </p><h3 id="UART（串口通信）"><strong>UART（串口通信）</strong></h3><p>串口是非常常用的通信接口，有很多工控产品、无线透传模块都是使用串口来收发指令和传输数据，这样用户就可以在无须考虑底层实现原理的前提下将各类串口功能模块灵活应用起来。</p><p> </p><p>K210 一共有 3 个串口，每个串口可以自由映射引脚。 例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># IO6→RX1，IO7→TX1</span></span><br><span class="line">fm.register(<span class="number">6</span>, fm.fpioa.UART1_RX, force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">7</span>, fm.fpioa.UART1_TX, force=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p> </p><h4 id="构造函数-7">构造函数</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">machine.UART(uart,baudrate,bits,parity,stop,timeout, read_buf_len)</span><br></pre></td></tr></table></figure><p>创建 UART 对象。</p><p>【uart】串口编号。[UART.UART1~UART3]</p><p>【baudrate】波特率，常用 115200、9600</p><p>【bits】数据位,默认 8</p><p>【parity】校验；默认 None, 0(偶校验)，1(奇校验)</p><p>【stop】停止位，默认 1</p><p>【timeout】串口接收超时时间</p><p>【read_buf_len】串口接收缓冲大小。</p><h4 id="使用方法-5">使用方法</h4><p>UART.read(num)</p><p>读取串口缓冲数据</p><p>【num】读取字节数</p><p>UART.readline(num)</p><p>读取串口缓冲数据的行</p><p>【num】行数</p><p>UART.write(buf)</p><p>串口发送数据</p><p>【buf】需要发送的数据</p><p>UART.deinit()</p><p>注销串口</p><p> </p><p>我们可以用一个USB转TTL工具，配合电脑上位机串口助手来跟MicroPython</p><p>开发板模拟通信。</p><p>注意要使用 3.3V 电平的 USB 转串口 TTL 工具，本实验我们使用 pyBase 的外</p><p>接串口引脚，也就是 Y9（TX）和 Y10（RX），接线示意图如下：</p><p>从 pyAI-K210 原理图可以看到外部 IO6→Y9→RX ，IO7→Y10→TX。</p><p>在本实验中我们可以先初始化串口，然后给串口发去一条信息，这样 PC 机的串口助手就会在接收区显示出来，然后进入循环，当检测到有数据可以接收时候就将数据接收并打印，并通过 REPL 打印显示。代码编写流程图如下：</p><h4 id="代码">代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> machine <span class="keyword">import</span> UART,Timer</span><br><span class="line"><span class="keyword">from</span> fpioa_manager <span class="keyword">import</span> fm</span><br><span class="line"><span class="comment">#映射串口引脚</span></span><br><span class="line">fm.register(<span class="number">6</span>, fm.fpioa.UART1_RX, force=<span class="literal">True</span>)</span><br><span class="line">fm.register(<span class="number">7</span>, fm.fpioa.UART1_TX, force=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#初始化串口</span></span><br><span class="line">uart = UART(UART.UART1, <span class="number">115200</span>, read_buf_len=<span class="number">4096</span>)</span><br><span class="line">uart.write(<span class="string">&#x27;Hello 01Studio!&#x27;</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> text=uart.read() <span class="comment">#读取数据</span></span><br><span class="line"> <span class="keyword">if</span> text: <span class="comment">#如果读取到了数据</span></span><br><span class="line">  <span class="built_in">print</span>(text.decode(<span class="string">&#x27;utf-8&#x27;</span>)) <span class="comment">#REPL 打印</span></span><br><span class="line">  uart.write(<span class="string">&#x27;I got&#x27;</span>+text.decode(<span class="string">&#x27;utf-8&#x27;</span>)) <span class="comment">#数据回传</span></span><br></pre></td></tr></table></figure><h4 id="实验结果">实验结果</h4><p>这时候打开电脑的设备管理器，能看到 2 个 COM。写着 CH340 的是串口工具，另外一个则是 pyAI-K210 的 REPL。如果 CH340 驱动没安装，则需要手动安装，驱动在：配套资料包→开发工具→windows→串口终端→CH340 文件夹下。</p><p>本实验要用到串口助手，打开配套资料包→开发工具→windows→串口终端工具下的【UartAssist.exe】软件。</p><p>将串口工具配置成 COM14（根据自己的串口号调整）。波特率 115200。运行程序，可以看到一开始串口助手收到 pyAI-K210 上电发来的信息“Hello 01Studio!”。我们在串口助手的发送端输入“<a href="http://www.01studio.org">http://www.01studio.org</a>”， 点击发送，可以看到pyAI-K210 在接收到该信息后在 REPL 里面打印了出来。如下图所示：</p><p> </p><p> </p><h3 id="thread（线程）"><strong>thread（线程）</strong></h3><p>我们看到前面的编程都是一个循环来完成，但当我们需要分时完成不同任务时候，线程编程就派上用场了。这有点像 RTOS(实时操作系统)，今天我们就来学习一下如何通过 MicroPython 编程实现多线程。</p><p> </p><p>pyAI-K210 的 MicroPython 固件已经集成了_thread 线程模块。我们直接调用即可。该模块衍生于 python3，属于低级线程，详情可以看官网介绍：<a href="https://docs.python.org/3.5/library/_thread.html#module-thread">https://docs.python.org/3.5/library/_thread.html#module-thread</a></p><p>编程流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> _thread <span class="comment">#导入线程模块</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">#线程函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">func</span>(<span class="params">name</span>):</span><br><span class="line"> <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&quot;hello &#123;&#125;&quot;</span>.<span class="built_in">format</span>(name)) </span><br><span class="line"> time.sleep(<span class="number">1</span>)</span><br><span class="line"> _thread.start_new_thread(func,(<span class="string">&quot;1&quot;</span>,)) <span class="comment">#开启线程 1，参数必须是元组</span></span><br><span class="line">_thread.start_new_thread(func,(<span class="string">&quot;2&quot;</span>,)) <span class="comment">#开启线程 2，参数必须是元组</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line"><span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p> </p><p> </p>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>k210</title>
      <link href="/posts/a08a9fe.html"/>
      <url>/posts/a08a9fe.html</url>
      
        <content type="html"><![CDATA[<h1>k210开发环境</h1><h3 id="python的一些基本语法">python的一些基本语法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用.format 来格式化字符串</span></span><br><span class="line"><span class="comment"># 可以重复参数以节省时间</span></span><br><span class="line"><span class="string">&quot;&#123;0&#125; be nimble, &#123;0&#125; be quick, &#123;0&#125; jump over the &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;Jack&quot;</span>, </span><br><span class="line"><span class="string">&quot;candle stick&quot;</span>)</span><br><span class="line"><span class="comment"># =&gt; &quot;Jack be nimble, Jack be quick, Jack jump over the candle stick&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果不想数参数，可以用关键字</span></span><br><span class="line"><span class="string">&quot;&#123;name&#125; wants to eat &#123;food&#125;&quot;</span>.<span class="built_in">format</span>(name=<span class="string">&quot;Bob&quot;</span>, food=<span class="string">&quot;lasagna&quot;</span>) </span><br><span class="line"><span class="comment"># =&gt; &quot;Bob wants to eat lasagna&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># None，0，空字符串，空列表，空字典都算是 False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="搭建开发环境">搭建开发环境</h2><h3 id="安装开发软件-MaixPy-IDE"><strong>安装开发软件</strong> <strong>MaixPy IDE</strong></h3><p>当前版本为 v0.2.5，官网下载地址：（如有更新请下载最新版）</p><p><a href="http://cn.dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5%EF%BC%8C%E4%B8%8B%E8%BD%BD%E7%95%8C%E9%9D%A2%E5%A6%82%E4%B8%8B%E5%9B%BE%E3%80%82">http://cn.dl.sipeed.com/MAIX/MaixPy/ide/_/v0.2.5，下载界面如下图。</a></p><h3 id="安装驱动">安装驱动</h3><p>驱动路径选择：零一科技（01Studio）MicroPython 开发套件配套资料\01-开</p><p>发工具\01-Windows\串口终端工具\CH9102x 驱动，点击确认后即可自动安装：</p><h3 id="例程测试"><strong>例程测试</strong></h3><p>我们用最简单的 LED 程序来测试，在 MaixPy IDE 中打开 零一科技（01Studio）</p><p>MicroPython 开发套件配套资料_latest\02-示例程序\5.pyAI-K210\1.基础实验\1.点</p><p>亮第一个 LED 里面的 <a href="http://LED.py">LED.py</a> 例程</p><p>在连接状态下点击工具—将打开的脚本保存到开发板的 <a href="http://boot.py">boot.py</a>，这里的意</p><p>思是将当前编辑框的代码拷贝到开发板文件系统中的 <a href="http://boot.py">boot.py</a>，由于 <a href="http://boot.py">boot.py</a> 是</p><p>Maixpy 上电运行的第一个脚本文件，因此相当于实现了上电运行写入的程序。</p><h3 id="REPL-串口调试"><strong>REPL</strong> <strong>串口调试</strong></h3><p>MicroPython 固件集成了交互解释器 REPL 【读取(Read)-运算(Eval)-输出(Print)-循环(Loop) 】，开发者可以直接通过串口终端来调试 pyboard 或 micropython 开发套件。我们使用的软件是一款免费的串口终端软件 putty。</p><p>打开 MicroPython 开发套件配套资料\开发工具\串口终端工具\Putty.exe，选择左下角 Serial，配置信息如下：</p><p>配置好后不是点 open，而是点左边上方 Session，选择 Serial 后可看到刚刚的配置信息。串口号通常不会变化，我们在 Save Session 下方输入 COM4 或者自己喜欢的名称，点右边 Save，在空白框里面就出现 COM4 字样，以后可以直接使用。设置好后我们点击 Open。</p><p>现在对话框相当于连接上了开发板上，由于 pyAI-K210 集成了 MicroPython</p><p>解析器。我们在这里可以进行调试和简单编程，接下来我们测试一下。在对话框</p><p>输入下面代码，按回车，可以看到代码运行情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(“Hello 01Studio!”)</span><br></pre></td></tr></table></figure><h3 id="固件更新"><strong>固件更新</strong></h3><p>MaixPy 官方提供了免安装的烧录工具，通过板载 USB 转串口烧录的。我们</p><p>打开 MicroPython 开发套件配套资料\开发工具\Windows\固件更新工具\</p><p>kflash_gui 目录下的 kflash_gui.exe 烧录软件。</p><p>选择配套资料包路径 零一科技（01Studio）MicroPython 开发套件配套资料</p><p>\03-相关固件\05-pyAI-K210 下的固件：</p><p>烧录地址默认为 0x00000 即可。选择开发板和串口 COM，开发板可以选择</p><p>跟 pyAI-K210 串口方案一样的 Maix Dock ，而串口则选择自己开发板对应的串口。</p><p>点击 Download 下载。<strong>（如出现一直等待情况说明无法自动下载，这时候按</strong></p><p><strong>一下开发板的</strong> <strong>RST</strong> <strong>复位键即可。）</strong></p><p>或者直接连按两下ret键</p><p>MaixPy 针对不同的应用场景提供不同大小的固件，而且不断更新，详见固件</p><p>下载链接（不同固件区别见里面的 readme.txt）：</p><p><a href="https://dl.sipeed.com/shareURL/MAIX/MaixPy/release/master">https://dl.sipeed.com/shareURL/MAIX/MaixPy/release/master</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> k210 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp8266闪存文件系统</title>
      <link href="/posts/58716004.html"/>
      <url>/posts/58716004.html</url>
      
        <content type="html"><![CDATA[<h2 id="ESP8266闪存文件系统">ESP8266闪存文件系统</h2><p>如果网页比较大，那么只用程序去储存明显是不太可能的，我们可以用esp8266闪存文件系统储存网页。</p><p>通常的闪存文件系统大小为4Mb</p><table><thead><tr><th>名称</th><th>大小</th><th></th></tr></thead><tbody><tr><td>闪存文件系统</td><td>4Mb</td><td></td></tr><tr><td>程序储存</td><td>1Mb</td><td></td></tr><tr><td>用户可以文件储存（会包含一些系统文件）</td><td>3Mb</td><td></td></tr></tbody></table><p> </p><h3 id="ESP8266闪存文件系统基本操作">ESP8266闪存文件系统基本操作</h3><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/spiffs/spiffs-operation/">ESP8266闪存文件系统基本操作 </a></p><h3 id="1-通过程序向闪存文件系统写入信息">1.通过程序向闪存文件系统写入信息</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-write</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何向NodeMCU的SPIFFS中建立名为</span></span><br><span class="line"><span class="comment">                            notes.txt的文件，程序还将向该文件写入信息。</span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">函数说明：</span></span><br><span class="line"><span class="comment">SPIFFS.open(file_name, &quot;w&quot;); </span></span><br><span class="line"><span class="comment">以上函数有两个参数：</span></span><br><span class="line"><span class="comment">第一个参数是被操作的文件名称，本示例中该文件为/notes.txt</span></span><br><span class="line"><span class="comment">第二个参数&quot;w&quot; 代表写入文件信息。（如需了解如何读取信息，请参阅示例程序esp8266-flash-read）</span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span>  </span></span><br><span class="line"> </span><br><span class="line">String file_name = <span class="string">&quot;/taichi-maker/notes.txt&quot;</span>; <span class="comment">//被读取的文件位置和名称</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  Serial.println(<span class="string">&quot;SPIFFS format start&quot;</span>);</span><br><span class="line">  SPIFFS.format();    <span class="comment">// 格式化SPIFFS</span></span><br><span class="line">  Serial.println(<span class="string">&quot;SPIFFS format finish&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(SPIFFS.begin())&#123; <span class="comment">// 启动SPIFFS</span></span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Failed to Start.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  File dataFile = SPIFFS.open(file_name, <span class="string">&quot;w&quot;</span>);<span class="comment">// 建立File对象用于向SPIFFS中的file对象（即/notes.txt）写入信息</span></span><br><span class="line">  dataFile.println(<span class="string">&quot;Hello IOT World.&quot;</span>);       <span class="comment">// 向dataFile写入字符串信息</span></span><br><span class="line">  dataFile.close();                           <span class="comment">// 完成文件写入后关闭文件</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Finished Writing data to SPIFFS&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="2-通过程序从闪存文件系统读取信息">2.通过程序从闪存文件系统读取信息</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-read</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何从NodeMCU的内置SPIFFS中存储的文件notes.txt读取数据。</span></span><br><span class="line"><span class="comment">                           notes.txt 文件内容将会通过串口监视器显示出来供用户确认。</span></span><br><span class="line"><span class="comment">                           注意在使用本程序以前需要先将notes.txt 文件上传到NodeMCU开发板的SPIFFS中</span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment">函数说明：</span></span><br><span class="line"><span class="comment">SPIFFS.open(file_name, &quot;r&quot;); </span></span><br><span class="line"><span class="comment">以上SPIFFS函数有两个参数：</span></span><br><span class="line"><span class="comment">第一个参数是被操作的文件名称，本示例中该文件为/notes.txt</span></span><br><span class="line"><span class="comment">第二个参数&quot;r&quot; 代表读取文件信息。（如需了解如何写入信息，请参阅示例程序esp8266-flash-write）</span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">String file_name = <span class="string">&quot;/taichi-maker/notes.txt&quot;</span>;              <span class="comment">//被读取的文件位置和名称</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(SPIFFS.begin())&#123; <span class="comment">// 启动闪存文件系统</span></span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Failed to Start.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">//确认闪存中是否有file_name文件</span></span><br><span class="line">  <span class="keyword">if</span> (SPIFFS.exists(file_name))&#123;</span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.println(<span class="string">&quot; FOUND.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.print(<span class="string">&quot; NOT FOUND.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">//建立File对象用于从SPIFFS中读取文件</span></span><br><span class="line">  File dataFile = SPIFFS.open(file_name, <span class="string">&quot;r&quot;</span>); </span><br><span class="line"> </span><br><span class="line">  <span class="comment">//读取文件内容并且通过串口监视器输出文件信息</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;dataFile.size(); i++)&#123;</span><br><span class="line">    Serial.print((<span class="type">char</span>)dataFile.read());       </span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">//完成文件读取后关闭文件</span></span><br><span class="line">  dataFile.close();                           </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="3-通过程序向闪存文件系统文件添加信息">3.通过程序向闪存文件系统文件添加信息</h3><p>要注意写入操作和添加操作的区别。假设闪存系统中已经有这样一文件，写入操作会对原文件进行覆盖，而添加操作会将文件最后加入新的内容。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-append</span></span><br><span class="line"><span class="comment">=</span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何向NodeMCU的内置SPIFFS中存储的文件</span></span><br><span class="line"><span class="comment">                            notes.txt添加数据。                      </span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------  </span></span><br><span class="line"><span class="comment">函数说明：</span></span><br><span class="line"><span class="comment">SPIFFS.open(file_name, &quot;a&quot;); </span></span><br><span class="line"><span class="comment">以上SPIFFS函数有两个参数：</span></span><br><span class="line"><span class="comment">第一个参数是被操作的文件名称，本示例中该文件为/notes.txt</span></span><br><span class="line"><span class="comment">第二个参数&quot;a&quot; 代表添加文件信息。（如需了解如何读取信息，请参阅示例程序esp8266-flash-read）</span></span><br><span class="line"><span class="comment">此示例程序所演示的是向SPIFFS中的文件里添加信息。这一操作写入信息有所区别。</span></span><br><span class="line"><span class="comment">添加信息是不会删除文件内原有信息，而是在原有信息后面添加新的信息。</span></span><br><span class="line"><span class="comment">但写入操作（示例 esp8266-flash-write.ino）是将文件内容完全清除，重新写入新信息。    </span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">String file_name = <span class="string">&quot;/taichi-maker/notes.txt&quot;</span>;              <span class="comment">//被读取的文件位置和名称</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(SPIFFS.begin())&#123; <span class="comment">// 启动闪存文件系统</span></span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Failed to Start.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="comment">//确认闪存中是否有file_name文件</span></span><br><span class="line">  <span class="keyword">if</span> (SPIFFS.exists(file_name))&#123;</span><br><span class="line">    </span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.println(<span class="string">&quot; FOUND.&quot;</span>);</span><br><span class="line"> </span><br><span class="line">    File dataFile = SPIFFS.open(file_name, <span class="string">&quot;a&quot;</span>);<span class="comment">// 建立File对象用于向SPIFFS中的file对象（即/notes.txt）写入信息</span></span><br><span class="line">    dataFile.println(<span class="string">&quot;This is Appended Info.&quot;</span>); <span class="comment">// 向dataFile添加字符串信息</span></span><br><span class="line">    dataFile.close();                           <span class="comment">// 完成文件操作后关闭文件   </span></span><br><span class="line">    Serial.println(<span class="string">&quot;Finished Appending data to SPIFFS&quot;</span>);</span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.print(<span class="string">&quot; NOT FOUND.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">                        </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="4-通过程序读取目录内容">4.通过程序读取目录内容</h3><p>读取某个文件夹中程序的内容。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-folder-read</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何从NodeMCU的内置SPIFFS中文件夹里读取文件信息</span></span><br><span class="line"><span class="comment">                           文件夹内容将会通过串口监视器显示出来。</span></span><br><span class="line"><span class="comment">                           </span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">函数说明：</span></span><br><span class="line"><span class="comment">SPIFFS.openDir(folder_name);</span></span><br><span class="line"><span class="comment">以上函数打开指定目录并返回一个目录对象实例。</span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">String file_name = <span class="string">&quot;/taichi-maker/myFile.txt&quot;</span>; <span class="comment">//被读取的文件位置和名称</span></span><br><span class="line">String folder_name = <span class="string">&quot;/taichi-maker&quot;</span>;         <span class="comment">//被读取的文件夹</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(SPIFFS.begin())&#123; <span class="comment">// 启动闪存文件系统</span></span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Failed to Start.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  File dataFile = SPIFFS.open(file_name, <span class="string">&quot;w&quot;</span>);<span class="comment">// 建立File对象用于向SPIFFS中的file对象（即myFile.txt）写入信息</span></span><br><span class="line">  dataFile.println(<span class="string">&quot;Hello Taichi-Maker.&quot;</span>);    <span class="comment">// 向dataFile写入字符串信息</span></span><br><span class="line">  dataFile.close();                           <span class="comment">// 完成文件写入后关闭文件</span></span><br><span class="line">  Serial.println(F(<span class="string">&quot;Finished Writing data to SPIFFS&quot;</span>));</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 显示目录中文件内容以及文件大小</span></span><br><span class="line">  Dir dir = SPIFFS.openDir(folder_name);  <span class="comment">// 建立“目录”对象</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span> (dir.next()) &#123;  <span class="comment">// dir.next()用于检查目录中是否还有“下一个文件”</span></span><br><span class="line">    Serial.println(dir.fileName()); <span class="comment">// 输出文件名</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="5-从闪存文件系统中删除文件">5.从闪存文件系统中删除文件</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-remove</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">日期/Date（YYYYMMDD）      : 20191109</span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何删除SPIFFS中存储的文件                        </span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">String file_name = <span class="string">&quot;/taichi-maker/notes.txt&quot;</span>;              <span class="comment">//被读取的文件位置和名称</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(SPIFFS.begin())&#123; <span class="comment">// 启动闪存文件系统</span></span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.println(<span class="string">&quot;SPIFFS Failed to Start.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//从闪存中删除file_name文件</span></span><br><span class="line">  <span class="keyword">if</span> (SPIFFS.remove(file_name))&#123;</span><br><span class="line">    </span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.println(<span class="string">&quot; remove sucess&quot;</span>);</span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Serial.print(file_name);</span><br><span class="line">    Serial.println(<span class="string">&quot; remove fail&quot;</span>);</span><br><span class="line">  &#125;                       </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="6-显示闪存文件系统信息">6.显示闪存文件系统信息</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name      : esp8266-flash-info</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose           : 此程序用于演示如何使用FSInfo对象来显示闪存文件系统状态</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;FS.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">FSInfo fs_info;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line"> </span><br><span class="line">  SPIFFS.begin();       <span class="comment">//启动SPIFFS</span></span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;SPIFFS Started.&quot;</span>);</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 闪存文件系统信息</span></span><br><span class="line">  SPIFFS.info(fs_info);</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 可用空间总和（单位：字节）</span></span><br><span class="line">  Serial.print(<span class="string">&quot;totalBytes: &quot;</span>);     </span><br><span class="line">  Serial.print(fs_info.totalBytes); </span><br><span class="line">  Serial.println(<span class="string">&quot; Bytes&quot;</span>); </span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 已用空间（单位：字节）</span></span><br><span class="line">  Serial.print(<span class="string">&quot;usedBytes: &quot;</span>); </span><br><span class="line">  Serial.print(fs_info.usedBytes);</span><br><span class="line">  Serial.println(<span class="string">&quot; Bytes&quot;</span>); </span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 最大文件名字符限制（含路径和&#x27;\0&#x27;）</span></span><br><span class="line">  Serial.print(<span class="string">&quot;maxPathLength: &quot;</span>); </span><br><span class="line">  Serial.println(fs_info.maxPathLength);</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 最多允许打开文件数量</span></span><br><span class="line">  Serial.print(<span class="string">&quot;maxOpenFiles: &quot;</span>); </span><br><span class="line">  Serial.println(fs_info.maxOpenFiles);</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// 存储块大小</span></span><br><span class="line">  Serial.print(<span class="string">&quot;blockSize: &quot;</span>); </span><br><span class="line">  Serial.println(fs_info.blockSize);</span><br><span class="line"> </span><br><span class="line">  <span class="comment">// </span></span><br><span class="line">  Serial.print(<span class="string">&quot;: &quot;</span>);</span><br><span class="line">  Serial.println(fs_info.pageSize);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="ESP8266闪存文件应用">ESP8266闪存文件应用</h2><p>向esp8266上传任意的文件类型。</p>]]></content>
      
      
      
        <tags>
            
            <tag> esp8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp8266网络服务器</title>
      <link href="/posts/56387d0f.html"/>
      <url>/posts/56387d0f.html</url>
      
        <content type="html"><![CDATA[<h2 id="ESP8266-NodeMCU网服务器">ESP8266-NodeMCU网服务器</h2><h3 id="建立基本网络服务器">建立基本网络服务器</h3><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/esp8266-nodemcu-web-server/web-server/">建立基本网络服务器</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment">项目名称/Project          : 零基础入门学用物联网</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose          : 使用NodeMCU建立基本服务器。用户可通过浏览器使用8266的IP地址</span></span><br><span class="line"><span class="comment">                           访问8266所建立的基本网页（Hello from ESP8266）</span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>        <span class="comment">// 本程序使用 ESP8266WiFi库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFiMulti.h&gt;</span>   <span class="comment">//  ESP8266WiFiMulti库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WebServer.h&gt;</span>   <span class="comment">//  ESP8266WebServer库</span></span></span><br><span class="line"> </span><br><span class="line">ESP8266WiFiMulti wifiMulti;     <span class="comment">// 建立ESP8266WiFiMulti对象,对象名称是&#x27;wifiMulti&#x27;</span></span><br><span class="line"> </span><br><span class="line">ESP8266WebServer <span class="title function_">esp8266_server</span><span class="params">(<span class="number">80</span>)</span>;<span class="comment">// 建立ESP8266WebServer对象，对象名称为esp8266_server</span></span><br><span class="line">                                    <span class="comment">// 括号中的数字是网路服务器响应http请求的端口号</span></span><br><span class="line">                                    <span class="comment">// 网络服务器标准http端口号为80，因此这里使用80为端口号</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);          <span class="comment">// 启动串口通讯</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">//通过addAp函数存储  WiFi名称       WiFi密码</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker&quot;</span>, <span class="string">&quot;12345678&quot;</span>);  <span class="comment">// 这三条语句通过调用函数addAP来记录3个不同的WiFi网络信息。</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker2&quot;</span>, <span class="string">&quot;87654321&quot;</span>); <span class="comment">// 这3个WiFi网络名称分别是taichi-maker, taichi-maker2, taichi-maker3。</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker3&quot;</span>, <span class="string">&quot;13572468&quot;</span>); <span class="comment">// 这3个网络的密码分别是123456789，87654321，13572468。</span></span><br><span class="line">                                                <span class="comment">// 此处WiFi信息只是示例，请在使用时将需要连接的WiFi信息填入相应位置。</span></span><br><span class="line">                                                <span class="comment">// 另外这里只存储了3个WiFi信息，您可以存储更多的WiFi信息在此处。</span></span><br><span class="line"> </span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;                                 </span><br><span class="line">  <span class="keyword">while</span> (wifiMulti.run() != WL_CONNECTED) &#123;  <span class="comment">// 此处的wifiMulti.run()是重点。通过wifiMulti.run()，NodeMCU将会在当前</span></span><br><span class="line">    delay(<span class="number">1000</span>);                             <span class="comment">// 环境中搜索addAP函数所存储的WiFi。如果搜到多个存储的WiFi那么NodeMCU</span></span><br><span class="line">    Serial.print(i++); Serial.print(<span class="string">&#x27; &#x27;</span>);    <span class="comment">// 将会连接信号最强的那一个WiFi信号。</span></span><br><span class="line">  &#125;                                          <span class="comment">// 一旦连接WiFI成功，wifiMulti.run()将会返回“WL_CONNECTED”。这也是</span></span><br><span class="line">                                             <span class="comment">// 此处while循环判断是否跳出循环的条件。</span></span><br><span class="line"> </span><br><span class="line">  <span class="comment">// WiFi连接成功后将通过串口监视器输出连接成功信息 </span></span><br><span class="line">  Serial.println(<span class="string">&#x27;\n&#x27;</span>);                     <span class="comment">// WiFi连接成功后</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Connected to &quot;</span>);            <span class="comment">// NodeMCU将通过串口监视器输出。</span></span><br><span class="line">  Serial.println(WiFi.SSID());              <span class="comment">// 连接的WiFI名称</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address:\t&quot;</span>);            <span class="comment">// 以及</span></span><br><span class="line">  Serial.println(WiFi.localIP());           <span class="comment">// NodeMCU的IP地址</span></span><br><span class="line">  </span><br><span class="line"><span class="comment">//--------&quot;启动网络服务功能&quot;程序部分开始-------- //  此部分为程序为本示例程序重点1</span></span><br><span class="line">  esp8266_server.begin();                   <span class="comment">//  详细讲解请参见太极创客网站《零基础入门学用物联网》</span></span><br><span class="line">  esp8266_server.on(<span class="string">&quot;/&quot;</span>, handleRoot);       <span class="comment">//  第3章-第2节 ESP8266-NodeMCU网络服务器-1</span></span><br><span class="line">  esp8266_server.onNotFound(handleNotFound);        </span><br><span class="line"><span class="comment">//--------&quot;启动网络服务功能&quot;程序部分结束--------</span></span><br><span class="line">  Serial.println(<span class="string">&quot;HTTP esp8266_server started&quot;</span>);<span class="comment">//  告知用户ESP8266网络服务功能已经启动</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 以下函数语句为本示例程序重点3</span></span><br><span class="line"><span class="comment">详细讲解请参见太极创客网站《零基础入门学用物联网》</span></span><br><span class="line"><span class="comment">第3章-第2节 3_2_1_First_Web_Server 的说明讲解*/</span>  </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  esp8266_server.handleClient();     <span class="comment">// 处理http服务器访问</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 以下两个函数为本示例程序重点2</span></span><br><span class="line"><span class="comment">详细讲解请参见太极创客网站《零基础入门学用物联网》</span></span><br><span class="line"><span class="comment">第3章-第2节 3_2_1_First_Web_Server 的说明讲解*/</span>                                                                            </span><br><span class="line"><span class="type">void</span> <span class="title function_">handleRoot</span><span class="params">()</span> &#123;   <span class="comment">//处理网站根目录“/”的访问请求 </span></span><br><span class="line">  esp8266_server.send(<span class="number">200</span>, <span class="string">&quot;text/plain&quot;</span>, <span class="string">&quot;Hello from ESP8266&quot;</span>);   <span class="comment">// NodeMCU将调用此函数。</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">handleNotFound</span><span class="params">()</span>&#123;                                        <span class="comment">// 当浏览器请求的网络资源无法在服务器找到时，</span></span><br><span class="line">  esp8266_server.send(<span class="number">404</span>, <span class="string">&quot;text/plain&quot;</span>, <span class="string">&quot;404: Not found&quot;</span>);   <span class="comment">// NodeMCU将调用此函数。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当这段示例程序上传给NodeMCU以后，启动NodeMCU并且确保它已经成功连接WiFi。接下来请打开浏览器，并且在地址栏中输入NodeMCU的IP地址并按下回车。假如将在浏览器中看到“Hello from ESP8266”，那么恭喜你已经成功的让NodeMCU实现了网络服务功能，因为你所看到的这条文字信息正是来自于NodeMCU。换句话说，NodeMCU为你建立了一个超级迷你的小网站。这个网站只有一个网页。这个网页只有一行文字“Hello from ESP8266”。</p><p> </p><h3 id="通过网络服务实现NodeMCU开发板基本控制">通过网络服务实现NodeMCU开发板基本控制</h3><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/esp8266-nodemcu-web-server/pin-control/">通过网络服务实现NodeMCU开发板基本控制 </a></p><p>在网页中控制nodemcu</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name     : 3_2_2_Turning_on_and_off_an_LED</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose          : 使用NodeMCU建立基本服务器。用户可通过浏览器使用8266的IP地址</span></span><br><span class="line"><span class="comment">                           访问8266所建立的基本网页并通过该页面点亮/熄灭NodeMCU的内置LED</span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>        <span class="comment">// 本程序使用 ESP8266WiFi库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFiMulti.h&gt;</span>   <span class="comment">//  ESP8266WiFiMulti库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WebServer.h&gt;</span>   <span class="comment">//  ESP8266WebServer库</span></span></span><br><span class="line"> </span><br><span class="line">ESP8266WiFiMulti wifiMulti;     <span class="comment">// 建立ESP8266WiFiMulti对象,对象名称是 &#x27;wifiMulti&#x27;</span></span><br><span class="line"> </span><br><span class="line">ESP8266WebServer <span class="title function_">esp8266_server</span><span class="params">(<span class="number">80</span>)</span>;<span class="comment">// 建立网络服务器对象，该对象用于响应HTTP请求。监听端口（80）</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);   <span class="comment">// 启动串口通讯</span></span><br><span class="line"> </span><br><span class="line">  pinMode(LED_BUILTIN, OUTPUT); <span class="comment">//设置内置LED引脚为输出模式以便控制LED</span></span><br><span class="line">  </span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_1&quot;</span>, <span class="string">&quot;your_password_for_AP_1&quot;</span>); <span class="comment">// 将需要连接的一系列WiFi ID和密码输入这里</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_2&quot;</span>, <span class="string">&quot;your_password_for_AP_2&quot;</span>); <span class="comment">// ESP8266-NodeMCU再启动后会扫描当前网络</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_3&quot;</span>, <span class="string">&quot;your_password_for_AP_3&quot;</span>); <span class="comment">// 环境查找是否有这里列出的WiFi ID。如果有</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Connecting ...&quot;</span>);                            <span class="comment">// 则尝试使用此处存储的密码进行连接。</span></span><br><span class="line">  </span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;                                 </span><br><span class="line">  <span class="keyword">while</span> (wifiMulti.run() != WL_CONNECTED) &#123;  <span class="comment">// 此处的wifiMulti.run()是重点。通过wifiMulti.run()，NodeMCU将会在当前</span></span><br><span class="line">    delay(<span class="number">1000</span>);                             <span class="comment">// 环境中搜索addAP函数所存储的WiFi。如果搜到多个存储的WiFi那么NodeMCU</span></span><br><span class="line">    Serial.print(i++); Serial.print(<span class="string">&#x27; &#x27;</span>);    <span class="comment">// 将会连接信号最强的那一个WiFi信号。</span></span><br><span class="line">  &#125;                                          <span class="comment">// 一旦连接WiFI成功，wifiMulti.run()将会返回“WL_CONNECTED”。这也是</span></span><br><span class="line">                                             <span class="comment">// 此处while循环判断是否跳出循环的条件。</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// WiFi连接成功后将通过串口监视器输出连接成功信息 </span></span><br><span class="line">  Serial.println(<span class="string">&#x27;\n&#x27;</span>);</span><br><span class="line">  Serial.print(<span class="string">&quot;Connected to &quot;</span>);</span><br><span class="line">  Serial.println(WiFi.SSID());              <span class="comment">// 通过串口监视器输出连接的WiFi名称</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address:\t&quot;</span>);</span><br><span class="line">  Serial.println(WiFi.localIP());           <span class="comment">// 通过串口监视器输出ESP8266-NodeMCU的IP</span></span><br><span class="line"> </span><br><span class="line">  esp8266_server.begin();                           <span class="comment">// 启动网站服务</span></span><br><span class="line">  esp8266_server.on(<span class="string">&quot;/&quot;</span>, HTTP_GET, handleRoot);     <span class="comment">// 设置服务器根目录即&#x27;/&#x27;的函数&#x27;handleRoot&#x27;</span></span><br><span class="line">  esp8266_server.on(<span class="string">&quot;/LED&quot;</span>, HTTP_POST, handleLED);  <span class="comment">// 设置处理LED控制请求的函数&#x27;handleLED&#x27;</span></span><br><span class="line">  esp8266_server.onNotFound(handleNotFound);        <span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;</span></span><br><span class="line"> </span><br><span class="line">  Serial.println(<span class="string">&quot;HTTP esp8266_server started&quot;</span>);<span class="comment">//  告知用户ESP8266网络服务功能已经启动</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">(<span class="type">void</span>)</span>&#123;</span><br><span class="line">  esp8266_server.handleClient();                     <span class="comment">// 检查http服务器访问</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*设置服务器根目录即&#x27;/&#x27;的函数&#x27;handleRoot&#x27;</span></span><br><span class="line"><span class="comment">  该函数的作用是每当有客户端访问NodeMCU服务器根目录时，</span></span><br><span class="line"><span class="comment">  NodeMCU都会向访问设备发送 HTTP 状态 200 (Ok) 这是send函数的第一个参数。</span></span><br><span class="line"><span class="comment">  同时NodeMCU还会向浏览器发送HTML代码，以下示例中send函数中第三个参数，</span></span><br><span class="line"><span class="comment">  也就是双引号中的内容就是NodeMCU发送的HTML代码。该代码可在网页中产生LED控制按钮。 </span></span><br><span class="line"><span class="comment">  当用户按下按钮时，浏览器将会向NodeMCU的/LED页面发送HTTP请求，请求方式为POST。</span></span><br><span class="line"><span class="comment">  NodeMCU接收到此请求后将会执行handleLED函数内容*/</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">handleRoot</span><span class="params">()</span> &#123;       </span><br><span class="line">  esp8266_server.send(<span class="number">200</span>, <span class="string">&quot;text/html&quot;</span>, <span class="string">&quot;&lt;form action=\&quot;/LED\&quot; method=\&quot;POST\&quot;&gt;&lt;input type=\&quot;submit\&quot; value=\&quot;Toggle LED\&quot;&gt;&lt;/form&gt;&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//处理LED控制请求的函数&#x27;handleLED&#x27;</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">handleLED</span><span class="params">()</span> &#123;                          </span><br><span class="line">  digitalWrite(LED_BUILTIN,!digitalRead(LED_BUILTIN));<span class="comment">// 改变LED的点亮或者熄灭状态</span></span><br><span class="line">  esp8266_server.sendHeader(<span class="string">&quot;Location&quot;</span>,<span class="string">&quot;/&quot;</span>);          <span class="comment">// 跳转回页面根目录</span></span><br><span class="line">  esp8266_server.send(<span class="number">303</span>);                           <span class="comment">// 发送Http相应代码303 跳转  </span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">handleNotFound</span><span class="params">()</span>&#123;</span><br><span class="line">  esp8266_server.send(<span class="number">404</span>, <span class="string">&quot;text/plain&quot;</span>, <span class="string">&quot;404: Not found&quot;</span>); <span class="comment">// 发送 HTTP 状态 404 (未找到页面) 并向浏览器发送文字 &quot;404: Not found&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过网络服务实现NodeMCU开发板基本控制-2">通过网络服务实现NodeMCU开发板基本控制</h3><p>我们可以通过NodeMCU开发板上的FLASH按键控制D3引脚的电平。当我们没有按下该按键时，D3引脚将会保持高电平状态。当按下该按键后，D3引脚会变为低电平。</p><figure class="highlight v"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name     : 3_2_3_Pin_State_Display</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose          : 使用NodeMCU建立基本服务器。该页面将会自动刷新并且显示NodeMCU</span></span><br><span class="line"><span class="comment">                           的D3引脚状态。NodeMCU开发板上的FLASH按键可以控制D3引脚的电平。</span></span><br><span class="line"><span class="comment">                           没有按下该按键时D3引脚将会保持高电平状态。当按下该按键后，</span></span><br><span class="line"><span class="comment">                           D3引脚会变为低电平。</span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line">#<span class="keyword">include</span> &lt;ESP8266WiFi<span class="variable">.h</span>&gt;        <span class="comment">// 本程序使用 ESP8266WiFi库</span></span><br><span class="line">#<span class="keyword">include</span> &lt;ESP8266WiFiMulti<span class="variable">.h</span>&gt;   <span class="comment">//  ESP8266WiFiMulti库</span></span><br><span class="line">#<span class="keyword">include</span> &lt;ESP8266WebServer<span class="variable">.h</span>&gt;   <span class="comment">//  ESP8266WebServer库</span></span><br><span class="line"> </span><br><span class="line">#define buttonPin D3            <span class="comment">// 按钮引脚D3</span></span><br><span class="line"> </span><br><span class="line">ESP8266WiFiMulti wifiMulti;     <span class="comment">// 建立ESP8266WiFiMulti对象,对象名称是&#x27;wifiMulti&#x27;</span></span><br><span class="line"> </span><br><span class="line">ESP8266WebServer esp8266_server(<span class="number">80</span>);<span class="comment">// 建立网络服务器对象，该对象用于响应HTTP请求。监听端口（80）</span></span><br><span class="line"> </span><br><span class="line">bool pinState;  <span class="comment">// 存储引脚状态用变量</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">void</span> setup()&#123;</span><br><span class="line">  Serial<span class="variable">.begin</span>(<span class="number">9600</span>);   <span class="comment">// 启动串口通讯</span></span><br><span class="line"> </span><br><span class="line">  pinMode(buttonPin, INPUT_PULLUP); <span class="comment">// 将按键引脚设置为输入上拉模式</span></span><br><span class="line"> </span><br><span class="line">  wifiMulti<span class="variable">.addAP</span>(<span class="string">&quot;ssid_from_AP_1&quot;</span>, <span class="string">&quot;your_password_for_AP_1&quot;</span>); <span class="comment">// 将需要连接的一系列WiFi ID和密码输入这里</span></span><br><span class="line">  wifiMulti<span class="variable">.addAP</span>(<span class="string">&quot;ssid_from_AP_2&quot;</span>, <span class="string">&quot;your_password_for_AP_2&quot;</span>); <span class="comment">// ESP8266-NodeMCU再启动后会扫描当前网络</span></span><br><span class="line">  wifiMulti<span class="variable">.addAP</span>(<span class="string">&quot;ssid_from_AP_3&quot;</span>, <span class="string">&quot;your_password_for_AP_3&quot;</span>); <span class="comment">// 环境查找是否有这里列出的WiFi ID。如果有</span></span><br><span class="line">  Serial<span class="variable">.println</span>(<span class="string">&quot;Connecting ...&quot;</span>);                            <span class="comment">// 则尝试使用此处存储的密码进行连接。</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">int</span> i = <span class="number">0</span>;                                 </span><br><span class="line">  <span class="keyword">while</span> (wifiMulti<span class="variable">.run</span>() != WL_CONNECTED) &#123;  <span class="comment">// 此处的wifiMulti.run()是重点。通过wifiMulti.run()，NodeMCU将会在当前</span></span><br><span class="line">    delay(<span class="number">1000</span>);                             <span class="comment">// 环境中搜索addAP函数所存储的WiFi。如果搜到多个存储的WiFi那么NodeMCU</span></span><br><span class="line">    Serial<span class="variable">.print</span>(i++); Serial<span class="variable">.print</span>(&#x27; &#x27;);    <span class="comment">// 将会连接信号最强的那一个WiFi信号。</span></span><br><span class="line">  &#125;                                          <span class="comment">// 一旦连接WiFI成功，wifiMulti.run()将会返回“WL_CONNECTED”。这也是</span></span><br><span class="line">                                             <span class="comment">// 此处while循环判断是否跳出循环的条件。</span></span><br><span class="line">  <span class="comment">// WiFi连接成功后将通过串口监视器输出连接成功信息 </span></span><br><span class="line">  Serial<span class="variable">.println</span>(&#x27;\n&#x27;);                     <span class="comment">// WiFi连接成功后</span></span><br><span class="line">  Serial<span class="variable">.print</span>(<span class="string">&quot;Connected to &quot;</span>);            <span class="comment">// NodeMCU将通过串口监视器输出。</span></span><br><span class="line">  Serial<span class="variable">.println</span>(WiFi<span class="variable">.SSID</span>());              <span class="comment">// 连接的WiFI名称</span></span><br><span class="line">  Serial<span class="variable">.print</span>(<span class="string">&quot;IP address:\t&quot;</span>);            <span class="comment">// 以及</span></span><br><span class="line">  Serial<span class="variable">.println</span>(WiFi<span class="variable">.localIP</span>());           <span class="comment">// NodeMCU的IP地址</span></span><br><span class="line">  </span><br><span class="line">  esp8266_server<span class="variable">.begin</span>();                   <span class="comment">// 启动网站服务                </span></span><br><span class="line">  esp8266_server<span class="variable">.on</span>(<span class="string">&quot;/&quot;</span>, handleRoot);       <span class="comment">// 设置服务器根目录即&#x27;/&#x27;的函数&#x27;handleRoot&#x27;</span></span><br><span class="line">  esp8266_server<span class="variable">.onNotFound</span>(handleNotFound);<span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;        </span></span><br><span class="line"> </span><br><span class="line">  Serial<span class="variable">.println</span>(<span class="string">&quot;HTTP esp8266_server started&quot;</span>);<span class="comment">//  告知用户ESP8266网络服务功能已经启动</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">void</span> loop()&#123;</span><br><span class="line">  esp8266_server<span class="variable">.handleClient</span>();     <span class="comment">// 处理http服务器访问</span></span><br><span class="line">  pinState = digitalRead(buttonPin); <span class="comment">// 获取引脚状态</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 以下函数处理网站首页的访问请求。此函数为本示例程序重点1</span></span><br><span class="line"><span class="comment">*/</span>                                                                       </span><br><span class="line"><span class="keyword">void</span> handleRoot() &#123;   </span><br><span class="line">  String displayPinState;                   <span class="comment">// 存储按键状态的字符串变量</span></span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(pinState == HIGH)&#123;                     <span class="comment">// 当按键引脚D3为高电平</span></span><br><span class="line">    displayPinState = <span class="string">&quot;Button State: HIGH&quot;</span>; <span class="comment">// 字符串赋值高电平信息</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;                                  <span class="comment">// 当按键引脚D3为低电平</span></span><br><span class="line">    displayPinState = <span class="string">&quot;Button State: LOW&quot;</span>;  <span class="comment">// 字符串赋值低电平信息</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  esp8266_server<span class="variable">.send</span>(<span class="number">200</span>, <span class="string">&quot;text/plain&quot;</span>, displayPinState); </span><br><span class="line">                                            <span class="comment">// 向浏览器发送按键状态信息  </span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;</span></span><br><span class="line"><span class="keyword">void</span> handleNotFound()&#123;                                        <span class="comment">// 当浏览器请求的网络资源无法在服务器找到时，</span></span><br><span class="line">  esp8266_server<span class="variable">.send</span>(<span class="number">404</span>, <span class="string">&quot;text/plain&quot;</span>, <span class="string">&quot;404: Not found&quot;</span>);   <span class="comment">// NodeMCU将调用此函数。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然。也可以不用一种刷新网页，让其自动刷新。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**********************************************************************</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序名称/Program name     : 3_2_4_Pin_State_Display_Auto_Refresh</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">程序目的/Purpose          : 使用NodeMCU建立基本服务器。该网页将显示引脚D3状态。同时状态会</span></span><br><span class="line"><span class="comment">                           每隔5秒钟更新一次。</span></span><br><span class="line"><span class="comment">-----------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">***********************************************************************/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>        <span class="comment">// 本程序使用 ESP8266WiFi库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFiMulti.h&gt;</span>   <span class="comment">//  ESP8266WiFiMulti库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WebServer.h&gt;</span>   <span class="comment">//  ESP8266WebServer库</span></span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">define</span> buttonPin D3            <span class="comment">// 按钮引脚D3</span></span></span><br><span class="line"> </span><br><span class="line">ESP8266WiFiMulti wifiMulti;     <span class="comment">// 建立ESP8266WiFiMulti对象,对象名称是&#x27;wifiMulti&#x27;</span></span><br><span class="line"> </span><br><span class="line">ESP8266WebServer <span class="title function_">esp8266_server</span><span class="params">(<span class="number">80</span>)</span>;<span class="comment">// 建立网络服务器对象，该对象用于响应HTTP请求。监听端口（80）</span></span><br><span class="line"> </span><br><span class="line"><span class="type">bool</span> pinState;                      <span class="comment">// 存储引脚状态用变量</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span>&#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);          <span class="comment">// 启动串口通讯</span></span><br><span class="line">  delay(<span class="number">10</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);</span><br><span class="line"> </span><br><span class="line">  pinMode(buttonPin, INPUT_PULLUP); <span class="comment">// 将按键引脚设置为输入上拉模式</span></span><br><span class="line"> </span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_1&quot;</span>, <span class="string">&quot;your_password_for_AP_1&quot;</span>); <span class="comment">// 将需要连接的一系列WiFi ID和密码输入这里</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_2&quot;</span>, <span class="string">&quot;your_password_for_AP_2&quot;</span>); <span class="comment">// ESP8266-NodeMCU在启动后会扫描当前网络</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;ssid_from_AP_3&quot;</span>, <span class="string">&quot;your_password_for_AP_3&quot;</span>); <span class="comment">// 环境查找是否有这里列出的WiFi ID。如果有</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Connecting ...&quot;</span>);                            <span class="comment">// 则尝试使用此处存储的密码进行连接。</span></span><br><span class="line">                                                               <span class="comment">// 另外这里只存储了3个WiFi信息，您可以存储更多</span></span><br><span class="line">                                                               <span class="comment">// 的WiFi信息在此处。</span></span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;                                 </span><br><span class="line">  <span class="keyword">while</span> (wifiMulti.run() != WL_CONNECTED) &#123;  <span class="comment">// 此处的wifiMulti.run()是重点。通过wifiMulti.run()，NodeMCU将会在当前</span></span><br><span class="line">    delay(<span class="number">1000</span>);                             <span class="comment">// 环境中搜索addAP函数所存储的WiFi。如果搜到多个存储的WiFi那么NodeMCU</span></span><br><span class="line">    Serial.print(i++); Serial.print(<span class="string">&#x27; &#x27;</span>);    <span class="comment">// 将会连接信号最强的那一个WiFi信号。</span></span><br><span class="line">  &#125;                                          <span class="comment">// 一旦连接WiFI成功，wifiMulti.run()将会返回“WL_CONNECTED”。这也是</span></span><br><span class="line">                                             <span class="comment">// 此处while循环判断是否跳出循环的条件。</span></span><br><span class="line">  <span class="comment">// WiFi连接成功后将通过串口监视器输出连接成功信息 </span></span><br><span class="line">  Serial.println(<span class="string">&#x27;\n&#x27;</span>);                     <span class="comment">// WiFi连接成功后</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Connected to &quot;</span>);            <span class="comment">// NodeMCU将通过串口监视器输出。</span></span><br><span class="line">  Serial.println(WiFi.SSID());              <span class="comment">// 连接的WiFI名称</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address:\t&quot;</span>);            <span class="comment">// 以及</span></span><br><span class="line">  Serial.println(WiFi.localIP());           <span class="comment">// NodeMCU的IP地址</span></span><br><span class="line">  </span><br><span class="line">  esp8266_server.begin();                  </span><br><span class="line">  esp8266_server.on(<span class="string">&quot;/&quot;</span>, handleRoot);      </span><br><span class="line">  esp8266_server.onNotFound(handleNotFound);        </span><br><span class="line"> </span><br><span class="line">  Serial.println(<span class="string">&quot;HTTP esp8266_server started&quot;</span>);<span class="comment">//  告知用户ESP8266网络服务功能已经启动</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span>&#123;</span><br><span class="line">  esp8266_server.handleClient();     <span class="comment">// 处理http服务器访问</span></span><br><span class="line">  pinState = digitalRead(buttonPin); <span class="comment">// 获取引脚状态</span></span><br><span class="line">&#125;                                                                   </span><br><span class="line"> </span><br><span class="line"><span class="comment">/* 以下函数处理网站首页的访问请求。此函数为本示例程序重点1</span></span><br><span class="line"><span class="comment">*/</span>    </span><br><span class="line"><span class="type">void</span> <span class="title function_">handleRoot</span><span class="params">()</span> &#123;   <span class="comment">//处理网站目录“/”的访问请求 </span></span><br><span class="line">  esp8266_server.send(<span class="number">200</span>, <span class="string">&quot;text/html&quot;</span>, sendHTML(pinState));  </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">建立用于发送给客户端浏览器的HTML代码。此代码将会每隔5秒刷新页面。</span></span><br><span class="line"><span class="comment">通过页面刷新，引脚的最新状态也会显示于页面中</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">String <span class="title function_">sendHTML</span><span class="params">(<span class="type">bool</span> buttonState)</span>&#123;</span><br><span class="line">  </span><br><span class="line">  String htmlCode = <span class="string">&quot;&lt;!DOCTYPE html&gt; &lt;html&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;head&gt;&lt;meta http-equiv=&#x27;refresh&#x27; content=&#x27;5&#x27;/&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;title&gt;ESP8266 Butoon State&lt;/title&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;style&gt;html &#123; font-family: Helvetica; display: inline-block; margin: 0px auto; text-align: center;&#125;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;body&#123;margin-top: 50px;&#125; h1 &#123;color: #444444;margin: 50px auto 30px;&#125; h3 &#123;color: #444444;margin-bottom: 50px;&#125;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;/style&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;/head&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;body&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;h1&gt;ESP8266 BUTTON STATE&lt;/h1&gt;\n&quot;</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span>(buttonState)</span><br><span class="line">    &#123;htmlCode +=<span class="string">&quot;&lt;p&gt;Button Status: HIGH&lt;/p&gt;\n&quot;</span>;&#125;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    &#123;htmlCode +=<span class="string">&quot;&lt;p&gt;Button Status: LOW&lt;/p&gt;\n&quot;</span>;&#125;</span><br><span class="line">    </span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;/body&gt;\n&quot;</span>;</span><br><span class="line">  htmlCode +=<span class="string">&quot;&lt;/html&gt;\n&quot;</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> htmlCode;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 设置处理404情况的函数&#x27;handleNotFound&#x27;</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">handleNotFound</span><span class="params">()</span>&#123;                                        <span class="comment">// 当浏览器请求的网络资源无法在服务器找到时，</span></span><br><span class="line">  esp8266_server.send(<span class="number">404</span>, <span class="string">&quot;text/plain&quot;</span>, <span class="string">&quot;404: Not found&quot;</span>);   <span class="comment">// NodeMCU将调用此函数。</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p>]]></content>
      
      
      
        <tags>
            
            <tag> esp8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>esp8266</title>
      <link href="/posts/6450c6c0.html"/>
      <url>/posts/6450c6c0.html</url>
      
        <content type="html"><![CDATA[<h1>esp8266-NodeMCU</h1><p>esp8266的数字引脚电压是3.3v，即其引脚输出高电平就是3.3v。</p><p>设置数字引脚为读取模式，其所连接的电压不能超过3.3v。</p><p>模拟引脚可以读取电压范围0-1v。</p><h2 id="互联网协议">互联网协议</h2><h2 id="TCP-IP协议">TCP/IP协议</h2><p>以下内容的具体解释也可以在<a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/internet-basics/">第2章 互联网知识基础 – 太极创客 (taichi-maker.com)</a>中找到更好的解释。</p><table><thead><tr><th>分层名称</th><th>TCP/IP 包含以下协议</th></tr></thead><tbody><tr><td>应用层</td><td>HTTP，FTP，mDNS，WebSocket，OSC…</td></tr><tr><td>传输层</td><td>TCP,UDP</td></tr><tr><td>网络层</td><td>IP</td></tr><tr><td>链路层（网络接口层）</td><td>Ethernet,Wi-Fi…</td></tr></tbody></table><h3 id="链路层">链路层</h3><p>链路层的主要作用是实现设备之间的物理链接。</p><p>链路层的主要作用是实现设备之间的物理链接。举例来说，我们日常使用的WiFi就是链路层协议中的一种。</p><h4 id="ESP8266利用WiFi联网时有三种工作模式。">ESP8266利用WiFi联网时有三种工作模式。</h4><ul><li>接入点模式（esp8266自己当wifi）</li><li>无线终端模式（esp8266自己跟wifi进行连接，控制其他跟wifi连接后的设备）</li><li>混合模式</li></ul><p> </p><h3 id="网络层">网络层</h3><ul><li>IP地址</li></ul><p>给设备提供地址功能</p><h4 id="IP协议版本">IP协议版本</h4><p>查看电脑ip</p><p>命令提示符&gt;&gt;&gt;ipconfig</p><p> </p><p>网关相当于连接网络与网络之间的端口</p><p>wifi路由器会创建一个局域网，并给局域网内的每个设备分配一个ip地址，相对于互联网</p><p> </p><h2 id="传输层">传输层</h2><h3 id="TCP协议">TCP协议</h3><p>特点：稳</p><ul><li><p>保证所有数据都能被接收端接收</p></li><li><p>数据的传输顺序不会打乱</p></li><li><p>传输数据如有损坏则重发受损数据</p></li></ul><p> </p><p>TCP协议经常用于对数据稳定性要求比较高的领域</p><h4 id="TCP协议应用领域：">TCP协议应用领域：</h4><ul><li>电子邮件</li><li>文件传输</li></ul><p> </p><h3 id="UDP协议">UDP协议</h3><p>特点：快</p><ul><li>UDP比TCP速度快</li><li>不保证所有数据都能被接收端接收数数据一旦受损的，UDP协议将抛弃受损数据。</li><li>有数据损坏不会重发受损数据</li></ul><p> </p><h4 id="UDP协议应用领域：">UDP协议应用领域：</h4><ul><li>在线语音/视频</li><li>网游</li></ul><p> </p><h3 id="应用层">应用层</h3><h4 id="HTTP协议">HTTP协议</h4><p>由==请求==和==响应==进行工作的</p><h5 id="HTTP请求">HTTP请求</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET/HTTP/1.1    //请求行</span><br><span class="line">Host:www.taichi-maker.com   //请求头</span><br><span class="line">User-Agent:Mozilla/5.0（Windows NT 10.0WOW64）Accept：：text/html   </span><br><span class="line">Accept-Language:zh-CN,zh；q=0.8</span><br><span class="line">Accept-Encoding:gzip,deflate,sdch</span><br><span class="line">Connection:Keep-Alive</span><br></pre></td></tr></table></figure><h6 id="请求行">请求行</h6><h6 id="请求头">请求头</h6><p>HTTP1.0定义了三种请求方法：GET,POST和HEAD方法。 、</p><h5 id="HTTP响应">HTTP响应</h5><p> </p><p> </p><h2 id="ESP8266物联网开发基础">ESP8266物联网开发基础</h2><p>安装esp8266的网址<a href="https://cn.silabs.com/developers/usb-to-uart-bridge-vcp-drivers?tab=downloads">USB 至 UART 桥 VCP 驱动器 - 芯科科技 (silabs.com)</a></p><p> </p><h3 id="为开发板搭建开发环境">为开发板搭建开发环境</h3><p>要想使用Arduino IDE来配合NodeMCU开发板使用，首先要对Arduino IDE进行设置工作。</p><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/nodemcu-arduino-ide/">3-1-2 为ESP8266-NodeMCU搭建Arduino IDE开发环境 – 太极创客 (taichi-maker.com)</a></p><p>如果开发板库中没有，可以去网盘盘里进行手动安装。</p><p> </p><p>如果一切都正常安装，那么我们可以用如下一段代码测试，测试结果应为esp8266一个板载LED间断闪烁。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">// initialize digital pin LED_BUILTIN as an output.</span></span><br><span class="line">  pinMode(LED_BUILTIN, OUTPUT);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// the loop function runs over and over again forever</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">  digitalWrite(LED_BUILTIN, HIGH);  <span class="comment">// turn the LED on (HIGH is the voltage level)</span></span><br><span class="line">  delay(<span class="number">1000</span>);                      <span class="comment">// wait for a second</span></span><br><span class="line">  digitalWrite(LED_BUILTIN, LOW);   <span class="comment">// turn the LED off by making the voltage LOW</span></span><br><span class="line">  delay(<span class="number">1000</span>);                      <span class="comment">// wait for a second</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="NodeMCU开发板的接入点模式">NodeMCU开发板的接入点模式</h3><p>NodeMCU开发板可以建立WiFi网络供其它设备连接。当NodeMCU以此模式运行时，我们可以使用手机或者电脑搜索NodeMCU所发出的WiFi网络并进行连接。</p><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/ap/">3-1-3 NodeMCU开发板的接入点模式 – 太极创客 (taichi-maker.com)</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">NodeMCU接入点模式</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">此程序用于演示如何将NodeMCU以接入点模式工作。通过此程序，您可以使用</span></span><br><span class="line"><span class="comment">电脑或者手机连接NodeMCU所建立WiFi网络。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">网络名: taichi-maker</span></span><br><span class="line"><span class="comment">密码：12345678</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>        <span class="comment">// 本程序使用ESP8266WiFi库</span></span></span><br><span class="line"> </span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *ssid = <span class="string">&quot;taichi-maker&quot;</span>; <span class="comment">// 这里定义将要建立的WiFi名称。此处以&quot;taichi-maker&quot;为示例</span></span><br><span class="line">                                   <span class="comment">// 您可以将自己想要建立的WiFi名称填写入此处的双引号中</span></span><br><span class="line"> </span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *password = <span class="string">&quot;12345678&quot;</span>;  <span class="comment">// 这里定义将要建立的WiFi密码。此处以12345678为示例</span></span><br><span class="line">                                    <span class="comment">// 您可以将自己想要使用的WiFi密码放入引号内</span></span><br><span class="line">                                    <span class="comment">// 如果建立的WiFi不要密码，则在双引号内不要填入任何信息</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);              <span class="comment">// 启动串口通讯</span></span><br><span class="line"> </span><br><span class="line">  WiFi.softAP(ssid, password);     <span class="comment">// 此语句是重点。WiFi.softAP用于启动NodeMCU的AP模式。</span></span><br><span class="line">                                   <span class="comment">// 括号中有两个参数，ssid是WiFi名。password是WiFi密码。</span></span><br><span class="line">                                   <span class="comment">// 这两个参数具体内容在setup函数之前的位置进行定义。</span></span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">  Serial.print(<span class="string">&quot;Access Point: &quot;</span>);    <span class="comment">// 通过串口监视器输出信息</span></span><br><span class="line">  Serial.println(ssid);              <span class="comment">// 告知用户NodeMCU所建立的WiFi名</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address: &quot;</span>);      <span class="comment">// 以及NodeMCU的IP地址</span></span><br><span class="line">  Serial.println(WiFi.softAPIP());   <span class="comment">// 通过调用WiFi.softAPIP()可以得到NodeMCU的IP地址</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行如上代码，我们可以创建一个wifi</p><p>连接过后在命令提示符中输入&gt;&gt;ping 192.168.4.1</p><p>ping就是用来测试我们的电脑是不是已经与某个网络设备成功连接了</p><p> </p><h3 id="NodeMCU开发板的无线终端模式">NodeMCU开发板的无线终端模式</h3><p>NodeMCU通过WiFi连接无线路由器并访问互联网。</p><p><a href="http://www.taichi-maker.com/homepage/esp8266-nodemcu-iot/iot-c/station/">3-1-4 NodeMCU开发板的无线终端模式 – 太极创客 (taichi-maker.com)</a></p><p>以下示例程序用于演示如何使用NodeMCU以无线终端模式通过WiFi连接无线路由器。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">NodeMCU无线终端模式连接WiFi</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">本示例程序用于演示如何使用NodeMCU无线终端模式连接WiFi</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>        <span class="comment">// 本程序使用ESP8266WiFi库</span></span></span><br><span class="line"> </span><br><span class="line"><span class="type">const</span> <span class="type">char</span>* ssid     = <span class="string">&quot;taichi-maker&quot;</span>;      <span class="comment">// 连接WiFi名（此处使用taichi-maker为示例）</span></span><br><span class="line">                                            <span class="comment">// 请将您需要连接的WiFi名填入引号中</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span>* password = <span class="string">&quot;12345678&quot;</span>;          <span class="comment">// 连接WiFi密码（此处使用12345678为示例）</span></span><br><span class="line">                                            <span class="comment">// 请将您需要连接的WiFi密码填入引号中</span></span><br><span class="line">                                            </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);         <span class="comment">// 启动串口通讯</span></span><br><span class="line">  </span><br><span class="line">  WiFi.begin(ssid, password);                  <span class="comment">// 启动网络连接</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Connecting to &quot;</span>);              <span class="comment">// 串口监视器输出网络连接信息</span></span><br><span class="line">  Serial.print(ssid); Serial.println(<span class="string">&quot; ...&quot;</span>);  <span class="comment">// 告知用户NodeMCU正在尝试WiFi连接</span></span><br><span class="line">  </span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;                                   <span class="comment">// 这一段程序语句用于检查WiFi是否连接成功</span></span><br><span class="line">  <span class="keyword">while</span> (WiFi.status() != WL_CONNECTED) &#123;      <span class="comment">// WiFi.status()函数的返回值是由NodeMCU的WiFi连接状态所决定的。 </span></span><br><span class="line">    delay(<span class="number">1000</span>);                               <span class="comment">// 如果WiFi连接成功则返回值为WL_CONNECTED                       </span></span><br><span class="line">    Serial.print(i++); Serial.print(<span class="string">&#x27; &#x27;</span>);      <span class="comment">// 此处通过While循环让NodeMCU每隔一秒钟检查一次WiFi.status()函数返回值</span></span><br><span class="line">  &#125;                                            <span class="comment">// 同时NodeMCU将通过串口监视器输出连接时长读秒。</span></span><br><span class="line">                                               <span class="comment">// 这个读秒是通过变量i每隔一秒自加1来实现的。</span></span><br><span class="line">                                               </span><br><span class="line">  Serial.println(<span class="string">&quot;&quot;</span>);                          <span class="comment">// WiFi连接成功后</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Connection established!&quot;</span>);   <span class="comment">// NodeMCU将通过串口监视器输出&quot;连接成功&quot;信息。</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address:    &quot;</span>);             <span class="comment">// 同时还将输出NodeMCU的IP地址。这一功能是通过调用</span></span><br><span class="line">  Serial.println(WiFi.localIP());              <span class="comment">// WiFi.localIP()函数来实现的。该函数的返回值即NodeMCU的IP地址。</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;                                   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然也可以一次性添加很多wifi名称和密码，使nodemuc选择性添加最强信号的网络。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">NodeMCU无线终端模式连接WiFi-2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">此程序将会控制NodeMCU在当前的网络环境里搜索预先存储好的WiFi。</span></span><br><span class="line"><span class="comment">一旦找到预存的WiFi名称，NodeMCU将会使用预存的密码信息尝试连接该WiFi。</span></span><br><span class="line"><span class="comment">如果同时找到多个预存WiFi，NodeMCU将会尝试连接信号最强的WiFi。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFi.h&gt;</span>          <span class="comment">// 本程序使用ESP8266WiFi库</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ESP8266WiFiMulti.h&gt;</span>   <span class="comment">// 本程序使用ESP8266WiFiMulti库</span></span></span><br><span class="line"> </span><br><span class="line">ESP8266WiFiMulti wifiMulti;     <span class="comment">// 建立ESP8266WiFiMulti对象,对象名称是&#x27;wifiMulti&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);            <span class="comment">// 启动串口通讯</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">//通过addAp函数存储  WiFi名称       WiFi密码</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker&quot;</span>, <span class="string">&quot;12345678&quot;</span>);  <span class="comment">// 这三条语句通过调用函数addAP来记录3个不同的WiFi网络信息。</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker2&quot;</span>, <span class="string">&quot;87654321&quot;</span>); <span class="comment">// 这3个WiFi网络名称分别是taichi-maker, taichi-maker2, taichi-maker3。</span></span><br><span class="line">  wifiMulti.addAP(<span class="string">&quot;taichi-maker3&quot;</span>, <span class="string">&quot;13572468&quot;</span>); <span class="comment">// 这3个网络的密码分别是123456789，87654321，13572468。</span></span><br><span class="line">                                                <span class="comment">// 此处WiFi信息只是示例，请在使用时将需要连接的WiFi信息填入相应位置。</span></span><br><span class="line">                                                <span class="comment">// 另外这里只存储了3个WiFi信息，您可以存储更多的WiFi信息在此处。</span></span><br><span class="line">                                                </span><br><span class="line">  Serial.println(<span class="string">&quot;Connecting ...&quot;</span>);         <span class="comment">// 通过串口监视器输出信息告知用户NodeMCU正在尝试连接WiFi</span></span><br><span class="line">  <span class="type">int</span> i = <span class="number">0</span>;                                 </span><br><span class="line">  <span class="keyword">while</span> (wifiMulti.run() != WL_CONNECTED) &#123;  <span class="comment">// 此处的wifiMulti.run()是重点。通过wifiMulti.run()，NodeMCU将会在当前</span></span><br><span class="line">    delay(<span class="number">1000</span>);                             <span class="comment">// 环境中搜索addAP函数所存储的WiFi。如果搜到多个存储的WiFi那么NodeMCU</span></span><br><span class="line">    Serial.print(<span class="string">&#x27;.&#x27;</span>);                       <span class="comment">// 将会连接信号最强的那一个WiFi信号。</span></span><br><span class="line">  &#125;                                           <span class="comment">// 一旦连接WiFI成功，wifiMulti.run()将会返回“WL_CONNECTED”。这也是</span></span><br><span class="line">                                              <span class="comment">// 此处while循环判断是否跳出循环的条件。</span></span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">  Serial.println(<span class="string">&#x27;\n&#x27;</span>);                     <span class="comment">// WiFi连接成功后</span></span><br><span class="line">  Serial.print(<span class="string">&quot;Connected to &quot;</span>);            <span class="comment">// NodeMCU将通过串口监视器输出。</span></span><br><span class="line">  Serial.println(WiFi.SSID());              <span class="comment">// 连接的WiFI名称</span></span><br><span class="line">  Serial.print(<span class="string">&quot;IP address:\t&quot;</span>);            <span class="comment">// 以及</span></span><br><span class="line">  Serial.println(WiFi.localIP());           <span class="comment">// NodeMCU的IP地址</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p>]]></content>
      
      
      
        <tags>
            
            <tag> esp8266 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>inventor开发</title>
      <link href="/posts/null.html"/>
      <url>/posts/null.html</url>
      
        <content type="html"><![CDATA[<h1>app inventor开发蓝牙app</h1><h2 id="蓝牙app开发流程">蓝牙app开发流程</h2><ol><li>App inventor开发APP</li><li>AT指令配置蓝牙模块</li><li>测试</li></ol><p> </p><p>App inventor网址：<a href="http://app.gzjkw.net/">http://app.gzjkw.net/</a></p><h2 id="组件设计">组件设计</h2><h3 id="创建">创建</h3><h4 id="蓝牙的选择和断开">蓝牙的选择和断开</h4><p>表格布局--------列表选择框-------可以选择连接哪个蓝牙</p><p> </p><h2 id="逻辑设计">逻辑设计</h2><p>列表选择框</p>]]></content>
      
      
      
        <tags>
            
            <tag> app开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hc06</title>
      <link href="/posts/85bbd6e3.html"/>
      <url>/posts/85bbd6e3.html</url>
      
        <content type="html"><![CDATA[<h1>HC-06 无线蓝牙串口透传模块</h1><p>arduino和hc06的高电平时不一样的</p><p> </p><h2 id="串口透传">串口透传</h2><p>在数据传输过程中，数据不发生任何形式的改变，仿佛传输过程是透明的一样。数据原封不动地从发送者传到接收者。</p><h3 id="使用Arduino通过无线蓝牙控制Arduino引脚11的LED点亮／熄灭">使用Arduino通过无线蓝牙控制Arduino引脚11的LED点亮／熄灭</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"> <span class="type">char</span> serialData;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  pinMode(<span class="number">11</span>, OUTPUT); <span class="comment">//11引脚连接演示用LED</span></span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( Serial.available()&gt;<span class="number">0</span> )&#123; </span><br><span class="line">    </span><br><span class="line">    serialData =  Serial.read();   </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (serialData == <span class="string">&#x27;1&#x27;</span> ) &#123;  <span class="comment">//接收到点亮LED指令</span></span><br><span class="line">      Serial.print(<span class="string">&quot;Got command: &quot;</span>);  Serial.println(serialData); </span><br><span class="line">      Serial.println(<span class="string">&quot;LED-ON&quot;</span>);</span><br><span class="line">      </span><br><span class="line">      digitalWrite(<span class="number">11</span>, HIGH);  <span class="comment">//点亮LED指令</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;    <span class="comment">//接收到熄灭LED指令</span></span><br><span class="line">      Serial.print(<span class="string">&quot;Got command: &quot;</span>);  </span><br><span class="line">      Serial.println(serialData); </span><br><span class="line">      Serial.println(<span class="string">&quot;LED-OFF&quot;</span>);</span><br><span class="line"> </span><br><span class="line">      digitalWrite(<span class="number">11</span>, LOW);      <span class="comment">//熄灭LED指令  </span></span><br><span class="line">    &#125;      </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="使用Arduino通过无线蓝牙控制调节Arduino引脚11的LED明暗">使用Arduino通过无线蓝牙控制调节Arduino引脚11的LED明暗</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">HC-06-Serial-LED-Fade</span></span><br><span class="line"><span class="comment">by 太极创客（2017-07-08）</span></span><br><span class="line"><span class="comment">www.taici-maker.com</span></span><br><span class="line"><span class="comment">此程序旨在演示如何利用HC-06蓝牙模块通过手机或平板电脑的</span></span><br><span class="line"><span class="comment">蓝牙功能来设置arduino开发板上11引脚上连接LED的亮度。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">如需获得更多关于本程序的使用说明，请参见太极创客制作的《零基础入门学用Arduino》教程。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">---- 电路连接 ---- </span></span><br><span class="line"><span class="comment">HC-06     Arduino Uno R3 引脚</span></span><br><span class="line"><span class="comment">TX                0 (RX)  </span></span><br><span class="line"><span class="comment">RX                1 (TX)</span></span><br><span class="line"><span class="comment">VCC              +5v</span></span><br><span class="line"><span class="comment">GND              GND</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">LED       Arduino Uno R3 引脚</span></span><br><span class="line"><span class="comment"> +                11 (RX) </span></span><br><span class="line"><span class="comment"> -                GND (通过220欧姆限流电阻)</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">注意：</span></span><br><span class="line"><span class="comment">1. 须使用分压电路，确保HC-06 RX信号电压为3.3伏特。</span></span><br><span class="line"><span class="comment">2. 须先将此程序上传至ARDUINO后，再将HC-06连接在ARDUINO开发板的串口引脚上。</span></span><br><span class="line"><span class="comment">   否则程序将无法正常上传。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">int</span> brightness;  <span class="comment">//LED亮度变量</span></span><br><span class="line"><span class="type">int</span> serialData;  <span class="comment">//串口数据变量</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  pinMode(LED_BUILTIN, OUTPUT);</span><br><span class="line">  pinMode(<span class="number">11</span>, OUTPUT);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( Serial.available()&gt;<span class="number">0</span> )&#123;             <span class="comment">//如果串口缓存有数据</span></span><br><span class="line">    serialData =  Serial.parseInt();      <span class="comment">//将串口缓存数值存储到serialData变量</span></span><br><span class="line">    Serial.print(<span class="string">&quot;serialData = &quot;</span>); Serial.println(serialData);  </span><br><span class="line">    <span class="keyword">if</span> (serialData &gt;=<span class="number">0</span> &amp;&amp; serialData &lt;= <span class="number">255</span>) &#123;  </span><br><span class="line">      <span class="keyword">if</span> (serialData &gt;= brightness)&#123;       <span class="comment">//逐渐调节LED亮度</span></span><br><span class="line">        <span class="keyword">for</span> (brightness; brightness &lt;= serialData; brightness++)&#123;</span><br><span class="line">          analogWrite(<span class="number">11</span>, brightness); </span><br><span class="line">          Serial.print(<span class="string">&quot;brightness = &quot;</span>); Serial.println(brightness);  </span><br><span class="line">          delay(<span class="number">5</span>);</span><br><span class="line">        &#125;      </span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (brightness; brightness &gt;= serialData; brightness--)&#123;</span><br><span class="line">          analogWrite(<span class="number">11</span>, brightness); </span><br><span class="line">          Serial.print(<span class="string">&quot;brightness = &quot;</span>); Serial.println(brightness);          </span><br><span class="line">          delay(<span class="number">5</span>);          </span><br><span class="line">        &#125;        </span><br><span class="line">      &#125;       </span><br><span class="line">    &#125;     </span><br><span class="line">  &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电机</title>
      <link href="/posts/ef868677.html"/>
      <url>/posts/ef868677.html</url>
      
        <content type="html"><![CDATA[<h1>电机</h1><ul><li><p>普通直流电机</p></li><li><p>步进电机</p></li><li><p>伺服电机（舵机）</p><p>电机又称为电动机、马达，是一种通过电磁感应定律将电能转化成机械能，并可再使用机械能产生动能，用来驱动其他装置的电气设备。</p></li></ul><h2 id="种类">种类</h2><ul><li>直流电机（DC）</li><li>交流电机（AC）</li><li>交直流两用电机（Universal）</li></ul><p>直流电机根据有无电刷可分为</p><ul><li><p>有刷直流电机（BDC）</p><p>电刷和换向器之间会不断进行摩擦</p></li><li><p>无刷直流电机（BLDC）</p></li></ul><p>​转子的永磁场和定子的电磁场互动进行工作</p><h2 id="直流电机">直流电机</h2><h3 id="有刷直流电机（BDC）主要参数">有刷直流电机（BDC）主要参数</h3><h4 id="额定电流">额定电流</h4><p>即电机在额定环境条件下可以长期连续工作的电流。</p><h4 id="空载转速">空载转速</h4><p>电机不带任何负载的转速。</p><h4 id="其它参数">其它参数</h4><p>重量、工作温度等。</p><p> </p><p>对于电机的控制，我们主要考虑电机的==旋转方向==和==旋转速度==</p><h5 id="旋转方向">旋转方向</h5><p>H桥电路可以用来控制电机的旋转方向</p><h5 id="旋转速度">旋转速度</h5><p>通过PWM控制转速</p><p>用arduino控制开关的开合，从而使电压产生PWM</p><p> </p><h2 id="步进电机">步进电机</h2><ul><li>可精确控制电机输出轴角度</li><li>低速运行时可获得更高的扭矩</li><li>开环控制/性价比高</li></ul><h3 id="分类">分类</h3><ul><li>单极性步进电机</li><li>双极性步进电机</li></ul><h3 id="单-双极性步进电机比较">单/双极性步进电机比较</h3><table><thead><tr><th>单极性</th><th>双极性</th></tr></thead><tbody><tr><td>通常有5-6条引线</td><td>通常有4条引线</td></tr><tr><td>相对输出扭矩低</td><td>通常输出扭矩高</td></tr><tr><td>控制电路相对简单</td><td>控制电路相对复杂</td></tr></tbody></table><h3 id="分类-2">分类</h3><ul><li>永磁式步进电机（Permanent Magnet Stepper）</li><li>反应式步进电机（Variable Reluctance Stepper）</li><li>混含式步进电机（Hybrid Stepper）</li></ul><p> </p><p>永磁式步进电机的转子用永磁材料制成。</p><p>反应式步进电机的转子用软磁材料制成。</p><p> </p><h3 id="28BYJ-48-步进电机">28BYJ-48 步进电机</h3><h4 id="永磁型单极性四相步进电机">永磁型单极性四相步进电机</h4>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>红外遥控</title>
      <link href="/posts/24aabf4.html"/>
      <url>/posts/24aabf4.html</url>
      
        <content type="html"><![CDATA[<h2 id="红外遥控">红外遥控</h2><p>常用红外协议资料<a href="http://www.taichi-maker.com/homepage/reference-index/arduino-library-index/irremote-library/#ir-protocol">IRremote库 – 太极创客 (taichi-maker.com)</a></p><p> </p><h3 id="1838红外接收器">1838红外接收器</h3> <table><thead><tr><th>1838红外接收器引脚</th><th>Arduino引脚</th><th></th></tr></thead><tbody><tr><td>OUT</td><td>11</td><td></td></tr><tr><td>VCC</td><td>+5V</td><td></td></tr><tr><td>GND</td><td>GND</td><td></td></tr></tbody></table><h3 id="红外接收（NEC协议）">红外接收（NEC协议）</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;IRremote.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span>  RECV_PIN 11</span></span><br><span class="line"> </span><br><span class="line">IRrecv <span class="title function_">irrecv</span><span class="params">(RECV_PIN)</span>;   <span class="comment">// 红外遥控初始化</span></span><br><span class="line">decode_results results;   <span class="comment">// 储存接收到的红外遥控信息</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  pinMode(LED_BUILTIN, OUTPUT);</span><br><span class="line">  digitalWrite(LED_BUILTIN, LOW);     </span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;Enabling IRin&quot;</span>);</span><br><span class="line">  irrecv.enableIRIn();     <span class="comment">// 启动红外接收</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Enabled IRin&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="comment">/* </span></span><br><span class="line"><span class="comment">  decode()库函数用于判断红外接收器所接收到的红外信号是否可以被解析。</span></span><br><span class="line"><span class="comment">  如可以成功解析，则返回非零数值。并将解析结果存储于results中。</span></span><br><span class="line"><span class="comment">  如无法成功解析，则返回零。</span></span><br><span class="line"><span class="comment">  </span></span><br><span class="line"><span class="comment">  每一次解析完成，都需要调用resume()函数从而让Arduino开始准备接收下一个红外</span></span><br><span class="line"><span class="comment">  遥控指令。</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">if</span> (irrecv.decode(&amp;results)) &#123;  </span><br><span class="line">    Serial.println(results.value, HEX);  <span class="comment">// results.value为红外遥控信号的具体数值</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">if</span>(results.value == <span class="number">0xF7C03F</span>) <span class="comment">//如果控制信息数值为F7C03F</span></span><br><span class="line">    &#123;          </span><br><span class="line">        Serial.println(<span class="string">&quot;Command Received: Turn On LED.&quot;</span>);</span><br><span class="line">        digitalWrite(LED_BUILTIN, HIGH); </span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(results.value == <span class="number">0xF740BF</span>) <span class="comment">//如果控制信息数值为F740BF</span></span><br><span class="line">    &#123;          </span><br><span class="line">        Serial.println(<span class="string">&quot;Command Received: Turn Off LED.&quot;</span>);</span><br><span class="line">        digitalWrite(LED_BUILTIN, LOW); </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    irrecv.resume(); <span class="comment">// 恢复接收下一个红外遥控信号</span></span><br><span class="line">  &#125;</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="信号发射">信号发射</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;IRremote.h&gt;</span></span></span><br><span class="line">IRsend irsend;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;  </span><br><span class="line">    irsend.sendNEC(<span class="number">0xF7C03F</span>, <span class="number">32</span>);  <span class="comment">//发射NEC红外遥控协议F7C03F指令码，16进制每个占用4bit，所以一共32个bit</span></span><br><span class="line">    delay(<span class="number">40</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * IRremote库支持NEC, Sony, Philips RC5, Philips RC6等协议指令。</span></span><br><span class="line"><span class="comment">  * 本示例程序中Arduino将通过调用函数sendSony(0xa90, 12) 来发射Sony协议指令。</span></span><br><span class="line"><span class="comment">  * 该函数的两个参数中， 0xa90为指令信息内容，12位指令信息位数。</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * 假如需要发射NEC协议指令则可以调用函数sendNEC(0xF7C03F, 32)。</span></span><br><span class="line"><span class="comment">  * 其中0xF740BF为指令信息内容，32位指令信息位数。</span></span><br><span class="line"><span class="comment">  * </span></span><br><span class="line"><span class="comment">  * 如果需要发射其它遥控协议指令请参考以下程序代码：</span></span><br><span class="line"><span class="comment">  * sendNEC(unsigned long data, int nbits);   //发射NEC协议指令</span></span><br><span class="line"><span class="comment">  * sendSony(unsigned long data, int nbits);  //发射Sony协议指令</span></span><br><span class="line"><span class="comment">  * void sendRC5(unsigned long data, int nbits);   //发射Philips RC5协议指令</span></span><br><span class="line"><span class="comment">  * void sendRC6(unsigned long data, int nbits);   //发射Philips RC6协议指令</span></span><br><span class="line"><span class="comment">  * void sendSharp(unsigned long data, int nbits); //发射Sharp协议指令</span></span><br><span class="line"><span class="comment">  * void sendPanasonic(unsigned int address, unsigned long data); //发射Panasonic协议指令</span></span><br><span class="line"><span class="comment">  * void sendJVC(unsigned long data, int nbits, int repeat);  //发射JVC协议指令</span></span><br><span class="line"><span class="comment">  * void sendRaw(unsigned int buf[], int len, int hz);        //发射原始指令</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  delay(<span class="number">5000</span>); <span class="comment">//延迟5秒</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>红外LED发射的信号具有方向性</li><li>控制距离最远不超过2-3米</li><li>需要为红外LED配限流电阻</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>arduino内存</title>
      <link href="/posts/44ae0abd.html"/>
      <url>/posts/44ae0abd.html</url>
      
        <content type="html"><![CDATA[<h2 id="arduino内存">arduino内存</h2><p>内部储存单元由几种不同的介质组成</p><table><thead><tr><th>介质</th><th>名称</th><th>特点</th><th>储存特点</th></tr></thead><tbody><tr><td>FLASH</td><td>闪存（U盘）</td><td>价格低，读写慢</td><td>数量较大的静态信息。断电后可以保持存储内容。存储程序</td></tr><tr><td>SRAM</td><td>静态随机存储器</td><td>价格高，读写快</td><td>数量较小的动态信息，断电后不可以保持存储内容。储存程序变量</td></tr><tr><td>EEPROM</td><td>电可擦除可编程只读存储器</td><td>可擦写可编程 ，读写速度慢</td><td>只能读取信息，不能储存信息。（例如光盘）用于需要断电保持的程序变量</td></tr></tbody></table><p> </p><h3 id="在EEPROM中读取和储存数据">在EEPROM中读取和储存数据</h3><p>对于arduino uno其有1024个字节（1kb）</p><p>可以储存1024个0~255十进制数</p><p> </p><h2 id="内存优化">内存优化</h2><p>SRAM资源远远小于FLASH资源</p><h3 id="优化SRAM">优化SRAM</h3><h4 id="串口监视器输出时用">串口监视器输出时用</h4><p>用SRAM储存</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Serial. println(<span class="string">&quot;Taichi-Maker&quot;</span>);</span><br></pre></td></tr></table></figure><p>用FLASH储存</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Serial. println (F(<span class="string">&quot;Taichi-Maker&quot;</span>));</span><br></pre></td></tr></table></figure><p> </p><h3 id="建立常量">建立常量</h3><p>用SRAM储存静态信息会对使用空间进行浪费</p><p>此时我们可以用FLASH分担SRAM的压力</p><p>将常量储存在FLASH中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> a = <span class="number">125</span>;<span class="comment">//储存在SRAM中</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> PROGMEM a = <span class="number">125</span>；<span class="comment">//储存在Flash中</span></span><br></pre></td></tr></table></figure><p> </p><h3 id="局部变量和全局变量">局部变量和全局变量</h3><p>我们可以从下列代码中来体会全局变量和局部变量的特点</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> globalVarl；<span class="comment">//全局变量1</span></span><br><span class="line"><span class="type">int</span> globalVar2；<span class="comment">//全局变量2</span></span><br><span class="line"><span class="type">void</span> setup（）&#123;</span><br><span class="line">｝</span><br><span class="line"><span class="type">void</span> loop（）&#123;</span><br><span class="line">function_1（）；<span class="comment">//调用函数1</span></span><br><span class="line">function_2（）；<span class="comment">//调用函数2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> function_1（）&#123;</span><br><span class="line"><span class="type">int</span> localVarl；<span class="comment">//函数1局部变量</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> function_2&#123;</span><br><span class="line"><span class="type">int</span> localVar2；<span class="comment">//函数2局部变量</span></span><br><span class="line">｝</span><br></pre></td></tr></table></figure><table><thead><tr><th>内存</th><th>特点</th></tr></thead><tbody><tr><td>SRAM</td><td>共享的局部变量</td></tr><tr><td>SRAM</td><td>独享的全局变量</td></tr></tbody></table><p>要更好地优化空间我们就需要尽量多使用==局部变量==代替==全局变量==</p><p> </p><h3 id="用bool型的变量代替int型的变量做逻辑判断">用bool型的变量代替int型的变量做逻辑判断</h3><h4 id="用整形占用两个字节">用整形占用两个字节</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a；　　<span class="comment">//变量a用于逻辑判断</span></span><br><span class="line"><span class="type">void</span> setup（）&#123;</span><br><span class="line">｝</span><br><span class="line"><span class="type">void</span> loop（）&#123;</span><br><span class="line"><span class="keyword">if</span>（a== <span class="number">1</span>）&#123;</span><br><span class="line"><span class="comment">//变量a等于1时执行的内容</span></span><br><span class="line">&#125;</span><br><span class="line">｝</span><br></pre></td></tr></table></figure><h4 id="用bool占用一个字节">用bool占用一个字节</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">bool</span> a；<span class="comment">//变量a用于逻辑判断</span></span><br><span class="line"><span class="type">void</span> setup（）&#123;</span><br><span class="line">｝</span><br><span class="line"><span class="type">void</span> loop（）&#123;</span><br><span class="line"><span class="keyword">if</span>（a == <span class="number">1</span>）&#123;</span><br><span class="line"><span class="comment">//变量a等于1时执行的内容</span></span><br><span class="line">&#125;</span><br><span class="line">｝</span><br></pre></td></tr></table></figure><p>尽量使用占用内存少的数据类型</p><p>具体的数据类型及其相关信息可以参考这个网站<a href="http://www.taichi-maker.com/homepage/reference-index/arduino-code-reference/data-types/">Arduino常用数据类型简介 – 太极创客 (taichi-maker.com)</a></p><p>（8位微控制器）</p><p> </p><h3 id="优化FLASH">优化FLASH</h3><p>即优化我们的arduino程序</p><h4 id="删除无用代码">删除无用代码</h4><ul><li>无用库</li><li>无用变量</li><li>无用函数</li><li>无用代码</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> arduino </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LED</title>
      <link href="/posts/null.html"/>
      <url>/posts/null.html</url>
      
        <content type="html"><![CDATA[<h2 id="RGB-LED">RGB-LED</h2><p> </p><p>代码实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> rLedPin = <span class="number">6</span>; <span class="comment">//引脚R</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> gLedPin = <span class="number">5</span>; <span class="comment">//引脚G</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> bLedPin = <span class="number">3</span>; <span class="comment">//引脚B</span></span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> ledR  = <span class="number">0</span>; <span class="comment">//R Led 亮度</span></span><br><span class="line"><span class="type">int</span> ledG  = <span class="number">0</span>; <span class="comment">//G Led 亮度</span></span><br><span class="line"><span class="type">int</span> ledB  = <span class="number">0</span>; <span class="comment">//B Led 亮度</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">setup</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">pinMode</span>(rLedPin, OUTPUT);</span><br><span class="line">  <span class="built_in">pinMode</span>(gLedPin, OUTPUT);</span><br><span class="line">  <span class="built_in">pinMode</span>(bLedPin, OUTPUT);</span><br><span class="line">  Serial.<span class="built_in">begin</span>(<span class="number">9600</span>);</span><br><span class="line">  Serial.<span class="built_in">println</span>(<span class="string">&quot;Welcome to Taichi-Maker RGB Led Tutorial.&quot;</span>);</span><br><span class="line">  Serial.<span class="built_in">println</span>(<span class="string">&quot;Please Input RGB value(eg. r128g100b20).&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">loop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (Serial.<span class="built_in">available</span>()&gt;<span class="number">0</span>) &#123; </span><br><span class="line">    <span class="type">char</span> serialCmdChar = Serial.<span class="built_in">read</span>();  </span><br><span class="line">    <span class="built_in">serialCmd</span>(serialCmdChar);       </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">delay</span>(<span class="number">50</span>);      </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">serialCmd</span><span class="params">(<span class="type">char</span> serialCmdChar)</span> </span>&#123;  <span class="comment">//r128g100b20</span></span><br><span class="line">  <span class="keyword">switch</span> (serialCmdChar)&#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;r&#x27;</span>:</span><br><span class="line">      ledR = Serial.<span class="built_in">parseInt</span>();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;g&#x27;</span>:</span><br><span class="line">      ledG = Serial.<span class="built_in">parseInt</span>();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;b&#x27;</span>:</span><br><span class="line">      ledB = Serial.<span class="built_in">parseInt</span>();</span><br><span class="line">      <span class="keyword">break</span>;    </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;c&#x27;</span>:</span><br><span class="line">      ledR = <span class="number">0</span>;</span><br><span class="line">      ledG = <span class="number">0</span>;</span><br><span class="line">      ledB = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"> </span><br><span class="line">  <span class="built_in">analogWrite</span>(rLedPin, ledR);</span><br><span class="line">  <span class="built_in">delay</span>(<span class="number">100</span>);</span><br><span class="line">  <span class="built_in">analogWrite</span>(gLedPin, ledG);</span><br><span class="line">  <span class="built_in">delay</span>(<span class="number">100</span>);</span><br><span class="line">  <span class="built_in">analogWrite</span>(bLedPin, ledB); </span><br><span class="line">  <span class="built_in">delay</span>(<span class="number">100</span>); </span><br><span class="line">  </span><br><span class="line">  Serial.<span class="built_in">print</span> (<span class="string">&quot;Red Value = &quot;</span>);</span><br><span class="line">  Serial.<span class="built_in">println</span> (ledR);</span><br><span class="line">  Serial.<span class="built_in">print</span> (<span class="string">&quot;Green Value = &quot;</span>);</span><br><span class="line">  Serial.<span class="built_in">println</span> (ledG);</span><br><span class="line">  Serial.<span class="built_in">print</span> (<span class="string">&quot;Blue Value = &quot;</span>);</span><br><span class="line">  Serial.<span class="built_in">println</span> (ledB);</span><br><span class="line">  Serial.<span class="built_in">println</span> (<span class="string">&quot;-------------&quot;</span>);    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 模块 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>红外人体感应模块</title>
      <link href="/posts/ea9332b4.html"/>
      <url>/posts/ea9332b4.html</url>
      
        <content type="html"><![CDATA[<h2 id="红外人体感应模块">红外人体感应模块</h2><h3 id="引脚信息">引脚信息</h3><h3 id="人体感应传感器基本工作原理">人体感应传感器基本工作原理</h3>d<p>感应到区域内红外状况变化</p><p>OUT引脚输出高电平</p><p>OUT引脚输出低电平</p><table><thead><tr><th>更多操作感应区域内红外状</th><th>OUT引脚输出情况</th></tr></thead><tbody><tr><td>感应区域内红外状况变化</td><td>OUT引脚输出高电平</td></tr><tr><td>感应区域内红外状况无变化</td><td>OUT引脚输出低电平</td></tr></tbody></table><p> </p><h3 id="人体感应传感器模块基本参数">人体感应传感器模块基本参数</h3><ul><li><p>工作电压范围（VCC）：直流电压4.5-20V</p></li><li><p>电平输出（OUT）：高3.3 V/低OV</p></li><li><p>工作温度：-15摄氏度$\pm ——70摄氏度</p></li></ul><h3 id="代码实现">代码实现</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> irSensorPin = <span class="number">7</span> ;            <span class="comment">// 连接红外传感器引脚</span></span><br><span class="line"><span class="type">bool</span> irSensorOutput;            <span class="comment">// 红外传感器输出信号</span></span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  pinMode(irSensorPin, INPUT);</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;Welcome to Taichi-Maker&#x27;s IR Motion Sensor tutorial.&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span>&#123;</span><br><span class="line">  irSensorOutput = digitalRead(irSensorPin);  <span class="comment">// 读取红外传感器输出</span></span><br><span class="line">  <span class="keyword">if</span> (irSensorOutput == HIGH) &#123;  <span class="comment">// 如果红外传感器输出高电平</span></span><br><span class="line">      Serial.println(<span class="string">&quot;IR Motion Sensor OUTPUT: HIGH.&quot;</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      Serial.println(<span class="string">&quot;IR Motion Sensor OUTPUT: LOW.&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  delay(<span class="number">100</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="人体感应传感器模块感应距离调节">人体感应传感器模块感应距离调节</h3><h3 id="人体感应传感器模块感应延时调节">人体感应传感器模块感应延时调节</h3><h3 id="人体感应传感器模块触发方式">人体感应传感器模块触发方式</h3><h4 id="触发方式：（可跳线选择）">触发方式：（可跳线选择）</h4><p>L-不可重复触发方式<br>H-可重复触发方式</p><p>这两种方式最大区别在于模块在输出高电平的延迟时间内，是否再次检查监测区域内的红外状态有无变化</p><h3 id></h3><table><thead><tr><th>人体感应传感器模块触发方式</th><th>解释</th></tr></thead><tbody><tr><td>不可重复触发方式</td><td>即感应输出高电平后，延时时间内不再检查监测区域有无红外状态改变，当延时一结束，输出将自动从高电平变成低电平</td></tr><tr><td>可重复触发方式</td><td>即感应输出高电平后，延时时间内持续不断地检查监测区域有无红外状态改变，如果在延时结束前再次检查到区域内有红外状态改变，模块将重新开始延时</td></tr></tbody></table><p>两种触发方式区别：倒计时期间是否检查红外区域内的状况。</p><p>如果没有跳线：一般默认为可重复触发方式</p>]]></content>
      
      
      
        <tags>
            
            <tag> 模块 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>修音</title>
      <link href="/posts/1b69608.html"/>
      <url>/posts/1b69608.html</url>
      
        <content type="html"><![CDATA[<h2 id="软件-studio-one">软件-------studio one</h2><p>ctrl+m打开插件</p><h4 id="常规设置">常规设置</h4><p>Studio One—&gt;选项----&gt;常规</p><h4 id="定位设置">定位设置</h4><h5 id="设置默认保存路径">设置默认保存路径</h5><p>Studio One—&gt;选项-----&gt;定位</p><h4 id="音频设置">音频设置</h4><h5 id="选择声卡">选择声卡</h5><p>Studio One—&gt;选项-----&gt;音频设置</p><h4 id="导入文件">导入文件</h4><p>视图----&gt;显示文件----&gt;直接拖入</p><h3 id="录音">录音</h3><p>按空格键盘停止录音</p><h3 id="导出干声">导出干声</h3><p>右键—&gt;选择----&gt;输出选择</p><h5 id="如果有很多断点">如果有很多断点</h5><p>点击S----&gt;乐曲-----&gt;导出混音-----&gt;导出范围------&gt;乐曲开始/结束标记之间</p><h3 id="导出混音">导出混音</h3><h4 id="只想导出一段">只想导出一段</h4><p>往上点击选择画笔工具勾选范围</p><h3 id="窗口得缩放">窗口得缩放</h3><p>放大E，缩小W</p><h3 id="重录干声片段">重录干声片段</h3><p>画笔工具选中-----&gt;按i激活穿插录音----&gt;点击录音</p><p>在到达这个区域前是不会进行录音的，右键选择录得最满意的一次</p><h3 id="节奏修正工具">节奏修正工具</h3><p>点击音频轨上的==音频弯曲==工具-------&gt;点击分析------&gt;</p><h3 id="消除无声音频块">消除无声音频块</h3><p>点击音频轨上的==消除无声==工具----&gt;手册模式-----&gt;应用（适当提高最小长度，可以把间隔不是很长的音频快都保存下来）</p><p>设计开启级别可以去掉区范围以下的噪音</p><h3 id="吸附功能">吸附功能</h3><p>点击音频轨上的==吸附功能==工具-----&gt;选择量化的节拍</p><h3 id="淡入淡出">淡入淡出</h3><p>切出来一片------&gt;拖拽上方的小方块</p><h3 id="交叉淡化">交叉淡化</h3><p>讲两块音频合成一起进行交叉，点击x后即完成交叉淡化</p><h3 id="节拍器">节拍器</h3><p>alt+方向键：音频向某个方向走10ms</p><h3 id="自动化控制">自动化控制</h3><p>左下角的小箭头N-----&gt;选择写入--------&gt;点击读取</p><h3 id="升降调">升降调</h3><p>右键音频片段-------&gt;更改变调-------&gt;（这个变调是针对整个音频轨来说的）</p><h3 id="音频加速减速">音频加速减速</h3><p>右键音频片段-------&gt;更改变速-------&gt;（这个变速是针对整个音频轨来说的）</p><h3 id="标记轨的使用">标记轨的使用</h3><p>整体听一下，提前标记好什么地方需要修改</p><p>左边得标记上有一个加号，可以加标签</p><h3 id="设置声像">设置声像</h3><p>按f4打开检察器</p><h3 id="认识调音台">认识调音台</h3><p>按f3打开 调音台</p><p>监听，可以听到自己录音时的声音</p><h3 id="插入效果器">插入效果器</h3><p>浏览----&gt;效果器--------&gt;厂商—&gt;PreSonus-------&gt;</p><p>f3打开混音器------&gt;拖入效果器放到插入一栏中（或者拖入到轨道）------&gt;</p><h3 id="发送效果">发送效果</h3><p>在轨道下方f3点击发送旁边的加号➕--------&gt;添加效果通道--------&gt;</p><p>一般这个发送的插入效果用在做混响或延迟</p><h3 id="创建BUS轨">创建BUS轨</h3><p>多选轨道-------&gt;为已选择音轨增加Bus</p><p>此时的bus轨就是可以同时控制多选轨道的一个轨</p><h3 id="分配VCA推子">分配VCA推子</h3><p>多选轨道-------&gt;为已选择音轨增加Vca-------&gt;以一定比例增加或减少音量</p>]]></content>
      
      
      
        <tags>
            
            <tag> 音乐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率论</title>
      <link href="/posts/155618b9.html"/>
      <url>/posts/155618b9.html</url>
      
        <content type="html"><![CDATA[<h1>概率论的基本概念</h1><h2 id="随机实验">随机实验</h2><h3 id="特点">特点</h3><ol><li>可以在相同的条件下重复地进行</li><li>每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果</li><li>进行一次试验之前不能确定哪一个结果会出现</li></ol><p> </p><h2 id="样本空间，随机事件">样本空间，随机事件</h2><table><thead><tr><th>名称</th><th>特点</th></tr></thead><tbody><tr><td>样本空间</td><td>随机试验E的所有可能结果组成的集合</td></tr><tr><td>样本点（基本事件）</td><td>样本空间的元素，即E的每个结果</td></tr></tbody></table><p>样本空间的两种记法</p><p>$A_{1}={0,1,2,3}$</p><p>$A_{2}={x|\mathrm0\leq x\leq3}$</p><p> </p><p> </p><h2 id="集合理论">集合理论</h2><table><thead><tr><th>示例图</th><th>公式</th><th>意义</th></tr></thead><tbody><tr><td>1-1</td><td>$A\subset B$</td><td>A发生必导致B发生</td></tr><tr><td>1-2</td><td>$A \cup B=\left {  x</td><td>x \in A  {或}x \in B  \right } $</td></tr><tr><td>1-3</td><td>$A \cap B=\left {  x</td><td>x \in A  {且}x \in B  \right } $</td></tr><tr><td>1-4</td><td>$A-B={x</td><td>x\in A \mathbb {且}x\notin B}$</td></tr><tr><td>1-5</td><td>$A\cap B=\varnothing$</td><td>A和B是互斥的</td></tr><tr><td>1-6</td><td>$A\cup B=S{且} A\cap B=\varnothing$</td><td>A与B互为逆事件</td></tr></tbody></table><h3 id="进行事件运算时要用到以下定律">进行事件运算时要用到以下定律</h3><table><thead><tr><th>定律</th><th>公式</th><th>备注</th></tr></thead><tbody><tr><td>交换律</td><td>$A\cup B=B\cup A;A\cap B=B\cap A$</td><td></td></tr><tr><td>结合律</td><td>$A\cup(B\cup C)=(A\cup B)\cup C \A\cap\left(B\cap C\right)=\left(A\cap B\right)\cap C$</td><td></td></tr><tr><td>分配律</td><td>$A\cap\left(B\cap C\right)=\left(A\cap B\right)\cap C \ A\cap(B\cup C)=(A\cap B)\cup(A\cap C)$</td><td>注意括号里的符号</td></tr><tr><td>德摩根律</td><td>$\overline{A\cup B}=\overline{A}\cap\overline{B} \ \overline{A\cap B}=\overline{A}\cup\overline{B}$</td><td></td></tr></tbody></table><p> </p><p> </p><h2 id="频率与概率">频率与概率</h2><h3 id="频率">频率</h3><p>在相同的条件下，进行了n次试验，在这n次试验中</p><table><thead><tr><th>名称</th><th>特点</th></tr></thead><tbody><tr><td>频数</td><td>事件A发生的次数</td></tr><tr><td>频率</td><td>比值$n_A/n$称为事件A发生的频率</td></tr></tbody></table><p> </p><h4 id="基本性质">基本性质</h4><ol><li>$0\leqslant f_n(A)\leqslant1$</li><li>$f_{n}\left(S\right)=1$</li><li>若$A_{1},A_{2},\cdots,A_{k}$是两两互不相容的事件，则$f_n(A_1\cup A_2\cup\cdots\cup A_s)=f_s(A_1)+f_s(A_2)+\cdots+f_s(A_s).$</li></ol><p> </p><h3 id="概率">概率</h3><h4 id="基本性质-2">基本性质</h4><p>设E是随机试验，S是它的样本空间.对于E的每一事件A赋予一个实数，记为P（A），称为事件A的概率</p><p>集合函数P满足一个重要的条件；</p><ul><li>==可列可加性==</li></ul><p>设$A_{1},A_{2},\cdots$是两两互不相容的事件，即对于$A_{i}A_{j}=\varnothing$，$i\neq j,i,j=1,2,\cdots,$有$P(A_{1}\cup A_{2}\cup\cdots\big)=P(A_{1})+P(A_{2})+\cdots.$</p><p> </p><h4 id="重要的性质">重要的性质</h4><table><thead><tr><th>性质</th><th>公式</th></tr></thead><tbody><tr><td>有限可加性</td><td>若$A_1,A_2,\cdots,A_n$是两两互不相容的事件，则$P(A_{1}\cup A_{2}\cup\cdots\cup A_{n})=P(A_{1})+P(A_{2})+\cdots+P(A_{n})$</td></tr><tr><td>性质iii</td><td>设A，B是两个事件，若$A\subset B$，则有$\begin{array}{c}{P(B-A)=P(B)-P(A);}\ {P(B)\geq P(A).}\ \end{array}$</td></tr><tr><td>加法公式</td><td>对于任意两事件A，B有$P(A\cup B)=P(A)+P(B)-P(A B)$</td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>串口通信</title>
      <link href="/posts/edc30276.html"/>
      <url>/posts/edc30276.html</url>
      
        <content type="html"><![CDATA[<h2 id="串口通信">串口通信</h2><table><thead><tr><th>引脚</th><th>功能</th></tr></thead><tbody><tr><td>引脚O RX</td><td>接收（Receive）</td></tr><tr><td>引脚1 TX</td><td>发送（Transmit）</td></tr></tbody></table><p>RX TX工作时，相应LED会闪烁</p><p>所有要进行串口通讯的设备，接地必须连在一起</p><p>ardunio：TTL标准（0V-5V）</p><p>每一位数据所持续的时间<br>通过波特率来限定<br>波特率：9600→每秒传输9600位</p><p>Serial. available（）函数，</p><p>Serial.available 返回串口接收缓存中等待传输的数据字节数量</p><p>Serial. read 读取数据</p><p>Serial.read成功读取数据后Arduino将已经被读取的数据从缓存中清除。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span>&#123;</span><br><span class="line">Serial.begin(<span class="number">9600</span>);<span class="comment">//启动串口通讯，传输波特率9600</span></span><br><span class="line">Serial.println(<span class="string">&quot;Please input serial data&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( Serial.available()&gt;<span class="number">0</span>)&#123;</span><br><span class="line">    <span class="type">int</span> serialData = Serial.read();</span><br><span class="line">    Serial.println(serialData);</span><br><span class="line">&#125;</span><br><span class="line">&#125;A</span><br></pre></td></tr></table></figure><p>输入角度控制</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Servo.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">Servo myServo;         <span class="comment">//创建Servo对象myServo</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> dataIndex = <span class="number">0</span>;     <span class="comment">//创建整数型变量，存储输入数据序列号</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  myServo.attach(<span class="number">6</span>);</span><br><span class="line">  Serial.begin(<span class="number">9600</span>); <span class="comment">//启动串口通讯，传输波特率9600</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Please input serial data.&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;          <span class="comment">// 检查串口缓存是否有数据等待传输 </span></span><br><span class="line">  <span class="keyword">if</span> ( Serial.available()&gt;<span class="number">0</span> ) &#123;  </span><br><span class="line">    dataIndex++;       <span class="comment">// 处理数据序列号并通过串口监视器显示</span></span><br><span class="line">    Serial.print(<span class="string">&quot;dataIndex = &quot;</span>);</span><br><span class="line">    Serial.print(dataIndex);</span><br><span class="line">    Serial.print(<span class="string">&quot; , &quot;</span>);      </span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> pos = Serial.parseInt();   <span class="comment">// 解析串口数据中的整数信息并赋值给变量pos</span></span><br><span class="line">    Serial.print(<span class="string">&quot;Set servo position: &quot;</span>);</span><br><span class="line">    Serial.println(pos);           <span class="comment">// 通过串口监视器显示变量pos数值</span></span><br><span class="line">    myServo.write(pos);             <span class="comment">// 使用pos变量数值设置伺服电机</span></span><br><span class="line">    delay(<span class="number">15</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>让其他引脚实现串行通信（软件模拟）</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SoftwareSerial BTserial（<span class="number">2</span>，<span class="number">3</span>）；<span class="comment">//建立SoftwareSerial对象，RX引脚2，TX引脚3</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图</title>
      <link href="/posts/ee040603.html"/>
      <url>/posts/ee040603.html</url>
      
        <content type="html"><![CDATA[<h2 id="图的定义">图的定义</h2><p>图是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：<br>$$<br>G=(V, E)<br>$$<br>其中：G表示一个图，V是图G中顶点的集合，E是图G中顶点之间边的集合。</p><p> </p><p>在线性表中，元素个数可以为零，称为空表；</p><p>在树中，结点个数可以为零，称为空树；</p><p>在图中，顶点个数不能为零，但可以没有边。(没有空图的概念)</p><p> </p><h2 id="图的逻辑结构">图的逻辑结构</h2><p>若顶点$v_i$和$v_j$之间的边没有方向，则称这条边为无向边，表示为$(v_i,v_j)$。<br>如果图的任意两个顶点之间的边都是无向边，则称该图为无向图<br><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615686.png" alt="image-20221124082008486"></p><p>若从顶点v，到v，的边有方向，则称这条边为有向边，表示为&lt;vi，v&gt;。<br>如果图的任意两个顶点之间的边都是有向边，则称该图为有向图</p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615687.png" alt="image-20221124082129599" style="zoom:50%;"><h3 id="图的基本术语">图的基本术语</h3><p>简单图：在图中，若不存在顶点到其自身的边，且同一条边不重复出现。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615688.png" alt="image-20221124082326034"><br>数据结构中讨论的都是简单图。</p><p> </p><h3 id="邻接-依附">邻接,依附</h3><h4 id="无向图">无向图</h4><p>无向图中，对于任意两个顶点$v_i$，和顶点$v_j$，若存在边$(v_i,v_j)$，则称顶点$v_i$，和顶点$v_j$，互为<strong>邻接</strong>点，同时称边$(v_i,v_j)$依附于顶点$v_i$，和顶点$v_j$</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615689.png" alt="image-20221124082923715"></p><p>$v_0$的邻接点：$v_1$,$v_3$<br>$v_1$的邻接点:$v_0$,$v_2$,$v_4$</p><h4 id="有向图">有向图</h4><p>无向图中，对于任意两个顶点$v_i$，和顶点$v_j$，若存在弧$&lt;v_i,v_j&gt;$，则称顶点$v_i$，和顶点$v_j$，互为<strong>邻接</strong>点，同时称弧$&lt;v_i,v_j&gt;$依附于顶点$v_i$，和顶点$v_j$</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615690.png" alt="image-20221124083330384"></p><p> </p><h4 id="不同逻辑结构关系的对比">不同逻辑结构关系的对比</h4><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615691.png" alt="image-20221124083511970"></p><p>在线性结构中，数据元素之间仅具有线性关系；<br>在树结构中，结点之间具有层次关系；<br>在图结构中，任意两个顶点之间都可能有关系。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615692.png" alt="image-20221124083535020"></p><p>在线性结构中，元素之间的关系为前驱和后继<br>在树结构中，结点之间的关系为双亲和孩子<br>在图结构中，顶点之间的关系为邻接。<br> </p><h4 id="图的基本术语-2">图的基本术语</h4><p>无向完全图：在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图。<br>有向完全图：在有向图中，如果任意两个顶点之间都存在方向相反的两条弧，则称该图为有向完全图</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615693.png" alt="image-20221124083745332"></p><p>含有n个顶点的无向完全图有$n\times（n-1）/2$条边。<br>含有n个顶点的有向完全图有$n\times （n-1）$条弧。</p><p> </p><p>稀疏图：称边数很少的图为稀疏图；稠密图：称边数很多的图为稠密图。<br>顶点的度：在无向图中，顶点v的度是指依附于该顶点的边数，通常记为$TD（v）$。<br>顶点的入度：在有向图中，顶点v的入度是指以该顶点为弧头的弧的数目，记为$ID（v）$；顶点的出度：在有向图中，顶点v的出度是指以该顶点为弧尾的弧的数目，记为$OD（v）$。</p><p> </p><p>在具有n个顶点、e条边的无向图中，各顶点的度之和与边数之和有如下关系<br>$$<br>\sum\limits_{i=1}^{n}T D\left(\nu_{i}\right)=2e<br>$$<br>在具有n个顶点、e条边的有向图中，各顶点的入度之和与各顶点的出度之和有如下关系<br>$$<br>\sum\limits_{i=1}<sup>{n}ID\left(v_i\right)=\sum\limits_{i=1}</sup>{n}OD\left(v_i\right)=e<br>$$<br> </p><p>权：是指对边赋予的有意义的数值量。(一个节点到另一个结点需要的代价)<br>网：边上带权的图，也称网图</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615694.png" alt="image-20221124090143821"></p><h4 id="路的长度">路的长度</h4><p>非带权图  ————&gt;  路径上边的个数<br>带权图      ————&gt;  路径上各边的权之和</p><h4 id="回路，简单路径，简单回路">回路，简单路径，简单回路</h4><p>回路（环）：第一个顶点和最后一个顶点相同的路径。<br>简单路径：序列中顶点不重复出现的路径。<br>简单回路（简单环）：除了第一个顶点和最后一个顶点外，其余顶点不重复出现的回路。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615695.png" alt="image-20221124090621209"></p><p> </p><h4 id="连通图，连通分量">连通图，连通分量</h4><p>连通图：在无向图中，如果从一个顶点$v_i$，到另一个顶点$v_j(i\ne j)$有路径，则称顶点$v_i$，和$v_j$，是连通的。如果图中任意两个顶点都是连通的，则称该图是连通图。<br>连通分量：非连通图的极大连通子图称为连通分量。</p><p>​1.含有极大顶点数；<br>​2.依附于这些顶点的所有边</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615696.png" alt="image-20221124091305502"></p><p>强连通图：在有向图中，对图中任意一对顶点$v_i$，$v_j(i\ne j)$，若从顶点$v_i$，到顶点$v_j$，和从顶点$v_j$，到顶点$v_i$，均有路径则称该有向图是强连通图。<br>强连通分量：非强连通图的极大强连通子图。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615697.png" alt="image-20221124092021166"></p><p> </p><h4 id="生成树">生成树</h4><p>生成树：n个顶点的连通图G的生成树是包含G中全部顶点的一个$极小连通子图$。</p><p>含有n-1条边，多一条构成回路，少一条不连通</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615698.png" alt="image-20221124092417837"></p><p>生成森林：在非连通图中，由每个连通分量都可以得到一棵生成树，这些连通分量的生成树就组成了一个非连通图的生成森林。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615699.png" alt="image-20221124092443323"></p><p> </p><h2 id="图的储存">图的储存</h2><h4 id="图的粗存结构及实现">图的粗存结构及实现</h4><h4 id="邻接矩阵">邻接矩阵</h4><p>基本思想：用一个一维数组存储图中顶点的信息，用一个二维数组（称为邻接矩阵）存储图中各顶点之间的邻接关系。</p><h5 id="无向图的邻接矩阵">无向图的邻接矩阵</h5><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615700.png" alt="image-20221124140130753"></p><p>特点：</p><p>主对角线为0且一定是对称矩阵。</p><h5 id="如何求邻接矩阵中的度">如何求邻接矩阵中的度</h5><p>通过扫描该点邻接矩阵中的行</p><p>该点边表中结点的个数</p><p> </p><h5 id="有向图的临界矩阵">有向图的临界矩阵</h5><p>可能不是对称的</p><p> </p><h5 id="网图邻接矩阵的定义">网图邻接矩阵的定义</h5><p>$$<br>\textbf{arc}[i][j]=\left{\begin{array}{l}\boldsymbol{w}_{ij}，若(v_i,v_j)\in E(或&lt;v_i,v_j&gt;\in E)<br>\ \boldsymbol{0},若i=j<br>\{\infty}，其他\end{array}\right.<br>$$</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615701.png" alt="image-20221124141906325"></p><h4 id="图的储存结构及实现">图的储存结构及实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MAX_VERTEX=<span class="number">10</span>;<span class="comment">//图的最大顶点数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MGraph</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">Data Type vertex[MAX_VERTEX];  </span><br><span class="line"><span class="type">int</span> arc[MAX_VERTEX][MAX_VERTEX];</span><br><span class="line"><span class="type">int</span> vertexNum， arcNum；</span><br><span class="line"><span class="keyword">public</span>：</span><br><span class="line"><span class="built_in">MGraph</span>(DataType v[]，<span class="type">int</span> n，<span class="type">int</span> e);<span class="comment">//构造函数</span></span><br><span class="line">-<span class="built_in">MGraph</span>();           <span class="comment">//析构函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(<span class="type">int</span> v)</span></span>; <span class="comment">//深度遍历</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTrayerse</span><span class="params">(<span class="type">int</span> v)</span></span>;  <span class="comment">//广度遍历</span></span><br><span class="line">&#125;；</span><br></pre></td></tr></table></figure><p> </p><h4 id="构造函数的实现">构造函数的实现</h4><p>邻接矩阵中图的基本操作——构造函数<br>1.确定图的顶点个数和边的个数；<br>2.输入顶点信息存储在一维数组vertex中；<br>3.初始化邻接矩阵arc；<br>4.依次输入每条边存储在邻接矩阵arc中；<br>4.1输入边依附的两个顶点的序号i，j；<br>4.2将邻接矩阵的第i行第j列的元素值置为1；<br>4.3将邻接矩阵的第j行第i列的元素值置为1；</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">MGraph::MGraph（Data Type v[], <span class="type">int</span> n,<span class="type">int</span> e）&#123;</span><br><span class="line">vertexNum = n;</span><br><span class="line">arcNum = e;</span><br><span class="line"><span class="keyword">for</span> （i = <span class="number">0</span>; i &lt; vertexNum; i++）</span><br><span class="line">vertex[i] = v[i];</span><br><span class="line"><span class="keyword">for</span> （i = <span class="number">0</span>; i &lt; vertexNum; i++）</span><br><span class="line"><span class="comment">//初始化邻接矩阵</span></span><br><span class="line"><span class="keyword">for</span> （j = <span class="number">0</span>; j &lt; vertexNum; j++）</span><br><span class="line">arc[i][] = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> （i = <span class="number">0</span>; i&lt; arcNum; i++）[ <span class="comment">//依次输入每一条边</span></span><br><span class="line">cin &gt;&gt;vi&gt;&gt;vj； <span class="comment">//输入边依附的两个顶点的编号</span></span><br><span class="line">arc[vi][vj] = <span class="number">1</span>; <span class="comment">//置有边标志</span></span><br><span class="line">arc[vj][vi] = <span class="number">1</span>;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h3 id="邻接表">邻接表</h3><p>图的邻接矩阵储存结构的空间复杂度？</p><p>假设图G有n个顶点e条边，则储存该图需要$O(n^2)$</p><p> </p><p>如果为稀疏图则会出现什么现象？</p><p>邻接表储存的基本思想：对于图的每个顶点$v_i$，将所有邻接于$v_i$的顶点链成一个单链表，称为顶点$v_i$的边表（对于有向图则称为出边表）所有边表的头指针和存储顶点信息的一维数组构成了顶点表。</p><p> </p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615702.png" alt="image-20221201133112610"></p><table><thead><tr><th>vertex</th><th>数据域，存放顶点信息</th></tr></thead><tbody><tr><td>firstEdge</td><td>指针域，指向边表中第一个结点</td></tr><tr><td>adjvex</td><td>邻接点域，边的终点在顶点表中的下标</td></tr><tr><td>next</td><td>指针域，指向边表中的下一个结点</td></tr></tbody></table><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">ArcNode</span><span class="comment">//边表</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> adjvex;</span><br><span class="line">ArcNode *next;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">VertexNode</span> <span class="comment">//顶点表</span></span><br><span class="line">&#123;</span><br><span class="line">DataType vertex;</span><br><span class="line">ArcNode *fristEdge;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h4 id="图的存储结构及实现">图的存储结构及实现</h4><h5 id="邻接表存储有向图的类">邻接表存储有向图的类</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MAx_VERTEX = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ALGraph</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">VertexNode adjList[MAX_VERTEX];</span><br><span class="line"><span class="type">int</span> vertexNum,arcNum;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"><span class="built_in">ALGraph</span>(DataType v[],<span class="type">int</span> n,<span class="type">int</span> e);<span class="comment">//构造函数</span></span><br><span class="line">~<span class="built_in">ALGraph</span>();                      <span class="comment">//析构函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">DFSTraverse</span><span class="params">(<span class="type">int</span> v)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">BFSTraverse</span><span class="params">(<span class="type">int</span> v)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="邻接表中图的基本操作-构造函数">邻接表中图的基本操作----构造函数</h5><p>1.确定图的顶点个数和边的个数</p><p>2.输入顶点信息，初始化该顶点的边表</p><p>3.依次输入边的信息并储存在边表中</p><p>​3.1输入边所依附的两个顶点的序号$v_i$和$v_j$</p><p>​3.2生成邻接点序号为$v_j$的边表结点s</p><p>​3.3将结点s插入到第$v_i$个边表的头部</p><p> </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ALGraph:: <span class="built_in">ALGraph</span>(DataType v[], <span class="type">int</span> n, <span class="type">int</span> e)&#123;</span><br><span class="line">vertexNum = n;</span><br><span class="line">arcNum = e;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; vertexNum; i++) &#123;</span><br><span class="line"><span class="comment">//初始化顶点信息，指针域都为空</span></span><br><span class="line">adjList[i].vertex = v[i];</span><br><span class="line">adjList[i].firstEdge = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; arcNum ;i++)&#123;</span><br><span class="line">        <span class="comment">//输入边的信息存储在边表中</span></span><br><span class="line">        cin&gt;&gt;vi&gt;&gt;vj;<span class="comment">//输入边依附的两个顶点的编号</span></span><br><span class="line">        s = newArcNode;</span><br><span class="line">        s-&gt;adjvex = vj;</span><br><span class="line">        s-&gt;next = adjList[vi].fristEdge;</span><br><span class="line">        adjList[vi].fristEdge = s;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h4 id="十字链表">十字链表</h4><p>将邻接表和逆邻接表合二为一，方便计算每个结点的入读和出度。</p><p>要频繁计算数据的入度和出度，用十字链表。</p><table><thead><tr><th></th><th>空间性能</th><th>时间性能</th><th>适用范围</th><th>唯一</th></tr></thead><tbody><tr><td>邻接矩阵</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>稠密图</td><td>唯一</td></tr><tr><td>邻接表</td><td>$O(n+e)$</td><td>$O(n+e)$</td><td>稀疏图</td><td>不唯一</td></tr></tbody></table><p> </p><h2 id="图的遍历">图的遍历</h2><p>1.在图中，任何两个顶点之间都可能存在边，顶点是没有确定的先后次序的，所以，顶点的编号不唯一。<br>为了定义操作的方便，将图中的顶点按任意顺序排列起来，比如，按顶点的存储顺序。</p><p>2.从某个起点始可能到达不了所有其它顶点，怎么办？</p><p>解决方案：多次调用从某顶点出发遍历图的算法。</p><p>3.因图中可能存在回路，某些顶点可能会被重复访问，那么如何避免遍历不会因回路而陷入死循环。</p><p>解决方案：附设访问标志数组visited[n]</p><p>4.在图中，一个顶点可以和其它多个顶点相连，当这样的顶点访问过后，如何选取下一个要访问的顶点？</p><p>深度和广度优先遍历</p><h3 id="深度优先遍历">深度优先遍历</h3><p>（1）访问顶点v；<br>（2）从v的未被访问的邻接点中选取一个顶点w，从w出发进行深度优先遍历；<br>（3）重复上述两步，直至图中所有和v有路径相通的顶点都被访问到。</p><h4 id="伪代码">伪代码</h4><p>1.访问顶点v；visited[v]= 1；<br>2.w=顶点v的第一个邻接点；<br>3.while（w存在）<br>3.1 if（w未被访问）从顶点w出发递归执行该算法；<br>3.2 w=顶点v的下一个邻接点；</p><h5 id="邻接表实现">邻接表实现</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ALGraph::DFSTraverse</span><span class="params">(<span class="type">int</span> * visited)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; vertexNum; i++) &#123;</span><br><span class="line">visited[i] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; vertexNum; i++) &#123;  <span class="comment">//循环遍历每个顶点</span></span><br><span class="line"><span class="keyword">if</span> (!visited[i]) &#123;</span><br><span class="line"><span class="built_in">DFS</span>(i, visited);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ALGraph::DFS</span><span class="params">(<span class="type">int</span> v, <span class="type">int</span> *visited)</span> </span>&#123;   <span class="comment">//遍历单个头顶点</span></span><br><span class="line"></span><br><span class="line">visited[v] = <span class="number">1</span>;</span><br><span class="line">cout &lt;&lt; adjList[v].vertex &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">ArcNode *p = adjList[v].firstEdge;</span><br><span class="line"><span class="keyword">while</span> (p) &#123;</span><br><span class="line"><span class="keyword">if</span> (!visited[p-&gt;adjvex]) &#123;</span><br><span class="line"><span class="built_in">DFS</span>(p-&gt;adjvex, visited);</span><br><span class="line">&#125;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="邻接矩阵实现">邻接矩阵实现</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">DFS</span>(<span class="type">int</span> i,<span class="type">int</span> * visited)&#123;</span><br><span class="line">cout&lt;&lt;vertex[i]&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">visited[i] = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;vertexNum;j++)&#123;</span><br><span class="line"><span class="keyword">if</span>(visited[j] == <span class="number">0</span>&amp;&amp;arc[i][j] != <span class="number">0</span> &amp;&amp;arc[i][j] != INFINIT)&#123;</span><br><span class="line"><span class="built_in">DFS</span>(j,visited);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">DFSTraverse</span>(<span class="type">int</span> * visited)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;vertexNum;i++)&#123;</span><br><span class="line">visited[i] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;vertexNum;i++)&#123;</span><br><span class="line"><span class="keyword">if</span>(!visited[i])&#123;</span><br><span class="line"><span class="built_in">DFS</span>(i,visited);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="广度优先遍历">广度优先遍历</h3><p>基本思想：<br>（1）访问顶点v；<br>（2）依次访问v的各个未被访问的邻接点v1，V2，…，Vk<br>（3）分别从v1，V2,…, Vk出发依次访问它们未被访问的邻接点，并使“先被访问顶点的邻接点”先于后被访问顶点的邻接点”被访问。直至图中所有与顶点v有路径相通的顶点都被访问到。</p><h5 id="邻接表实现-2">邻接表实现</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">ALGraph::BFSTraverse</span><span class="params">(<span class="type">int</span> * visited)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> i;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; vertexNum; i++) &#123;</span><br><span class="line">visited[i] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; vertexNum; i++) &#123;</span><br><span class="line"><span class="keyword">if</span> (!visited[i]) &#123;</span><br><span class="line"><span class="built_in">BFS</span>(i, visited);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ALGraph::BFS</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> *visited)</span> </span>&#123;</span><br><span class="line">queue&lt;<span class="type">int</span>&gt; q;</span><br><span class="line">visited[i] = <span class="number">1</span>;</span><br><span class="line">q.<span class="built_in">push</span>(i);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line"><span class="type">int</span> temp = q.<span class="built_in">front</span>();</span><br><span class="line">cout&lt;&lt;adjList[temp].vertex&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">q.<span class="built_in">pop</span>();</span><br><span class="line">ArcNode * p = adjList[i].firstEdge;</span><br><span class="line"><span class="keyword">while</span>(p)&#123;</span><br><span class="line"><span class="keyword">if</span>(!visited[p-&gt;adjvex])&#123;</span><br><span class="line">q.<span class="built_in">push</span>(p-&gt;adjvex);</span><br><span class="line">visited[p-&gt;adjvex] = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="邻接矩阵实现-2">邻接矩阵实现</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">BFS</span>(<span class="type">int</span> i,<span class="type">int</span> * visited)&#123;</span><br><span class="line">queue&lt;<span class="type">int</span>&gt; q;</span><br><span class="line">visited[i] = <span class="number">1</span>;</span><br><span class="line">q.<span class="built_in">push</span>(i);</span><br><span class="line"><span class="keyword">while</span>(!q.<span class="built_in">empty</span>())&#123;</span><br><span class="line"><span class="type">int</span> temp = q.<span class="built_in">front</span>();</span><br><span class="line">cout&lt;&lt;vertex[temp]&lt;&lt;<span class="string">&quot; &quot;</span>;</span><br><span class="line">q.<span class="built_in">pop</span>();</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;vertexNum;j++)&#123;</span><br><span class="line"><span class="keyword">if</span>(!vertex[i]&amp;&amp;arc[i][j]!=<span class="number">0</span>&amp;&amp;arc[i][j]!=INFINIT)&#123;</span><br><span class="line"></span><br><span class="line">visited[j] = <span class="number">1</span>;</span><br><span class="line">q.<span class="built_in">push</span>(j);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">cout&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="type">void</span> MGraph&lt;T&gt;::<span class="built_in">BFSTraverse</span>(<span class="type">int</span> * visited)&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;vertexNum;i++)&#123;</span><br><span class="line">visited[i] = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;vertexNum;i++)&#123;</span><br><span class="line"><span class="keyword">if</span>(!visited[i])&#123;</span><br><span class="line"><span class="built_in">BFS</span>(i,visited);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h1>最短路径—Dijkstra算法</h1><p>在网图中，最短路径是指两顶点之间经历的边上权值之和最短的路径。</p><p><img src="https://raw.githubusercontent.com/Rozen12123/picture/main/202310201615703.png" alt="image-20221203171309968"></p><h3 id="单源点最短路径问题">单源点最短路径问题</h3><p>问题描述：给定带权有向图G=（V，E）和源点v$\in $V，求从v到G中其余各顶点的最短路径。</p><p>图的存储结构：带权的邻接矩阵存储结构</p><p>数组dist[n]：每个分量dist[i]表示当前所找到的从始点v到终点$v_i$，的最短路径的长度。初态为：若从v到$v_i$，有弧，则dist[i]为弧上权值；否则置dist[i]为$\infty $。<br>数组path[n]： path[i]是一个字符串，表示当前所找到的从始点v到终点$v_i$，的最短路径。初态为：若从v到<br>$v_i$有弧，则path[i]为0；否则置path[i]为-1。<br>数组s[n]：存放源点和已经生成的终点，其初态为只有一个源点v。</p><p> </p><h4 id="伪代码-2">伪代码</h4><p>1.初始化数组dist、path和s；</p><ol start="2"><li>while （s中的元素个数&lt;n）<br>2.1 在dist[n]中求最小值，其下标为k；<br>2.2 输出dist[j]和path[jl；<br>2.3修改数组dist和path；<br>2.4将顶点$v_k$添加到数组s中；</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>c++基础</title>
      <link href="/posts/7b58e60a.html"/>
      <url>/posts/7b58e60a.html</url>
      
        <content type="html"><![CDATA[<h2 id="c-基础">c++基础</h2><h3 id="new与delete">new与delete</h3><p>new，delete用于堆空间的分配与回收</p><p>new：用于从堆中分配指定大小得内存区域，并返回内存区域得首地址，相较于malloc可以自动计算大小，无需指针转换。</p><p>用法示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> *arr = <span class="keyword">new</span> <span class="type">int</span>[<span class="number">100</span>];</span><br></pre></td></tr></table></figure><p>delete:用于释放new分配的堆内存</p><p>用法示例：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span>[] arr;</span><br></pre></td></tr></table></figure><p> </p><h3 id="引用">引用</h3><p>引用是某个对象（即变量）的别名，定义形式如下：</p><p>类型&amp;引用名 = 变量名；</p><p>例如</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a = <span class="number">10</span>;</span><br><span class="line"><span class="type">int</span> &amp;b = a;</span><br></pre></td></tr></table></figure><p>引用很少单独使用，<strong>常常作为形参</strong>的方式</p><p>例如：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> &amp;a,<span class="type">int</span> &amp;b)</span></span>&#123;...&#125;</span><br></pre></td></tr></table></figure><p>注意：</p><p>（1）在变量声明时出现&amp;才是引用运算符，其它地方的&amp;都是取地址运算符；<br>（2）引用代表一个变量的别名，必须在定义时初始化，不能在定义完成后再赋值；<br>（3）一个引用名只能作为一个变量的别名；</p><p> </p><h3 id="传参方式">传参方式</h3><h4 id="传地址方式">传地址方式</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> *p1, <span class="type">int</span> *p2)</span></span>;</span><br></pre></td></tr></table></figure><p>传地址方式的要点是：main函数和swap函数共用x，y变量的存储空间，只不过在main函数中，用x，y访问此空间；而在swap函数中，则用$*p1，*p2$这种间接访问方式访问此空间。由于空间是共用的，所以形参$*p1，*p2$发生了改变，也就影响到了实参x，y。</p><p> </p><h4 id="传引用方式">传引用方式</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">swap</span><span class="params">(<span class="type">int</span> &amp;a, <span class="type">int</span> &amp;b)</span></span></span><br></pre></td></tr></table></figure><p>传引用方式的要点是：在main中，用变量x，y访问存储空间，在swap函数中，用变量的别名a，b访问存储空间。由于a，b就可以看成是x，y，因此交换了a，b的内容，自然就影响了x，y。</p><p> </p><h2 id="类与对象">类与对象</h2><h4 id="类与对象的基本概念">类与对象的基本概念</h4><p>类（class）：它将数据以及这些数据上的操作封装在一起。</p><p>对象（object）：是具有类类型的变量</p><h4 id="类的定义">类的定义</h4><h4 id="成员函数">成员函数</h4><h4 id="构造函数">构造函数</h4><h4 id="析构函数">析构函数</h4><h4 id="构造函数重载">构造函数重载</h4><h4 id="默认构造函数">默认构造函数</h4>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二阶方程</title>
      <link href="/posts/1636524d.html"/>
      <url>/posts/1636524d.html</url>
      
        <content type="html"><![CDATA[<h1>线性齐次方程</h1><p>形如$x’‘+p(t)x’+q(t)x=f(t)$的形式，当f(t)等于零的时候，就是线性齐次方程，否则就是非齐次的方程。</p><p>对于一个普通的二阶线性齐次方程，$x’‘+x=0$  $z=x^{\prime}=\frac{d x}{d t}$<br>$$<br>x’‘=\frac{dx’}{dt}=\frac{dz}{dt}=\frac{dz}{dx}:\frac{dx}{dt}=z:\frac{dz}{dx}<br>$$</p><p>$$<br>z\frac{dz}{dx}+x=0<br>$$</p><p>$$<br>z:dz+x:dx=0<br>$$</p><p>有$\frac{z<sup>{2}}{2}+\frac{x</sup>{2}}{2}=c$可以写作$:z<sup>{2}+x</sup>{2}=k_{1}$,$x^{\prime}={\frac{d x}{d t}}=\pm{\sqrt{k_{1}-x^{2}}}$<br>$$<br>\frac{\pm:dx}{\sqrt{k_1-x^2}}=dt<br>$$<br>$$<br>s i n^{-1}\frac{x}{\sqrt{k_{1}}}=t+k_2,或者\frac{x}{\sqrt{k_{1}}}=\sin(t+k_{2})<br>$$</p><p>此时令$k_{2}=0\mathrm{,}{\sqrt{k_{1}}}=c_{1}$</p><p>正负的两种情况是$x=c_1\sin t$和$x=c_2\cos t$,因此，它的解是$x=c_1:sin t+c_2:cos t$</p><p>就是找到两个方程的特殊解，然后使得这个方程的其他的解都能够表示成两个特殊解的线性方程组合（通解）。</p><p>1.二阶齐形方程可能有无穷多个零点。</p><p>2.最大或者最小值的解不会在t=0的上下。例如:$x=(t-1)^2$</p><p>即不会出现$x’(t_0)=x’(t)=0$</p><h1>线性无关和朗斯基行列式</h1><p>对于两个方程$f(x)$和$g(x)$,证明其是线性无关的，只需要证明$c_1f(x)+c_2g(x)=0$当且仅当$c_1=c_2=0$时成立，即可证明。</p><p>例如：$f(t)=sint$,$g(t)=cost$</p><p>当t=0，$c_2$=0；当t=$\frac{\pi}{2}$,$c_1=0$,若$c_1,c_2$要满足对所有的t都成立，那么有$c_1=c_2=0$</p><p> </p><h3 id="朗斯基行列式">朗斯基行列式</h3><p>对下列行列式判断是否线性<br>$$<br>\left{\begin{array}{c}c_1\sin t+c_2\cos t=0\ c_1\cos t-c_2\sin t=0\end{array}\right.<br>$$<br>可以写作下面的朗斯基行列式。<br>$$<br>W(f,g)(t)=\begin{vmatrix}f(t)&amp;g(t)\ f’(t)&amp;g’(t)\end{vmatrix}=f(t)g’(t)-f’(t)g(t)<br>$$</p><p>那么对于任意的二阶齐形方程$x’‘+p(t)x’+q(t)x=0$,都有$W(t)=c e^{-\int p(t):dt}$</p><p>如果c=0，那么W(t)恒等于0，否则W(t)不等于0.</p><p>$W(t)=x_1x_2’-x_1’x_2$-----&gt;$W<sup>{\prime}(t)=x_{1}x_{2}</sup>{\prime\prime}-x_{2}x_{1}<sup>{\prime\prime}$-----&gt;$x_{1}</sup>{\prime\prime}=-p(t)x_{1}<sup>{\prime}-q(t)x_{1}$-------&gt;$x_{2}</sup>{\prime\prime}={-}p(t)x_{2}<sup>{\prime}-q(t)x_{2}$-----&gt;$W</sup>{\prime}(t)=[-p(t)x_{2}<sup>{\prime}-q(t)x_{2}]x_{1}-[-p(t)x_{1}</sup>{\prime}-q(t)x_{1}]x_{2}=-p(t)[x_{1}x_{2}<sup>{\prime}-x_{1}</sup>{\prime}x_{2}]=-p(t)W(t)$</p><p>如此便转化成一个可分方程：$W(t)=\stackrel{.}{c}e^{-\int p(t):d t}$</p><p> </p><p>如果朗斯基行列式等于0，说明两个解是线性相关的</p><p>如果W(t)不等于0，说明两个解是线性无关的，且两个解叫做方程的两个基本解（fundamental solution）。</p><p> </p><p>如果给了方程的$x=c_1x_1+c_2x_2$，证明$x_1和x_2$是方程的基本解。</p><p> </p><h3 id="已知一个解求另一个解">已知一个解求另一个解</h3><p>在一个二阶方程中，我们已知一个一般解$x_1(t)$,-此时如果$x_1(t) \ne 0$，我们可以通过如下的式子求出另一个一般解$x_2(t)$<br>$$<br>x_2(t)=x_1(t)\int\frac{e^{-\int p(t)dt}}{x_1^2(t)}dt<br>$$<br> </p><h3 id="线性非齐次方程">线性非齐次方程</h3><p>有如下形式<br>$$<br>x’‘+p(t)x’+q(t)x=f(t).<br>$$<br>带入$x_1$和$x_2$后将两式相减，可以得到如下方程<br>$$<br>(x_1’‘-x_2’‘)+p(t)(x_1’-x_2’)+a(t)(x_1-x_2)=0.<br>$$<br>有二阶线性非齐次方程的一个特解$x_p$</p><p>带入可知$x_P’‘+p(t)x_p’+q(t)x_p=f(t).$</p><p>可知，此二阶线性齐次方程的通解为$x=c_1x_1+c_2x_2+x_p$</p><p> </p><h4 id="解题思路">解题思路</h4><p>对于如下的二阶非齐次方程<br>$$<br>x’‘+p(t)x’+q(t)x=f(t)<br>$$<br>解题步骤如下</p><p>1.先令$$f(t)\equiv0$$，求出$x&quot;+ p（t）x’+ g（t）x = f（t）$的特解$x_1$与$x_2$</p><p>2.非齐次方程的通解可以表示为：$x=c_1x_1+c_2x_2+x_p,$其中$$ x_p=v_1(t)x_1+v_2(t)x_2$$</p><p>3.求解$v_1(t),v_2(t)$</p><p>​（1）列方程组<br>$$<br>\begin{cases}v’_1x_1+v’_2x_2=0\{}\v’_1x’_1+v’_2x’_2=f(t)\end{cases}<br>$$<br>​（2）克莱姆法则求解</p><img src="https://i.imgtg.com/2022/11/22/4Bv2S.png" alt="4Bv2S.png" border="0">$$v1'=\dfrac{\begin{vmatrix}0&x_2\\ f(t)&x_1'\end{vmatrix}}{W(t)}=-\dfrac{x_2f(t)}{W(t)}v2'=\dfrac{\begin{vmatrix}x_1&0\\ x_1'&f(t)\end{vmatrix}}{W(t)}=-\dfrac{x_1f(t)}{W(t)}$$​（3）对$v_1'(t)和v(2)'(t)$求解$$v_1=\int v_1'dt,v_2=\int v_2'dt$$​（4）最终可得齐次方程通解:$x=c_1x_1+c_2x_2+x_p$<p> </p><h2 id="具有常系数的线性齐次方程组">具有常系数的线性齐次方程组</h2><p>方程有如下形式<br>$$<br>ax’‘+bx’+cx=0<br>$$<br>当我们设$x(t)=e^{mt}$带入方程可得<br>$$<br>am<sup>2e</sup>{mt}+bme<sup>{mt}+ce</sup>{mt}=0<br>$$<br>化简可得(特征方程)<br>$$<br>am^2+bm+c=0<br>$$<br>此时可以求出方程的两个解<br>$$<br>m=\frac{-b\pm\sqrt{b^2-4ac}}{2a}<br>$$<br>一般情况下有三种情况：</p><p>​case1:   $b^2-4ac&gt;\textbf{0}$</p><p>此时方程有两个不同解<br>$$<br>m_1=\dfrac{-b+\sqrt{b<sup>2-4ac}}{2a},m_2=\dfrac{-b-\sqrt{b</sup>2-4ac}}{2a}<br>$$<br>此时有方程的解$x=c_1e<sup>{m_1t}+c_2e</sup>{m_2t}$</p><p> </p><p>​case2:   $b^2-4ac={0}$</p><p>（1）求出唯一解</p><p>此时m有唯一解$m=-\frac{b}{2a}$,代入可得方程的解为$x_1=e^{-\frac{b}{2a}t}$.</p><p>（2）已知一解，求另一解<br>$$<br>x_2=e<sup>{-\frac{b}{2a}t}\int\frac{e</sup>{-\frac{b}{a}t}}{(e<sup>{-\frac{b}{2a}t})</sup>2}dt=e<sup>{-\frac{b}{2a}t}\int\frac{e</sup>{-\frac{b}{a}t}}{e<sup>{-\frac{b}{a}t}}dt=e</sup>{-\frac{b}{2a}t}\int dt=te^{-\frac{b}{2a}t}<br>$$<br>（3）得出方程的解<br>$$<br>x=c_{1}e^{-\frac{b}{2a}t}+c_{2}t e^{-\frac{b}{2a}t}<br>$$<br>case3：$\quad b^2-4ac&lt;0\quad\text{}$没有实数解</p><p>（1）求出特征方程的解<br>$$<br>m=\frac{-b\pm\sqrt{4ac-b^2}{i}}{2a}=u\pm\lambda\text{i}<br>$$<br>有$e^{\mu+\lambda i}=e<sup>{\mu}e</sup>{\lambda i}=e^{\mu}(\mathrm{cos}\lambda+i\mathrm{sin}\lambda)$</p><p>可知两个解分别为$x_1 = u(t),x_2=i(t)$</p><p>(2)此方程的通解为<br>$$<br>c_1x_1+c_2x_2<br>\<br>C_1\mathrm{e}^{ut}\cos\lambda t+C_2\mathrm{e}^{ut}\sin\lambda t<br>$$</p><p>$$<br>x=c_1e^{\mu t}\cos{\lambda t}+c_2e^{\mu t}\sin{\lambda t}=e^{\mu t}(c_1\cos{\lambda t}+c_2\sin{\lambda t})<br>$$</p><p> </p><h2 id="欧拉方程（Euler-equation）">欧拉方程（Euler equation）</h2><p>欧拉方程形式如下</p><p>$$<br>at^2x’‘+btx’+cx=0,\quad t&gt;0<br>$$<br>求解方法：</p><p>1.令$t=e^s,s=lnt$</p><p>2.则有</p><p>​（1）$\frac{ds}{dt}=\frac{1}{t}=\frac{1}{e^s}$</p><p>​（2）${\frac{\mathrm{d}x}{\mathrm{d}t}}={\frac{\mathrm{d}x}{\mathrm{d}s}}\cdot{\frac{\mathrm{d}s}{\mathrm{d}t}}={\frac{1}{t}}\cdot{\frac{\mathrm{d}x}{\mathrm{d}s}}$</p><p>​$\frac{\mathrm{d}<sup>2x}{\mathrm{d}t</sup>2}=\frac{\mathrm{d}}{\mathrm{d}t}\left(\frac{1}{t}\cdot\frac{\mathrm{d}x}{\mathrm{d}s}\right)\\hspace{5cm}=-\frac{1}{t<sup>{2}}\cdot\frac{\mathrm{d}x}{\mathrm{d}s}+\frac{1}{t}\cdot\frac{\mathrm{d}}{\mathrm{d}s}\left(\frac{\mathrm{d}x}{\mathrm{d}s}\right)\cdot\frac{\mathrm{d}s}{\mathrm{d}t}\\hspace{3cm}=-\frac{1}{t</sup>2}\cdot\frac{\text{d}x}{\text{d}s}+\frac{1}{t<sup>2}\cdot\frac{\text{d}</sup>2x}{\text{d}s^2}$</p><p>可得：$\left{\begin{array}{c}<br>tx’ = t \frac{\mathrm{d} x}{\mathrm{~d} t}=\frac{\mathrm{d} x}{\mathrm{~d} s} \<br>t<sup>{2}x’'=t</sup>{2} \frac{\mathrm{d}^{2} x}{\mathrm{~d} t^{2}}=-\frac{\mathrm{d} x}{\mathrm{~d} s}+\frac{\mathrm{d}^{2} x}{\mathrm{~d} s^{2}}<br>\end{array}\right.$</p><p>​（3）将上式带入原方程，此时原方程（1）可变为$a\frac{\mathrm d^2x}{\mathrm d s^2}+(b-a)\frac{\mathrm dx}{\mathrm d s}+cx=0$</p><p>即此特征方程为$am^2+(b-a)m+c=0$</p><p>可知其通解为：$x=c_1x_1(s)+c_2x_2(s)$</p><p>​（4）根据常系数的二阶微分方程的求解方法$e<sup>{mt}(am</sup>2+(b-a)m+c)=0$</p><p>​（5）分三种情讨论$\begin{cases}\Delta&gt;0\ \ \Delta=0\ \ \Delta&lt;0\end{cases}$</p><p>​（6）最终用$s = lnt替换掉结果中的s得到x(t)$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 常微分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>电子学</title>
      <link href="/posts/9992c400.html"/>
      <url>/posts/9992c400.html</url>
      
        <content type="html"><![CDATA[<h1>电子学</h1><p>电子学是研究<strong>电子运动</strong>和<strong>控制</strong>的科学分支。</p><h3 id="主要电子元件">主要电子元件</h3><p>电阻：它限制了电流的流动，因此，电阻是用来控制电路中的电压的。</p><p>电容器：它被用来在两块板之间以电荷的形式出储存能量。</p><p>电感器：以磁能的形式储存电能。</p><h2 id="材料概述">材料概述</h2><p>在材料学中，材料主要被分为导体，绝缘体和半导体</p><p>导体(Metals):能让电流或热通过的材料被称为导体。</p><p>绝缘体(Insulators)：不允许电流或热通过的导体</p><p>半导体(Semiconductors)：介于导体和半导体之间具有导电性的材料</p><p>半导体广泛应用于各种电子器件，如晶体管、<strong>集成电路</strong>和二极管。</p><h2 id="能带图（Energy-band-Diagram）">能带图（Energy band Diagram）</h2><p>原子是不能再细分的最小粒子。</p><p>质子（Proton），中子（Neutron）和电子（Electon）.Center of the atom is called nucleus(原子核)</p><p>1.原子核包含质子和中子<br>2.原子的最外层叫做电子壳层，里面有电子。<br>3.电子绕原子核旋转。</p><p> </p><p>传导带（CB）和价带（vB）是如何形成的？<br>情况1：假设：所有原子彼此之间都很远。<br>注：所有原子第一轨道上所有电子的能量保持不变。</p><p> </p><p>Conduction band   导带<br>Forbidden energy gap  禁能隙<br>Valance band  价带</p><p>在晶体中，由于引力和斥力的关系，每个电子都有不同的能级。<br>在任何固体中，都有两种类型的带：价带和导带。</p><p>完全最高的填充或部分填充的能带为<strong>价带</strong>（Valance band ）</p><p>最低未填充能量叫做<strong>导带</strong>（Conduction band）</p><p> </p><p>$E_v$为价带中的最大能量，$E_c$为能带中的最小能量。带隙能量（band Gap）$E_g$是$E_v和E_c$之间的差值，两个能带之间的区域又叫禁带隙，电子不能位于禁带隙中。</p><p>一个电子从价带中获取足够的能量运动到导带中的过程叫做跃迁。</p><p> </p><p>如下如，分别为导体，半导体和绝缘体的能带图</p><p> </p><p>所有的原子在任何固体中都是紧密结合的</p><p>在晶体中，由于引力和斥力的关系，每个电子都有不同的能级。</p><p> </p><p>绝缘体：<br>1.导带为空。这些材料不允许电流通过。<br>玻璃和塑料是绝缘体的例子。<br>2.它们具有高电阻率和非常低的导电性。绝缘体中的能隙在6ev左右非常高。<br>注：导带与价带之间的间隙称为带隙（Eg）。<br>3.要将电子从价带移动到导带，需要大量的能量（超过6ev），这实际上是不可能的。<br>4.因此，电子从价带移动到导带是不可能的。</p><p> </p><p>半导体：<br>1.锗和硅是电性能介于导体和绝缘体之间的最佳材料。<br>2.两个带之间的禁隙非常小，约为1eV。<br>11注：导和价带之间的间隙称为禁带隙或禁带隙（Eg）。<br>3.在低温或绝对零度温度下，半导体表现得像绝缘体。<br>4.即使在室温下，价带中的电子获得的能量也大于能隙，因此电子进入传导带。</p><p> </p><p>导体：</p><p>1.在价带和导带之间没有禁带隙，导致了两个带的重叠。<br>2.在室温下，传导带中自由电子的数量是可用的。电导带几乎充满了电子。</p><p> </p><p>在绝对零度时，半导体是绝缘体，因为是导带中不存在电子.</p><p>在绝对0度和没有外界激发时,价电子被共价键束缚，本征半导体中没有可以运动的带电粒子（即载流子），不导电，相当于绝缘体。</p><p>导体价带与导带之间的能带间隙为0</p><p> </p><h2 id="化学键（Chemical-Bonding）">化学键（Chemical Bonding）</h2><h3 id="离子键（lonic-Bonding）">离子键（lonic Bonding）</h3><p><strong>金属</strong>和<strong>非金属</strong>之间通过电子的完全转移而形成离子键，去达到稳定状态（stability）</p><h3 id="金属键（Metallic-bonding）">金属键（Metallic bonding）</h3><h3 id="共价键合（Co-valent-bonding）">共价键合（Co-valent bonding）</h3><p>共价键是当两个原子共享一个或多个电子对时形成的键.</p><p>每个原子为键的形成贡献了相等数量的电子。</p><p> </p><h3 id="本征和非本征半导体-Intrinsic-and-extrinsic-Semiconductor">本征和非本征半导体(Intrinsic and extrinsic Semiconductor)</h3><h4 id="本征半导体">本征半导体</h4><p>1.本征半导体被称为纯半导体，它只由单一类型的元素组成。</p><p>2.本征半导体最常见的例子是硅（Si）和锗（Ge），它们属于元素周期表的第IV组。</p><p>3.硅和锗的原子序数分别为14和32。</p><p>4.这表明Si和Ge的最外层轨道各有4个电子。这些电子是<strong>最外层电子</strong> （valence electrons）， 用于半导体的传导</p><p>5.为了完成它的八隅体，附近的原子通过共用价电子形成共价键。</p><p>6.所有的共价键都是稳定的，没有自由电子可用于传导。在这里，本征半导体充当绝缘体（insulator）或非导体。</p><p> </p><h4 id="温度对本征半导体的影响">温度对本征半导体的影响</h4><p>1.在绝对零度下，共价键非常强或紧密结合，没有目由电子可用来传导电流。（表现为绝缘体）</p><p>2.换句话说，如果温度升高，一些共价键会断裂；一个电子的去除会在其后面留下一个空位，即键中缺少一个电子。这种缺失的电子称为<strong>空穴</strong>。</p><p>3.共价键中缺少电子的现象称为空穴。</p><p>4.在固有半导体中，产生相同数量的电子和空穴，因此它表现出<strong>电中性</strong></p><p> </p><h4 id="非本征半导体">非本征半导体</h4><p>1.本征半导体的电导率（conductivity）不好。由于其导电性低，被认为不适合在电子器件中使用。</p><h5 id="如何提高电导率？">如何提高电导率？</h5><p>2.掺杂（doping）：将杂质添加到半导体中的过程称为掺杂。</p><p>3.添加杂质的半导体称为不纯（impure）或非本征半导体</p><p>将杂质添加到半导体中的过程称为掺杂。</p><p>4.在纯材料中加入少量合适的杂质，使其电导率提高数倍.</p><h4 id="一些常用的掺杂剂Some-Commonly-Used-Dopants">一些常用的掺杂剂Some Commonly Used Dopants</h4><p>5.五价原子：原子价为5（元素周期表中第5族）的原子；如碑（as）、磷锦（Sb）等。</p><p>6.三价原子：原子价为3（元素周期表中第3组）的原子；如铟（In）、铝（AI）、硼（B）等。</p><p> </p><p>注：当导带中有足够或足够的电子数时，任何材料都参与导通。</p><p> </p><h2 id="非本征半导体：N型半导体">非本征半导体：N型半导体</h2><p>1.n型半导体是一种与五价杂质掺杂的非本征半导体。</p><p>2.在纯半导体中加入五价杂质，以增加导电所需的电子数量。</p><p>3.五价杂质在其最外层轨道上有五个电子。</p><p>五价杂质的例子是磷[15]（P），碑[33]（As），锦（Sb）[51]</p><p>4.在n型半导体中添加五价杂质，使原始本征半导体的晶体结构不受干扰。</p><p>5.五价杂质原子与四个硅原子形成共价键，第五个电子不与任何硅原子成键</p><p>6.在n型半导体中，这第5个电子主要产生电流。</p><p>让我们假设六个电子来自六个不同的磷元素。</p><p>在室温下，电子-空穴对由于共价键的断裂而产生。<br>假设两个共价键被打破这意味着产生了两个电子和两个空穴。<br>总的来说，它现在有8个电子和2个空穴。</p><p>换句话说，在n型半导体中电子增加了；所以电子电流会很大而空穴电流会很小。<br>为了区分它，科学家用了两个词：多数电荷(majority charge)（i.e.Electron）和少数电荷(minority)（i.e. Hole）。</p><p>7.每个五价杂质原子给n型半导体提供一个电子，因此被称为供体杂质(Donor impurities)。</p>DD<p>在这里，每个电子都与带正电的离子。</p><p> </p><h2 id="非本征半导体：P型半导体">非本征半导体：P型半导体</h2><p>1.p型半导体是一种非本征半导体。</p><p>2.当三价杂质被添加到固有的或纯的半导体（硅或锗）中时，它被称为p型半导体。</p><p>3.三价杂质，如硼[5]（B），镓[31]|（Ga）铟[49]（In），铝[13]<br>（AI）等</p><p>4.三价杂质有三个价电子，它们与三个si原子形成共价键。<br>因此，第四个共价键由于短缺而不完整的电子。这个缺失的电子被称为空穴。</p><p>5.空穴的行为类似于能接受电子的止电何。因此被称为受体杂质。</p><p>6.p型半导体中的电流主要由空（hole）贡献。</p><p>换句话说，在 p型半导体中，空穴有所增加；所以空穴电流会很大，而电子电流会很小。</p><p>为了区分它，科学家用了两个词：多数电荷（i.e. Hole）和少数电荷（i.e. Electron）。</p><p> </p><h2 id="11、电子和空穴">11、电子和空穴</h2><p>1.这个空白空间被认为是在原子的特定位置没有一个电子的情况下的空穴。</p><p>2.这个洞的行为与正电荷相似。这个空的空间吸引了邻近原子的一个电子。</p><p>本征半导体中的总电流是空穴和电子的总和。<br>电流。<br>总电流=电子电流+空穴电流</p><p>$\mathbf I=\mathbf I_{hole}+\mathbf I_{electron}$</p><p>3.因此我们得出了空穴和电子向相反方向运动的结论</p><p>4.空穴和电子是两种载流子；它们负责半导体中的电流。</p><p>note：空穴不是电子那样的物理粒子；在半导体材料中，孔洞似乎从一个原子传递到另一个原子。</p><p><a href="https://byjus.com/jee/semiconductors/#holes-and-electrons">Semiconductors - Types, Examples, Properties, Application, Uses (byjus.com)</a></p><p> </p><h2 id="12-质量作用定律-mess-action-law">12,质量作用定律(mess action law)</h2><p><a href="https://www.physics-and-radio-electronics.com/electronic-devices-and-circuits/semiconductor/law-of-mass-action.html">Law of mass action (physics-and-radio-electronics.com)</a></p><p>在热平衡下，电子浓度数与空穴浓度数的乘积为常数或等于本征载流子浓度的平方。</p><p>$n_i$=内在载流子浓度</p><p>n=单位体积的自由电子数</p><p>p=每单位体积的自由空穴数</p><p>2.质量作用规律与添加的给体和受体杂质量无关。</p><p> </p><h3 id="非本征半导体-2">非本征半导体</h3><p>电子的浓度远远大于空穴的浓度</p><p>空穴的浓度远远大于电子的浓度</p><p>掺杂后电子与空穴的复合速率增加。因此，product保持不变。因此我们可以说它独立于给体和受体的杂质。</p><h3 id="n型和p型半导体的质量作用定律">n型和p型半导体的质量作用定律</h3><p>$n_n$=n型半导体的电子数</p><p>$p_n$=n型空洞的电子数</p><h4 id="p型半导体">p型半导体</h4><p>$p_p$=p型半导体的空穴数</p><p>$n_p$=p型半导体的电子数</p><p>对于非本征半导体，质量作用定律表明：多数载流子和少数载流子的乘积是恒定的。</p><p> </p><h3 id="基于质量作用定律的问题">基于质量作用定律的问题</h3><table><thead><tr><th>名称</th><th></th></tr></thead><tbody><tr><td>Potential difference</td><td>潜在差异</td></tr><tr><td>Electric Field</td><td>电场</td></tr><tr><td>Current Density</td><td>当前密度</td></tr><tr><td>Conductivity</td><td>电导率</td></tr><tr><td>Resistivity</td><td>电阻率</td></tr><tr><td>Proportional</td><td>成比例的</td></tr><tr><td>Reciprocal</td><td>倒数</td></tr><tr><td>Electron Mobility</td><td>电子迁移率</td></tr><tr><td>Hole mobility</td><td>空穴迁移率</td></tr></tbody></table><p>1.电子沿外加电场的相反方向流动<br>2.空穴在外加电场的作用下沿同一方向流动。</p><p> </p><p>Vd是漂移速度</p><p>流动（$\mu$）：单位电场的漂移速度称为迁移率。</p><p>$$<br>\mu=V_{\mathrm{d}}/E<br>$$<br>$\mu$：电子的迁移率</p><p>$v_d$:漂移速度</p><p>E：施加电场</p><p>换句话说，迁移率是衡量在外加电场或存在的情况下，电子在金属或半导体中移动的速度或容易程度</p><p>在外加电场的存在下，电子在金属或半导体中移动的能力称为电子迁移能力。<br>$$<br>I=I_e +I_h<br>$$<br>1.电子产生的电流$I_e$<br>$I_e = neAv_d$</p><p>$I_e = neA \mu_e E$</p><p>2.空穴电流</p><p>$I_h = peAv_d$</p><p>$I_h= peA \mu_h E$</p><p>3.电子和空穴产生的总电流</p><p>$I= I_e +I_h$</p><p>$I = neA \mu_eE + peA\mu_hE$</p><p>$I = EA[ne\mu_e +pe\mu_h]$</p><p>$\frac{I}{A}=E[ne\mu_e+pe\mu_h]$</p><p>其中，$\frac{I}{A}=J$,$[ne\mu_e+pe\mu_h]=\sigma $</p><p>$J = \sigma  E$</p><p>$\sigma = ne\mu_e + pe\mu_h$</p><p>$\sigma \approx  ne\mu_e$</p><p> </p><h2 id="16-无偏置下的PN结">16,无偏置下的PN结</h2><p><a href="https://www.physics-and-radio-electronics.com/electronic-devices-and-circuits/semiconductor-diodes/zero-bias-pn-junction.html">Zero bias pn junction (physics-and-radio-electronics.com)</a></p><table><thead><tr><th></th><th>P-型</th><th>N-型</th></tr></thead><tbody><tr><td>多数充电器</td><td>空穴</td><td>电子</td></tr><tr><td>少数充电器</td><td>电子</td><td>空穴</td></tr></tbody></table><p>P-n结是通过连接n型和p型半导体材料形成的。p型和n型之间的边界称为PN结。</p><p>PN结有三种可能的偏置条件：</p><p>偏置：如果在PN结二极管的两端施加外部电压（外部电）。</p><p><a href="http://A.no">A.no</a> bias / zero bias 零偏 / unbias</p><p>B.Forward bais 正向偏向</p><p>C.Reverse bias 反向偏向</p><p> </p><h3 id="无偏置下的PN结">无偏置下的PN结</h3><p>无外部电压的p-n结称为零偏p-n结。</p><p>N区的电子浓度更高与P区相比。因此，存在扩散电子从N区到P区</p><p>同样，p区域的孔洞浓度高于n区域。因此，有一种扩散从P区到n区。</p><p>从p区流出的空穴揭示了带负电荷的受体离子，从n区流出的电子揭示了带正电荷的供体离子</p><p> </p><p>在载流子从P向N和N向P运动的过程中，在接点处出现的电位差称为势垒电位，它起势垒作用。</p><p>由于这个电位差，就产生了电场。</p><p>一旦在结附近建立势垒电位。电荷载流子不可能从P到N和从N到P进一步移动（运动）</p><h4 id="复习">复习</h4><p>由于浓度梯度的作用，在结合部形成了势垒电位。</p><p> </p><h2 id="17-正偏压下的PN结">17,正偏压下的PN结</h2><p>1.当正电压加到p侧，负电压加到n侧时，二极管是正向偏置的。</p><p>如果p端施加的电压大于n端，称为<strong>正向偏置</strong>。</p><p>2.孔从电池的正极排斥，并向连接处移动。同样，n型中的电子从电池的负极排斥并向结方向移动。</p><p>3.当外加电压（VF）大于势垒电位（Vb）时，损耗宽度变窄，势垒电位降低。</p><p>注：由于这个电场，一个电子在结的p侧移动到结的n侧。这种运动称为漂移。</p><p>4.这个动作消除了势垒，并建立了传导路径。<br>结果，电流随外加电压呈指数增长。这种电流叫做正向电流。</p><p>5.电流通过二极管迅速增加的正向偏置电压称为膝压或角压或内置电位或打开电压。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 电子学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二叉树</title>
      <link href="/posts/e85d694a.html"/>
      <url>/posts/e85d694a.html</url>
      
        <content type="html"><![CDATA[<h1>二叉树</h1><h2 id="二叉树的逻辑结构">二叉树的逻辑结构</h2><h3 id="二叉树的定义">二叉树的定义</h3><p>二叉树是n（n$\ge$0）个结点的有限集合，该集合或者为空集（称为空二叉树），或者由一个根结点和两棵互不相交的、分别称为根结点的左子树和右子树的二叉树组成。</p><h3 id="二叉树特点">二叉树特点</h3><p>1.每个结点最多有两颗子树。</p><p>2.二叉树是有序的，其次序不能任意颠倒。</p><p>注意：二叉树和树是两种树结构。</p><p> </p><h3 id="分类">分类</h3><p>了解好：斜树，满二叉树，完全二叉树</p><p> </p><h2 id="二叉树的基本性质">二叉树的基本性质</h2><p>性质1:二叉树的第i层上最多有$2^{i-1}$个结点（i$\ge$1）</p><p>性质2:一棵深度为k的二叉树中，最多有$2^{k-1}$个结点，最少有k个结点。</p><p>性质3:在一棵二叉树中，如果叶子结点数为$n_0$，度为2的结点数为$n_2$，则有：$n_0=n_2+1$。</p><p>性质4:具有n个结点的完全二叉树的深度为$\left\lfloor\log _{2} n\right\rfloor+1$。</p><p>性质5:对一棵具有n个结点的完全二叉树中从1开始按层序编号，则对于任意的序号为i（$1\le i \le n$）的结点(简称为结点i），有：<br>（1）如果i&gt;1，则结点的双亲结点的序号为i/2；如果i=1，则结点是根结点，无双亲结点。</p><p>（2）如果$2i \le n$，则结点i的左孩子的序号为2i；如果2i&gt;n，则结点i无左孩子。</p><p>（3）如果$2i+1\le n$，则结点i的右孩子的序号为2i+1；如果$2i+1&gt;n$，则结点无右孩子。</p><p> </p><h2 id="顺序存储结构">顺序存储结构</h2><p>二叉树的顺序存储结构就是用一维数组存储二叉树中的结点，并且结点的存储位置（下标）应能体现结点之间的逻辑关系-父子关系。</p><h3 id="完全二叉树的顺序储存">完全二叉树的顺序储存</h3><img src="https://i.imgtg.com/2022/11/07/R6CWa.png" alt="R6CWa.png" border="0"><img src="https://i.imgtg.com/2022/11/07/R6IjK.png" alt="R6IjK.png" border="0"><h3 id="二叉树编号">二叉树编号</h3><p>按照完全二叉树编号</p><img src="https://i.imgtg.com/2022/11/07/R6XhB.png" alt="R6XhB.png" border="0"><p>可以编号为：<img src="/posts/e85d694a.htm/R6uRs.png" alt="R6uRs.png" border="0"></p><img src="https://i.imgtg.com/2022/11/07/R66Ig.png" alt="R66Ig.png" border="0"><p>没有编号的位置直接存储为空。</p><h3 id="二叉链表">二叉链表</h3><img src="https://i.imgtg.com/2022/11/07/R6wyS.png" alt="R6wyS.png" border="0"><table><thead><tr><th>data</th><th>数据域，存放该结点的数据信息</th></tr></thead><tbody><tr><td>Ichild</td><td>左指针域，存放指针指向左孩子的指针</td></tr><tr><td>rchild</td><td>右指针域，存放指针指向右孩子的指针</td></tr></tbody></table><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">tree</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> data;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">tree</span>* Ichild;</span><br><span class="line">    <span class="keyword">class</span> <span class="title class_">tree</span>* rchild;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">class</span> <span class="title class_">tree</span> node;</span><br><span class="line"><span class="keyword">typedef</span> node *btree;</span><br></pre></td></tr></table></figure><p> </p><h2 id="二叉树的遍历">二叉树的遍历</h2><p>二叉树的组成：根结点D，左子树L，右子树R。</p><p>如果限定先左后右，则二叉树遍历方式有三种：</p><p>前序（Preorder）：DLR</p><p>中序（Inorder）：LDR</p><p>后序（Postorder）：LRD</p><p>如下图所视</p><img src="https://i.imgtg.com/2022/11/07/R8MsN.png" alt="R8MsN.png" border="0"><h3 id="中序遍历">中序遍历</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.遍历左子树</span><br><span class="line">2.遍历（或访问）树根</span><br><span class="line">3.遍历右子树</span><br></pre></td></tr></table></figure><p>中序遍历为：FDHGIBEAC</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Inorder</span><span class="params">(btree ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (ptr != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">Inorder</span>(ptr-&gt;left);   <span class="comment">//遍历左子树</span></span><br><span class="line">cout&lt;&lt;ptr -&gt;data;     <span class="comment">//遍历并打印树根</span></span><br><span class="line"><span class="built_in">Inorder</span>(ptr-&gt;right);   <span class="comment">//遍历右子树</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="后序遍历">后序遍历</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.遍历左子树</span><br><span class="line">2.遍历右子树</span><br><span class="line">3.遍历树根</span><br></pre></td></tr></table></figure><p>中序遍历为：FHIGDEBCA</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">void Postorder (btree ptr)</span><br><span class="line">&#123;</span><br><span class="line">if (ptr != NULL)</span><br><span class="line">&#123;</span><br><span class="line">Postorder(ptr-&gt;left);     //遍历左子树</span><br><span class="line">Postorder(ptr-&gt;right);    //遍历右子树</span><br><span class="line">cout&lt;&lt;ptr-&gt;data;          //遍历并打印树根</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="前序遍历">前序遍历</h3><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.遍历树根</span><br><span class="line">2.遍历左子树</span><br><span class="line">3.遍历右子树</span><br></pre></td></tr></table></figure><p>中序遍历为：ABDFGHIEC</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Preorder</span><span class="params">(btree ptr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span> (ptr != <span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">    cout&lt;&lt;ptr -&gt;data;     <span class="comment">//遍历并打印树根</span></span><br><span class="line"><span class="built_in">Inorder</span>(ptr-&gt;left);   <span class="comment">//遍历左子树</span></span><br><span class="line"><span class="built_in">Inorder</span>(ptr-&gt;right);   <span class="comment">//遍历右子树</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="二叉树节点的插入和删除">二叉树节点的插入和删除</h3><p>在二叉树建立的过程中，是根据<strong>左子树&lt;树根&lt;右子树</strong>的原则建立的。</p><h4 id="查找">查找</h4><p>只需从树根出发比较键值，如果比树根大就往右，否则往左而下，直到相等就找到了要查找的值，如果比到NULL，无法再前进就代表查找不到此值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">btree <span class="title">search</span> <span class="params">(btree ptr,<span class="type">int</span> val)</span>  <span class="comment">//查找二叉树某键值得函数</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">while</span>（<span class="number">1</span>）</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(ptr==<span class="literal">NULL</span>)     <span class="comment">//没找到就返回NULL</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">if</span>(ptr-&gt;data==val)   <span class="comment">//节点值等于查找值</span></span><br><span class="line"><span class="keyword">return</span> ptr;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(ptr-&gt;data&gt;val)  <span class="comment">//节点值大于查找值</span></span><br><span class="line">ptr=ptr-&gt;left;</span><br><span class="line"><span class="keyword">else</span>                  <span class="comment">//小于查找值</span></span><br><span class="line">ptr=ptr-&gt;right;    </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="插入操作">插入操作</h4><p>插入节点的情况和查找相似，关键是插入后仍要保持二叉查找树的<strong>特性（左子树&lt;树根&lt;右子树）</strong>。如果插入的节点在二叉树中没有找到，就是出现查找失败的情况，就相当于找到了要插入的位置。我们可以修改，只要多加一条if判断语句，当查找到键值时输出“二叉树中有此节点了！”，如果找不到，再将此节点加到此二叉树中。算法如下所示。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">btree ptr=<span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">if</span>((<span class="built_in">search</span>(ptr,data))!=<span class="literal">NULL</span>)     <span class="comment">//查找二叉树</span></span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;二叉树中有此节点了-&quot;</span>&lt;&lt;data&lt;&lt;endl;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">&#123;</span><br><span class="line">    ptr=<span class="built_in">creat_tree</span>(ptr,data);<span class="comment">//将此键值加入到此二叉树中</span></span><br><span class="line">    <span class="built_in">inorder</span>(ptr);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">btree <span class="title">creat_tree</span><span class="params">(btree root,<span class="type">int</span> val)</span></span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">btree newnode,current,backup;</span><br><span class="line">newnode=(btree)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(node));<span class="comment">//创建一个新结点</span></span><br><span class="line">newnode-&gt;data=val;</span><br><span class="line">newnode-&gt;left=<span class="literal">NULL</span>;</span><br><span class="line">newnode-&gt;right=<span class="literal">NULL</span>;</span><br><span class="line"><span class="keyword">if</span>(root==<span class="literal">NULL</span>)    <span class="comment">//如果树根为空</span></span><br><span class="line">&#123;  </span><br><span class="line">root=newnode;</span><br><span class="line"><span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>     <span class="comment">//树不为空</span></span><br><span class="line">&#123;  </span><br><span class="line"><span class="keyword">for</span>(current=root;current!=<span class="literal">NULL</span>;)   <span class="comment">//把树赋给root</span></span><br><span class="line">&#123;  </span><br><span class="line">backup=current;    <span class="comment">//current赋给backup</span></span><br><span class="line"><span class="keyword">if</span>(current-&gt;data &gt; val)    <span class="comment">//val小于此结点的data</span></span><br><span class="line">current=current-&gt;left; <span class="comment">//current被赋为右树的节点</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">current=current-&gt;right;<span class="comment">//current被赋为左树的节点</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span>(backup-&gt;data &gt;val) <span class="comment">//节点数据域大于val值说明新结点是它的左孩子</span></span><br><span class="line">backup-&gt;left=newnode;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">backup-&gt;right=newnode;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">inorder</span><span class="params">(btree ptr)</span><span class="comment">//中序遍历子程序</span></span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">  <span class="keyword">if</span>(ptr!=<span class="literal">NULL</span>)</span><br><span class="line">     &#123;  </span><br><span class="line">      <span class="built_in">inorder</span>(ptr-&gt;left);</span><br><span class="line">      cout&lt;&lt;<span class="string">&quot;[&quot;</span>&lt;&lt;ptr-&gt;data&lt;&lt;<span class="string">&quot;]&quot;</span>;</span><br><span class="line">      <span class="built_in">inorder</span>(ptr-&gt;right);</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="二叉树的删除">二叉树的删除</h3><p>1.删除的结点为树叶：只要将其相连的父节点指向NULL即可。</p><p>2.删除的节点只有一颗子树，如下图，要删除节点1，就要将其右指针放到其父节点的左指针</p><p>3.删除的节有两颗子树，如下图，要删除节点4，方式有两种</p><p>​3.1 找出中序立即先行者（inorder immediate predecessor）</p><p>即是将欲删除节点的左子树中最大者向上提，在此即为图中的节点2，简单来说，就是在该节点的左子树，往右寻找，直到右指针为NULL，这个节点就是中序立即先行者。</p><p>​3.2 找出中序立即后继者（inorder immediate successor）</p><p>即是将欲删除节点的右子树中最小者向上提，在此即为图中的节点5，简单来说，就是在该节点的右子树，往左寻找，直到左指针为NULL，这个节点就是中序立即后继者。</p><img src="https://i.imgtg.com/2022/11/07/R8aaC.png" alt="R8aaC.png" border="0"><p> </p><h2 id="平衡二叉树（AVL树）">平衡二叉树（AVL树）</h2><p>由于二叉查找树的缺点是无法永远保持在最佳状态。当加入的数据部分已排序的情况下，极有可能产生斜二叉树，因而使树的高度增加，导致查找效率降低。所以二叉查找树不利于数据的经常变动（加入或删除）的情况。为了能够尽量降低所需要的时间，在查找的时候能够很快找到所要的键值，就必须让树的高度越小越好。</p><p>现在又a[8] = {1,2,3,4,5,6,7,8}需要构建二叉排序树。在没有学习平衡二叉树之前，根据二叉排序树的特性，通常会将它构建成如下左图。虽然完全符合二叉排序树的定义，但是对这样高度达到8的二叉树来说，查找是非常不利的。因此，更加期望构建出如下右图的样子，高度为4的二叉排序树，这样才可以提供高效的查找效率。</p><h3 id="二叉排序树">二叉排序树</h3><p>由序列{1，2，3，4，5}得到二叉排序树：ASL=（1+2+3+4+5）/5=3</p><p>由序列{3，1，2，5，4}得到二叉排序树：ASL =（2+3+1+3+2）/5= 2.2</p><img src="/posts/e85d694a.htm/image-20221110195616249.png" alt="image-20221110195616249" style="zoom:50%;"><h3 id="平衡树的定义">平衡树的定义</h3><p>在AVL树中，每次在插入数据和删除数据后，必要的时候会对二叉树作一些高度的调整让二叉查找树的高度随时维持平衡。T是一个非空的二叉树，$T_l$和$T_r$，分别是它的左右子树，若符合$\left|h_{1}-h_{r}\right|\leq1$。$h_i$和$h_r$，分别为$T_l$和$T_r$的高度，也就是所有内部节点的左右子树高度相差必定小于或等于1，则称T是个高度平衡树。</p><p>平衡因子：结点的平衡因子是该结点的左子树的深度与右子树的深度之差。</p><h3 id="平衡二叉树的调整">平衡二叉树的调整</h3><p>构造平衡二叉树的基本思想：每插入一个结点，<br>（1）从插入结点开始向上计算各结点的平衡因子，如果某结点平衡因子的绝对值超过1，则说明插入操作破坏了二叉排序树的平衡性，需要进行平衡调整；否则继续执行插入操作。<br>（2）如果二叉排序树不平衡，则找出最小不平衡子树的根结点，根据新插入结点与最小不平衡子树根结点之间的关系判断调整类型。<br>（3）根据调整类型进行相应的调整，使之成为新的平衡子树。</p><p>当我们从零开始插入一个二叉树的时候，最开始是一个空的树</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (root == <span class="literal">NULL</span>) &#123;</span><br><span class="line">root = (AVLTREE*)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(AVLTREE));</span><br><span class="line">root-&gt;data = data;</span><br><span class="line">root-&gt;height = <span class="number">0</span>;</span><br><span class="line">root-&gt;leftChlid = root-&gt;rightChild = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果判断树为空，那么我们先给树跟分配一个空间，树的data域储存第一个数据，这个树的高度为零，左右孩子都为空。</p><p>然后当我们去插入节点的时候，通过规则判断，比这个数据小的会储存到左孩子中，比这个数据大的会储存到右孩子中。但当我们插入第三个开始就可能会出现不平衡的情况，即不符合$\left|h_{1}-h_{r}\right|\leq1$我们归纳为以下四种情况，每次插入我们都进行判断，从而保证二叉树一直在一个平衡的状态。</p><p>设结点A为最小不平衡子树的根结点，对该子树进行平衡调整归纳起来有以下四种情况：<br>1.LL型</p><ol start="2"><li><p>RR型</p></li><li><p>LR型</p></li><li><p>RL型</p></li></ol><h4 id="LL型">LL型</h4><p>当根结点左子树的左子树中的节点导致根结点的平衡因子为2时，采用LL型旋转进行调整。</p><p>因为我们插入的时候就已经知道$B_R$是大于B小于A的，所以我们可以把$B_R$当作A的一个左孩子</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (data &lt; root-&gt;data) &#123;    <span class="comment">//如果要插入的数据小于树的data域，插入为树的左孩子            </span></span><br><span class="line">root-&gt;leftChlid = <span class="built_in">insertPoint</span>(data, root-&gt;leftChlid); </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getHeight</span>(root-&gt;leftChlid) - <span class="built_in">getHeight</span>(root-&gt;rightChild) == <span class="number">2</span>) &#123;<span class="comment">//如果左子树的深                                                                          度比右子树的深度高1</span></span><br><span class="line"><span class="keyword">if</span> (data &lt; root-&gt;leftChlid-&gt;data)  <span class="comment">//插入数据小于左孩子就是左左</span></span><br><span class="line">root = <span class="built_in">left_Left_Rotation</span>(root);</span><br><span class="line"><span class="keyword">else</span>                               <span class="comment">//反之则为右右</span></span><br><span class="line">root = <span class="built_in">left_Right_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="左左的操作">左左的操作</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AVLTREE* <span class="title">left_Left_Rotation</span><span class="params">(AVLTREE* root)</span> </span>&#123;</span><br><span class="line">AVLTREE* newRoot = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">newRoot = root-&gt;leftChlid;</span><br><span class="line">root-&gt;leftChlid = newRoot-&gt;rightChild;</span><br><span class="line">newRoot-&gt;rightChild = root;</span><br><span class="line"></span><br><span class="line">root-&gt;height = <span class="built_in">max</span>(<span class="built_in">getHeight</span>(root-&gt;leftChlid), <span class="built_in">getHeight</span>(root-&gt;rightChild)) + <span class="number">1</span>;</span><br><span class="line">newRoot-&gt;height = <span class="built_in">max</span>(<span class="built_in">getHeight</span>(newRoot-&gt;leftChlid), root-&gt;height) + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> newRoot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RR型">RR型</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AVLTREE* <span class="title">right_Right_Rotation</span><span class="params">(AVLTREE* root)</span> </span>&#123;</span><br><span class="line">AVLTREE* newRoot = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">newRoot = root-&gt;rightChild;</span><br><span class="line">root-&gt;rightChild = newRoot-&gt;leftChlid;</span><br><span class="line">newRoot-&gt;leftChlid = root;</span><br><span class="line"></span><br><span class="line">root-&gt;height = <span class="built_in">max</span>(<span class="built_in">getHeight</span>(root-&gt;leftChlid), <span class="built_in">getHeight</span>(root-&gt;rightChild)) + <span class="number">1</span>;</span><br><span class="line">newRoot-&gt;height = <span class="built_in">max</span>(<span class="built_in">getHeight</span>(newRoot-&gt;rightChild), root-&gt;height) + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> newRoot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h4 id="LR型">LR型</h4><p>LR型是一种特殊情况，前面两次LL和RR都是单旋转，而LR型和RL型是双旋转</p><p>对其应该先进行一次右右，再进行一次左左</p><img src="/posts/e85d694a.htm/image-20221110171353649.png" alt="image-20221110171353649" style="zoom:50%;"><img src="/posts/e85d694a.htm/image-20221110171414775.png" alt="image-20221110171414775" style="zoom:50%;"><img src="/posts/e85d694a.htm/image-20221110171439473.png" alt="image-20221110171439473" style="zoom:50%;"><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AVLTREE* <span class="title">left_Right_Rotation</span><span class="params">(AVLTREE* root)</span> </span>&#123;</span><br><span class="line">root-&gt;leftChlid = <span class="built_in">right_Right_Rotation</span>(root-&gt;leftChlid);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">left_Left_Rotation</span>(root);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="RL形">RL形</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AVLTREE* <span class="title">right_Left_Rotation</span><span class="params">(AVLTREE* root)</span> </span>&#123;</span><br><span class="line">root-&gt;rightChild = <span class="built_in">left_Left_Rotation</span>(root-&gt;rightChild);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">right_Right_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><img src="/posts/e85d694a.htm/image-20221110171722135.png" alt="image-20221110171722135" style="zoom:50%;"><img src="/posts/e85d694a.htm/image-20221110171739008.png" alt="image-20221110171739008" style="zoom:50%;"><img src="/posts/e85d694a.htm/image-20221110171801176.png" alt="image-20221110171801176" style="zoom:50%;"><h3 id="AVL树的插入">AVL树的插入</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">AVLTREE* <span class="title">insertPoint</span><span class="params">(<span class="type">int</span> data, AVLTREE* root)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(root == <span class="literal">NULL</span>) &#123;</span><br><span class="line">root = (AVLTREE *)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(AVLTREE));</span><br><span class="line">root-&gt;data = data;</span><br><span class="line">root-&gt;height = <span class="number">0</span>;</span><br><span class="line">root-&gt;leftChlid = root-&gt;rightChild = <span class="literal">NULL</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span>(data &lt; root-&gt;data) &#123; <span class="comment">//如果插入数据小于树的数据，则插入到书的左子树        </span></span><br><span class="line">root-&gt;leftChlid = <span class="built_in">insertPoint</span>(data, root-&gt;leftChlid);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">getHeight</span>(root-&gt;leftChlid) - <span class="built_in">getHeight</span>(root-&gt;rightChild) == <span class="number">2</span>) &#123;<span class="comment">//判断是LX</span></span><br><span class="line"><span class="keyword">if</span>(data &lt; root-&gt;leftChlid-&gt;data)</span><br><span class="line">root = <span class="built_in">left_Left_Rotation</span>(root);<span class="comment">//判断为LL</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">root = <span class="built_in">left_Right_Rotation</span>(root);<span class="comment">//判断为LR</span></span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span>(data &gt; root-&gt;data) &#123;<span class="comment">//如果插入数据大于于树的数据，则插入到书的左子树  </span></span><br><span class="line">root-&gt;rightChild = <span class="built_in">insertPoint</span>(data, root-&gt;rightChild);</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">getHeight</span>(root-&gt;rightChild) - <span class="built_in">getHeight</span>(root-&gt;leftChlid) == <span class="number">2</span>) &#123;<span class="comment">//判断为RX型</span></span><br><span class="line"><span class="keyword">if</span>(data &gt; root-&gt;rightChild-&gt;data)  <span class="comment">//判断为RR型</span></span><br><span class="line">root = <span class="built_in">right_Right_Rotation</span>(root);</span><br><span class="line"><span class="keyword">else</span>                               <span class="comment">//判断为RL型</span></span><br><span class="line">root = <span class="built_in">right_Left_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span>(data == root-&gt;data) &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">NULL</span>;               </span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">root-&gt;height = <span class="built_in">max</span>(<span class="built_in">getHeight</span>(root-&gt;leftChlid), <span class="built_in">getHeight</span>(root-&gt;rightChild)) + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">return</span> root;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="平衡二叉树的删除">平衡二叉树的删除</h3><p>删除操作和二叉查找树删除一样，分为三种情况讨论</p><p>（1）删除节点没有左右子树，这种情况直接删除此节点即可</p><p>（2）删除节点没有左子树，这种情况直接将删除节点的父节点指向删除节点的右子树。</p><p>（3）删除节点没有右子树，这种情况直接将删除节点的父节点指向删除节点的左子树。</p><p>（4）删除节点左右子树都存在，可以采用两种方式，</p><p>​     1：让删除节点左子树的最右侧节点代替当前节点</p><p>​     2：让删除节点右子树的最左侧节点代替当前节点</p><p>  </p><h3 id="只有左右子树，或者无子树">只有左右子树，或者无子树</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">AVLTREE* temp = root;</span><br><span class="line"></span><br><span class="line">root = root-&gt;leftChlid ? root-&gt;leftChlid : root-&gt;rightChild;</span><br><span class="line"><span class="built_in">destroy</span>(temp);</span><br></pre></td></tr></table></figure><p>创建一个临时节点存放树，如果左孩子不为空，此节点root等于root的左子树，如果左子树节点为空，此节点root就等于root的右孩子。就相当于删除了root</p><p>如果是没有子节点的情况下，三目运算判断root为root的右子树，但是右子树为null就相当于把其删去</p><p> </p><h3 id="有左右子树">有左右子树</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (root-&gt;leftChlid &amp;&amp; root-&gt;rightChild) &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getHeight</span>(root-&gt;leftChlid) &gt; <span class="built_in">getHeight</span>(root-&gt;rightChild)) &#123;</span><br><span class="line"></span><br><span class="line">AVLTREE* max = <span class="built_in">getMaxNum</span>(root-&gt;leftChlid);</span><br><span class="line">root-&gt;data = max-&gt;data;</span><br><span class="line">root-&gt;leftChlid = <span class="built_in">deletePoint</span>(max-&gt;data, root-&gt;leftChlid);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line"></span><br><span class="line">AVLTREE* min = <span class="built_in">getMinNum</span>(root-&gt;rightChild);</span><br><span class="line">root-&gt;data = min-&gt;data;</span><br><span class="line">root-&gt;rightChild = <span class="built_in">deletePoint</span>(min-&gt;data, root-&gt;rightChild);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><p>重要的是，在每一次删除节点以后，都要对新的树进行判断是否平衡，也就是平衡因子是小于等于1。</p><h3 id="待删除的点在左子树">待删除的点在左子树</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">abs</span>(<span class="built_in">getHeight</span>(root-&gt;rightChild) - <span class="built_in">getHeight</span>(root-&gt;leftChlid)) == <span class="number">2</span>) &#123;</span><br><span class="line">AVLTREE* p = root-&gt;rightChild;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getHeight</span>(p-&gt;leftChlid) &gt; <span class="built_in">getHeight</span>(p-&gt;rightChild)) &#123;</span><br><span class="line">root = <span class="built_in">right_Left_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">root = <span class="built_in">right_Right_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="待删除的点在右子树">待删除的点在右子树</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">abs</span>(<span class="built_in">getHeight</span>(root-&gt;leftChlid) - <span class="built_in">getHeight</span>(root-&gt;rightChild)) == <span class="number">2</span>) &#123;</span><br><span class="line">AVLTREE* p = root-&gt;leftChlid;</span><br><span class="line"><span class="keyword">if</span> (<span class="built_in">getHeight</span>(p-&gt;rightChild) &gt; <span class="built_in">getHeight</span>(p-&gt;leftChlid)) &#123;</span><br><span class="line">root = <span class="built_in">left_Right_Rotation</span>(root);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">root = <span class="built_in">left_Left_Rotation</span>(root);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>舵机</title>
      <link href="/posts/bbc04e21.html"/>
      <url>/posts/bbc04e21.html</url>
      
        <content type="html"><![CDATA[<h2 id="直流伺服电机">直流伺服电机</h2><p>伺服（servo）</p><table><thead><tr><th>颜色</th><th>功能</th></tr></thead><tbody><tr><td>棕色</td><td>GND</td></tr><tr><td>红色</td><td>VCC</td></tr><tr><td>橙色</td><td>信号（PWM）</td></tr></tbody></table><p>由<strong>控制电路</strong>，<strong>电机</strong>和<strong>电位器</strong>（接受反馈）形成闭环系统</p><h3 id="实现代码">实现代码</h3><p>创建对象</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Servo.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">Servo myServo;         <span class="comment">//创建Servo对象myServo</span></span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> dataIndex = <span class="number">0</span>;     <span class="comment">//创建整数型变量，存储输入数据序列号</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  myServo.attach(<span class="number">6</span>);</span><br><span class="line">  Serial.begin(<span class="number">9600</span>); <span class="comment">//启动串口通讯，传输波特率9600</span></span><br><span class="line">  Serial.println(<span class="string">&quot;Please input serial data.&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;          <span class="comment">// 检查串口缓存是否有数据等待传输 </span></span><br><span class="line">  <span class="keyword">if</span> ( Serial.available()&gt;<span class="number">0</span> ) &#123;  </span><br><span class="line">    dataIndex++;       <span class="comment">// 处理数据序列号并通过串口监视器显示</span></span><br><span class="line">    Serial.print(<span class="string">&quot;dataIndex = &quot;</span>);</span><br><span class="line">    Serial.print(dataIndex);</span><br><span class="line">    Serial.print(<span class="string">&quot; , &quot;</span>);      </span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> pos = Serial.parseInt();   <span class="comment">// 解析串口数据中的整数信息并赋值给变量pos</span></span><br><span class="line">    Serial.print(<span class="string">&quot;Set servo position: &quot;</span>);</span><br><span class="line">    Serial.println(pos);           <span class="comment">// 通过串口监视器显示变量pos数值</span></span><br><span class="line">    myServo.write(pos);             <span class="comment">// 使用pos变量数值设置伺服电机</span></span><br><span class="line">    delay(<span class="number">15</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br></pre></td></tr></table></figure><p> </p><h2 id="控制多个舵机">控制多个舵机</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Serial-Servo-2</span></span><br><span class="line"><span class="comment"> 使用</span></span><br><span class="line"><span class="comment">本示例程序旨在演示如何通过串口监视器控制4个伺服电机（舵机）。</span></span><br><span class="line"><span class="comment"> </span></span><br><span class="line"><span class="comment">This example code is in the public domain.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Servo.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line">Servo base, fArm, rArm, claw;  <span class="comment">//建立4个电机对象</span></span><br><span class="line"> </span><br><span class="line"><span class="type">int</span> dataIndex = <span class="number">0</span>;</span><br><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  base.attach(<span class="number">11</span>);     <span class="comment">// base 伺服电机连接引脚11 电机代号&#x27;b&#x27;</span></span><br><span class="line">  rArm.attach(<span class="number">10</span>);     <span class="comment">// rArm 伺服电机连接引脚10 电机代号&#x27;r&#x27;</span></span><br><span class="line">  fArm.attach(<span class="number">9</span>);      <span class="comment">// fArm 伺服电机连接引脚9  电机代号&#x27;f&#x27;</span></span><br><span class="line">  claw.attach(<span class="number">6</span>);      <span class="comment">// claw 伺服电机连接引脚6  电机代号&#x27;c&#x27;</span></span><br><span class="line">  Serial.begin(<span class="number">9600</span>);</span><br><span class="line">  Serial.println(<span class="string">&quot;Please input serial data.&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">if</span> (Serial.available()) &#123;  <span class="comment">// 检查串口缓存是否有数据等待传输 </span></span><br><span class="line">    <span class="type">char</span> servoName = Serial.read();   <span class="comment">//获取电机指令中电机编号信息</span></span><br><span class="line"> </span><br><span class="line">    Serial.print(<span class="string">&quot;servoName = &quot;</span>);</span><br><span class="line">    Serial.print(servoName);    </span><br><span class="line">    Serial.print(<span class="string">&quot; , &quot;</span>);      </span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> data = Serial.parseInt();   <span class="comment">//获取电机指令中电机角度信息</span></span><br><span class="line"> </span><br><span class="line">    <span class="keyword">switch</span>(servoName)&#123; <span class="comment">//根据电机指令中电机信息决定对哪一个电机进行角度设置</span></span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;b&#x27;</span>:   <span class="comment">// 电机指令b，设置base电机角度</span></span><br><span class="line">        base.write(data);</span><br><span class="line">        Serial.print(<span class="string">&quot;Set base servo value: &quot;</span>);</span><br><span class="line">        Serial.println(data);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;r&#x27;</span>:  <span class="comment">// 电机指令r，设置rArm电机角度  </span></span><br><span class="line">        rArm.write(data);</span><br><span class="line">        Serial.print(<span class="string">&quot;Set rArm servo value: &quot;</span>);</span><br><span class="line">        Serial.println(data);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;f&#x27;</span>:   <span class="comment">// 电机指令f，设置fArm电机角度  </span></span><br><span class="line">        fArm.write(data);</span><br><span class="line">        Serial.print(<span class="string">&quot;Set fArm servo value: &quot;</span>);</span><br><span class="line">        Serial.println(data);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> <span class="string">&#x27;c&#x27;</span>:   <span class="comment">// 电机指令c，设置claw电机角度  </span></span><br><span class="line">        claw.write(data);  </span><br><span class="line">        Serial.print(<span class="string">&quot;Set claw servo value: &quot;</span>);</span><br><span class="line">        Serial.println(data);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一阶非线性微分方程</title>
      <link href="/posts/a913fd01.html"/>
      <url>/posts/a913fd01.html</url>
      
        <content type="html"><![CDATA[<h1>一阶非线性微分方程</h1><h2 id="可分方程-Separable-Equation">可分方程(Separable Equation)</h2><p>可分方程一般都有如下形式<br>$$<br>x’(t)=h(t)g(x)<br>$$<br>且有h(t)是连续的，g(x)是连续可微的</p><p> </p><h3 id="解可分方程思路">解可分方程思路</h3><p>解可分方程思路一般为两大块-------求常数解和求非常数解</p><p>且要注意的是，常数解和非常数解代表的曲线不相交</p><p>一般会先求出常数解，从而求出非常数解的区间，如果有初值，或者给出图上一个点，就可以确定此非常数解的曲线在哪个区间</p><p> </p><h4 id="求常数解">求常数解</h4><p>我们已知x是关于t的函数，当k是微分方程的一个常熟解时，有$x(t)=k$</p><p>$x’(t)=0$,此时当且仅当$g(k)=0$时，微分方程成立</p><p> </p><p>那么当$g(x) \ne 0$时，此时方程有非常数解。</p><h4 id="求非常数解">求非常数解</h4><p>$$<br>\frac{x^{\prime}(t)}{g(x(t))}=h(t)<br>$$</p><p>$$<br>\int \frac{x^{\prime}(t)}{g(x(t))} dt=\int h(t) dt<br>$$</p><p>$$<br>\int \frac{d x}{g(x)}=\int h(t)+c<br>$$</p><p>当解中带有绝对值时，我们可以通过求常数解来确定x的范围，从而去绝对值，求出在此区间上的解。</p><p> </p><h2 id="恰当方程（Exact-Equation）">恰当方程（Exact Equation）</h2><p>假设有一个微分方程$F(x,y)$,有方程对x的偏导$F_x(x,y)$和关于y的偏导$F_y(x,y)$</p><p>关于x的偏导写作$M(x,y)$,y的偏导为$N(x,y)$。</p><p>$F_x(x,y)=M(x,y),F_y(x,y)=N(x,y)$</p><p>此时<br>$$<br>M(x,y)dx+N(x,y)dy=0<br>$$<br>方程有$M_y=N_x$恒成立。</p><h3 id="解法一（M，N分别求原函数）">解法一（M，N分别求原函数）</h3><p>我们知道，$M(x,y)$关于x的原函数和$N(x,y)$关于y的原函数都是$F(x,y)$</p><p>根据做题经验，我们可以分别求出M，N的原函数。</p><p>M的原函数加常数解项$c_1$($c_1$中可以包含y)</p><p>N的原函数加常数解项$c_2$($c_2$中可以包含x)</p><p>令两式相等，我们可以得出$c_1,c_2$的值，从而求出恰当方程$F(x,y)$。</p><p> </p><h3 id="解法二（M或N求原函数）">解法二（M或N求原函数）</h3><p>$$<br>F(x,y)=\int M(x,y)dx+h(y)<br>$$</p><p>$$<br>F_{x}(x,y)=M(x,y)<br>$$</p><p>$$<br>F_{y}(x, y)=\frac{\partial}{\partial y}\left(\int M(x, y) d x\right)+h^{\prime}(y)<br>$$</p><p>$$<br>h^{\prime}(y)=N(x,y)-\frac{\partial}{\partial y}\left(\int M(x,y) dx\right)<br>$$</p><p>如此，我们可以求出h(y)的值，从而求出$F(x,y)$</p><p> </p><h3 id="解法三（作图）">解法三（作图）</h3><p>$$<br>F(x,y)=\int_{x_{0}}^{x} M(s,y) ds+\int_{y_{0}}^{y} N\left(x_{0},s\right)ds<br>$$</p><p>其中有两种解法，一种是先对x积分，后对y积分。</p><p>积分路径为$(x_0,y_0)-&gt;(x,y_0)-&gt;(x,y)$</p><p>另一种是先对y积分，后对x积分。</p><p>积分路径为$(x_0,y_0)-&gt;(x_0,y)-&gt;(x,y)$</p><p> </p><p>其中积分路径的起点我们可以根据方程的特点，选取最容易计算的对应点</p><p>例如存在$lnx$时我们不妨设x为1，但一般情况下我们都设积分路径的起点为(0,0)</p><p> </p><h2 id="积分因子">积分因子</h2><p>简单说，有形式为$M(x, y) d x+N(x, y) d y=0$的方程。但是此方程不是恰当方程（$M_y \ne N_x$）</p><p>此时我们令方程的每一项都同时乘一个式子$\mu$，$\mu(x, y) M(x, y) d x+\mu(x, y) N(x, y) d y=0$从而使整个方程为恰当的，我们称作这个式子$\mu$为积分因子。</p><p>例如有方程$ydx-xdy=0$可知此方程不恰当,如果我们在方程的每一项同时乘以$\frac{1}{y<sup>2}$,此时方程为$\frac{1}{y}dx-\frac{x}{y</sup>2}dy=0$,此时方程为恰当方程。从而可以根据求解恰当方程的解法去求解。</p><p> </p><h3 id="寻找积分因子">寻找积分因子</h3><p>我们发现如果直接让我们找一个完整的积分因子$\mu(x,y)$是困难的，不妨先去寻找可以使方程恰当的$\mu(x)$或者$\mu(y)$<br>$$<br>\mu(x) M(x, y) d x+\mu(x) N(x, y) d y=0<br>$$</p><p>$$<br>\mu(y) M(x, y) d x+\mu(y) N(x, y) d y=0<br>$$</p><p>因为方程是恰当的，满足$M_y=N_x$即$\frac{\partial}{\partial y}(\mu(x) M(x, y))=\frac{\partial}{\partial x}(\mu(x) N(x, y))$</p><p>可得$ M_{y}(x, y)=\mu^{\prime}(x) N(x, y)+\mu(x) N_{x}(x, y) $化简可得$\frac{\mu^{\prime}(x)}{\mu(x)}=\frac{M_{y}(x, y)-N_{x}(x, y)}{N(x, y)} $</p><p>我们令$\frac{\mu’(x)}{\mu(x)}=\Psi$即$\Psi=\frac{M_{y}(x, y)-N_{x}(x, y)}{N(x, y)}$那么求解我们得到的ODE：$\mu(x)=c e^{\int \Psi(x) d x}$</p><p> </p><p>同理，如果设积分因子为$\mu(y)$得到的结果为$\Psi=\frac{N_{x}(x, y)-M_{y}(x, y)}{N(x, y)}$,$\mu(y)=c e^{\int \Psi(y) d y}$</p><p> </p><p>当然，如果想求出$\mu(x,y)$，满足$M_y=N_x$可得$ \mu^{\prime}(x,y) M(x, y)+\mu(x,y) M_{y}(x, y)=\mu^{\prime}(x) N(x, y)+\mu(x) N_{x}(x, y) $化简可得$\Psi=\frac{N_{x}(x, y)-M_{y}(x, y)}{M(x, y)-N(x, y)}$,但明显，求单变量的积分因$\mu(x),\mu_(y)$子比求双变量的积分因子$\mu(x,y)$简单得多。</p><p>因此在找积分因子时，我们通常根据方程去寻找单变量积分因子$\mu(x),\mu_(y)$</p><h2 id="齐次方程">齐次方程</h2><p>有齐次方程$x’=f(t,x)$,$f(t,x)$表示为关于$\frac{x}{t}$的方程。</p><p>例如$x<sup>{\prime}=\frac{x</sup>{3}+t^{3}}{t x^{2}}, \quad t \neq 0$是齐次的，$x<sup>{\prime}=x</sup>{2} \sin t$是非齐次的。</p><p> </p><p>因此，齐次方程的形式为<br>$$<br>x<sup>{\prime}=x</sup>{2} \sin t<br>$$<br>它可以通过改变未知量$x=tz$,使其而转化为一个可分方程<br>$$<br>x’=(tz)‘=z+tz’=g(z)<br>$$</p><p>$$<br>tz’=g(z)-z<br>$$</p><p>$$<br>\frac{z’}{g(z)-z}=\frac{1}{t}(可分方程)<br>$$</p><p>z是关于t的函数，如此用可分方程的方法求解即可。</p><p> </p><h2 id="伯努利方程">伯努利方程</h2><p>伯努利方程有如下形式$x^{\prime}+p(x) x=q(t) x<sup>{k+1}$因为$p(t),q(t)$都是连续的，所以我们只考虑$x</sup>{k+1}$使方程有意义的解。</p><p>对于<br>$$<br>x^{\prime}+p(t) x=q(t) x^{k+1}<br>$$<br>令$z=x^{-k}$使转化为线性方程。</p><p>注意：当$k=0,-1或q(t)=0$时，伯努利方程是线性方程</p><p>分别为$x’+p(t)x=q(t)x$,$x’+p(t)x=q(t)$,$x’+p(t)x=0$</p><p> <br>$$<br>z’=-kx’x^{-(k+1)}<br>=-kx<sup>{-(k+1)}(-p(t)x+q(t)x</sup>{k+1}<br>=kp(t)x^{-k}-kq(t)<br>=kp(t)z-kq(t)<br>$$<br>带入方程中仍然可以将其当作一个可分方程去求解。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 常微分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>堆栈</title>
      <link href="/posts/af55460a.html"/>
      <url>/posts/af55460a.html</url>
      
        <content type="html"><![CDATA[<h1>堆栈</h1><h2 id="栈的概念">栈的概念</h2><p>栈（Stack）是操作受限的<strong>线性表</strong>，<strong>插入</strong>和<strong>删除</strong>数据元素的操作只能在线性表的一端进行。</p><p> </p><p>当然，你也可以简单理解栈为一个很多层的篮子，一层篮子只能存放一个数据，我们对这个篮子能处理的就只有最上面的那个数据。</p><p>往篮子里放入数据的过程就叫做<strong>插入</strong>（入栈，进栈，压栈）</p><p>把篮子最上面的那一层数据拿出的过程就叫做<strong>删除</strong>（出栈，弹栈）</p><p> </p><h2 id="栈的主要操作">栈的主要操作</h2><h3 id="入栈（Push）">入栈（Push）</h3><h3 id="出栈（Pop）">出栈（Pop）</h3><img src="https://i.imgtg.com/2022/11/03/Rg6ag.png" alt="Rg6ag.png" border="0"><h5 id="操作特性：后进先出">操作特性：后进先出</h5><h2 id="栈的顺序储存结构">栈的顺序储存结构</h2><h3 id="顺序栈—栈的顺序储存结构">顺序栈—栈的顺序储存结构</h3><img src="https://i.imgtg.com/2022/11/03/Rgjdl.png" alt="Rgjdl.png" border="0"><p>指针top指示栈顶元素在数组中的位置</p><p> </p><p>进栈：top+1</p><p>栈空：top = -1</p><p>栈出：top-1</p><p>栈满：top = MAX_SIZE</p><p> </p><h3 id="栈的上溢与下溢">栈的上溢与下溢</h3><p>在顺序栈中有&quot;上溢&quot;和&quot;下溢&quot;的概念。</p><p>顺序栈好比一个盒子，我们在里面放了一叠书，当我们要用书的话只能从最上面一本开始拿，那么当我们把书本放到这个栈中超过盒子的顶部时就放不下了，这时就是“上溢”，“上溢”也就是栈顶指针指出栈的外面，显然时出错了。</p><p>反之，当栈中已经没有书时，我们再去拿，发现已经没有书了，这就是“下溢”。“下溢”本身可以表示栈为栈空，因此可以用它来作为控制转移的条件。</p><p> </p><img src="https://i.imgtg.com/2022/11/03/Rg9yb.png" alt="Rg9yb.png" border="0"><p>如图</p><p>1.$a_N,…,a_2,a_1$用来储存数据。</p><p>2.定义一个top变量储存栈顶指针的位置。</p><p>3.定义一个MAX_SIZE表示栈的最大容量。</p><p> </p><h3 id="上溢的判断">上溢的判断</h3><p>当栈为空时，top的值为-1.当往栈中压入一个元素时，top的值就会加1.</p><p>这样，a[0]就代表第一个进栈的元素，a[i-1]代表第i个进栈的元素，a[top]则表示栈顶的元素。</p><p>当top=MAX_SIZE-1时，表示栈满。如果再有元素进栈时，则栈会溢出，这时称为&quot;上栈&quot;。</p><h3 id="下栈的判断">下栈的判断</h3><p>反之，当top=-1时，再将栈顶元素弹出，就要发生&quot;下溢&quot;</p><p> </p><h3 id="栈类的定义">栈类的定义</h3><p>栈类的定义（以储存字符型数据为例）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> MAX_SIZE = <span class="number">100</span>; <span class="comment">//定义栈最大常数值</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Stack</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">    <span class="type">char</span>* data;     <span class="comment">//线性表</span></span><br><span class="line">    <span class="type">int</span> size;       <span class="comment">//堆栈的实际大小</span></span><br><span class="line">    <span class="type">int</span> top;        <span class="comment">//栈顶</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">Stack</span>();               <span class="comment">//构造函数</span></span><br><span class="line">    <span class="built_in">Stack</span>(<span class="type">int</span> s);          <span class="comment">//有参构造函数</span></span><br><span class="line">    ~<span class="built_in">Stack</span>();   <span class="comment">//析构函数</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(<span class="type">char</span> ch)</span></span>;   <span class="comment">//成员函数：入栈</span></span><br><span class="line">    <span class="function"><span class="type">char</span> <span class="title">pop</span><span class="params">()</span></span>;            <span class="comment">//成员函数：出栈并返回栈顶元素</span></span><br><span class="line">    <span class="function"><span class="type">char</span> <span class="title">getTop</span><span class="params">()</span></span>;           <span class="comment">//成员函数：获得栈顶元素</span></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">isEmpty</span><span class="params">()</span></span>;        <span class="comment">//成员函数：栈是否为空</span></span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">isFull</span><span class="params">()</span></span>;         <span class="comment">//成员函数：栈是否满</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">setNull</span><span class="params">()</span></span>;        <span class="comment">//设置栈为空</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="构造函数">构造函数</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">Stack</span>()&#123;</span><br><span class="line">size = MAX_SIZE;</span><br><span class="line">top = <span class="number">-1</span>;</span><br><span class="line">data = <span class="keyword">new</span> <span class="type">char</span>[MAX_SIZE];<span class="comment">//缺省构造函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">Srack</span>(<span class="type">int</span> s)&#123;</span><br><span class="line">size = s;</span><br><span class="line">top = <span class="number">-1</span>;</span><br><span class="line">data = <span class="keyword">new</span> <span class="type">char</span>[size]; <span class="comment">//根据指定的大小分配栈的内存空间</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="析构函数">析构函数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Stack::~Stack()&#123;</span><br><span class="line">delete[]data;     //内存回收</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="入栈">入栈</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">push</span>(<span class="type">char</span> ch)&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="built_in">isFull</span>())     <span class="comment">//解决数据上溢问题</span></span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;栈已满，无法入栈&quot;</span>&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        top++;</span><br><span class="line">        data[top] = ch;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;已将元素&quot;</span>&lt;&lt;ch&lt;&lt;<span class="string">&quot;压入栈中&quot;</span>&lt;&lt;endl;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;此时top=&quot;</span>&lt;&lt;top&lt;&lt;endl;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="出栈并返回栈顶元素">出栈并返回栈顶元素</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">pop</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(!<span class="built_in">isEmpty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;出栈中&quot;</span>&lt;&lt;endl;</span><br><span class="line">        top--;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;此时top=&quot;</span>&lt;&lt;top&lt;&lt;endl;</span><br><span class="line">    <span class="keyword">return</span> data[top+<span class="number">1</span>];<span class="comment">//返回被删除元素</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="comment">//解决数据下溢过程</span></span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;栈已为空，无法继续出栈&quot;</span>&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="获得栈顶元素">获得栈顶元素</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">getTop</span>()</span><br><span class="line">&#123;</span><br><span class="line"> <span class="keyword">if</span>(!<span class="built_in">isEmpty</span>())</span><br><span class="line">    &#123;</span><br><span class="line">    cout&lt;&lt;<span class="string">&quot;获得栈顶元素中...&quot;</span>&lt;&lt;endl;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;此时top=&quot;</span>&lt;&lt;top&lt;&lt;endl;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;栈顶元素为&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span> data[top];</span><br><span class="line">    &#125;   </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;栈已为空，无法获得栈顶元素&quot;</span>&lt;&lt;endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="栈是否为空">栈是否为空</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">isEmpty</span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(top = <span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">//栈为空</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">//栈不为空</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="栈是否满">栈是否满</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Stack::isFull</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(top &gt;= size - <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;<span class="comment">//栈已满</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>； <span class="comment">//栈未满</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="设置栈为空">设置栈为空</h3><h4 id="memset函数">memset函数</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> *<span class="title">memset</span><span class="params">(<span class="type">void</span> *s, <span class="type">int</span> ch, <span class="type">size_t</span> n)</span></span>;</span><br></pre></td></tr></table></figure><p>s中当前位置开始向后的n个字节中，把n个字节的<strong>每个字节</strong>都替换成ch。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">char</span> str[] = <span class="string">&quot;This is a new world&quot;</span>;</span><br><span class="line"><span class="built_in">memset</span> (str,<span class="string">&#x27;#&#x27;</span>,<span class="number">6</span>);</span><br><span class="line">cout&lt;&lt;str&lt;&lt;endl;</span><br></pre></td></tr></table></figure><p>输出为</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#####<span class="meta">#s a new world</span></span><br></pre></td></tr></table></figure><p> </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Stack::<span class="built_in">setNull</span>(<span class="type">int</span> len)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">memset</span>(data,<span class="number">0</span>,len *<span class="built_in">sizeof</span>(<span class="type">char</span>));</span><br><span class="line">    <span class="comment">//将char中元素全班替换为0</span></span><br><span class="line"><span class="keyword">this</span>-&gt;top = <span class="number">-1</span>;</span><br><span class="line">cout&lt;&lt;<span class="string">&quot;此时top=&quot;</span>&lt;&lt;top&lt;&lt;endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="用异常捕获优化顺序栈">用异常捕获优化顺序栈</h2><p>函数中最好不要有cout的输出语句，为保证类能多次重用。</p><p>输入输出的语句在display或者main函数中即可。</p><h3 id="用try…catch语句">用try…catch语句</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    语句<span class="number">1</span>;</span><br><span class="line">    语句<span class="number">2</span>;</span><br><span class="line">    语句<span class="number">3</span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">catch</span>(异常类型)&#123;</span><br><span class="line">    异常处理代码</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">    <span class="built_in">catch</span>(异常处理)&#123;</span><br><span class="line">        异常处理代码</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="自定义异常类的使用">自定义异常类的使用</h3><h4 id="定义一场内部类（在类的声明部分定义）">定义一场内部类（在类的声明部分定义）</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Empty</span>&#123;&#125;;</span><br></pre></td></tr></table></figure><h4 id="丢出异常类（在pop函数遇到空栈时的语句）">丢出异常类（在pop函数遇到空栈时的语句）</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">throw</span> <span class="built_in">Empty</span>();</span><br></pre></td></tr></table></figure><h4 id="捕获异常类（在调用pop函数时，用try-catch捕获）">捕获异常类（在调用pop函数时，用try/catch捕获）</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">       stack.<span class="built_in">pop</span>();</span><br><span class="line">   &#125;</span><br><span class="line"><span class="built_in">catch</span>(Stack::Empty)&#123;</span><br><span class="line">       cout&lt;&lt;<span class="string">&quot;Stack Empty!!&quot;</span>&lt;&lt;endl;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="用类模板实现顺序栈">用类模板实现顺序栈</h2><h3 id="通用的栈类">通用的栈类</h3><p>DataType就是我们要使用的数据类型</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Stack</span>&#123;</span><br><span class="line"><span class="keyword">public</span> :</span><br><span class="line">    <span class="built_in">Stack</span>();                    <span class="comment">//初始化栈</span></span><br><span class="line">    ~<span class="built_in">Stack</span>();                   <span class="comment">//销毁栈</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">empty</span><span class="params">()</span></span>;                <span class="comment">//判断栈是否为空</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">pop</span><span class="params">(DataType &amp; x)</span></span>;   <span class="comment">//出栈</span></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">push</span><span class="params">(DataType x)</span></span>;    <span class="comment">//压栈</span></span><br><span class="line">    <span class="function">DataType <span class="title">top</span><span class="params">()</span></span>;          <span class="comment">//取栈顶元素</span></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">print</span><span class="params">()</span></span>;               <span class="comment">//遍历栈</span></span><br><span class="line"><span class="keyword">private</span> :</span><br><span class="line">    DataType * data;         <span class="comment">//栈数据储存</span></span><br><span class="line">    <span class="type">int</span> len;                    <span class="comment">//栈当前元素个数</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="成员函数定义">成员函数定义</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">Stack&lt;DataType&gt;::<span class="built_in">Stack</span>()&#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="type">void</span> Stack&lt;DataType&gt;::<span class="built_in">push</span>(DataType e)&#123;</span><br><span class="line">......</span><br><span class="line">&#125;</span><br><span class="line">......</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>有类Stack的地方，后面都要改成Stack<Datatype></Datatype></p><p> </p><p>为了使用类模板对象，必须显示指定模板参数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stack&lt;<span class="type">char</span>&gt; charStack;</span><br><span class="line">Stack&lt;<span class="type">int</span>&gt; intStack;</span><br></pre></td></tr></table></figure><h4 id="存在问题">存在问题</h4><p><a href="https://blog.csdn.net/m0_53157173/article/details/113728312">(44条消息) c++模板学习10之类模板分文件编写_热爱编程的大忽悠的博客-CSDN博客</a></p><p> </p><h2 id="双端堆栈（两栈共享存储空间）">双端堆栈（两栈共享存储空间）</h2><h3 id="优点：提高空间利用率">优点：提高空间利用率</h3><p>两栈共享空间：使用一个数组来存储两个栈，让一个栈的栈底为该数组的始端，另一个栈的栈底为该数组的末端，两个栈从各自的端点向中间延伸。</p><img src="https://i.imgtg.com/2022/10/30/RUZ9v.png" alt="RUZ9v.png" border="0"><p> </p><h3 id="性质">性质</h3><p>栈1为空</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top1 = <span class="number">-1</span>;</span><br></pre></td></tr></table></figure><p>栈2为空</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">op2 = Stack_Size;</span><br></pre></td></tr></table></figure><p>栈满</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top1+<span class="number">1</span> == top2;</span><br></pre></td></tr></table></figure><h3 id="两栈共享空间类的声明">两栈共享空间类的声明</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> Stack_Size=<span class="number">100</span>;  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BothStack</span> </span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">       <span class="built_in">BothStack</span>( );</span><br><span class="line">       ~<span class="built_in">BothStack</span>( ); </span><br><span class="line">       <span class="function"><span class="type">void</span> <span class="title">Push</span><span class="params">(<span class="type">int</span> num, DataType x)</span></span>;   </span><br><span class="line">    <span class="comment">//num表示要处理1号栈还是2号栈</span></span><br><span class="line">       <span class="function">DataType <span class="title">Pop</span><span class="params">(<span class="type">int</span> num)</span></span>;          </span><br><span class="line">       <span class="function">DataType <span class="title">GetTop</span><span class="params">(<span class="type">int</span> num)</span></span>;       </span><br><span class="line">       <span class="function"><span class="type">bool</span> <span class="title">isEmpty</span><span class="params">(<span class="type">int</span> num)</span></span>;     </span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">       DataType data[Stack_Size];     </span><br><span class="line">       <span class="type">int</span> top1, top2;        </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>当然，也可以用类模板去实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">const</span> <span class="type">int</span> Stack_Size=<span class="number">100</span>;  </span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BothStack</span> </span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">       <span class="built_in">BothStack</span>( );</span><br><span class="line">       ~<span class="built_in">BothStack</span>( ); </span><br><span class="line">       <span class="function"><span class="type">void</span> <span class="title">Push</span><span class="params">(<span class="type">int</span> i, T x)</span></span>;   </span><br><span class="line">       <span class="function">T <span class="title">Pop</span><span class="params">(<span class="type">int</span> i)</span></span>;          </span><br><span class="line">       <span class="function">T <span class="title">GetTop</span><span class="params">(<span class="type">int</span> i)</span></span>;       </span><br><span class="line">       <span class="function"><span class="type">bool</span> <span class="title">Empty</span><span class="params">(<span class="type">int</span> i)</span></span>;     </span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">       T data[Stack_Size];     </span><br><span class="line">       <span class="type">int</span> top1, top2;        </span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p> </p><h4 id="插入">插入</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">1.</span> 如果栈满，则抛出上溢异常；</span><br><span class="line"><span class="bullet">2.</span> 判断是插在栈1还是栈2；</span><br><span class="line"><span class="code">       2.1 若在栈1插入，则</span></span><br><span class="line"><span class="code">             2.1.1 top1加1;</span></span><br><span class="line"><span class="code">             2.1.2 在top1处填入x；</span></span><br><span class="line"><span class="code">       2.2 若在栈2插入，则</span></span><br><span class="line"><span class="code">             2.2.1 top2减1;</span></span><br><span class="line"><span class="code">             2.2.2 在top2处填入x；</span></span><br><span class="line"><span class="code"></span></span><br></pre></td></tr></table></figure><p>代码实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">T</span>&gt; </span><br><span class="line"><span class="type">void</span> BothStack&lt;T&gt;::<span class="built_in">Push</span>(<span class="type">int</span> i, T x )</span><br><span class="line">&#123;</span><br><span class="line">   <span class="keyword">if</span> (top1==top2<span class="number">-1</span>) </span><br><span class="line">   <span class="keyword">throw</span> <span class="string">&quot;上溢&quot;</span>;</span><br><span class="line">   <span class="keyword">if</span> (i==<span class="number">1</span>) </span><br><span class="line">   data[++top1]=x;</span><br><span class="line">   <span class="keyword">if</span> (i==<span class="number">2</span>) </span><br><span class="line">   data[--top2]=x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="删除">删除</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.若是在栈1删除，则</span><br><span class="line"><span class="code">1.1 若栈1为空栈，抛出下溢异常；</span></span><br><span class="line"><span class="code">1.2 删除并返回栈1的栈顶元素；</span></span><br><span class="line"><span class="code">2.若是在栈2删除，则</span></span><br><span class="line"><span class="code">2.1 若栈2为空栈，抛出下溢异常；</span></span><br><span class="line"><span class="code">2.2 删除并返回栈2的栈顶元素；</span></span><br></pre></td></tr></table></figure><p>代码实现</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">DataType BothStack&lt;DataType&gt;::<span class="built_in">Pop</span>(<span class="type">int</span> i)&#123;</span><br><span class="line">   <span class="keyword">if</span> (i == <span class="number">1</span>) &#123;   </span><br><span class="line">       <span class="keyword">if</span> (top1 == <span class="number">-1</span>) </span><br><span class="line">           <span class="keyword">throw</span> <span class="string">&quot;下溢&quot;</span>;</span><br><span class="line">       <span class="keyword">return</span> data[top1--];</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">if</span> (i == <span class="number">2</span>) &#123;                           </span><br><span class="line">       <span class="keyword">if</span> (top2 == StackSize)  </span><br><span class="line">           <span class="keyword">throw</span> <span class="string">&quot;下溢&quot;</span>;</span><br><span class="line">       <span class="keyword">return</span> data[top2++]; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="判断每个栈空">判断每个栈空</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt; </span><br><span class="line"><span class="type">bool</span> BothStack&lt;DataType&gt;::<span class="built_in">Empty</span>(<span class="type">int</span> i)</span><br><span class="line">&#123;  </span><br><span class="line">    <span class="keyword">if</span>(i == <span class="number">1</span>)&#123;     <span class="comment">//对于栈1操作</span></span><br><span class="line">        <span class="keyword">if</span>(top1 == <span class="number">-1</span>) </span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">//栈空就返回1</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i == <span class="number">2</span>)&#123;    <span class="comment">//对于栈2操作</span></span><br><span class="line">        <span class="keyword">if</span>(top2 == StackSize)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;  </span><br><span class="line">        <span class="keyword">else</span>  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="取某个栈顶">取某个栈顶</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt; </span><br><span class="line">DataType BothStack&lt;DataType&gt;::<span class="built_in">GetTop</span>(<span class="type">int</span> i)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (top1!=<span class="number">-1</span>) </span><br><span class="line">            <span class="keyword">return</span> data[top1];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(i==<span class="number">2</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span>(top2!=StackSize)  </span><br><span class="line">            <span class="keyword">return</span> data[top2];</span><br><span class="line">   &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h4 id="压栈">压栈</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="type">void</span> BothStack&lt;DataType&gt;::<span class="built_in">push</span>(<span class="type">int</span> num, DataType x)&#123;</span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">isFull</span>(num))&#123;      <span class="comment">//如果栈已满</span></span><br><span class="line">    <span class="keyword">throw</span> BothStack&lt;DataType&gt;::<span class="built_in">Full</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(num == <span class="number">1</span>)&#123;</span><br><span class="line">      top1++;</span><br><span class="line">      data[top1] = x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(num == <span class="number">2</span>)&#123;</span><br><span class="line">      top2--;</span><br><span class="line">      data[top2] = x;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h4 id="出栈">出栈</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">DataType BothStack&lt;DataType&gt;::<span class="built_in">pop</span>(<span class="type">int</span> num)&#123;</span><br><span class="line">  <span class="keyword">if</span>(num == <span class="number">1</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">isEmpty1</span>(num))&#123;       <span class="comment">//如果栈空</span></span><br><span class="line">      <span class="keyword">throw</span> BothStack&lt;DataType&gt;::<span class="built_in">Empty1</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> data[top1--];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(num == <span class="number">2</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">isEmpty2</span>(num))&#123;</span><br><span class="line">      <span class="keyword">throw</span> BothStack&lt;DataType&gt;::<span class="built_in">Empty2</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> data[top2++];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="取栈顶元素">取栈顶元素</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">DataType BothStack&lt;DataType&gt;::<span class="built_in">getTop</span>(<span class="type">int</span> num)&#123;</span><br><span class="line">  <span class="keyword">if</span>(num == <span class="number">1</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">isEmpty1</span>(num))&#123;</span><br><span class="line">      <span class="keyword">throw</span> BothStack&lt;DataType&gt;::<span class="built_in">Empty1</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> data[top1];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span>(num == <span class="number">2</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">isEmpty2</span>(num))&#123;</span><br><span class="line">      <span class="keyword">throw</span> BothStack&lt;DataType&gt;::<span class="built_in">Empty2</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">      <span class="keyword">return</span> data[top2];</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="栈的链式储存">栈的链式储存</h3><h4 id="通用类">通用类</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinkStack</span>&#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">node</span>&#123;</span><br><span class="line">  DataType data;</span><br><span class="line">  <span class="keyword">struct</span> <span class="title class_">node</span>*next;</span><br><span class="line">  &#125;Node;</span><br><span class="line">   Node *top;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="built_in">LinkStack</span>();</span><br><span class="line">  ~<span class="built_in">LinkStack</span>();</span><br><span class="line">  <span class="function"><span class="type">void</span> <span class="title">push</span><span class="params">(DataType x)</span></span>;</span><br><span class="line">  <span class="function">DataType <span class="title">pop</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function">DataType <span class="title">getTop</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="function"><span class="type">bool</span> <span class="title">isEmpty</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">class</span> <span class="title class_">Empty</span>&#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="成员函数">成员函数</h3><h5 id="初始化链栈">初始化链栈</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">LinkStack&lt;DataType&gt;::<span class="built_in">LinkStack</span>()&#123;</span><br><span class="line">  top == <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="销毁栈">销毁栈</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">LinkStack&lt;DataType&gt;::~<span class="built_in">LinkStack</span>()&#123;</span><br><span class="line">  Node *q = top;</span><br><span class="line">  Node *p = top -&gt; next;</span><br><span class="line">  <span class="keyword">while</span>(top-&gt;next)&#123;</span><br><span class="line">    q = p -&gt;next;</span><br><span class="line">    <span class="built_in">delete</span>(p);</span><br><span class="line">    p = q -&gt;next;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">delete</span>(top);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="压栈-2">压栈</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="type">void</span> LinkStack&lt;DataType&gt;::<span class="built_in">push</span>(DataType x)&#123;</span><br><span class="line">  Node *s ;</span><br><span class="line">  s = <span class="keyword">new</span> Node;</span><br><span class="line">  s-&gt;data = x;</span><br><span class="line">  s-&gt;next = top;</span><br><span class="line">  top = s;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="是否栈空">是否栈空</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="type">bool</span> LinkStack&lt;DataType&gt;::<span class="built_in">isEmpty</span>()&#123;</span><br><span class="line">  <span class="keyword">if</span>(top == <span class="literal">NULL</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="取栈顶元素-2">取栈顶元素</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">DataType LinkStack&lt;DataType&gt;::<span class="built_in">pop</span>()&#123;</span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">isEmpty</span>())</span><br><span class="line">    <span class="keyword">throw</span> LinkStack&lt;DataType&gt;::<span class="built_in">Empty</span>();</span><br><span class="line">  DataType x = top-&gt;data;</span><br><span class="line">  Node*p = top;</span><br><span class="line">  top = top -&gt;next;</span><br><span class="line">  <span class="keyword">delete</span> p;</span><br><span class="line">  <span class="keyword">return</span> x;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="取栈顶元素-3">取栈顶元素</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line">DataType LinkStack&lt;DataType&gt;::<span class="built_in">getTop</span>()&#123;</span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">isEmpty</span>())</span><br><span class="line">    <span class="keyword">throw</span> LinkStack&lt;DataType&gt;::<span class="built_in">Empty</span>();</span><br><span class="line">  DataType x = top-&gt;data;</span><br><span class="line">  <span class="keyword">return</span> x;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h4 id="主函数">主函数</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">class</span> DataType&gt;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">typedef</span> LinkStack &lt;<span class="type">int</span>&gt; intStack;</span><br><span class="line">  <span class="type">int</span> x;</span><br><span class="line">  intStack s;</span><br><span class="line">  s.<span class="built_in">push</span>(<span class="number">1</span>);</span><br><span class="line">  s.<span class="built_in">push</span>(<span class="number">2</span>);</span><br><span class="line">  s.<span class="built_in">push</span>(<span class="number">3</span>);</span><br><span class="line">  cout &lt;&lt;<span class="string">&quot;栈顶元素：&quot;</span>&lt;&lt; s.<span class="built_in">getTop</span>() &lt;&lt;endl;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    x = s.<span class="built_in">pop</span>();</span><br><span class="line">    cout &lt;&lt; x &lt;&lt;endl;</span><br><span class="line">    x = s.<span class="built_in">pop</span>();</span><br><span class="line">    cout &lt;&lt; x &lt;&lt;endl;</span><br><span class="line">    x = s.<span class="built_in">pop</span>();</span><br><span class="line">    cout &lt;&lt; x &lt;&lt;endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">catch</span>(intStack::Empty)&#123;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;LinkStack is Empty!&quot;</span>&lt;&lt;endl;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><p> </p><h2 id="栈的应用–表达式求值">栈的应用–表达式求值</h2><h3 id="一、表达式求值的规则">一、表达式求值的规则</h3><p>表达式求值是程序设计语言编译中的一个基本问题。它的实现就是对“栈”的典型应用。<br>首先了解算术四则运算的运算规则：<br>（1）先乘除，后加减。<br>（2）从左到右计算<br>（3）先算括号内，再算括号外</p><p> </p><p>任何一个表达式都由操作数（operand）、运算符（operator）和界定符组成：</p><p> </p><h3 id="二、运算符优先级">二、运算符优先级</h3><p>对于两个相继出现的操作符$\theta_1$和$\theta_2$有三种关系：<br>$\theta_1$ &lt;$\theta_2$ $\theta_1$的优先级低于$\theta_2$<br>$\theta_1$ =$\theta_2$ $\theta_1$的优先级等于$\theta_2$<br>$\theta_1$ &gt;$\theta_2$ $\theta_1$的优先级高于$\theta_2$<br>由此可以列出“±*/”之间的优先级。如下图</p><img src="https://i.imgtg.com/2022/10/30/RUmdr.png" alt="RUmdr.png" border="0"><h4 id="代码实现">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">char</span> <span class="title">getPriority</span><span class="params">(<span class="type">char</span> theta1, <span class="type">char</span> theta2)</span>   <span class="comment">//获取theta1与theta2之间的优先级  </span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span> priority[][<span class="number">7</span>] =     <span class="comment">//算符间的优先级关系  </span></span><br><span class="line">    &#123;</span><br><span class="line">        &#123; <span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;=&#x27;</span>,<span class="string">&#x27;0&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span>,<span class="string">&#x27;&gt;&#x27;</span> &#125;,</span><br><span class="line">        &#123; <span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;&lt;&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;=&#x27;</span> &#125;,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> index1 = <span class="built_in">getIndex</span>(theta1);    <span class="comment">//theta_1即为表中的行</span></span><br><span class="line">    <span class="type">int</span> index2 = <span class="built_in">getIndex</span>(theta2);    <span class="comment">//theta_1即为表中的列</span></span><br><span class="line">    <span class="keyword">return</span> priority[index1][index2];   <span class="comment">//返回表中的index1行index2列</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//其返回值为&gt;,&lt;,=</span></span><br></pre></td></tr></table></figure><h3 id="三、算法思路">三、算法思路</h3><p>为实现优先算法，可以使用两个工作栈，一个是OPTR，用于寄存运算符，一个是OPND，用于寄存操作数和运算结果。算法的基本思想是：<br>（1） 首先置操作数栈为空栈，表达式起始符’#‘为栈底元素。<br>（2）依次读入表达式中的每个字符，若是操作数则进OPND栈，若是运算符则和OPTR栈的栈顶运算符比较优先级作相应操作，直至整个表达式求值完毕（OPTR栈顶元素和当前读入的字符均为’#'）</p><img src="https://i.imgtg.com/2022/10/30/RUgvc.png" alt="RUgvc.png" border="0"><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">getAnswer</span><span class="params">()</span> </span>&#123;   <span class="comment">//表达式求值  </span></span><br><span class="line">&#123;</span><br><span class="line">    opter.<span class="built_in">push</span>(<span class="string">&#x27;#&#x27;</span>);      <span class="comment">//首先将&#x27;#&#x27;入栈opter  </span></span><br><span class="line">    <span class="type">int</span> counter = <span class="number">0</span>;      <span class="comment">//添加变量counter表示有多少个数字相继入栈，实现多位数的四则运算  </span></span><br><span class="line">    <span class="type">char</span> c = <span class="built_in">getchar</span>();    <span class="comment">//读取缓冲区</span></span><br><span class="line">    <span class="keyword">while</span> (c != <span class="string">&#x27;#&#x27;</span> || opter.<span class="built_in">top</span>() != <span class="string">&#x27;#&#x27;</span>)   <span class="comment">//终止条件  </span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isdigit</span>(c))   <span class="comment">//如果c在&#x27;0&#x27;~&#x27;9&#x27;之间  </span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (counter == <span class="number">1</span>)   <span class="comment">//counter==1表示上一字符也是数字，所以要合并，比如12*12，要算12，而不是单独的1和2  </span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="type">double</span> t = opval.<span class="built_in">top</span>();</span><br><span class="line">                opval.<span class="built_in">pop</span>();</span><br><span class="line">                opval.<span class="built_in">push</span>(t * <span class="number">10</span> + (c - <span class="string">&#x27;0&#x27;</span>));</span><br><span class="line">                counter = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            &#123;</span><br><span class="line">                opval.<span class="built_in">push</span>(c - <span class="string">&#x27;0&#x27;</span>);     <span class="comment">//将c对应的数值入栈opval  </span></span><br><span class="line">                counter++;</span><br><span class="line">            &#125;</span><br><span class="line">            c = <span class="built_in">getchar</span>();   <span class="comment">//读取缓冲区</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            counter = <span class="number">0</span>;   <span class="comment">//counter置零  </span></span><br><span class="line">            <span class="keyword">switch</span> (<span class="built_in">getPriority</span>(opter.<span class="built_in">top</span>(), c))   <span class="comment">//获取运算符栈opter栈顶元素与c之间的优先级，用&#x27;&gt;&#x27;，&#x27;&lt;&#x27;，&#x27;=&#x27;表示  </span></span><br><span class="line">            &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:               <span class="comment">//&lt;则将c入栈opter  </span></span><br><span class="line">                opter.<span class="built_in">push</span>(c);</span><br><span class="line">                c = <span class="built_in">getchar</span>();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;=&#x27;</span>:               <span class="comment">//=将opter栈顶元素弹出，用于括号的处理  </span></span><br><span class="line">                opter.<span class="built_in">pop</span>();</span><br><span class="line">                c = <span class="built_in">getchar</span>();</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:               <span class="comment">//&gt;则计算  </span></span><br><span class="line">                <span class="type">char</span> theta = opter.<span class="built_in">top</span>();</span><br><span class="line">                opter.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="type">double</span> a = opval.<span class="built_in">top</span>();</span><br><span class="line">                opval.<span class="built_in">pop</span>();</span><br><span class="line">                <span class="type">double</span> b = opval.<span class="built_in">top</span>();</span><br><span class="line">                opval.<span class="built_in">pop</span>();</span><br><span class="line">                opval.<span class="built_in">push</span>(<span class="built_in">calculate</span>(b, theta, a));<span class="comment">//计算栈出的b，theta和a</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> opval.<span class="built_in">top</span>();   <span class="comment">//返回opval栈顶元素的值  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="四，计算b，theta和a">四，计算b，theta和a</h3><h4 id="代码实现-2">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">double</span> <span class="title">calculate</span><span class="params">(<span class="type">double</span> b, <span class="type">char</span> theta, <span class="type">double</span> a)</span>   <span class="comment">//计算b theta a  </span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">switch</span> (theta)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> b + a;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> b - a;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> b * a;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> b / a;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="五，获取theta所对应的索引">五，获取theta所对应的索引</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">getIndex</span><span class="params">(<span class="type">char</span> theta)</span>   <span class="comment">//获取theta所对应的索引  </span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> index = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">switch</span> (theta)</span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">        index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">        index = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">        index = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">        index = <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;(&#x27;</span>:</span><br><span class="line">        index = <span class="number">4</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;)&#x27;</span>:</span><br><span class="line">        index = <span class="number">5</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;#&#x27;</span>:</span><br><span class="line">        index = <span class="number">6</span>;</span><br><span class="line">    <span class="keyword">default</span>:<span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> index;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="六，主函数">六，主函数</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span>     </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cctype&gt;</span>  </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span>  </span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line">stack&lt;<span class="type">char</span>&gt; opter;    <span class="comment">//运算符栈  </span></span><br><span class="line">stack&lt;<span class="type">double</span>&gt; opval;  <span class="comment">//操作数栈  </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">//freopen(&quot;test.txt&quot;, &quot;r&quot;, stdin);  </span></span><br><span class="line">    <span class="type">int</span> t;     <span class="comment">// 需要计算的表达式的个数  </span></span><br><span class="line">    cin &gt;&gt; t;</span><br><span class="line">    <span class="built_in">getchar</span>();</span><br><span class="line">    <span class="keyword">while</span> (t--)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span> (!opter.<span class="built_in">empty</span>())opter.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="keyword">while</span> (!opval.<span class="built_in">empty</span>())opval.<span class="built_in">pop</span>();</span><br><span class="line">        <span class="type">double</span> ans = <span class="built_in">getAnswer</span>();</span><br><span class="line">        cout &lt;&lt; ans &lt;&lt; endl &lt;&lt; endl;</span><br><span class="line">        <span class="built_in">getchar</span>();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="示例">示例</h3><h4 id="输入">输入</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">2+3*4*(5-2)+6#</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/10/30/RUyUq.png" alt="RUyUq.png" border="0"><h4 id="输出">输出</h4><img src="https://i.imgtg.com/2022/10/30/RUPNG.png" alt="RUPNG.png" border="0"><p> </p><h4 id="输入（多位数）">输入（多位数）</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">23*(2+5)+62/3#</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/10/30/RURE1.png" alt="RURE1.png" border="0"><h4 id="输出-2">输出</h4><img src="https://i.imgtg.com/2022/10/30/RUDFD.png" alt="RUDFD.png" border="0">]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ardunio学习笔记</title>
      <link href="/posts/dcbcab13.html"/>
      <url>/posts/dcbcab13.html</url>
      
        <content type="html"><![CDATA[<h2 id></h2><h2 id="程序结构">程序结构</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、<span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span>属于初始化工作（只运行一次）</span><br><span class="line">2、<span class="type">void</span> loop（）函数会永远反复的运行</span><br><span class="line">    loop函数中最后最好加一个延时函数保证程序正常运行</span><br><span class="line">3、delay （）；延迟某段时间，括号内可以添加变量名称</span><br><span class="line">4、delay （）；：</span><br><span class="line">小LED会亮3s灭3s，一直持续下去</span><br></pre></td></tr></table></figure><p>arduino中有一个可以自己控制的LED连接在引脚13</p><h2 id="编程语句参考">编程语句参考</h2><p><a href="http://www.taichi-maker.com/homepage/reference-index/arduino-code-reference/">Arduino编程语句参考 – 太极创客 (taichi-maker.com)</a></p><p><a href="https://www.arduino.cc/reference/en/">阿尔杜伊诺参考 - 阿尔杜伊诺参考 (arduino.cc)</a></p><p> </p><h2 id="常用函数">常用函数</h2><h3 id="数字io">数字io</h3><h4 id="pinMode">pinMode</h4><p>形式pinMode(引脚，工作模式)</p><p>其中可以设置为1.input 2.output 3.INPUT_PULLUP</p><p>上拉电阻模式（INPUT_PULLUP）</p><p>arduino中内部自带上拉电阻</p><h4 id="digitalWrite-引脚，高低电平">digitalWrite(引脚，高低电平)</h4><p>将数字引脚写<a href="http://www.taichi-maker.com/homepage/reference-index/arduino-code-reference/high/">HIGH</a>（高电平）或<a href="http://www.taichi-maker.com/homepage/reference-index/arduino-code-reference/low/">LOW</a>（低电平）</p><p>digitalRead(pin)</p><p>pin就是被读取的引脚号</p><p>有返回值HIGH或者LOW</p><p> </p><h3 id="模拟io">模拟io</h3><h4 id="analogRead-读取引脚">analogRead(读取引脚)</h4><p>Arduino可以将0－5伏特的电压输入信号映射到数值0－1023我们可以将5伏特等分成1024份。0伏特的输入信号对应着数值0，而5伏特的输入信号对应着1023。</p><p>例：<br>当模拟输入引脚的输入电压为2.5伏特的时候，该引脚的数值为512。<br>(2.5伏特 / 5伏特 = 0.5， 1024 X 0.5 ＝512)</p><p> </p><h4 id="analogWrite-pin-value">analogWrite(pin, value)</h4><p><code>pin</code>：被读取的模拟引脚号码<br><code>value</code>：0到255之间的PWM频率值, 0对应off, 255对应on</p><p>可以将value的数值写入pin</p><p>Arduino每一次对引脚执行analogWrite()指令，都会给该引脚一个固定频率的PWM信号。</p><p>这个操作可以用来控制LED的亮度, 或者控制电机的转速</p><p> </p><h3 id="数学信号">数学信号</h3><h4 id="map（）-等比映射">map（）-等比映射</h4><p>map()可以用来将某一数值从一个区间等比映射到一个新的区间。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">map</span> (x, in_min, in_max, out_min, out_max)</span><br></pre></td></tr></table></figure><p>x： 要映射的值<br>in_min： 映射前区间最小值<br>in_max： 映射前区间最大值<br>out_min： 映射后区间最小值<br>out_max 映射后区间最大值</p><p> </p><h2 id="二极管">二极管</h2><p>LED工作电流为20毫安，工作是约产生2v左右的电压降</p><p> </p><h2 id="按键开关（数字输入）">按键开关（数字输入）</h2><p>按键开关：相连不同侧，同侧不相连</p><p>arduino的引脚设置为数字输入（input）状态时可以识别两种状态时可以识别两种状态</p><p>HIGH(高电平)LOW(低电平)</p><p> </p><h2 id="串口监视器">串口监视器</h2><p>Serial.begin(9600);</p><p>串口初始化，每秒9600位。</p><p>9600是常用的速度档。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>光敏电阻</title>
      <link href="/posts/dcbcab13.html"/>
      <url>/posts/dcbcab13.html</url>
      
        <content type="html"><![CDATA[<h2 id="光敏电阻（LDR）">光敏电阻（LDR）</h2><p>光敏电阻的阻值随着环境亮度的增加儿减小</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">setup</span><span class="params">()</span> &#123;</span><br><span class="line">  Serial.begin(<span class="number">9600</span>);  <span class="comment">//启动串口通讯</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="type">void</span> <span class="title function_">loop</span><span class="params">()</span> &#123;   </span><br><span class="line">  Serial.print(<span class="string">&quot;LDR Reading: &quot;</span>);  <span class="comment">//通过串口监视器</span></span><br><span class="line">  Serial.println(analogRead(A0)); <span class="comment">//输出LDR读数 </span></span><br><span class="line">  delay(<span class="number">10</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过加入一个10k的电子分压，使得AO引脚接收的电压值会随着LDR正向增大或减小。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 单片机 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>链表</title>
      <link href="/posts/79666db.html"/>
      <url>/posts/79666db.html</url>
      
        <content type="html"><![CDATA[<h1>链表</h1><h2 id="单链表">单链表</h2><p>单链表是由若干结点构成</p><p>单链表的结点只有一个指针域（单链表包含一个指针域和一个数据域）</p><h3 id="链表的结构">链表的结构</h3><p>头指针：指向第一个结点的地址</p><p>尾标志：终端结点的指针域为空</p><p> </p><h4 id="申请一个结点">申请一个结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">node</span></span><br><span class="line">&#123;</span><br><span class="line">DataType data;     <span class="comment">//数据域</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">node</span> *next;   <span class="comment">//指针域</span></span><br><span class="line">&#125;Node,*Link;   </span><br><span class="line"><span class="comment">//用typedef去声明结构体时，Node和*Link两个位置就被定义成了类型</span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Node st;    <span class="comment">//struct node st;</span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Link p;     <span class="comment">//struct node *p;  //p是一个指向结构体的指针</span></span><br></pre></td></tr></table></figure><h4 id="申请结点">申请结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p=(Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sizeof</span>(node);     <span class="comment">//计算出node结点的大小</span></span><br><span class="line"><span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));   <span class="comment">//用malloc分配给Link这么大的空间  malloc返回函数时viod*</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>分配地址以后，其把首地址分配给了指针p，在使用这块空间的时候，需要对这块地址进行强制转换。转换成指针p希望看到的类型。</p><p>指针p是一个Link类型，所以把malloc也定义成Link类型</p><p> </p><h3 id="如何引用数据元素？">如何引用数据元素？</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(*p).data;</span><br><span class="line">p-&gt;data;</span><br></pre></td></tr></table></figure><h3 id="如何引用指针域？">如何引用指针域？</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p-&gt;next;</span><br></pre></td></tr></table></figure><p> </p><h2 id="链表的实现">链表的实现</h2><h3 id="单链表的遍历操作">单链表的遍历操作</h3><p>操作接口：void displayNode(Link head);</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">displayNode</span><span class="params">(Link head)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">p= head-&gt;next;</span><br><span class="line"><span class="keyword">while</span>(p!=<span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">cout&lt;&lt;p-&gt;next&lt;&lt;endl;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="求单链表的元素个数">求单链表的元素个数</h3><p>操作接口：int length(Link head);</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">length</span><span class="params">(Link head)</span></span>&#123;</span><br><span class="line">p = head-&gt;next;    <span class="comment">//p指向头指针的next域</span></span><br><span class="line">count = <span class="number">0</span>;         <span class="comment">//count的数值为零</span></span><br><span class="line"><span class="keyword">while</span>(p！=<span class="literal">NULL</span>)</span><br><span class="line">&#123;</span><br><span class="line">p = p-&gt;next;    <span class="comment">//如果p不为空，则p指向下一个结点的                           // next域</span></span><br><span class="line">count++;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> count;      <span class="comment">//注意count和初始化返回值之间的关系</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="单链表的查找操作">单链表的查找操作</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">queryNode</span><span class="params">(Link head,DaraType x)</span></span>&#123;</span><br><span class="line">p = head-&gt;next;</span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(p!=<span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(p—&gt;data==x)</span><br><span class="line">        &#123;</span><br><span class="line">            cout&lt;&lt;data&lt;&lt;endl;    <span class="comment">//找到则调用输出函数，并提                                  //前返回true</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">    <span class="comment">//如果链表结束，说明没有找到</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="单链表的插入操作">单链表的插入操作</h3><p>操作接口：void insertNode(Link head,int i,DataType x);</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node)); <span class="comment">//申请一个结点node</span></span><br><span class="line">node-&gt;data = x;                    <span class="comment">//结点的数据域是x</span></span><br><span class="line">node -&gt; next = p-&gt;next;            <span class="comment">//p的next域赋给node的                                    //next域</span></span><br><span class="line">p-&gt;next = node;          <span class="comment">//将node的数据域赋值给p的next域</span></span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgcuI.png" alt="RgcuI.png" border="0"><ol><li><p>工作指针p初始化</p></li><li><p>查找第i-1个结点并使用、工作指针p指向该结点</p></li><li><p>若查找不成功，则返回false</p><p>3.1生成一个元素值为x的新结点；</p><p>3.2将新结点s插入到结点p之后；</p><p>3.3返回true；</p><p> </p></li></ol><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">insertNode</span><span class="params">(Link head,<span class="type">int</span> i,DataType x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    p = head;          <span class="comment">//工作指针p指向头结点</span></span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (p!=<span class="literal">NULL</span>&amp;&amp;count&lt;i<span class="number">-1</span>) <span class="comment">//查找第i-1个结点</span></span><br><span class="line">    &#123;</span><br><span class="line">        p=p-&gt;next;</span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(p==<span class="literal">NULL</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;  <span class="comment">//没有找到第i-1个结点</span></span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));<span class="comment">//申请一个结点                                             //node</span></span><br><span class="line">        node-&gt;data=x;</span><br><span class="line">        node-&gt;next=p-&gt;next; <span class="comment">//结点node插入结点p之后</span></span><br><span class="line">        p-&gt;next=node;</span><br><span class="line">        <span class="keyword">return</span> ture;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="创建一个单链表—头插法">创建一个单链表—头插法</h3><p>操作接口：Link newList(DataType a[],int n)</p><p><strong>头插法</strong>：将待插入结点插在头结点的后面。</p><h4 id="初始化头结点">初始化头结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">head = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">head-&gt;next=<span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgQaM.png" alt="RgQaM.png" border="0"><h4 id="插入第一个元素">插入第一个元素</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">node-&gt;data=a[<span class="number">0</span>];</span><br><span class="line">node-&gt;next=head-&gt;next;</span><br><span class="line">head-&gt;next=node;</span><br></pre></td></tr></table></figure><p>&lt;img src=“<a href="https://img1.imgtp.com/2022/10/13/6ct2kjQH.png">https://img1.imgtp.com/2022/10/13/6ct2kjQH.png</a>” alt=“image-20221005111133614.png” title=“image<img src="/posts/79666db.htm/Rg0E1.png" alt="Rg0E1.png" border="0">-20221005111133614.png” /&gt;</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">node-&gt;data=a[<span class="number">1</span>];</span><br><span class="line">node-&gt;next=head-&gt;next;</span><br><span class="line">head-&gt;next=node;</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgSNG.png" alt="RgSNG.png" border="0"><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">class</span> <span class="title class_">DataType</span>&gt;</span><br><span class="line"><span class="function">Link <span class="title">newList</span><span class="params">(DataType a[],<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    head=(Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">    head-&gt;next=<span class="literal">NULL</span>;</span><br><span class="line">    <span class="comment">//创建后续结点</span></span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; n;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">        node-&gt;data = a[i];</span><br><span class="line">        node-&gt;next = head-&gt;next;</span><br><span class="line">head-&gt;next = node;    </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="创建一个单链表—尾插法">创建一个单链表—尾插法</h3><p>操作接口：Link newList(DataType a[],int n)</p><p>尾插法：将待插入结点插在终端结点的后面</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">head = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));  <span class="comment">//创建一个头</span></span><br><span class="line">head-&gt;next = <span class="literal">NULL</span>;           </span><br><span class="line">rear = head;               <span class="comment">//将head赋给rear</span></span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgEdr.png" alt="RgEdr.png" border="0"><h4 id="插入第一个元素结点">插入第一个元素结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node)); <span class="comment">//创建结点node</span></span><br><span class="line">node-&gt;data = a[<span class="number">0</span>];         <span class="comment">//结点第一个数据域</span></span><br><span class="line">rear-&gt;next = node;         <span class="comment">//rear的next域是node</span></span><br><span class="line">rear = node;               <span class="comment">//将node名为rear</span></span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgsFD.png" alt="RgsFD.png" border="0"><h4 id="依次插入每一个结点">依次插入每一个结点</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node))</span><br><span class="line">node-&gt;dat = a[<span class="number">1</span>];</span><br><span class="line">rear-&gt;next = node;</span><br><span class="line">rear = node;</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/03/RgVRF.png" alt="RgVRF.png" border="0"><h4 id="尾插法">尾插法</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Link <span class="title">newList</span><span class="params">(DataType a[],<span class="type">int</span> n)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  head = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">  head-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">  rear = head;         <span class="comment">//尾指针初始化</span></span><br><span class="line">  <span class="keyword">for</span>(i = <span class="number">0</span>; i&lt;n;i++)</span><br><span class="line">  &#123;</span><br><span class="line">   node=(Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));<span class="comment">//创建结点</span></span><br><span class="line">   node-&gt;data = a[i];</span><br><span class="line">   rear-&gt;next = node;</span><br><span class="line">   rear = ndoe;</span><br><span class="line">  &#125;</span><br><span class="line">  rear-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">  <span class="keyword">return</span> head;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p> </p><h4 id="单链表结点的删除">单链表结点的删除</h4><p>操作接口：bool deleteNode(Link head, Datatype x);</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q-&gt;next = p-&gt;next;</span><br><span class="line"><span class="built_in">free</span>(p);     </span><br></pre></td></tr></table></figure><p>将q的next域指向p的next域，将被删除的p空间释放。</p><h5 id="查找结点">查找结点</h5><p>在查找过程中，如果发现p所指向的结点data值不是要找的x，则p，q同时后移；一旦找到则执行删除操作</p><p> </p><p>查找到p结点并将其删除</p><p>1.如何找到p结点。</p><p>2.如何保证p，q指针一前一后。</p><p> </p><h5 id="初始化">初始化</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p = head-&gt;next;</span><br><span class="line">q = head;</span><br></pre></td></tr></table></figure><h5 id="指针移动一次">指针移动一次</h5><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">q = p;</span><br><span class="line">p = p-&gt;next;</span><br></pre></td></tr></table></figure><h5 id="删除中的特殊情况">删除中的特殊情况</h5><p>在查找过程中，如果一直没有找到data域为x的结点，或者发现待删除的表是空表，则提前返回false</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(head==<span class="literal">NULL</span>||head-&gt;next==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="单链表的删除">单链表的删除</h4><p>1.判断是否是空表，如果是空表返回false；</p><p>2.工作指针p，q初始化</p><p>3.若p指针不为空，则继续下列循环：</p><p>​3.1如果找到data域等于x的结点，则：</p><p>​3.1.1摘链，将结点p的从链表上摘下来</p><p>​3.1.2释放别删除的结点</p><p>​3.1.3提前返回true，代表删除成功</p><p>4.循环结束了，说明没有找到和x相等的结点，则返回false</p><p> </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">deleteNode</span><span class="params">(Link head,DataType x)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(head==<span class="literal">NULL</span>||head-&gt;next==<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">p=head-&gt;next;</span><br><span class="line">q=head;</span><br><span class="line"><span class="keyword">while</span>(p!=<span class="literal">NULL</span>)&#123;</span><br><span class="line"><span class="keyword">if</span>(p-&gt;data==x)&#123;</span><br><span class="line">q-&gt;next=p-&gt;next;</span><br><span class="line"><span class="built_in">free</span>(p);    <span class="comment">//单链表的释放</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">q = p;</span><br><span class="line">p = p-&gt;next;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//如果循环结束了，说明没有找到和x相关的结点</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h2 id="循环列表的实现">循环列表的实现</h2><p>将单链表的首位相接，将终端结点的指针由空指针改为指向头结点，构成<strong>单循环链表</strong>，简称<strong>循环链表</strong></p><img src="https://i.imgtg.com/2022/11/03/RgY96.png" alt="RgY96.png" border="0"><p> </p><h4 id="循环链表的插入">循环链表的插入</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">node-&gt;data = x;</span><br><span class="line">node-&gt;next = p-&gt;next;</span><br><span class="line">p-&gt;next = node;</span><br></pre></td></tr></table></figure><p> </p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p! = <span class="literal">NULL</span>;     <span class="comment">//p != head</span></span><br><span class="line">p-&gt;next != <span class="literal">NULL</span>;    <span class="comment">//p-&gt;next != head </span></span><br></pre></td></tr></table></figure><p> </p><h3 id="双向链表">双向链表</h3><p>在单链表的每一个结点中再设置一个指向其前驱结点的指针域。</p><img src="https://i.imgtg.com/2022/11/03/RglUP.png" alt="RglUP.png" border="0"><p>data：数据域，储存数据元素</p><p>prior：指针域，储存该结点的前驱结点地址</p><p>next：指针域，储存该结点的后继结点地址</p><p> </p><h2 id="一元多项式的相加">一元多项式的相加</h2><h3 id="题目描述：">题目描述：</h3><p>实现两个一元n次多项式的加法。例如P(A)=x+3x2-5x5+7，P(B)=2x2+6x3+x5-4x6，求P(A)+P(B)。</p><p>首先弄清楚一元多项式的加法原理，然后明确多项式的存储方法。链表节点存储系数和指数，只存系数非0的项。</p><h3 id="输入二项式数据的函数">输入二项式数据的函数</h3><p>给用户合适的提示，读入用户输入的系数和指数。<br>调用函数insert，将用户输入的二项式的一项插入到链表中去。</p><h4 id="代码实现">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">inputPoly</span><span class="params">(Link head)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> coefficient, exp;<span class="comment">//系数和指数</span></span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;请输入系数和指数（如：\&quot;2 3\&quot;表示2x^3）:&quot;</span> &lt;&lt; endl;</span><br><span class="line">    cin &gt;&gt; coefficient&gt;&gt;exp;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (coefficient != <span class="number">0</span> || exp != <span class="number">0</span>)<span class="comment">//连续输入多个系数和指数</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">insert</span>(head, coefficient, exp);<span class="comment">//调函数输入多项式</span></span><br><span class="line"></span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;请输入系数和指数&quot;</span> &lt;&lt; endl;</span><br><span class="line">        cin &gt;&gt; coefficient&gt;&gt;exp;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="向多项式链表中插入元素的函数">向多项式链表中插入元素的函数</h3><p>int coefficient 一个多项式项的系数<br>int exp 一个多项式项的幂</p><h4 id="代码实现-2">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">bool</span> <span class="title">insert</span><span class="params">(Link head, <span class="type">int</span> coefficient, <span class="type">int</span> exp)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Link node;  <span class="comment">//node指针指向新创建的节点</span></span><br><span class="line">    Link q, p;   <span class="comment">//q,p两个节点一前一后</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">//创建一个新结点</span></span><br><span class="line">    q = head;</span><br><span class="line">    p = head-&gt;next;</span><br><span class="line"></span><br><span class="line">    node = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">    node-&gt;coefficient = coefficient;</span><br><span class="line">    node-&gt;exp = exp;</span><br><span class="line">    node-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (head-&gt;next == <span class="literal">NULL</span>)<span class="comment">//空表,插第1个</span></span><br><span class="line">    &#123;</span><br><span class="line">        head-&gt;next = node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span> (p != <span class="literal">NULL</span>) &#123; </span><br><span class="line">            <span class="keyword">if</span> (exp == p-&gt;exp) &#123;</span><br><span class="line">                p-&gt;coefficient += coefficient;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//大于当前次数</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (exp &gt; p-&gt;exp) &#123;</span><br><span class="line">                q-&gt;next = node;</span><br><span class="line">                node-&gt;next = p;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                q = p;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (p == <span class="literal">NULL</span>) &#123;</span><br><span class="line">            q-&gt;next = node;</span><br><span class="line">            node-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果退出循环是当前指针p移动到链表结尾，则说明之前没有插入，那么当前node节点的指数值是最大值，此时插在链表的最后面</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="多项式的输出">多项式的输出</h3><p>数字转换为字符串函数itoa<br>标志是否为第一个节点的flag的设置<br>字符串连接函数strcat<br>字符串清空函数memset。memset(item,0,20);清空长20的字符串item</p><h4 id="代码实现-3">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">Cout</span><span class="params">(Link head)</span> </span>&#123;</span><br><span class="line">    Link p; <span class="comment">//指向链表要输出的结点</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;多项式如下&quot;</span> &lt;&lt; endl;</span><br><span class="line">    p = head-&gt;next;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (p == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        </span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;多项式为空&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 不是空表</span></span><br><span class="line">    <span class="type">char</span> item[<span class="number">20</span>] = <span class="string">&quot;&quot;</span>; <span class="comment">//要打印的当前多项式的一项</span></span><br><span class="line">    <span class="type">char</span> number[<span class="number">7</span>] = <span class="string">&quot;&quot;</span>; <span class="comment">//暂时存放系数转换成的字符串</span></span><br><span class="line">    <span class="type">bool</span> isFirstItem = <span class="literal">true</span>;<span class="comment">//标志是否为第一个节点的flag</span></span><br><span class="line">    <span class="type">int</span> flag = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">//打印节点</span></span><br><span class="line">    <span class="keyword">while</span> (p != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="built_in">memset</span>(item, <span class="number">0</span>, <span class="number">20</span>); <span class="comment">//清空字符串item</span></span><br><span class="line">        _itoa_s(p-&gt;coefficient, number, <span class="number">10</span>);</span><br><span class="line">        <span class="keyword">if</span> (p-&gt;coefficient == <span class="number">0</span>) &#123;<span class="comment">//当为0时的判断非常容易出错</span></span><br><span class="line">            <span class="keyword">if</span> (flag == <span class="number">0</span>) &#123;</span><br><span class="line">                isFirstItem = <span class="literal">true</span>;<span class="comment">//如果第一项系数为0，移动指针，判断仍为true</span></span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (flag == <span class="number">1</span>) &#123;</span><br><span class="line">                p = p-&gt;next;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (isFirstItem != <span class="literal">true</span> &amp;&amp; p-&gt;coefficient &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, <span class="string">&quot;+&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;coefficient == <span class="number">1</span>) &#123;&#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (p-&gt;coefficient == <span class="number">-1</span>) &#123;</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, <span class="string">&quot;-&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (p-&gt;coefficient != <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, number);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;exp == <span class="number">1</span>) &#123;</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, <span class="string">&quot;x&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (p-&gt;exp == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (p-&gt;coefficient == <span class="number">1</span> || p-&gt;coefficient == <span class="number">-1</span>)</span><br><span class="line">                    <span class="built_in">strcat_s</span>(item, <span class="string">&quot;1&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, <span class="string">&quot;x^&quot;</span>);</span><br><span class="line">                _itoa_s(p-&gt;exp, number, <span class="number">10</span>);</span><br><span class="line">                <span class="built_in">strcat_s</span>(item, <span class="number">20</span>,number);</span><br><span class="line">                <span class="comment">//strcat_s(item, _itoa_s(p-&gt;exp, number, 10));</span></span><br><span class="line">            &#125;</span><br><span class="line">            flag = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        cout &lt;&lt; item ;<span class="comment">//打印当前节点代表的项</span></span><br><span class="line">        p = p-&gt;next;<span class="comment">//指向下个结点</span></span><br><span class="line">        isFirstItem = <span class="literal">false</span>; <span class="comment">//flag标志不是第一项了</span></span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="链表合并">链表合并</h3><p>合并两个有序链表a，b到链表ab<br>heada.headb,headab分别为链表a,b,ab的头指针</p><h4 id="代码实现-4">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">combin2List</span><span class="params">(Link heada, Link headb, Link headab)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Link pa, pb;<span class="comment">//指向a，b链表和ab的指针</span></span><br><span class="line">    pa = heada-&gt;next;</span><br><span class="line">    pb = headb-&gt;next;</span><br><span class="line">    <span class="keyword">while</span> (pa != <span class="literal">NULL</span> &amp;&amp; pb != <span class="literal">NULL</span>)<span class="comment">//a,b链表都没有没有访问完毕</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">//如果指数a&gt;指数b，a节点插入ab链表，a指针后移</span></span><br><span class="line">        <span class="keyword">if</span> (pa-&gt;exp &gt; pb-&gt;exp) &#123;</span><br><span class="line">            <span class="built_in">insert</span>(headab, pa-&gt;coefficient, pa-&gt;exp);</span><br><span class="line">            pa = pa-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果指数a&lt;指数b，b节点插入ab链表，b指针后移</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (pa-&gt;exp &lt; pb-&gt;exp) &#123;</span><br><span class="line">            <span class="built_in">insert</span>(headab, pb-&gt;coefficient, pb-&gt;exp);</span><br><span class="line">            pb = pb-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果指数a==指数b，a、b系数相加，插入ab链表，a、b指针后移</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (pa-&gt;exp == pb-&gt;exp) &#123;</span><br><span class="line">            <span class="type">int</span> coefficient;<span class="comment">//系数</span></span><br><span class="line">            coefficient = pa-&gt;coefficient + pb-&gt;coefficient;</span><br><span class="line">            <span class="built_in">insert</span>(headab, coefficient, pa-&gt;exp);</span><br><span class="line">            pa = pa-&gt;next;</span><br><span class="line">            pb = pb-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果a，b链表后还有尾巴，则加到链表后面   是否可以去掉</span></span><br><span class="line">        <span class="keyword">while</span> (pa != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">insert</span>(headab, pa-&gt;coefficient, pa-&gt;exp);</span><br><span class="line">            pa = pa-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (pb != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="built_in">insert</span>(headab, pb-&gt;coefficient, pb-&gt;exp);</span><br><span class="line">            pb = pb-&gt;next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果a、b链表还有尾巴，将它加到ab链表后面</span></span><br><span class="line">    <span class="keyword">while</span> (pa != <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">insert</span>(headab, pa-&gt;coefficient, pa-&gt;exp);</span><br><span class="line">        pa = pa-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (pb != <span class="literal">NULL</span>)</span><br><span class="line">    &#123;   </span><br><span class="line">        <span class="built_in">insert</span>(headab, pb-&gt;coefficient, pb-&gt;exp);</span><br><span class="line">        pb = pb-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="释放空间">释放空间</h3><p>在main函数中一定不能忘记释放空间</p><h4 id="代码实现-5">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">clearLink</span><span class="params">(Link head)</span> </span>&#123;</span><br><span class="line">    Link p, q;</span><br><span class="line">    <span class="keyword">if</span> (head == <span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    q = head-&gt;next;</span><br><span class="line">    <span class="built_in">free</span>(head);</span><br><span class="line">    <span class="keyword">while</span> (q != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        p = q;</span><br><span class="line">        q = q-&gt;next;</span><br><span class="line">        <span class="built_in">free</span>(p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="头文件">头文件</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> UNICODE</span></span><br><span class="line"><span class="meta">#<span class="keyword">undef</span> _UNICODE</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br></pre></td></tr></table></figure><p> </p><h3 id="定义结点">定义结点</h3><p>其中，数据域包含指数和系数，还有一个指向下一个结点的指针</p><h4 id="代码实现-6">代码实现</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">PNode</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> coefficient;<span class="comment">//系数</span></span><br><span class="line">    <span class="type">int</span> exp;<span class="comment">//指数</span></span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">PNode</span>* next;</span><br><span class="line">&#125;*Link, Node;</span><br></pre></td></tr></table></figure><p> </p><h3 id="函数声明">函数声明</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">inputPoly</span><span class="params">(Link head)</span></span>;<span class="comment">//用于从控制台读入链表的函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">Cout</span><span class="params">(Link head)</span></span>;<span class="comment">//打印链表用的函数</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">insert</span><span class="params">(Link head, <span class="type">int</span> coefficient, <span class="type">int</span> exp)</span></span>;<span class="comment">//向链表插入一个元素的函数</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">combin2List</span><span class="params">(Link heada, Link headb, Link headab)</span></span>;<span class="comment">//合并两个链表</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">clearLink</span><span class="params">(Link head)</span></span>;</span><br></pre></td></tr></table></figure><p> </p><h3 id="主函数">主函数</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Link headA, headB;<span class="comment">//两个多项式的头指针</span></span><br><span class="line">    Link headAB;<span class="comment">//合并后的多项式的头指针</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*链表的初始化*/</span></span><br><span class="line">    headA = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">    headA-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    headB = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">    headB-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    headAB = (Link)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(Node));</span><br><span class="line">    headAB-&gt;next = <span class="literal">NULL</span>; </span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;请输入第一个多项式的系数和指数，以（0 0）结束&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">inputPoly</span>(headA);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;第一个&quot;</span> ;</span><br><span class="line">    <span class="built_in">Cout</span>(headA);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;请输入第二个多项式的系数和指数，以（0 0）结束&quot;</span> &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">inputPoly</span>(headB);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;第二个&quot;</span> ;</span><br><span class="line">    <span class="built_in">Cout</span>(headB);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">combin2List</span>(headA, headB, headAB);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;合并后&quot;</span> ;</span><br><span class="line">    <span class="built_in">Cout</span>(headAB);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">clearLink</span>(headA);</span><br><span class="line">    <span class="built_in">clearLink</span>(headB);</span><br><span class="line">    <span class="built_in">clearLink</span>(headAB);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> </p><h3 id="示例">示例</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">请输入第一个多项式的系数和指数，以(<span class="number">0</span> <span class="number">0</span>)结束：</span><br><span class="line">请输入系数和指数(如：<span class="string">&quot;2 3&quot;</span>表示<span class="number">2</span>x^<span class="number">3</span>)：<span class="number">1</span> <span class="number">1</span></span><br><span class="line">请输入系数和指数：<span class="number">-1</span> <span class="number">1</span></span><br><span class="line">请输入系数和指数：<span class="number">2</span> <span class="number">2</span></span><br><span class="line">请输入系数和指数：<span class="number">0</span> <span class="number">0</span></span><br><span class="line">第一个多项式如下：</span><br><span class="line"><span class="number">2</span>x^<span class="number">2</span></span><br><span class="line">请输入第二个多项式的系数和指数，以(<span class="number">0</span> <span class="number">0</span>)结束：</span><br><span class="line">请输入系数和指数(如：<span class="string">&quot;2 3&quot;</span>表示<span class="number">2</span>x^<span class="number">3</span>)：<span class="number">-2</span> <span class="number">2</span></span><br><span class="line">请输入系数和指数：<span class="number">2</span> <span class="number">3</span></span><br><span class="line">请输入系数和指数：<span class="number">4</span> <span class="number">5</span></span><br><span class="line">请输入系数和指数：<span class="number">0</span> <span class="number">0</span></span><br><span class="line">第二个多项式如下：</span><br><span class="line"><span class="number">4</span>x^<span class="number">5</span>+<span class="number">2</span>x^<span class="number">3</span><span class="number">-2</span>x^<span class="number">2</span></span><br><span class="line">合并后多项式如下：</span><br><span class="line"><span class="number">4</span>x^<span class="number">5</span>+<span class="number">2</span>x^<span class="number">3</span></span><br></pre></td></tr></table></figure><p>输入</p><img src="https://i.imgtg.com/2022/11/01/RrkBG.png" alt="RrkBG.png" border="0"><p> </p><h4 id="示例-2">示例</h4><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">请输入第一个多项式的系数和指数，以(0 0)结束：</span><br><span class="line">请输入系数和指数(如：2 3表示2x^3)：4 2</span><br><span class="line">请输入系数和指数：-3 3</span><br><span class="line">请输入系数和指数：-1 1</span><br><span class="line">请输入系数和指数：2 0</span><br><span class="line">请输入系数和指数：0 0</span><br><span class="line">第一个多项式如下：</span><br><span class="line">-3x^3+4x^2-x+2</span><br><span class="line">请输入第二个多项式的系数和指数，以(0 0)结束：</span><br><span class="line">请输入系数和指数(如：2 3表示2x^3)：4 5</span><br><span class="line">请输入系数和指数：3 3</span><br><span class="line">请输入系数和指数：-3 1</span><br><span class="line">请输入系数和指数：0 0</span><br><span class="line">第二个多项式如下：</span><br><span class="line">4x^5+3x^3-3x</span><br><span class="line">合并后多项式如下：</span><br><span class="line">4x^5+4x^2-4x+2</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/01/RrWlM.png" alt="RrWlM.png" border="0"><p> </p><h4 id="示例-3">示例</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">请输入第一个多项式的系数和指数，以(<span class="number">0</span> <span class="number">0</span>)结束：</span><br><span class="line">请输入系数和指数(如：<span class="number">2</span> <span class="number">3</span>表示<span class="number">2</span>x^<span class="number">3</span>)：<span class="number">3</span> <span class="number">5</span></span><br><span class="line">请输入系数和指数：<span class="number">3</span> <span class="number">4</span></span><br><span class="line">请输入系数和指数：<span class="number">-3</span> <span class="number">0</span></span><br><span class="line">请输入系数和指数：<span class="number">1</span> <span class="number">4</span></span><br><span class="line">请输入系数和指数：<span class="number">0</span> <span class="number">0</span></span><br><span class="line">第一个多项式如下：</span><br><span class="line"><span class="number">3</span>x^<span class="number">5</span>+<span class="number">4</span>x^<span class="number">4</span><span class="number">-3</span></span><br><span class="line">请输入第二个多项式的系数和指数，以(<span class="number">0</span> <span class="number">0</span>)结束：</span><br><span class="line">请输入系数和指数(如：<span class="number">2</span> <span class="number">3</span>表示<span class="number">2</span>x^<span class="number">3</span>)：<span class="number">-3</span> <span class="number">5</span></span><br><span class="line">请输入系数和指数：<span class="number">7</span> <span class="number">1</span></span><br><span class="line">请输入系数和指数：<span class="number">2</span> <span class="number">4</span></span><br><span class="line">请输入系数和指数：<span class="number">3</span> <span class="number">0</span></span><br><span class="line">请输入系数和指数：<span class="number">0</span> <span class="number">0</span></span><br><span class="line">第二个多项式如下：</span><br><span class="line"><span class="number">-3</span>x^<span class="number">5</span>+<span class="number">2</span>x^<span class="number">4</span>+<span class="number">7</span>x+<span class="number">3</span></span><br><span class="line">合并后多项式如下：</span><br><span class="line"><span class="number">6</span>x^<span class="number">4</span>+<span class="number">7</span>x</span><br></pre></td></tr></table></figure><img src="https://i.imgtg.com/2022/11/01/RrUJr.png" alt="RrUJr.png" border="0">]]></content>
      
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/posts/0.html"/>
      <url>/posts/0.html</url>
      
        <content type="html"><![CDATA[<p><img src="C:/Users/12733/AppData/Roaming/Typora/typora-user-images/image-20220913103307137.png" alt="image-20220913103307137"></p><p><img src="C:/Users/12733/AppData/Roaming/Typora/typora-user-images/image-20220913105234970.png" alt="image-20220913105234970"></p><p><a href="https://kdocs.cn/l/cofxkBJNM9XX">大赛地址</a></p><p>小田</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>微积分三</title>
      <link href="/posts/470d838d.html"/>
      <url>/posts/470d838d.html</url>
      
        <content type="html"><![CDATA[<h1>向量与向量值函数</h1><h2 id="点积（Dot-Products）">点积（Dot Products）</h2><p>已知两个二维或者三维的非零向量<strong>u</strong>和<strong>v</strong>，它们的点积是<br>$$<br>u·v=|u| \times |v|cos \theta<br>$$<br>其中，$\theta$是<strong>u</strong>与<strong>v</strong>之间的夹角，且$0 \le \theta \le \pi$。</p><p> </p><h4 id="正交向量（Orthogonal-Vectors）">正交向量（Orthogonal Vectors）</h4><p>当两个向量<strong>u</strong>和<strong>v</strong>称为是正交，有<strong>u</strong>·<strong>v</strong>=0。这两个正交的非零向量相互垂直。</p><p> </p><h4 id="点积（Dot-Products）-2">点积（Dot Products）</h4><p>已知两个向量$u=&lt;u_1,u_2,u_3&gt;$和$v=&lt;v_1,v_2,v_3&gt;$,<br>$$<br>u·v=u_1v_1+u_2v_2+u_3v_3<br>$$<br> </p><h3 id="正交投影（Orthogonal-Projection-of-u-into-v）">正交投影（Orthogonal Projection of u into v）</h3><h4 id="u在v上的（正交投影）">u在v上的（正交投影）</h4><p>设$v \ne 0$,则u在v上的<strong>正交投影</strong>是<br>$$<br>proj_vu=|u|cos \theta(\frac{v}{|v|})<br>$$<br>正交投影也可以用如下的公式计算<br>$$<br>proj_vu=scal_vu(\frac{v}{|v|})=(\frac{u·v}{v·v})v<br>$$<br>其中u在v方向的<strong>纯分量</strong>是<br>$$<br>scal_vu=|u|cos \theta = \frac{u · v}{|v|}<br>$$<br><img src="https://i.imgtg.com/2022/11/03/RmOUC.png" alt="RmOUC.png" border="0"></p><p>ps：<strong>proj</strong>相较于<strong>scal</strong>的区别是其方向是否跟投影的向量一致。</p><p> </p><p> </p><h5 id="证明">证明</h5><p>$u=&lt;u_1,u_2,u_3&gt;$<br>$$<br>(u_1+u_2+u_3)^2 \le 3(u_1<sup>2+u_2</sup>2+u_3^2)<br>$$<br>过程如下</p><p>$v=&lt;u_2,u_3,u_1&gt;$有 $u·v=u_1u_2+u_2u_3+u_3u_1$和$|u||v|=u_1<sup>2+u_2</sup>2+u_3^2$，</p><p>因此有$u_1u_2+u_2u_3+u_3u_1 \le |u|^2$</p><p>有$(u_1+u_2+u_3)<sup>2=u_1</sup>2+u_2<sup>2+u_3</sup>2+2(u_1u_2+u_2u_3+u_3u_1) \le u_1<sup>2+u_2</sup>2+u_3<sup>2+2|u|</sup>2 = 3|u|^2$</p><h2 id="叉积（Cross-Product）">叉积（Cross Product）</h2><p><strong>u</strong>和<strong>v</strong>叉乘$u \times v$是一个大小为<br>$$<br>|u \times v| = |u||v|sin \theta<br>$$<br>的向量，其中其方向根据<strong>右手定则</strong>判断</p><img src="https://i.imgtg.com/2022/11/03/Rg3ha.png" alt="Rg3ha.png" border="0"><p> </p><h4 id="计算叉积">计算叉积</h4><p>$u=u_1i+u_2j+u_3k$，$v=v_1i+v_2j+v_3k$,则<br>$$<br>u \times v =\begin{vmatrix}<br>i&amp;j  &amp; k\<br>u_1&amp;u_2  &amp;u_3 \<br>v_1&amp;v_2 &amp;v_3<br>\end{vmatrix}=\begin{vmatrix}<br>u_2 &amp;u_3  \<br>v_2&amp;v_3</p><p>\end{vmatrix}i-<br>\begin{vmatrix}<br>u_1 &amp;u_3  \<br>v_1&amp; v_3</p><p>\end{vmatrix}j+<br>\begin{vmatrix}<br>u_1&amp;u_2  \<br>v_1&amp;v_2</p><p>\end{vmatrix}k<br>$$<br><strong>注意：线性代数运算中，偶数项系数为负</strong></p><p> </p><p> </p><h3 id="空间直线与曲线">空间直线与曲线</h3><h4 id="直线方程（Equation-of-a-Line）">直线方程（Equation of a Line）</h4><p>过点$p_0(x_0,y_0,z_0)$且以向量$v=&lt;a,b,c&gt;$为方向的<strong>直线方程</strong>是$r = r_0+tv$,或<br>$$<br>&lt;x,y,z&gt;=&lt;x_0,y_0,z_0&gt;+t&lt;a,b,c&gt;,-\infty  &lt;t&lt;\infty<br>$$<br> </p><h5 id="空间曲线">空间曲线</h5><p>$$<br>r(t)=&lt;f(t),g(t),h(t)&gt;=f(t) i +g(t)j+h(t)k<br>$$</p><img src="https://i.imgtg.com/2022/11/03/RgCRS.png" alt="RgCRS.png" border="0"><h4 id="导数与切向量（Derivative-and-Tangent-Vector）">导数与切向量（Derivative and Tangent Vector）</h4><p>设$r(t)=f(t)i+g(t)j+h(t)k$其中f，g，h是（a，b）上的可导函数，则r在（a，b）上有<strong>导数</strong>，且<br>$$<br>r’(t)=f’(t)i+g’(t)j+h’(t)k<br>$$<br>当$r’(t) \ne 0$时，$r’(t)$是在对应$r(t)$处的<strong>切向量</strong>（速度向量）。</p><p> </p><p> </p><h4 id="单位切向量（Unit-Tangent-Vector）">单位切向量（Unit Tangent Vector）</h4><p>设$r=f(t)i+g(t)j+h(t)k$是一条光滑参数曲线，其单位切向量是<br>$$<br>T(t)=\frac{r’(t)}{|r’(t)|}<br>$$<br> </p><h2 id="曲线的长度">曲线的长度</h2><p>对于曲线方程，$r(t)=&lt;f(t),g(t),h(t)&gt;$，在$a \le t \le b$上的<strong>弧长</strong>是<br>$$<br>L=\int_{a}^{b} \sqrt{f’(t)<sup>2+g’(t)</sup>2+h’(t)^2}dt=\int_{a }^{b}|r’(t)|dt<br>$$<br> </p><h4 id="极坐标曲线的弧长">极坐标曲线的弧长</h4><p>设f是区间$[\alpha ,\beta ]$上的连续函数，极坐标曲线$r=f(\theta)$在$[\alpha ,\beta ]$上的<strong>弧长</strong>为<br>$$<br>L=\int_{\alpha}^{\beta} \sqrt{f(\theta)<sup>2+f’(\theta)</sup>2}d\theta<br>$$<br> </p><h2 id="曲率与法向量（Curvate-and-Normal-Vectors）">曲率与法向量（Curvate and Normal Vectors）</h2><h4 id="弧长作为参数的函数">弧长作为参数的函数</h4><p>设$r(t)$描述一条光滑曲线，$t \ge a$弧长由<br>$$<br>s(t)=\int_{a}^{t}|v(u)|du<br>$$<br>其中，$|v|=|r’(t)|$,等价地，$\frac{ds}{dt}=|v(t)|&gt;0$。如果$|v(t)|=1$对所有$t \ge a$成立，则参数t是弧长。</p><p> </p><p> </p><h3 id="曲率Curvature">曲率Curvature</h3><p>设r描绘一条光滑参数曲线，记s为弧长，且$T =r’/|r’|$是单位切向量，<strong>曲率</strong>为$\kappa (s)=|\frac{dT}{ds}|$</p><p> </p><h3 id="曲率公式">曲率公式</h3><p>设r是一条光滑参数曲线，其中t是任意参数，如果$v=r’$是速度，T是单位切向量，则曲率是<br>$$<br>\kappa (t)=\frac{1}{|v|}|\frac{dT}{dt}|=\frac{T’(t)}{r’(t)}<br>$$<br> </p><h3 id="曲率替代公式">曲率替代公式</h3><p>设r时光滑曲线上运动的物体的位置，曲线的<strong>曲率</strong>是<br>$$<br>\kappa =\frac{a \times v}{|v|^3}<br>$$<br>其中$v=r’$是速度，$a=v’$是加速度。</p><p> </p><h3 id="单位主法向量（Principal-Unit-Normal-Vector）">单位主法向量（Principal Unit Normal Vector）</h3><p>设r描述光滑参数曲线，在曲线上$\kappa \ne 0$的点P处的<strong>单位主法向量</strong>是<br>$$<br>N=\frac{dT/ds}{|dT/ds|}=\frac{1}{\kappa }\frac{dT}{ds}<br>$$<br>实际中使用等价公式<br>$$<br>N= \frac{dT/dt}{|dT/dt|}<br>$$<br> </p><h3 id="单位副法向量（Unit-Binormal-Vector）和挠率（Torsion）">单位副法向量（Unit Binormal Vector）和挠率（Torsion）</h3><p>单位副法向量<br>$$<br>B=T·N=\frac{v \times a}{|v \times a|}<br>$$<br>挠率<br>$$<br>\tau =-\frac{dB}{ds}·N = \frac{(v \times a)·a’}{|v \times a|^2}=\frac{(r’ \times r’‘)·r’‘’}{|r’ \times r’'|^2}<br>$$</p><h3 id="名词总结">名词总结</h3><table><thead><tr><th>名称</th><th>英文</th></tr></thead><tbody><tr><td>位置函数</td><td>Position function</td></tr><tr><td>单位切向量</td><td>Unit tangent vector</td></tr><tr><td>单位主法向量</td><td>Principal unit normal vector</td></tr><tr><td>曲率</td><td>Curvature</td></tr><tr><td>单位副法向量</td><td>Unit Binormal Vector</td></tr><tr><td>挠率</td><td>Torsion</td></tr></tbody></table><p> </p><p> </p><h1>多元函数（functions of serveral variables）</h1><h2 id="平面和曲面-planes-and-surfaces">平面和曲面(planes and surfaces)</h2><h3 id="空间平面的一般方程">空间平面的一般方程</h3><p>过点$P_0(x_0,y_0,z_O)$且法向量为$n$的平面方程<br>$$<br>a(x-x_0)+b(y-y_0)+c(z-z_0)=0<br>$$<br>或<br>$$<br>ax+by+cz=d,其中  d=ax_0+by_0+cz_0<br>$$<br> </p><h4 id="平行平面（Parallel）与正交平面-Orthogonal-Planes">平行平面（Parallel）与正交平面(Orthogonal Planes)</h4><p>解题时可根据，平行平面和正交平面来进行求解。</p><p> </p><h3 id="迹-trace">迹(trace)</h3><p>一个空间图形与xy平面的相交为xy-迹，同理还有xz-迹，yz-迹。</p><p> </p><ul><li><img src="https://i.imgtg.com/2022/11/03/RmayL.png" alt="RmayL.png" border="0"></li></ul><p> </p><h5 id="法向量求法">法向量求法</h5><p>想求一个平面的法向量，可以令平面中相交的两条线<strong>叉乘</strong>即得。</p><h4 id="已知两个平面求其相交的直线">已知两个平面求其相交的直线</h4><p>1.先求两个平面的法向量</p><p>此时我们只需要找到平面上的一个<strong>点</strong>和平面的<strong>法向量</strong></p><p>2.令$x=0$，可得在yz平面上的两条线，及其焦点。</p><p>3.将两个法向量叉乘记得获得平面的向。</p><p> </p><h4 id="已知三个平面求其焦点">已知三个平面求其焦点</h4><p>1.由上列方法已知两个平面求相交的直线</p><p>2.直接将已求出的交线带入第二个平面方程即可。</p><p> </p><h2 id="极限与连续性">极限与连续性</h2><h3 id="内点（Interior）和边界点（Boundary-Point）">内点（Interior）和边界点（Boundary Point）</h3><p>边界点相较于内点，边界点包含边缘。</p><h4 id="开集（Open）和闭集-Closed-Sets">开集（Open）和闭集(Closed Sets)</h4><p>如果区域由所有的内点组成，则它是<strong>开的</strong>，如果区域包含所有的边界点，则它是<strong>闭的</strong>。</p><p> </p><h4 id="机选不存在的双路径判别法">机选不存在的双路径判别法</h4><p>如果（x,y）沿f的定义域中两条不同的路径趋于（a,b）时，f趋于两个不同的值，则$\lim_{(x，y) \to (a,b)}f(x,y) $不存在。</p><p> </p><h4 id="连续性">连续性</h4><p>如果函数f满足</p><p>1.f在（a，b）处有定义</p><p>2.$\lim_{(x，y) \to (a,b)}f(x,y) $存在</p><p>3.$\lim_{(x，y) \to (a,b)}f(x,y) =f(a,b)$</p><p>则称f在（a,b）处连续。</p><p> </p><h4 id="计算技巧（双路径判别法）">计算技巧（双路径判别法）</h4><p>如果在计算时出现$\lim_{(x，y) \to (0,0)}f(x,y) $的情况</p><p>1.我们可以直接令$x=y或x=-y$（分两种情况讨论），从而化两个未知数为一个未知数。</p><p>2.可以先令$x=0$求y化简的值，也可以先令$y=0$求x化简后的值。</p><p>3.可以令$x=ny$，n可取任意常数。</p><p>4.可令$x=y^2$</p><p>主要用于双路径判别法，判断出两个结果不一致即可。</p><p> </p><h4 id="判断-R-2-在方程中的哪一点连续">判断$R^2$在方程中的哪一点连续</h4><p>1.方程中，分母等于零的情况</p><p>2.如果时分段函数，一般情况下计算断点的值，大部是断点处不连续。</p><p> </p><h4 id="判断是否为连续">判断是否为连续</h4><p>可以将函数方程转化为极坐标方程，$x=rcos\theta, y=rsin\theta$转换，如果化简后的结果里面没有r即为极限不存在，如果结果里面有r，则说明此函数的极限存在。</p><p> </p><p> </p><h2 id="偏导数（Partial-Derivatives）">偏导数（Partial Derivatives）</h2><h3 id="偏导（Partial-Derivatives）">偏导（Partial Derivatives）</h3><p>f在（a,b）处对x的偏导<br>$$<br>f_x(a,b)=\lim_{h \to 0}\frac{f(a+h,b)-f(a,b)}{h}<br>$$<br>eg:$f_{yx}函数f$先对y求偏导，然后对x求偏导</p><h4 id="混合偏导相等">混合偏导相等</h4><p>如果$f$在点D点连续，则在D点有$f_{xy}=f_{yx}$。</p><p> </p><p> </p><h2 id="链法则（The-Chain-Rule）">链法则（The Chain Rule）</h2><h3 id="链法则">链法则</h3><p>z是关于x和y的在其定义域上的可微函数，其中x和y是t在区间I上的可微函数，则<br>$$<br>\frac{dz}{dt}=\frac{\partial z}{\partial x} \frac{dx}{dt}+\frac{\partial z}{\partial y}\frac{dy}{dt}<br>$$<br> </p><p> </p><h3 id="隐函数求导-Implicit-Differentiation">隐函数求导(Implicit Differentiation)</h3><p>设F在其定义域上可微，并假设$F（x,y）=0$,定义y是x的可微函数，只要$F_y \ne 0$,有<br>$$<br>\frac{dy}{dx}=-\frac{F_x}{F_y}<br>$$</p><h4 id="证明隐函数求导">证明隐函数求导</h4><p>有$F(x,y,z(x,y))=0$z是x和y的可微函数,证明$\frac{\partial z}{\partial x} =-\frac{F_x}{F_z}$和$\frac{\partial z}{\partial y}=-\frac{F_y}{F_z} $<br>$$<br>F(x,y,z(x,y))=F_x·1+F_y·0+F_z\frac{\partial z}{\partial x} =0<br>$$<br>因此可得<br>$$<br>\frac{\partial z}{\partial x}  =-\frac{F_x}{F_z}<br>$$<br> </p><p> </p><h2 id="方向导数和梯度（Directional-Derivatives-and-the-Gradient）">方向导数和梯度（Directional Derivatives and the Gradient）</h2><h3 id="方向导数">方向导数</h3><p>设$f$在$（a,b）$处可微，$u=&lt;cos \theta ,sin\theta&gt;$是xy-平面上的<strong>单位向量</strong>，则$f$在点$(a,b)$处沿方向$u$的方向导数是<br>$$<br>D_uf(a,b)=\lim_{x \to 0} \frac{f(a+hcos\theta,b+sin\theta)-f(a,b)}{h}<br>$$<br> </p><h3 id="方向导数（Directional-Derivative）">方向导数（Directional Derivative）</h3><p>设$f$在$(a,b)$处可微，$u=&lt;u_1,u_2&gt;$是xy-平面上的单位向量，f在点$(a,b)$处沿方向u的方向导数是<br>$$<br>D_uf(a,b)=&lt;f_x(a,b),f_y(a,b)&gt;·&lt;u_1,u_2&gt;<br>$$<br> </p><h3 id="梯度（Gradient）">梯度（Gradient）</h3><p>设$f$在点$(x,y)$处可微分，$f$在$(x,y)$处的<strong>梯度</strong>是向量值函数<br>$$<br>\bigtriangledown f(x,y)=&lt;f_x(x,y),f_y(x,y)&gt;=f_x(x,y)i+f_y(x,y)j<br>$$<br>由梯度的定义可知，f在点（a,b）处沿着单位向量$u$的方向导数可写为$D_uf(a,b)=\bigtriangledown f_(a,b)·u $</p><p> </p><h4 id="最速上升和最速下降（Directions-of-Change）">最速上升和最速下降（Directions of Change）</h4><p>1.$f$在$(a,b)$处沿梯度$\bigtriangledown f(a,b)$方向有最大增长率，沿这个方向的增长率是$|\bigtriangledown  f(a,b)|$</p><p>2,其最大的下降速度是$-|\bigtriangledown  f(a,b)|$</p><img src="https://i.imgtg.com/2022/11/03/RgwjN.png" alt="RgwjN.png" border="0"><p> </p><h2 id="切平面与线性逼近（Tangent-Planes-and-Linear-Approximation）">切平面与线性逼近（Tangent Planes and Linear Approximation）</h2><h3 id="F-x-y-z-0的切平面方程">F(x,y,z)=0的切平面方程</h3><p>设F在点$P_0(a,b,c)$处可微，且$\bigtriangledown F(a,b,c)\ne 0$,曲面$F(a,b,c)=0$在$P_0$处的切平面是过$P_0$且正交于$\bigtriangledown F(a,b,c)$的平面，切平面的方程是<br>$$<br>F_0(a,b,c)(x-a)+F_y(a,b,c)(y-b)+F_z(a,b,c)(z-c)=0<br>$$<br> </p><h3 id="z-f-x-y-的切平面">z=f(x,y)的切平面</h3><p>设$f$在点$(a,b)$处可微，曲面$z=f(x,y)$在点$(a,b,f(a,b))$处的切平面方程是<br>$$<br>z=f_x(a,b)(x-a)+f_y(a,b)(y-b)+f(a,b)<br>$$</p><h4 id="线性逼近（Linear-Approximation）">线性逼近（Linear Approximation）</h4><p>平面$z=f(x,y)$的线性逼近是在该点处的切平面，其方程为<br>$$<br>L(x,y)=f_x(a,b)(x-a)+f_y(a,b)(y-b)+f(a,b)<br>$$<br> </p><p> </p><h3 id="微分dz">微分dz</h3><p>设$f$在点$(a,b)$处可微，当因变量从$(a,b)$变化到$(a+dx,b+dy)$时，$z=f(x,y)$的变化<br>$$<br>\bigtriangleup  z \approx  dz =f_x(a,b)dx+f_y(a,b)dy<br>$$<br> </p><p> </p><h2 id="最大-最小值问题">最大/最小值问题</h2><h3 id="导数与极大值极小值（Local-Maximum-Minimum-Values）">导数与极大值极小值（Local Maximum / Minimum Values）</h3><p>如果$f$在$(a,b)$处有极大值或者极小值，并且偏导数$f_x$和$f_y$在$(a,b)$处存在。则$f_x(a,b)=f_y(a,b)=0$</p><p> </p><h3 id="临界点（Critical-Point）">临界点（Critical Point）</h3><p>设$(a,b)$是$f$的定义域的一个内点，如果下列条件之一成立：</p><p>1.$f_x(a,b)=f_y(a,b)=0$</p><p>2.$f_x$或$f_y$在$(a,b)$处不存在</p><p>则$(a,b)$称为$f$的一个临界点，临界点是极大值和极小值的候选点</p><p> </p><h3 id="鞍点（Saddle-Point）">鞍点（Saddle Point）</h3><p>设$(a,b)$是函数的一个临界点，如果存在一些点$(x,y)$满足$f(x,y) &gt; f(a,b)$和另外一些点$(x,y)$满足$f(x,y)&lt;f(a,b)$,则称f在$(a,b)$处有一个鞍点。</p><img src="https://i.imgtg.com/2022/11/03/Rmosi.png" alt="Rmosi.png" border="0"><p> </p><h3 id="二阶导数判别法">二阶导数判别法</h3><p>设$f$的二阶偏导数是在以点$(a,b)$为圆心的某个开圆盘上连续，其中$f_x(a,b)=f_y(a,b)=0$.令$D(x,y)=f_{xx}f_{yy}-f^2_{xy}$</p><p>1.如果$D(a,b)&gt;0且f_{xx}(a,b)&lt;0$,则$f$在$(a,b)$处有极大值</p><p>2.如果$D(a,b)&gt;0且f_{xx}(a,b)&gt;0$,则$f$在$(a,b)$处有极小值</p><p>3.如果$D(a,b)&lt;0$,则$f$在$(a,b)$处有鞍点</p><p>4.如果$D(a,b)=0$,则判断法无结果</p><p> </p><h3 id="求最大值-最小值（Absolute-Maximum-Minimum-Values）">求最大值/最小值（Absolute Maximum/Minimum Values）</h3><p>设$f$在$R^2$的有界闭集R上连续，欲求$f$在R上的最大值和最小值：</p><p>1.确定$f$在R中所有临界点处的值</p><p>2.求$f$在R边界上的最大值和最小值</p><p>求边界点的值中，其中边界分很多情况</p><p>&lt;1&gt;$(x,y):x<sup>2+y</sup>2 \le 4$</p><p>令$x=2cos\theta,y=2sin\theta且有0\le\theta\le2\pi$将x，y的值带入其中，即可用$\theta$求出最大值和最小值。</p><p>&lt;2&gt;$R=(x,y):-2\le x\le2,-1\le y\le1$</p><p>先考虑$x=\pm2$.y为任意值的情况；之后考虑$y=\pm1$，x为任意值的情况。</p><p>&lt;3&gt;在函数$y=x,y=2x,y=2$之间包围。</p><p>可以分别将每一个式子带入求导。从而求出每个式子的最大值。</p><p>3.在第一步和第二步求出函数值，最大者是$f$在R上的最大值，最小者是$f$在R上的最小值。</p><p> </p><h4 id="求与平面最近的点">求与平面最近的点</h4><p>如果有平面方程$x+y+z=4$和点$p(0,3,6)$,求平面相对于点的最近距离。</p><p>1.有$z=4-x-y$,带入得平面上的坐标$Q(x,y,4-x-y)$</p><p>2.问题转化为P点与Q点之间得距离</p><p>得$w=x<sup>2+(y-3)</sup>2+(x+y+2)^2$</p><p>3.求出其临界点，及$w_x=w_y=0$的时候。就是最近的点。</p><p> </p><p> </p><h2 id="拉格朗日乘子法（Lagrange-Multipliers）">拉格朗日乘子法（Lagrange Multipliers）</h2><h4 id="平行梯度（Parallel-Gradients）">平行梯度（Parallel Gradients）</h4><p>目标函数$f$，约束曲线$g$。</p><p>设$f$是$R^2$的一个区域上的可微函数，区域包含由$g(x,y)$给出的光滑曲线C。假设$f$在C上的点P$(a,b)$处有极值，则$\bigtriangledown f(a,b)$与C在P处的切线正交。假设$\bigtriangledown g（a,b）\ne 0$,于是存在一个实数$\lambda$(拉格朗日乘子)使得$\bigtriangledown f(a,b)=\lambda \bigtriangledown  g(a,b)$</p><p> </p><p> </p><h3 id="二元拉格朗日乘子法">二元拉格朗日乘子法</h3><p>有目标函数$f$和约束方程$g$，为求$f$在约束条件$g(x,y)=0$下的最大值和最小值</p><p>1.求x,y和$\lambda$的值（如果存在），满足方程<br>$$<br>\bigtriangledown f(x,y)=\lambda\bigtriangledown g(x,y)和g(x,y)=0<br>$$<br>2.在第一步得到的值（x，y）中，选择对应的最大和最小函数值，它们就是$f$在约束条件下的最大值或则最小值。</p><p> </p><h4 id="距平面的最短距离">距平面的最短距离</h4><p>1.先列出与点的距离方程，例如与点$（-2，5，1）$</p><p>其方程可为$f(x,y,z)=(x+2)<sup>2+(y-5)</sup>2+(z-1)^2$,且有$g(x,y,z)=2x+3y+6z-10=0$</p><p>2.计算其<strong>梯度</strong>$\bigtriangledown  f=&lt;2x+4,2y-10,2z-2&gt;$,$\bigtriangledown g=&lt;2,3,6&gt;$</p><p>3.拉格朗日乘子法，计算$\lambda$化简可得最短距离的坐标。</p><p>4.将坐标带入即可求出最短距离。</p><p> </p><p> </p><h2 id="多重积分（Multiple-Integration）">多重积分（Multiple Integration）</h2><h3 id="体积与二重积分">体积与二重积分</h3><p>极限<br>$$<br>\lim_{\bigtriangleup  \to 0} \sum_{n}^{k=1}f(\bar{x}_k ,\bar{y}_k) \bigtriangleup A_k<br>$$</p><p>$$<br>\iint_{R}^{} f(x,y)dA<br>$$</p><p>如果f在R上非负，则二重积分等于区域R上$z=f(x,y)$和$xy-$平面所包围的立体的<strong>体积</strong>。</p><p> </p><h3 id="矩形区域上的二重积分-Double-Integrals-on-Rectangular-Regions">矩形区域上的二重积分(Double Integrals on Rectangular Regions)</h3><p>假设$f$在矩形区域$R={(x,y):a\le x \le b,c \le y\le d}$上连续，$f$在R上的二重积分还可以用下列公式计算。<br>$$<br>\iint\limits_{R}^{} f(x,y)dA=\int_{c}<sup>{d}\int_{a}</sup>{b}f(x,y)dxdy=\int_{a}<sup>{b}\int_{c}</sup>{d}f(x,y)dxdy<br>$$</p><h4 id="平面区域上的平均值">平面区域上的平均值</h4><p>$$<br>\bar{f}=\frac{1}{R的面积}\iint\limits_{R}^{} f(x,y)dA<br>$$</p><h2 id="一般区域上的二重积分">一般区域上的二重积分</h2><p>非矩形区域上的二重积分（Double Integrals over Nonrectangular Region）</p><p>设区域R在上下分别由连续函数$y=g(x)$和$y=h(x)$的图像所围，并且由直线$x=a$和$x=b$所围，若$f$在R上连续，则<br>$$<br>\iint\limits_{R}^{} f(x,y)dA=\int_{a}<sup>{b}\int_{g(x)}</sup>{h(x)}f(x,y)dxdy<br>$$</p><h4 id="用二重积分求区域的面积">用二重积分求区域的面积</h4><p>设R是xy-平面内的区域，则<br>$$<br>R的面积=\iint_{R}dA<br>$$<br> </p><p> </p><h3 id="极坐标下的二重积分">极坐标下的二重积分</h3><p>设$f$在xy-平面内的区域$R={(r,\theta):0\le a\le r \le b,\alpha \le \theta \le \beta}$上连续，其中$\beta - \alpha \le 2\pi$,则<br>$$<br>\iint\limits_{R}^{} f(r,\theta)dA=\int_{\alpha}<sup>{\theta}\int_{a}</sup>{b}f(r,\theta)rdrd\theta<br>$$</p><h3 id="极坐标区域的面积">极坐标区域的面积</h3><p>$$<br>A=\iint\limits_{R}^{} dA=\int_{\alpha}<sup>{\beta}\int_{g(\theta)}</sup>{h(\theta)}rdrd\theta<br>$$</p><p> </p><p> </p><h2 id="三重积分">三重积分</h2><h3 id="三重积分（Triple-Integrals）">三重积分（Triple Integrals）</h3><p>设$D={(x,y,z):a \le x \le b,g(x) \le y \le h(x) ,G(x,y) \le z \le H(x,y)}$其中g,h,G,H是连续函数，在D上的连续函数$f$的三重积分可以用如下累次积分计算：<br>$$<br>\iiint\limits_{D}^{} f(x,y,z)dV=\int_{a}<sup>{b}\int_{g(x)}</sup>{h(x)}\int_{G(x,y)}^{H(x,y)}f(x,y,z)dzdydx<br>$$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 微积分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大学物理(三)</title>
      <link href="/posts/9ab27f24.html"/>
      <url>/posts/9ab27f24.html</url>
      
        <content type="html"><![CDATA[<h1>1.电荷和电场</h1><h2 id="1-1-静电，电荷及其保护">1.1 静电，电荷及其保护</h2><h4 id="电荷守恒定律">电荷守恒定律</h4><p>在任何过程中，产生的电荷量的净变化为零。</p><p>例如，当用一条毛巾摩擦一个塑料尺子时，该塑料获得一个负电荷，而该毛巾获得一个等量的正电荷。电荷是分开的，但两者的和是零。</p><p> </p><h2 id="1-4感应电荷和验电器">1.4感应电荷和验电器</h2><p>在带电棒没有接触验电器时，此时无论电荷还是验电器中的电荷不变，体现同性相斥，异性相吸。</p><p>在带电棒接触验电器后，正负电荷进行中和。</p><p> </p><h2 id="1-5库仑定律">1.5库仑定律</h2><p>$$<br>F=k\frac{Q_1Q_2}{R^2}<br>$$</p><p>常数$k\approx  9.0 \times 10<sup>9N·m</sup>2/C^2$</p><p>元电荷$e=1602 \times 10^{-19}C$</p><h4 id="介电常数（permittivity）">介电常数（permittivity）</h4><p>在等式中的常数k通常用另一个常数(介电常数)$\epsilon_0 $来写<br>$$<br>F=\frac{1}{4 \pi \epsilon_0 }\frac{Q_1Q_2}{r^2}<br>$$</p><p>$$<br>\epsilon_0  =\frac{1}{4 \pi k}=8.85 \times 10<sup>{-12}C</sup>2/N·m^2<br>$$</p><h5 id="常见题型">常见题型</h5><p>在一条直线有三个电荷，对其中的某一个电荷进行受力分析</p><p> </p><h2 id="1-6-电场">1.6 电场</h2><p>假设在电场中有一试验电荷P</p><img src="https://img1.imgtp.com/2022/09/08/c7kdPyKq.png" alt="image-20220908224127779.png" title="image-20220908224127779.png"><p>那么此电荷所在的电场强度E由下式计算。<br>$$<br>E=\frac{F}{q} =\frac{kqQ/r^2}{q}<br>$$</p><p>$$<br>E= k\frac{Q}{r^2}<br>$$</p><p>$$<br>E=\frac{1}{4 \pi \epsilon_0} \frac{Q}{r^2}<br>$$</p><p> </p><p> </p><h2 id="1-7连续电荷分布的电场强度计算">1.7连续电荷分布的电场强度计算</h2><p>在很多情况下，我们可以处理连续分布的电荷，可以把分布的电荷分隔成无限小的电荷元dQ，它们每个都相当于一个微小电荷。每个dQ在相距为r的地方对电场强度的贡献为<br>$$<br>dE=\frac{1}{4 \pi \epsilon_0}\frac{dQ}{r^2}<br>$$<br>电场强度<em><strong>E</strong></em>为所有这些无限小电荷的贡献累加，即为积分<br>$$<br>E = \int dE<br>$$</p><h5 id="经典题型">经典题型</h5><p>电荷环，均匀带电的圆盘,两块平行板</p><p> </p><p> </p><h4 id="无限大平面">无限大平面</h4><img src="https://img1.imgtp.com/2022/09/08/GUhTZYSd.png" alt="image-20220908225430225.png" title="image-20220908225430225.png"><p>如果圆盘的半径远远大于P点到盘的距离（例如，$z \ll  R$）那么我们可以得到一个结果<br>$$<br>E = \frac{\sigma }{2 \epsilon_0},<br>$$<br> </p><p> </p><h2 id="1-8电场线">1.8电场线</h2><ol><li><p>电场线的方向</p></li><li><p>大小问题–电场线的疏密</p></li><li><p>电场的起始问题</p><p>（起于正电荷（或者无穷远）</p></li><li><p>电场线不交叉，不相接</p></li></ol><p> </p><p> </p><h2 id="1-9电场及导体">1.9电场及导体</h2><img src="https://img1.imgtp.com/2022/09/08/iUlLVvWC.png" alt="image-20220908231347848.png" title="image-20220908231347848.png"><p>如图，一个在中性金属球壳内的电荷在金属球壳表面感应出电荷。电场在球壳外也存在，但是在导体内不存在。</p><h2 id="1-10带电粒子在电场中的运动">1.10带电粒子在电场中的运动</h2><h4 id="经典题型-2">经典题型</h4><p>被加速的电子，如右图所示</p><img src="https://img1.imgtp.com/2022/09/08/jbjeo8vG.png" alt="image-20220908231705033.png" title="image-20220908231705033.png"><p> </p><h2 id="2-11电偶极子（Electric-Dipole-Potentical）">2.11电偶极子（Electric Dipole Potentical）</h2><p>牢记力矩的定义与公式</p><p><strong>力矩</strong>是以<strong>施力大小</strong>与<strong>力臂</strong>的乘积衡量物体的转动效果<br>$$<br>M=F \times L<br>$$<br><img src="https://img1.imgtp.com/2022/09/08/hXQ11stK.png" alt="image-20220908232243918.png" title="image-20220908232243918.png"></p><h4 id="在外电场中的电偶极子">在外电场中的电偶极子</h4><p>电场是均匀的，在正电荷上的力QE和负电荷上的力-QE将使得作用在电偶极子的合力为零名单上却又一个力矩作用其上。<br>$$<br>\tau =QE \frac{l}{2}sin \theta + QE \frac{l}{2}sin\theta=pEsin\theta<br>$$<br>上式可用矢量表示为<br>$$<br>\tau = p \times  E \times sin\theta<br>$$<br> </p><p> </p><p>当$\theta=90$时力矩值最大，$\theta=180$势能最大此时E和p时反向平行的</p><h3 id="稳态和亚稳态">稳态和亚稳态</h3><h5 id="共同点">共同点</h5><p>1，长期稳定存在</p><p>2，合力为零</p><p> </p><p>差别</p><p>稳态：给一个非常小的干扰，能保持稳态</p><p>亚稳态：给一个非常小的干扰，不能保持稳态</p><h3 id="总结：">总结：</h3><p>关于电场中的问题分析，一共有四点</p><p>1.作图和确定方向（draw a careful diagram）</p><p>对于受力物体的力和方向的进行作图分析，确定电子在电场中的方向。</p><p>2.应用库伦定理(apply coulomb’s law)</p><p>用库伦定理求出每个电荷所产生的力的大小施加在一个带电物体上。</p><p>3.添加向量(add vectorially and use symmetry)</p><p>在几何图形中尽可能用向量表示</p><p>4.检查(check the reasonableness)</p><h1>高斯定理</h1><h1>电场强度通量（电通量）electric flux</h1><h3 id="概念：">概念：</h3><p>通过一个给定的区域的电场强度，对于均匀电场，穿过一个平面A的电场强度通量$\Phi _E$定义为<br>$$<br>\Phi _E =EAcos \theta<br>$$</p><img src="https://i.imgtg.com/2022/10/30/RUL96.png" alt="RUL96.png" border="0"><p>面积A，可以有一个矢量<strong>A</strong>来表示，，矢量大小为A，方向垂直于该平面。$\theta$为<strong>E</strong>和<strong>A</strong>之间的夹角，电场强度通量也可以写成<br>$$<br>\Phi _E = E·A<br>$$<br> </p><p>在更为普遍的情况下，如下图</p><img src="https://i.imgtg.com/2022/10/30/RUGUP.png" alt="RUGUP.png" border="0"><p>当电场不均匀，曲面不平坦时，可以把该曲面分割为n个曲面微元，使其满足：</p><p>1.可以看作平面</p><p>2.电场强度在这个微元区域中变化很小</p><p>因此可以默认电场强度时均匀的，整个曲面的电场强度可以近似为<br>$$<br>\phi <em>E \approx  \sum</em>{i = 1}^{n}E_i ·\bigtriangleup A_i<br>$$<br>对这个曲面进行积分，可以表示为：<br>$$<br>\phi <em>E= \int E ·dA<br>$$<br>对闭合曲面的电场强度通量可写为：<br>$$<br>\Phi</em>{E}=\oint\vec{\mathbf{E}}\cdot d\vec{\mathbf{A}}<br>$$</p><p> </p><h2 id="高斯定理">高斯定理</h2><p>高斯定理是描述一个<strong>封闭平面</strong>的<strong>电通量</strong>与该表面内封闭的<strong>静电荷</strong>之间的关系。</p><p>$$<br>\Phi_{E}=\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=\oint E d A=E \oint d A=E\left(4 \pi r^{2}\right)<br>$$<br>$$<br>E=\frac{Q}{4 \pi \epsilon_{0} r^{2}}<br>$$</p><p> </p><p>表示为<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=\frac{Q_{\mathrm{encl}}}{\epsilon_{0}}<br>$$</p><h4 id="注意">注意</h4><p>1.$Q_{encl}$是指包含在闭合平面表面的净电荷Q，该表面以外的电荷不包含在平面内。</p><p>2.电荷$Q_{encl}$在表面内的位置或如何分布并不重要。</p><p>3.左边的积分超过了任何封闭曲面上的E值，为了方便，我们选择这个曲面</p><img src="https://i.imgtg.com/2022/10/30/RUSdl.png" alt="RUSdl.png" border="0"><p>如上图的闭合曲面，进入闭合曲面的电场线同时也离开闭合曲面。因此$\Phi _E=\oint Ecos\theta dA=0$</p><p>除非曲面内包含净电荷，$\oint Ecos\theta dA$才不为零。</p><img src="https://i.imgtg.com/2022/10/30/RUHRF.png" alt="RUHRF.png" border="0"><p>电偶极子通过曲面$A_1$的电场强度通量为正，通过曲面$A_2$的电场强度通量为负。</p><p>电荷$Q_{encl}$是闭合曲面内的净电荷，其分布并不重要。</p><p> </p><h3 id="高斯定理的应用">高斯定理的应用</h3><p>关于高斯定理的应用一共有九种题型，一共可以分为：绝缘体（四种），导体（两种），薄球壳，无限长的电荷面，长而均匀的导体线。</p><p>绝缘体：球体和厚球壳的均匀和不均匀分布</p><p>导体：球体和厚球壳</p><p> </p><p>当在做此类题型的时候，重点要注意运用高斯定理，求出来在所选定r表面内的电荷$Q_{encl}$，从而求出此点的电场强度值。</p><h3 id="电荷分布在球的表面">电荷分布在球的表面</h3><img src="https://i.imgtg.com/2022/11/07/RX6Js.png" alt="RX6Js.png" border="0"><p>分别有导体实心球，导体厚球壳，导体和绝缘体的薄球壳</p><p>求$r_0&lt;r$和 $r_0&gt;0$时候的电场值</p><p>solution：</p><p>according to the Guss’s law,we can get $\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=\frac{Q_{\mathrm{encl}}}{\epsilon_{0}}$</p><p>when $r&lt;r_0$</p><p>Inside the shell, the electric field must be symmetric. So E have the same value at all points on a spherical gaussian surface , Thus the charge enclosed within the sphere is zero,<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E\left(4 \pi r^{2}\right)=0<br>$$<br>hence E = 0.</p><p>when $r&gt;r_0$<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E\left(4 \pi r^{2}\right)=\frac{Q}{\epsilon_{0}}<br>$$</p><p>$$<br>E=\frac{1}{4 \pi \epsilon_{0}} \frac{Q}{r^{2}}<br>$$</p><p> </p><h3 id="绝缘球体">绝缘球体</h3><img src="https://i.imgtg.com/2022/11/07/RX2zB.png" alt="RX2zB.png" border="0"><p>特点就是电荷平均分布在球的内部。</p><p>当$r&gt;r_0$<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E\left(4 \pi r^{2}\right)=\frac{Q}{\epsilon_{0}}<br>$$</p><p>$$<br>E=\frac{1}{4 \pi \epsilon_{0}} \frac{Q}{r^{2}}<br>$$</p><p>当$r&lt;r_0$<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E\left(4 \pi r^{2}\right)<br>$$<br>此时计算r内部的电荷$Q_{encl}$<br>$$<br>Q_{\mathrm{encl}}=\left(\frac{\frac{4}{3} \pi r^{3} \rho_{\mathrm{E}}}{\frac{4}{3} \pi r_{0}^{3} \rho_{\mathrm{E}}}\right) Q=\frac{r<sup>{3}}{r_{0}</sup>{3}} Q<br>$$</p><p>$$<br>E\left(4 \pi r^{2}\right)=\frac{Q_{\text {encl }}}{\epsilon_{0}}=\frac{r<sup>{3}}{r_{0}</sup>{3}} \frac{Q}{\epsilon_{0}}<br>$$</p><p>$$<br>E=\frac{1}{4 \pi \epsilon_{0}} \frac{Q}{r_{0}^{3}} r<br>$$</p><img src="https://i.imgtg.com/2022/11/18/tcWuF.png" alt="tcWuF.png" border="0"><h3 id="不均匀绝缘体">不均匀绝缘体</h3><p>如果上图（题）的球体是不均匀的，其密度$\rho_{\mathrm{E}}=\alpha r^{2}$</p><p><a>求$\alpha$,<b>求r和电场的关系</b></a></p><p>solution：<br>$$<br>Q=\int \rho_{\mathrm{E}} d V=\int_{0}^{r_{0}}\left(\alpha r^{2}\right)\left(4 \pi r^{2} d r\right)=4 \pi \alpha \int_{0}^{r_{0}} r^{4} d r=\frac{4 \pi \alpha}{5} r_{0}^{5}<br>$$</p><p>$$<br>\alpha=5 Q / 4 \pi r_{0}^{5}<br>$$</p><p>&lt;2&gt;</p><p>当$r&gt;r_0$时$Q_{encl}$同上题一样且不变化</p><p>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E\left(4 \pi r^{2}\right)=\frac{Q}{\epsilon_{0}}<br>$$</p><p>$$<br>E=\frac{1}{4 \pi \epsilon_{0}} \frac{Q}{r^{2}}<br>$$</p><p>当$r&lt;r_0$时<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=\frac{Q_{\mathrm{encl}}}{\epsilon_{0}}<br>$$</p><p>$$<br>(E)\left(4 \pi r^{2}\right)=Q \frac{r^{5}}{\epsilon_{0} r_{0}^{5}}<br>$$</p><p>$$<br>E=\frac{Q r^{3}}{4 \pi \epsilon_{0} r_{0}^{5}}<br>$$</p><p> </p><h3 id="长且均匀的导线">长且均匀的导线</h3><p>假设导线单位长度有正电荷$\lambda$</p><img src="https://i.imgtg.com/2022/11/18/tcULD.png" alt="tcULD.png" border="0">$$\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=E(2 \pi R \ell)=\frac{Q_{\text {encl }}}{\epsilon_{0}}=\frac{\lambda \ell}{\epsilon_{0}}$$for $\ell \ll \text { length of wire }$,$2\pi R$是它的周长$$E=\frac{1}{2 \pi \epsilon_{0}} \frac{\lambda}{R}$$<h3 id="无限长的电荷面、">无限长的电荷面、</h3><img src="https://i.imgtg.com/2022/11/18/tcBO1.png" alt="tcBO1.png" border="0"><p>单位面积电荷=$\sigma $=dQ/dA</p><p>根据高斯定理<br>$$<br>\oint \overrightarrow{\mathbf{E}} \cdot d \overrightarrow{\mathbf{A}}=2EA=\frac{Q_{enxl}}{\epsilon_{0}}=\frac{\sigma A}{\epsilon_{0}}<br>$$<br>where$Q_{encl}= \sigma $<br>$$<br>E=\frac{\sigma}{2\epsilon_{0}}<br>$$<br> </p><p> </p><h2 id="电势">电势</h2><h3 id="电势能和电势差">电势能和电势差</h3><p>$$<br>W=F d=q E d<br>$$</p><p>$$<br>U_{b}-U_{a}=-W=-q E d<br>$$</p><p>a和b两点之间的势能变化，等于物体从a移动时，保守力所做的功的<strong>负值</strong></p><h4 id="电势-2">电势</h4><p>$$<br>\varphi={\frac{E_{p A}}{q}}<br>$$</p><h4 id="电势能">电势能</h4><p>$$<br>U={\frac{W_{A B}}{q}}<br>$$</p><p> </p><h4 id="电位和电位差">电位和电位差</h4><p>在a点的的电势（假设有一个点电荷）<br>$$<br>V_{a}=\frac{U_{a}}{q}.<br>$$</p><p>$$<br>V_{b a}=\Delta V=V_{b}-V_{a}=\frac{q_{b}-U_{a}}{q-q}=-\frac{W_{b a}}{q}.<br>$$</p><p>因为电位差被足义为单位电荷的势能差，所以电荷q在a和b两点之间移动时势能的变化量为，<br>$$<br>\Delta U=U_{b}-U_{a}=q\left(V_{b}-V_{a}\right)=q V_{b a}.<br>$$<br>也就是说，如果一个带电荷q的物体通过一个电位差$V_{ba}$，它的势能变化量$qV_{ba}$。</p><p> </p><h3 id="电势与电场之间的关系">电势与电场之间的关系</h3><p>U是势能能，V是电势</p><p>有$V=\frac{U}{q}$</p><p>电势能的变化等于电力所做的功的负数，</p><img src="/posts/9ab27f24.htm/tcqcG.png" alt="tcqcG.png" border="0">$$U_{b}-U_{a}=-\int_{a}^{ b}\overrightarrow{F}·d\overrightarrow{l}$$<p> </p><h3 id="由点电荷引起的电位">由点电荷引起的电位</h3><img src="https://i.imgtg.com/2022/11/18/tcT7I.png" alt="tcT7I.png" border="0">$$E=\frac{1}{4\pi\epsilon_{0}}\frac{Q}{r^{2}},E =k\frac{Q}{r^{2}}$$<p>$$<br>V_{b}-V_{a}=-\int_{r_{a}}^{r_{b}}\vec{E}\cdot d\vec{l}=-\frac{Q}{4\pi \epsilon <em>{0}}\int</em>{r_{a}}<sup>{r_{b}}\frac{1}{r</sup>2}dr=\frac{1}{4\pi\epsilon_{0}}\left(\frac{Q}{r_{b}}-\frac{Q}{r_{a}}\right).<br>$$</p><p>let$V_b =0$  at  $r_b=\infty $</p><p>$$<br>V=\frac{1}{4\pi\epsilon_{0}}\frac{Q}{r}<br>$$<br> </p><h3 id="一般情况下的电荷分布">一般情况下的电荷分布</h3><p>$$<br>V_{a}=\sum_{i=1}<sup>{n}V_{i}=\frac{1}{4\pi\epsilon_{0}}\sum_{i=1}</sup>{n}\frac{Q_{i}}{r_{ia}}<br>$$</p><p>$$<br>V=\dfrac{1}{4\pi\epsilon_0}\int\dfrac{d q}{r}<br>$$</p><h3 id="任意电荷分布下的电势">任意电荷分布下的电势</h3><p>电荷分布在圆环</p><img src="https://i.imgtg.com/2022/11/18/tckz6.png" alt="tckz6.png" border="0">$$V=\frac{1}{4\pi\epsilon_{0}}\int\frac{d q}{r}=\frac{1}{4\pi\epsilon_{0}}\frac{1}{\left(x^{2}+R^{2}\right)^{\frac{1}{2}}}\int d q=\frac{1}{4\pi\epsilon_{0}}\frac{Q}{\left(x^{2}+R^{2}\right)^{\frac{1}{2}}}$$&nbsp;<p>电荷平均分布在圆盘</p><img src="https://i.imgtg.com/2022/11/18/tcxPP.png" alt="tcxPP.png" border="0"><p>关键在于求出积分点的电荷值q，当然这个是以一圈为定值对其进行积分。<br>$$<br>\frac{d q}{Q}=\frac{2\pi R d R}{\pi R_{0}^{2}}<br>$$</p><p>$$<br>V=\frac{1}{4\pi\epsilon_{0}}\int\frac{d q}{\left(x<sup>{2}+R</sup>{2}\right)<em>{2}<sup>{1}}=\frac{2Q}{4\pi\epsilon_{0}R_{0}</sup>{2}}\int</em>{0}^{R_{0}}\frac{R d R}{\left(x<sup>{2}+R</sup>{2}\right)<sup>{\frac{1}{2}}}=\left.\frac{Q}{2\pi\epsilon_{0}R_{0}</sup>{2}}\left(x<sup>{2}+R</sup>{2}\right)<sup>{\frac{1}{2}}\right|_{R=0}</sup>{R=R_{0}}=\frac{Q}{2\pi\epsilon_{0}R_{0}<sup>{2}}\left[\left(x</sup>{2}+R_{0}<sup>{2}\right)</sup>{\frac{1}{2}}-x\right]<br>$$</p><p> </p><h3 id="电偶极子的电位">电偶极子的电位</h3><img src="https://i.imgtg.com/2022/11/18/tcz9b.png" alt="tcz9b.png" border="0">$$V=\frac{1}{4\pi\epsilon_{0}}\frac{Q}{r}+\frac{1}{4\pi\epsilon_{0}}\frac{\left(-Q\right)}{\left(r+\Delta r\right)}=\frac{1}{4\pi\epsilon_{0}}Q\left(\frac{1}{r}-\frac{1}{r+\Delta r}\right)^{4}=\frac{Q}{4\pi\epsilon_{0}}\frac{\Delta r}{r\left(r+\Delta r\right)}$$$r>>\Delta r=l\cos\theta$$$V=\frac{1}{4\pi\epsilon_{0}}\frac{Q l\cos\theta}{r^{2}}=\frac{1}{4\pi\epsilon_{0}}\frac{p\cos\theta}{r^{2}}$$此时的电偶极子为p。$p=Ql$<p> </p><h3 id="用V来确定-overrightarrow-text-E">用V来确定$\overrightarrow{\text{E}}$</h3><p>我们都知道v是标量，但E是个矢量。其间的关系有<br>$$<br>V_{b}-V_{a}=-\int_{a}^{b}\overrightarrow{E}\cdot d\overrightarrow{l},<br>$$</p><p>$$<br>E_{l}=-\frac{d V_{l}}{d l}.<br>$$</p><p>此时的l可以是多个方向的。</p><p> </p><h3 id="静电势能-Electrostatic-Potential-Energy">静电势能(Electrostatic Potential Energy)</h3><p>假设一个点电荷q在空间中的两点a和b之间移动，其中由其他电荷引起的电势分别为$V_1$和$V_2$。q在这些其他电荷场中的静电势能的变化为<br>$$<br>\Delta U=U_{\mathrm{b}}-U_{\mathrm{a}}=q(V_{\mathrm{b}}-V_{\mathrm{a}})<br>$$<br>当电荷相距很远（理想情况下是无限远）时，选择电势能为零是最方便的。</p><p>单点电荷$Q_1$没有势能，因为如果周围没有其他电荷，就不会施加在它身上。如果第二点电荷$Q_2$接近势由于这个第一电荷的位置$Q_1$,此时$Q_1$在$Q_2$位置产生的电势为<br>$$<br>V=\dfrac{1}{4\pi\epsilon_0}\dfrac{Q_1}{r_{12}}<br>$$<br>如果系统由三个电荷组成，总势能将是将这三个电荷结合在一起的电势能</p><p>其三个电荷的经典势能就是<br>$$<br>U={\frac{1}{4\pi\epsilon_{0}}}\left({\frac{Q_{1}Q_{2}}{r_{12}}}+{\frac{Q_{1}Q_{3}}{r_{13}}}+{\frac{Q_{2}Q_{3}}{r_{23}}}\right)<br>$$</p><p> </p><h2 id="电容，电解质，电储能">电容，电解质，电储能</h2><h3 id="电容（capacitors-）">电容（capacitors  ）</h3><p>电容器是一种可以储存电荷的装置</p><p>$$<br>Q=C V<br>$$<br>对于给定的电容，我们发现每片获得的电荷量Q与它们之间的电位差V的大小成正比</p><p>上述关系中，比例常数C称为电容器的电容，电容的单位是库每伏，称为法拉（F）</p><p> </p><h3 id="计算电容">计算电容</h3><h4 id="平行板中的电容器">平行板中的电容器</h4><p>$$<br>E=\frac{Q}{\epsilon_{0}A}<br>$$</p><p>$$<br>V=V_{b a}=V_{b}-V_{a}=-\int_{a}^{b}\overrightarrow{E}\cdot d\overrightarrow{l}.<br>$$</p><p>$$<br>V=V_{b}-V_{a}=-\int_{a}^{b}E d l\cos180<sup>{\circ}=+\int_{a}</sup>{b}E d l=\frac{Q}{\epsilon_{0}A}\int_{a}^{b}d l=\frac{Q d}{\epsilon_{0}A}<br>$$</p><p>$$<br>C=\frac{Q}{V}=\epsilon_{0}\frac{A}{d}<br>$$</p><p> </p><h3 id="题型">题型</h3><p>一共有三种，分别为圆柱形电容器，球形电容器，球形导体之间的电容问题。</p><h4 id="圆柱形电容器">圆柱形电容器</h4><img src="https://i.imgtg.com/2022/11/18/tchTl.png" alt="tchTl.png" border="0">$$V=V_{\mathrm{b}}-V_{\mathrm{a}}=-\int_{a}^{\mathrm{b}}\vec{\mathbf{E}}\cdot d\vec{\ell}=-\dfrac{Q}{2\pi\epsilon_0\ell}\int_{R_\mathrm{a}}^{R_\mathrm{b}}\dfrac{dR}{R}=-\dfrac{Q}{2\pi\epsilon_0\ell}\ln\dfrac{R_\mathbb{b}}{R_\mathbb{a}}=\dfrac{Q}{2\pi\epsilon_0\ell}\ln\dfrac{R_\mathbb{a}}{R_\mathbb{b}}.$$<p>$$<br>C=\dfrac{Q}{V}=\dfrac{2\pi\epsilon_0\ell}{\ln(R_\mathrm a/R_\mathrm b)}<br>$$</p><p> </p><h3 id="球形电容器">球形电容器</h3><img src="https://i.imgtg.com/2022/11/18/tcivg.png" alt="tcivg.png" border="0">$$\begin{array}{rcl}V_{\text{ba}}=-\int_{a}^b\vec{\mathbf{E}}\cdot d\vec{\mathbf{l}}=-\dfrac{Q}{4\pi\epsilon_0}\int_{r_a}^{r_0}\dfrac{1}{r^2}dr\\=\dfrac{Q}{4\pi\epsilon_0}\left(\dfrac{1}{r_b}-\dfrac{1}{r_a}\right)=\dfrac{Q}{4\pi\epsilon_0}\left(\dfrac{r_a-r_b}{r_ar_b}\right)\end{array}$$<p>$$<br>C=\dfrac{Q}{V_{\text{ba}}}=4\pi\epsilon_0\biggl(\dfrac{r_\text{a}r_\text{b}}{r_\text{a}-r_\text{b}}\biggr)<br>$$</p><p> </p><h4 id="电容的串并联">电容的串并联</h4><p>并联：等于电容值的加和</p><p> </p><h3 id="电能储存">电能储存</h3><p>移动并联电容板。平行平板电容器的极板面积为a，间距为x，并与电压为v的电池连接。当与电池连接时，极板被拉开，直到它们间隔3x。<br>（a）储存在电容器中的初始和最终能量是多少？</p><p>（b）将两板分开需要做多少功（假设速度恒定）？<br>（c）与电池交换多少能量？<br>$$<br>U_1=\frac{1}{2}C_1V<sup>2=\frac{1}{2}\frac{\epsilon_0A}{x}V</sup>2<br>$$</p><p>$$<br>U_{2}=\frac{1}{2}\frac{\epsilon_{0}A}{3x}V^{2}<br>$$</p><p>$$<br>\Delta U_{c a p}=U_{2}-U_{1}=-\frac{\epsilon_{0}A V^{2}}{3x}<br>$$</p><p>（b）<br>$$<br>W=\int_{\ell=x}^{\ell-3x}Q E d\ell=\frac{\epsilon_{0}A V<sup>{2}}{2}\int_{x}</sup>{3x}d\ell=-\frac{\epsilon_{0}A V<sup>{2}}{2\ell}\Bigg|_{\ell=x}</sup>{\ell+3x}=\frac{\epsilon_{0}A V^{2}}{2}\left(\frac{-1}{3x}+\frac{1}{x}\right)=\frac{\epsilon_{0}A V^{2}}{3x}<br>$$<br>（c）<br>$$<br>W=\Delta U_{\text{cap}}+\Delta U_{\text{batt}}<br>$$</p><p>$$<br>\Delta U_{b a t t}=W-\Delta U_{c a p}=\frac{\epsilon_{0}A V^{2}}{3x}+\frac{\epsilon_{0}A V^{2}}{V_{0}3x}=\frac{2\epsilon_{0}A V^{2}}{3x}<br>$$</p><p>$$<br>U=\frac{1}{2}C V^{2}=\frac{1}{2}\left(\frac{\epsilon <em>{0}A}{d}\right)\left(E<sup>{2}d</sup>{2}\right)=\frac{1}{2}\epsilon</em>{0}E^{2}A d<br>$$</p><p> </p><h3 id="电解质">电解质</h3><p>如果电介质填满了两个导体之间的空间，它会使电容增加一个因数K，这个因数被称为介电常数。因此<br>$$<br>C=KC_{0}<br>$$</p><p>$$<br>C=K\epsilon_{0}\frac{A}{d}<br>$$</p><p>当电介质被插入时，电场也会改变。当无介质存在时，平行板电容器板间的电场为<br>$$<br>E_{0}=\frac{V_{0}}{d}<br>$$</p><p>$$<br>E=E_{D}=\frac{V}{d}=\frac{V_{0}}{K d}<br>$$</p><p>$$<br>E_{D}=\frac{E_{0}}{K}<br>$$</p><p> </p><h3 id="电流和电阻">电流和电阻</h3><p>电流：$I=\frac{d Q}{d t}$</p><h3 id="欧姆定律（ohm‘s-Law）">欧姆定律（ohm‘s Law）</h3><p>$$<br>I=\frac{V}{R}<br>$$</p><h3 id="电阻率">电阻率</h3><p>$$<br>R=\rho\frac{l}{A}<br>$$</p><p>电阻率的倒数称为电导（conductivity）<br>$$<br>\sigma=\frac{1}{\rho}<br>$$</p><h4 id="电阻率的温度依赖性">电阻率的温度依赖性</h4><p>$$<br>\rho_{T}=\rho_{0}\left[1+\alpha\left(T-T_{0}\right)\right]<br>$$</p><h3 id="功率">功率</h3><p>$$<br>P=\frac{d U}{d t}\Rightarrow\frac{d q}{d t}V<br>$$</p><h3 id="交流电">交流电</h3><p>方均根值被称为有效值rms$I_{r m s}=\sqrt{\overline{I^{2}}}=\frac{I_{0}}{\sqrt{2}}$</p><h3 id="电流密度和漂移速度-Current-Density-and-Drift-Velocity">电流密度和漂移速度(Current Density and Drift Velocity)</h3><p>电流密度：j<br>$$<br>I=\int\overrightarrow{\mathbf j}\cdot d\overrightarrow{A}<br>$$<br>飘逸速度：<br>$$<br>\overrightarrow{j}=-ne\overrightarrow{v}<em>{d} \\vec{\textbf{j}}=\sum\limits_i n_i q_i\vec{\textbf{v}}</em>{\text{d}i}<br>$$</p><p> </p><h2 id="直流电路">直流电路</h2><h3 id="电动势能和终端电压">电动势能和终端电压</h3><p>电池本身有自己的电阻，称为内阻（internal resistance）</p><p>电动势能（source of electromotive force）EMF</p><p> </p><h3 id="电阻的串并联">电阻的串并联</h3><h3 id="基尔霍夫定律">基尔霍夫定律</h3><h3 id="串并联电动势">串并联电动势</h3><p>在电动势相等的情况下，当需要大电流时，并联电源可以提供更多的能量。<br>并联的每个电池只能产生总电流的一小部分，因此内阻造成的能量损失比单个电池要小；电池很快就没电了。</p><p> </p><h3 id="含电阻和电容的电路（RC电路）">含电阻和电容的电路（RC电路）</h3><img src="https://i.imgtg.com/2022/11/22/4BtQt.png" alt="4BtQt.png" border="0">$$U=I R+\frac{Q}{C}$$电流并不是一个常数$I=d Q/d t$$$U=R\frac{d Q}{d t}+\frac{1}{C}Q\\\frac{d Q}{C U-Q}=\frac{d t}{R C}$$<p>$$<br>\ln\left(1-\frac{Q}{C U}\right)=-\frac{t}{R C}<br>\<br>Q=C U\left(1-e^{-t/R C}\right)<br>\<br>V_{C}=U\left(1-e^{-t/R C}\right)<br>$$</p><h4 id="放电">放电</h4><img src="https://i.imgtg.com/2022/11/22/4BRrX.png" alt="4BRrX.png" border="0">$$Q=Q_{0}e^{-t/R C} \\V_{C}=V_{0}e^{-t/R C}$$<p> </p><h2 id="磁场">磁场</h2><h3 id="磁铁和磁场">磁铁和磁场</h3><p>磁场的性质</p><p>（1）磁场的方向在任意一点上与电场线相切（2）单位面积上的线数与磁场强度成正比。</p><h4 id="磁场线">磁场线</h4><p>（1）磁场线在磁体内连续存在</p><p>（2）不相交</p><p>（3）磁场线总是形成闭环</p><h3 id="电生磁">电生磁</h3><img src="https://i.imgtg.com/2022/11/22/4BPqi.png" alt="4BPqi.png" border="0"><p>磁生电：电流与磁场方向选用右手螺旋定则。</p><p> </p><h3 id="磁场对电流产生的力">磁场对电流产生的力</h3><p>右手的叉乘定则</p><img src="https://i.imgtg.com/2022/11/22/4BpVL.png" alt="4BpVL.png" border="0">$$\overrightarrow{F}=I\overrightarrow{l}\times\overrightarrow{B}\\F=I\ell B\sin\theta$$<h4 id="在均匀磁场中运动">在均匀磁场中运动</h4><p>$$<br>\overrightarrow{F}=q\overrightarrow{v}\times\overrightarrow{B}.<br>$$</p><img src="https://i.imgtg.com/2022/11/22/4BmgC.png" alt="4BmgC.png" border="0"><p>右手定则</p><p>&amp;nbdp;</p><h2 id="在磁场中移动的电荷所受到的力">在磁场中移动的电荷所受到的力</h2><h4 id="电场和磁场的复合场">电场和磁场的复合场</h4><p>回旋加速器</p><p>质谱仪</p><p> </p><p>电流环上的转矩：磁偶极矩</p><img src="https://i.imgtg.com/2022/11/22/4BgbN.png" alt="4BgbN.png" border="0">$$\tau=IaB\frac{b}{2}+IaB\frac{b}{2}=IabB=IAB$$<h4 id="磁偶极矩（magnetic-dipole-moment）">磁偶极矩（magnetic dipole moment）</h4><p>$$<br>\vec{\mu}=N{I}\vec{\mathbf{A}}<br>\<br>\vec{\tau}=NI\vec{\mathbf{A}}\times\vec{\mathbf{B}}<br>$$</p>]]></content>
      
      
      
        <tags>
            
            <tag> 大物 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常微分</title>
      <link href="/posts/9c4368b0.html"/>
      <url>/posts/9c4368b0.html</url>
      
        <content type="html"><![CDATA[<h1>常微分</h1><h2 id="1-1-简介">1.1 简介</h2><h4 id="一阶线性方程">一阶线性方程</h4><h5 id="性质">性质</h5><p>微分方程     --&gt;      包含未知函数和未知函数的导数</p><p>微分方程的解    —&gt;   是在某个区间成立（区间范围也可以是无穷）</p><h6 id="例如：一个常微分方程">例如：一个常微分方程</h6><p>$$<br>x’(t)-x(t)=0<br>$$<br>此微分方程的解是$x（t）=e^{t}$,其解的区间是$(-\infty ,\infty )$</p><p>描述的就是未知函数和导数的关系（注意他们的解的区间)</p><h4 id="常微分和偏微分">常微分和偏微分</h4><p>常微分（ODE）：一维的（包含一个未知量）</p><p>偏微分(PDE)：多维的（包含多个未知量）</p><h5 id="常微分的次数">常微分的次数</h5><p>常微分最高阶的导数就是它的阶数</p><h5 id="例如">例如</h5><p>$ x’(t) - x(t) = 0 $ 最高阶导数为一阶导，其阶数为一阶</p><p>$x’'(t) - x(t) = 0$  最高阶导数为二阶导， 其阶数为二阶</p><h5 id="一个特殊写法">一个特殊写法</h5><p>通常情况下微分方程$x’(t)-x(t)=0$</p><p>可以把x(t)简化得写成x</p><p>化简后得写法是$x’-x=0$</p><p> </p><p> </p><h2 id="1-2-简单的例子">1.2 简单的例子</h2><h4 id="最重要的一个概念">最重要的一个概念</h4><p>一个关于x(t)的微分方程<br>$$<br>x’(t)=kx(t),k\in R<br>$$<br>此时，方程的通解为<br>$$<br>x(t) = ce^{kt}<br>$$<br>要求：给定一个微分方程的解，我们可以写出对应的微分方程</p><p>给出一个微分方程，我们可以求出它的解</p><p> </p><h5 id="例如-2">例如</h5><p>一个微分方程的解是$x(t)=2e^{kt}$其微分方程为$x’(t)=2x(t)$</p><p> </p><p> </p><p> </p><h2 id="1-3-应用的一些例子">1.3 应用的一些例子</h2><p>$x’(t)=kx(t),k \in R$经常运用在我们生活中的一些模型中,比如人口动态模型（Population dynamics），和RC电路模型（An RC electric circuit）</p><p> </p><p> </p><h2 id="1-4一般的情况">1.4一般的情况</h2><p>我们来分析一般的一阶线性方程<br>$$<br>x’(t)+p(t)x(t)=q(t),t\in I<br>$$<br>此时p(t),q(t)都是在区间I上连续的。</p><p>-如果q(t)=0,那么就称之为<strong>齐次</strong>的，否则方程就是<strong>非齐次</strong>的。</p><p> </p><p> </p><h4 id="积分因子">积分因子</h4><p>在我们解微分方程的重要一步就是找方程的<strong>积分因子</strong>（Integrating Factor）</p><p>假设一个微分方程u（t）满足$u（t）&gt;0$</p><p>存在$u(t)x’(t)+u(t)p(t)x(t)=(u(t)x(t))'$</p><p>这样，函数$u(t)$就被称为方程的<strong>积分因子</strong></p><p>有$x’(t)+p(t)x(t)=q(t)$</p><p>将上面的两式化简可得，当$x(t) \ne 0$时<br>$$<br>u(t)p(t)=u’(t)<br>$$<br>继续化简可得<br>$$<br>u(t)=e^{P(t)}<br>$$</p><p>$$<br>P(t)=\int {p(t)dt}<br>$$</p><p>因此，对于方程$(u(t)x(t))'=u(t)q(t)$,方程两边同时进行积分可得<br>$$<br>u(t)x(t)=C +\int u(t) q(t)dt<br>$$<br>带入$u(t)=e^{P(t)}$可得<br>$$<br>x(t)=e^{-P(t)}(c+ \int e^{P(t)q(t)dt}),<br>P(t)=\int p(t)dt<br>$$<br> </p><p> </p><h5 id="总结">总结</h5><p>对于下列求初值方程<br>$$<br>x’(t)+p(t)x(t)=q(t),x(t_0)=x_0<br>$$</p><p>$$<br>x(t)=e<sup>{\int_{t_0}</sup>{t}p(s)ds}(x_0+ \int_{t_0}<sup>{t}e</sup>{\int_{t_0}^{t}p(\tau )d\tau }q(s)ds)<br>$$</p><p>-当q(t)=0时有<br>$$<br>x’(t)+p(t)x(t)=0,x(t_0)=x_0<br>$$</p><p>$$<br>x(t)=x_0e<sup>{\int_{t_0}</sup>{t}p(s)ds}<br>$$</p><p> </p><p> </p><p> </p><h2 id="一阶非线性微分方程">一阶非线性微分方程</h2><h3 id="可分方程-Separable-Equation">可分方程(Separable Equation)</h3><h4 id="形式">形式</h4><p>$$<br>x’(t) = h(t)g(x)<br>$$</p><p>要求：h(t)连续，g(x)连续可微</p><p> </p><h5 id="g-t-的一个零点时函数的常数解">g(t)的一个零点时函数的常数解</h5><p>g(k)=0</p><p>x(t)=k</p><p> </p><h4 id="所有不变的解都用直线x-k分隔">所有不变的解都用直线x=k分隔</h4><p>函数的常数解和非常数解不相交</p><p> </p><h4 id="非常数解">非常数解</h4><p>$$<br>\frac{x’(t)}{g(x(t))}=h(t)，g(x)=0<br>$$</p><p>$$<br>\int \frac{x’(t)}{g(x(t))}dt = \int h(t)dt<br>$$</p><p>$$<br>\int \frac{dx}{g(x)}= \int h(t)+c<br>$$</p><p> </p><h4 id="总结-2">总结</h4><p>对于解一般的可分方程的思路，一般情况下，左边是x的微分形式，方程右边是关于x和关于t的方程</p><p>1.令关于x的方程g(x)等于0，其零点就是关于方程的常数解</p><p>2.将g(x)提取到方程左边，x’dt=1dx</p><p>3.方程两边同时积分，得出化简后的式子</p><p>4.如果有初值，带入即可求出方程中未知量</p><p>5.化简即可求出方程的解</p><p>关于一些会用到的积分技巧</p><p>$\int \frac{1}{x^2 +1}dx=t+c$   ----&gt; $arctanx=t+c$—&gt;  $x=tan(t+c)$</p><p>$\int \frac{1}{(x+1)(x-1)}dx=t+c$—&gt;$\frac{1}{2}\int \frac{1}{x-1}-\frac{1}{x+1}dx=t+c$----&gt;$\frac{1}{2}ln|\frac{x-1}{x+1}|=t+c$  (绝对值不要忘记加)</p><h3 id="逻辑方程">逻辑方程</h3><p>$$<br>x’(t)=x(t)(\alpha - \beta x(t)),\alpha,\beta&gt;0<br>$$</p><p>此时，$x = 0$和$x(t)=\frac{\alpha}{\beta}$是方程的两个常数解</p><p>如果再假设$x(t)&gt;0$</p><p>根据唯一性，可以将不定方程分为两类<br>$$<br>0&lt;x(t)&lt;\frac{\alpha}{\beta}<br>$$<br>和</p><p>其本质上是方程$x’=x(\alpha -\beta x)$的两个解，此时我们有<br>$$<br>\frac{dx}{x(\alpha - \beta x)}=dt<br>$$</p><p>$$<br>\int \frac{1}{\alpha}·\frac{1}{x}dx+\int \frac{\beta}{\alpha}\frac{1}{\alpha - \beta x}dx =t+c<br>$$</p><p>$$<br>\frac{1}{\alpha}ln|x|-\frac{1}{\alpha}ln|\alpha -\beta x|= t+c<br>$$</p><p>$$<br>\frac{|x|}{|\alpha - \beta x|}=e^{\alpha t+\alpha c}=ke^{\alpha t}<br>$$</p><p>这里$k=e^{\alpha c}$,可以获得两个区间<br>$$<br>0&lt;x(t)&lt;\frac{\alpha}{\beta}<br>$$<br>和<br>$$<br>x(t)&gt;\frac{\alpha}{\beta}<br>$$<br>当$x&lt;x(t)&lt;\frac{\alpha}{\beta}$时<br>$$<br>\frac{x}{\alpha - \beta x}=ke^{\alpha t}<br>$$<br>解得<br>$$<br>x(t)=\frac{\alpha k e^{\alpha t}}{1+\beta k e^{\alpha t}}<br>$$<br>当$x(t)&gt;\frac{\alpha}{\beta}$时<br>$$<br>-\frac{x}{\alpha - \beta x}=ke^{\alpha t}<br>$$<br>解得<br>$$<br>x(t)=\frac{-\alpha k e^{\alpha t}}{1-\beta ke^{\alpha t}}<br>$$<br>在此情况下，$\lim_{x \to \infty}x(t)=\frac{\alpha }{\beta}$</p><img src="https://i.imgtg.com/2022/11/03/Rg8eB.png" alt="Rg8eB.png" border="0">]]></content>
      
      
      
        <tags>
            
            <tag> 常微分 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/4a17b156.html"/>
      <url>/posts/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start">Quick Start</h2><h3 id="Create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* @font-face {  font-family: Candyhome;  src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/Candyhome.ttf);  font-display: swap;  font-weight: lighter;} */@font-face {    font-family: ZhuZiAYuanJWD;    src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2);    font-display: swap;    font-weight: lighter;}div#menus {    font-family: 'ZhuZiAYuanJWD';}h1#site-title {    font-family: ZhuZiAYuanJWD;    font-size: 3em !important;}a.article-title,a.blog-slider__title,a.categoryBar-list-link,h1.post-title {    font-family: ZhuZiAYuanJWD;}.iconfont {    font-family: 'iconfont' !important;    font-size: 3em;    /* 可以定义图标大小 */    font-style: normal;    -webkit-font-smoothing: antialiased;    -moz-osx-font-smoothing: grayscale;}/* 时间轴生肖icon */svg.icon {    /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */    width: 1em;    height: 1em;    /* width和height定义图标的默认宽度和高度*/    vertical-align: -0.15em;    fill: currentColor;    overflow: hidden;}.icon-zhongbiao::before {    color: #f7c768;}/* bilibli番剧插件 */.bangumi-active {    background: #dbecfe !important;    border-radius: 10px !important;}a.bangumi-tab:hover {    text-decoration: none !important;}.bangumi-button:hover {    background: #dbecfe !important;    border-radius: 10px !important;}a.bangumi-button.bangumi-nextpage:hover {    text-decoration: none !important;}.bangumi-button {    padding: 5px 10px !important;}a.bangumi-tab {    padding: 5px 10px !important;}svg.icon.faa-tada {    font-size: 1.1em;}/* 解决artitalk的图标问题 */#uploadSource>svg {    width: 1.19em;    height: 1.5em;}/*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */#page-header:not(.not-top-img):before {    background-color: transparent !important;}/* 首页文章卡片 */#recent-posts>.recent-post-item {    background: rgba(255, 255, 255, 0.9);}/* 首页侧栏卡片 */#aside-content .card-widget {    background: rgba(255, 255, 255, 0.9);}/* 文章页面正文背景 */div#post {    background: rgba(255, 255, 255, 0.9);}/* 分页页面 */div#page {    background: rgba(255, 255, 255, 0.9);}/* 归档页面 */div#archive {    background: rgba(255, 255, 255, 0.9);}/* 标签页面 */div#tag {    background: rgba(255, 255, 255, 0.9);}/* 分类页面 */div#category {    background: rgba(255, 255, 255, 0.9);}/*夜间模式伪类遮罩层透明*/[data-theme='dark'] #recent-posts>.recent-post-item {    background: #121212;}[data-theme='dark'] .card-widget {    background: #121212 !important;}[data-theme='dark'] div#post {    background: #121212 !important;}[data-theme='dark'] div#tag {    background: #121212 !important;}[data-theme='dark'] div#archive {    background: #121212 !important;}[data-theme='dark'] div#page {    background: #121212 !important;}[data-theme='dark'] div#category {    background: #121212 !important;}[data-theme='dark'] div#category {    background: transparent !important;}/* 页脚透明 *//*不需要一图流，删164--173*/#footer {    background: transparent !important;}/* 头图透明 */#page-header {    background: transparent !important;}#rightside>div>button {    border-radius: 5px;}/* 滚动条 */::-webkit-scrollbar {    width: 10px;    height: 10px;}::-webkit-scrollbar-thumb {    background-color: #49b1f5;    border-radius: 2em;}::-webkit-scrollbar-corner {    background-color: transparent;}::-moz-selection {    color: #fff;    background-color: #49b1f5;}/* 音乐播放器 *//* .aplayer .aplayer-lrc {    display: none !important;  } */.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {    left: -66px !important;    transition: all 0.3s;    /* 默认情况下缩进左侧66px，只留一点箭头部分 */}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {    left: 0 !important;    transition: all 0.3s;    /* 鼠标悬停是左侧缩进归零，完全显示按钮 */}.aplayer.aplayer-fixed {    z-index: 999999 !important;}/* 评论框  */.vwrap {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 30px 0px;}/* 设置评论框 */.vcard {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 0px 0px;}/* 鼠标图标 */body {    cursor: url('/img/x1.cur'), auto;}a,[type='button']:not(:disabled),[type='reset']:not(:disabled),[type='submit']:not(:disabled),button:not(:disabled) {    cursor: url('/img/x2.cur'), auto !important;}/* md网站下划线 */#article-container a:hover {    text-decoration: none !important;}#article-container #hpp_talk p img {    display: inline;}/* 404页面 */#error-wrap {    position: absolute;    top: 40%;    right: 0;    left: 0;    margin: 0 auto;    padding: 0 1rem;    max-width: 1000px;    transform: translate(0, -50%);}#error-wrap .error-content {    display: flex;    flex-direction: row;    justify-content: center;    align-items: center;    margin: 0 1rem;    height: 18rem;    border-radius: 8px;    background: var(--card-bg);    box-shadow: var(--card-box-shadow);    transition: all 0.3s;}#error-wrap .error-content .error-img {    box-flex: 1;    flex: 1;    height: 100%;    border-top-left-radius: 8px;    border-bottom-left-radius: 8px;    background-color: #49b1f5;    background-position: center;    background-size: cover;}#error-wrap .error-content .error-info {    box-flex: 1;    flex: 1;    padding: 0.5rem;    text-align: center;    font-size: 14px;    font-family: Titillium Web, 'PingFang SC', 'Hiragino Sans GB', 'Microsoft JhengHei', 'Microsoft YaHei', sans-serif;}#error-wrap .error-content .error-info .error_title {    margin-top: -4rem;    font-size: 9em;}#error-wrap .error-content .error-info .error_subtitle {    margin-top: -3.5rem;    word-break: break-word;    font-size: 1.6em;}#error-wrap .error-content .error-info a {    display: inline-block;    margin-top: 0.5rem;    padding: 0.3rem 1.5rem;    background: var(--btn-bg);    color: var(--btn-color);}#body-wrap.error .aside-list {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    bottom: 0px;    position: absolute;    padding: 1rem;    width: 100%;    overflow: scroll;}#body-wrap.error .aside-list .aside-list-group {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    max-width: 1200px;    margin: 0 auto;}#body-wrap.error .aside-list .aside-list-item {    padding: 0.5rem;}#body-wrap.error .aside-list .aside-list-item img {    width: 100%;    object-fit: cover;    border-radius: 12px;}#body-wrap.error .aside-list .aside-list-item .thumbnail {    overflow: hidden;    width: 230px;    height: 143px;    background: var(--heo-card-bg);    display: flex;}#body-wrap.error .aside-list .aside-list-item .content .title {    -webkit-line-clamp: 2;    overflow: hidden;    display: -webkit-box;    -webkit-box-orient: vertical;    line-height: 1.5;    justify-content: center;    align-items: flex-end;    align-content: center;    padding-top: 0.5rem;    color: white;}#body-wrap.error .aside-list .aside-list-item .content time {    display: none;}/* 代码框主题 */#article-container figure.highlight {    border-radius: 10px;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/manifest.json"/>
      <url>/js/runtime/manifest.json</url>
      
        <content type="html"><![CDATA[{"name":"小江的博客","short_name":"小江","theme_color":"#49b1f5","background_color":"#49b1f5","display":"standalone","scope":"/","start_url":"/","icons":[{"src":"/img/siteicon/16.png","sizes":"16x16","type":"image/png"},{"src":"/img/siteicon/32.png","sizes":"32x32","type":"image/png"},{"src":"/img/siteicon/48.png","sizes":"48x48","type":"image/png"},{"src":"/img/siteicon/64.png","sizes":"64x64","type":"image/png"},{"src":"/img/siteicon/128.png","sizes":"128x128","type":"image/png"},{"src":"/img/siteicon/144.png","sizes":"144x144","type":"image/png"},{"src":"/img/siteicon/512.png","sizes":"512x512","type":"image/png"}],"splash_pages":null}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/coin/coin.css"/>
      <url>/css/coin/coin.css</url>
      
        <content type="html"><![CDATA[.tip-button {    border: 0;    border-radius: 0.25rem;    cursor: pointer;    font-size: 20px;    font-weight: 600;    height: 2.6rem;    margin-bottom: -4rem;    outline: 0;    position: relative;    top: 0;    transform-origin: 0% 100%;    transition: transform 50ms ease-in-out;    width: auto;    -webkit-tap-highlight-color: transparent;}.tip-button:active {    transform: rotate(4deg);}.tip-button.clicked {    animation: 150ms ease-in-out 1 shake;    pointer-events: none;}.tip-button.clicked .tip-button__text {    opacity: 0;    transition: opacity 100ms linear 200ms;}.tip-button.clicked::before {    height: 0.5rem;    width: 60%;    background: $button-hover-color;}.tip-button.clicked .coin {    transition: margin-bottom 1s linear 200ms;    margin-bottom: 0;}.tip-button.shrink-landing::before {    transition: width 200ms ease-in;    width: 0;}.tip-button.coin-landed::after {    opacity: 1;    transform: scale(1);    transform-origin: 50% 100%;}.tip-button.coin-landed .coin-wrapper {    background: radial-gradient(circle at 35% 97%, rgba(3, 16, 50, 0.4) 0.04rem, transparent 0.04rem), radial-gradient(circle at 45% 92%,            rgba(3, 16, 50, 0.4) 0.04rem,            transparent 0.02rem), radial-gradient(circle at 55% 98%, rgba(3, 16, 50, 0.4) 0.04rem, transparent 0.04rem), radial-gradient(circle at 65% 96%, rgba(3, 16, 50, 0.4) 0.06rem, transparent 0.06rem);    background-position: center bottom;    background-size: 100%;    bottom: -1rem;    opacity: 0;    transform: scale(2) translateY(-10px);}.tip-button__text {    color: #fff;    margin-right: 1.8rem;    opacity: 1;    position: relative;    transition: opacity 100ms linear 500ms;    z-index: 3;}.tip-button::before {    border-radius: 0.25rem;    bottom: 0;    content: '';    display: block;    height: 100%;    left: 50%;    position: absolute;    transform: translateX(-50%);    transition: height 250ms ease-in-out 400ms, width 250ms ease-in-out 300ms;    width: 100%;    z-index: 2;}.tip-button::after {    bottom: -1rem;    color: white;    content: 'ヾ(≧O≦)〃嗷~';    /*点击后显示的内容*/    height: 110%;    left: 0;    opacity: 0;    position: absolute;    pointer-events: none;    text-align: center;    transform: scale(0);    transform-origin: 50% 20%;    transition: transform 200ms cubic-bezier(0, 0, 0.35, 1.43);    width: 100%;    z-index: 1;}.coin-wrapper {    background: none;    bottom: 0;    height: 18rem;    left: 0;    opacity: 1;    overflow: hidden;    pointer-events: none;    position: absolute;    transform: none;    transform-origin: 50% 100%;    transition: opacity 200ms linear 100ms, transform 300ms ease-out;    width: 100%;}.coin {    --front-y-multiplier: 0;    --back-y-multiplier: 0;    --coin-y-multiplier: 0;    --coin-x-multiplier: 0;    --coin-scale-multiplier: 0;    --coin-rotation-multiplier: 0;    --shine-opacity-multiplier: 0.4;    --shine-bg-multiplier: 50%;    bottom: calc(var(--coin-y-multiplier) * 1rem - 3.5rem);    height: 3.5rem;    margin-bottom: 3.05rem;    position: absolute;    right: calc(var(--coin-x-multiplier) * 34% + 16%);    transform: translateX(50%) scale(calc(0.4 + var(--coin-scale-multiplier))) rotate(calc(var(--coin-rotation-multiplier) * -1deg));    transition: opacity 100ms linear 200ms;    width: 3.5rem;    z-index: 3;}.coin__front,.coin__middle,.coin__back,.coin::before,.coin__front::after,.coin__back::after {    border-radius: 50%;    box-sizing: border-box;    height: 100%;    left: 0;    position: absolute;    width: 100%;    z-index: 3;}.coin__front {    background: radial-gradient(circle at 50% 50%, transparent 50%, rgba(115, 124, 153, 0.4) 54%, #c2cadf 54%),        linear-gradient(210deg, #8590b3 32%, transparent 32%), linear-gradient(150deg, #8590b3 32%, transparent 32%),        linear-gradient(to right, #8590b3 22%, transparent 22%, transparent 78%, #8590b3 78%), linear-gradient(to bottom,            #fcfaf9 44%,            transparent 44%,            transparent 65%,            #fcfaf9 65%,            #fcfaf9 71%,            #8590b3 71%), linear-gradient(to right, transparent 28%, #fcfaf9 28%, #fcfaf9 34%, #8590b3 34%, #8590b3 40%, #fcfaf9 40%, #fcfaf9 47%, #8590b3 47%, #8590b3 53%, #fcfaf9 53%, #fcfaf9 60%, #8590b3 60%, #8590b3 66%, #fcfaf9 66%, #fcfaf9 72%, transparent 72%);    background-color: #8590b3;    background-size: 100% 100%;    transform: translateY(calc(var(--front-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--front-scale-multiplier));}.coin__front::after {    background: rgba(0, 0, 0, 0.2);    content: '';    opacity: var(--front-y-multiplier);}.coin__middle {    background: #737c99;    transform: translateY(calc(var(--middle-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--middle-scale-multiplier));}.coin__back {    background: radial-gradient(circle at 50% 50%, transparent 50%, rgba(115, 124, 153, 0.4) 54%, #c2cadf 54%),        radial-gradient(circle at 50% 40%, #fcfaf9 23%, transparent 23%), radial-gradient(circle at 50% 100%, #fcfaf9 35%, transparent 35%);    background-color: #8590b3;    background-size: 100% 100%;    transform: translateY(calc(var(--back-y-multiplier) * 0.3181818182rem / 2)) scaleY(var(--back-scale-multiplier));}.coin__back::after {    background: rgba(0, 0, 0, 0.2);    content: '';    opacity: var(--back-y-multiplier);}.coin::before {    background: radial-gradient(circle at 25% 65%, transparent 50%, rgba(255, 255, 255, 0.9) 90%), linear-gradient(55deg, transparent calc(var(--shine-bg-multiplier) + 0%), #e9f4ff calc(var(--shine-bg-multiplier) + 0%), transparent calc(var(--shine-bg-multiplier) + 50%));    content: '';    opacity: var(--shine-opacity-multiplier);    transform: translateY(calc(var(--middle-y-multiplier) * 0.3181818182rem / -2)) scaleY(var(--middle-scale-multiplier)) rotate(calc(var(--coin-rotation-multiplier) * 1deg));    z-index: 10;}.coin::after {    background: #737c99;    content: '';    height: 0.3181818182rem;    left: 0;    position: absolute;    top: 50%;    transform: translateY(-50%);    width: 100%;    z-index: 2;}@keyframes shake {    0% {        transform: rotate(4deg);    }    66% {        transform: rotate(-4deg);    }    100% {        transform: rotate();    }}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/runtime.js"/>
      <url>/js/runtime/runtime.js</url>
      
        <content type="html"><![CDATA[var now = new Date;function createtime() {    var t = new Date("09/02/2022 00:00:00");    now.setTime(now.getTime() + 250);    var e = (now - t) / 1e3 / 60 / 60 / 24,        a = Math.floor(e),        n = (now - t) / 1e3 / 60 / 60 - 24 * a,        r = Math.floor(n); 1 == String(r).length && (r = "0" + r);    var s = (now - t) / 1e3 / 60 - 1440 * a - 60 * r,        i = Math.floor(s); 1 == String(i).length && (i = "0" + i);    var o = (now - t) / 1e3 - 86400 * a - 3600 * r - 60 * i,        l = Math.round(o); 1 == String(l).length && (l = "0" + l);    let g = ""; g = r < 18 && r >= 9        ? `<img class="boardsign" src="https://npm.elemecdn.com/anzhiyu-blog@2.0.3/img/badge/安知鱼-上班摸鱼中.svg" title="距离月入25k也就还差一个大佬带我~"><span class="textTip"> <br> 本站居然运行了 ${a} 天</span><span id="runtime"> ${r} 小时 ${i} 分 ${l} 秒 </span> <i class="fas fa-heartbeat" style="color:red"></i>` : `<img class="boardsign" src="https://npm.elemecdn.com/anzhiyu-blog@2.0.3/img/badge/安知鱼-下班啦.svg" title="下班了就该开开心心的玩耍，嘿嘿~"><span class="textTip"> <br> 本站居然运行了 ${a} 天</span><span id="runtime"> ${r} 小时 ${i} 分 ${l} 秒 </span> <i class="fas fa-heartbeat" style="color:red"></i>`, document.getElementById("workboard") && (document.getElementById("workboard").innerHTML = g)} setInterval((() => { createtime() }), 250);]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/coin/coin.js"/>
      <url>/js/coin/coin.js</url>
      
        <content type="html"><![CDATA[var tipButtons = document.querySelectorAll('.tip-button');function coinAudio() {    var coinAudio = document.getElementById('coinAudio');    if (coinAudio) {        coinAudio.play(); //有音频时播放    }}// Loop through all buttons (allows for multiple buttons on page)tipButtons.forEach(button => {    var coin = button.querySelector('.coin');    // The larger the number, the slower the animation    coin.maxMoveLoopCount = 90;    button.addEventListener('click', () => {        if (/Android|webOS|BlackBerry/i.test(navigator.userAgent)) return true; //媒体选择        if (button.clicked) return;        button.classList.add('clicked');        // Wait to start flipping th coin because of the button tilt animation        setTimeout(() => {            // Randomize the flipping speeds just for fun            coin.sideRotationCount = Math.floor(Math.random() * 5) * 90;            coin.maxFlipAngle = (Math.floor(Math.random() * 4) + 3) * Math.PI;            button.clicked = true;            flipCoin();            coinAudio();        }, 50);    });    var flipCoin = () => {        coin.moveLoopCount = 0;        flipCoinLoop();    };    var resetCoin = () => {        coin.style.setProperty('--coin-x-multiplier', 0);        coin.style.setProperty('--coin-scale-multiplier', 0);        coin.style.setProperty('--coin-rotation-multiplier', 0);        coin.style.setProperty('--shine-opacity-multiplier', 0.4);        coin.style.setProperty('--shine-bg-multiplier', '50%');        coin.style.setProperty('opacity', 1);        // Delay to give the reset animation some time before you can click again        setTimeout(() => {            button.clicked = false;        }, 300);    };    var flipCoinLoop = () => {        coin.moveLoopCount++;        var percentageCompleted = coin.moveLoopCount / coin.maxMoveLoopCount;        coin.angle = -coin.maxFlipAngle * Math.pow(percentageCompleted - 1, 2) + coin.maxFlipAngle;        // Calculate the scale and position of the coin moving through the air        coin.style.setProperty('--coin-y-multiplier', -11 * Math.pow(percentageCompleted * 2 - 1, 4) + 11);        coin.style.setProperty('--coin-x-multiplier', percentageCompleted);        coin.style.setProperty('--coin-scale-multiplier', percentageCompleted * 0.6);        coin.style.setProperty('--coin-rotation-multiplier', percentageCompleted * coin.sideRotationCount);        // Calculate the scale and position values for the different coin faces        // The math uses sin/cos wave functions to similate the circular motion of 3D spin        coin.style.setProperty('--front-scale-multiplier', Math.max(Math.cos(coin.angle), 0));        coin.style.setProperty('--front-y-multiplier', Math.sin(coin.angle));        coin.style.setProperty('--middle-scale-multiplier', Math.abs(Math.cos(coin.angle), 0));        coin.style.setProperty('--middle-y-multiplier', Math.cos((coin.angle + Math.PI / 2) % Math.PI));        coin.style.setProperty('--back-scale-multiplier', Math.max(Math.cos(coin.angle - Math.PI), 0));        coin.style.setProperty('--back-y-multiplier', Math.sin(coin.angle - Math.PI));        coin.style.setProperty('--shine-opacity-multiplier', 4 * Math.sin((coin.angle + Math.PI / 2) % Math.PI) - 3.2);        coin.style.setProperty(            '--shine-bg-multiplier',            -40 * (Math.cos((coin.angle + Math.PI / 2) % Math.PI) - 0.5) + '%'        );        // Repeat animation loop        if (coin.moveLoopCount < coin.maxMoveLoopCount) {            if (coin.moveLoopCount === coin.maxMoveLoopCount - 6) button.classList.add('shrink-landing');            window.requestAnimationFrame(flipCoinLoop);        } else {            button.classList.add('coin-landed');            coin.style.setProperty('opacity', 0);            setTimeout(() => {                button.classList.remove('clicked', 'shrink-landing', 'coin-landed');                setTimeout(() => {                    resetCoin();                }, 300);            }, 1500);        }    };});]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/runtime/runtime.min.js"/>
      <url>/js/runtime/runtime.min.js</url>
      
        <content type="html"><![CDATA[var now = new Date; function createtime() { var t = new Date("09/02/2022 00:00:00"); now.setTime(now.getTime() + 250); var e = (now - t) / 1e3 / 60 / 60 / 24, a = Math.floor(e), n = (now - t) / 1e3 / 60 / 60 - 24 * a, r = Math.floor(n); 1 == String(r).length && (r = "0" + r); var s = (now - t) / 1e3 / 60 - 1440 * a - 60 * r, i = Math.floor(s); 1 == String(i).length && (i = "0" + i); var o = (now - t) / 1e3 - 86400 * a - 3600 * r - 60 * i, l = Math.round(o); 1 == String(l).length && (l = "0" + l); let g = ""; g = r < 18 && r >= 9 ? `<img class="boardsign" src="https://npm.elemecdn.com/anzhiyu-blog@2.0.3/img/badge/安知鱼-上班摸鱼中.svg" title="距离月入25k也就还差一个大佬带我~"><span class="textTip"> <br> 本站居然运行了 ${a} 天</span><span id="runtime"> ${r} 小时 ${i} 分 ${l} 秒 </span> <i class="fas fa-heartbeat" style="color:red"></i>` : `<img class="boardsign" src="https://npm.elemecdn.com/anzhiyu-blog@2.0.3/img/badge/安知鱼-下班啦.svg" title="下班了就该开开心心的玩耍，嘿嘿~"><span class="textTip"> <br> 本站居然运行了 ${a} 天</span><span id="runtime"> ${r} 小时 ${i} 分 ${l} 秒 </span> <i class="fas fa-heartbeat" style="color:red"></i>`, document.getElementById("workboard") && (document.getElementById("workboard").innerHTML = g) } setInterval(() => { createtime() }, 250);]]></content>
      
    </entry>
    
    
  
</search>
